%___________________________________________________________
%
\section{Existencia de Tiempos de Regeneraci\'on}
%___________________________________________________________
%

%________________________________________________________________________
\subsection{Procesos Regenerativos: Thorisson}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.

\begin{Def}
Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$.
\end{Def}

\begin{Note}
Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto
$\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$
\end{Def}

\begin{Def}
Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.
\end{Def}

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.


\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo, es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.
\end{Def}


\begin{Def}
Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.
\end{Def}

\begin{Def}
Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$.
\end{Def}

\begin{Note}
Cualquier espacio Polaco es un espacio est\'andar.
\end{Note}


\begin{Def}
Un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.
\end{Def}

\begin{Def}
Un proceso estoc\'astico \textit{one-sided contiuous time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}


Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$.

\begin{Note}
La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}

\begin{Note}
En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales

\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}
\end{Note}

\begin{Note}
Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$.
\end{Def}

\begin{Note}
Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}
\end{Note}


\begin{Note}
$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$.
\end{Note}

\begin{Note}
La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es conjuntamente medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}


\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es can\'onicamente conjuntamente medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCTCCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.
\end{Note}

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es internamente shift-invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCTISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es shift-medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

\begin{Note}
Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es shift-medible si y s\'olo si es CCM
\end{Note}

\begin{Note}
\begin{itemize}
\item Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM.

\item Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas.

\end{itemize}
\end{Note}


\begin{Note}
Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.
\end{Note}

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

\begin{Note}
Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

\begin{Note}
Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\end{Note}

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.

\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.

\end{Def}



\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{wide-sense regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$.
Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}


\begin{Note}
\begin{itemize}
\item El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico.

\item Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico

\end{itemize}

\end{Note}


\begin{Note}
Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.
\end{Note}



\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}


\begin{Def}
Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$.
\end{Def}

\begin{Note}
Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto
$\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$
\end{Def}

\begin{Def}
Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.
\end{Def}

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.


\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo, es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.
\end{Def}


\begin{Def}
Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.
\end{Def}

\begin{Def}
Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$.
\end{Def}

\begin{Note}
Cualquier espacio Polaco es un espacio est\'andar.
\end{Note}


\begin{Def}
Un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.
\end{Def}

\begin{Def}
Un proceso estoc\'astico \textit{one-sided contiuous time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}


Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$.

\begin{Note}
La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}

\begin{Note}
En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales

\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}
\end{Note}

\begin{Note}
Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$.
\end{Def}

\begin{Note}
Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}
\end{Note}


\begin{Note}
$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$.
\end{Note}

\begin{Note}
La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es conjuntamente medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}


\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es can\'onicamente conjuntamente medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCTCCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.
\end{Note}

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es internamente shift-invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCTISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es shift-medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

\begin{Note}
Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es shift-medible si y s\'olo si es CCM
\end{Note}

\begin{Note}
\begin{itemize}
\item Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM.

\item Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas.

\end{itemize}
\end{Note}


\begin{Note}
Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.
\end{Note}

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

\begin{Note}
Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

\begin{Note}
Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\end{Note}

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.

\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.

\end{Def}



\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{wide-sense regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$.
Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}


\begin{Note}
\begin{itemize}
\item El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico.

\item Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico

\end{itemize}

\end{Note}


\begin{Note}
Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.
\end{Note}



\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}

\begin{Def}
Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$.
\end{Def}

\begin{Note}
Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto
$\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$
\end{Def}

\begin{Def}
Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.
\end{Def}

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.


\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo, es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.
\end{Def}


\begin{Def}
Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.
\end{Def}

\begin{Def}
Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$.
\end{Def}

\begin{Note}
Cualquier espacio Polaco es un espacio est\'andar.
\end{Note}


\begin{Def}
Un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.
\end{Def}

\begin{Def}
Un proceso estoc\'astico \textit{one-sided contiuous time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}


Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$.

\begin{Note}
La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}

\begin{Note}
En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales

\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}
\end{Note}

\begin{Note}
Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$.
\end{Def}

\begin{Note}
Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}
\end{Note}


\begin{Note}
$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$.
\end{Note}

\begin{Note}
La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es conjuntamente medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}


\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es can\'onicamente conjuntamente medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCTCCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.
\end{Note}

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es internamente shift-invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCTISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es shift-medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

\begin{Note}
Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es shift-medible si y s\'olo si es CCM
\end{Note}

\begin{Note}
\begin{itemize}
\item Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM.

\item Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas.

\end{itemize}
\end{Note}


\begin{Note}
Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.
\end{Note}

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

\begin{Note}
Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

\begin{Note}
Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\end{Note}

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.

\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.

\end{Def}



\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{wide-sense regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$.
Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}


\begin{Note}
\begin{itemize}
\item El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico.

\item Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico

\end{itemize}

\end{Note}


\begin{Note}
Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.
\end{Note}



\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}




\begin{Def}
Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$.
\end{Def}

\begin{Note}
Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto
$\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$
\end{Def}

\begin{Def}
Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.
\end{Def}

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.


\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo, es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.
\end{Def}


\begin{Def}
Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.
\end{Def}

\begin{Def}
Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$.
\end{Def}

\begin{Note}
Cualquier espacio Polaco es un espacio est\'andar.
\end{Note}


\begin{Def}
Un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.
\end{Def}

\begin{Def}
Un proceso estoc\'astico \textit{one-sided contiuous time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}


Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$.

\begin{Note}
La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}

\begin{Note}
En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales

\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}
\end{Note}

\begin{Note}
Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$.
\end{Def}

\begin{Note}
Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}
\end{Note}


\begin{Note}
$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$.
\end{Note}

\begin{Note}
La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es conjuntamente medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}


\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es can\'onicamente conjuntamente medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCTCCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.
\end{Note}

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es internamente shift-invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCTISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es shift-medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

\begin{Note}
Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es shift-medible si y s\'olo si es CCM
\end{Note}

\begin{Note}
\begin{itemize}
\item Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM.

\item Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas.

\end{itemize}
\end{Note}


\begin{Note}
Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.
\end{Note}

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

\begin{Note}
Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

\begin{Note}
Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\end{Note}

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.

\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.

\end{Def}



\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{wide-sense regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$.
Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}


\begin{Note}
\begin{itemize}
\item El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico.

\item Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico

\end{itemize}

\end{Note}


\begin{Note}
Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.
\end{Note}



\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}
%______________________________________________________________________


\section{Procesos Regenerativos}
%________________________________________________________________________

%________________________________________________________________________
\subsection{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman2}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
\subsubsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
\subsubsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
\subsubsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
\subsubsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
\subsubsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
%___________________________________________________________________________________________
%
\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

%\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
%\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}


%________________________________________________________________________
\subsubsection{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.
%_____________________________________________________
\subsection{Puntos de Renovaci\'on}
%_____________________________________________________

Para cada cola $Q_{i}$ se tienen los procesos de arribo a la cola, para estas, los tiempos de arribo est\'an dados por $$\left\{T_{1}^{i},T_{2}^{i},\ldots,T_{k}^{i},\ldots\right\},$$ entonces, consideremos solamente los primeros tiempos de arribo a cada una de las colas, es decir, $$\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ se sabe que cada uno de estos tiempos se distribuye de manera exponencial con par\'ametro $1/mu_{i}$. Adem\'as se sabe que para $$T^{*}=\min\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ $T^{*}$ se distribuye de manera exponencial con par\'ametro $$\mu^{*}=\sum_{i=1}^{4}\mu_{i}.$$ Ahora, dado que 
\begin{center}
\begin{tabular}{lcl}
$\tilde{r}=r_{1}+r_{2}$ & y &$\hat{r}=r_{3}+r_{4}.$
\end{tabular}
\end{center}


Supongamos que $$\tilde{r},\hat{r}<\mu^{*},$$ entonces si tomamos $$r^{*}=\min\left\{\tilde{r},\hat{r}\right\},$$ se tiene que para  $$t^{*}\in\left(0,r^{*}\right)$$ se cumple que 
\begin{center}
\begin{tabular}{lcl}
$\tau_{1}\left(1\right)=0$ & y por tanto & $\overline{\tau}_{1}=0,$
\end{tabular}
\end{center}
entonces para la segunda cola en este primer ciclo se cumple que $$\tau_{2}=\overline{\tau}_{1}+r_{1}=r_{1}<\mu^{*},$$ y por tanto se tiene que  $$\overline{\tau}_{2}=\tau_{2}.$$ Por lo tanto, nuevamente para la primer cola en el segundo ciclo $$\tau_{1}\left(2\right)=\tau_{2}\left(1\right)+r_{2}=\tilde{r}<\mu^{*}.$$ An\'alogamente para el segundo sistema se tiene que ambas colas est\'an vac\'ias, es decir, existe un valor $t^{*}$ tal que en el intervalo $\left(0,t^{*}\right)$ no ha llegado ning\'un usuario, es decir, $$L_{i}\left(t^{*}\right)=0$$ para $i=1,2,3,4$.

\subsection{Resultados para Procesos de Salida}




%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

\subsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}


Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}
%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}


%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}
%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

%______________________________________________________________________
\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
\subsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}



%___________________________________________________________________________________________
%
\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}
%_____________________________________________________
\subsection{Puntos de Renovaci\'on}
%_____________________________________________________

Para cada cola $Q_{i}$ se tienen los procesos de arribo a la cola, para estas, los tiempos de arribo est\'an dados por $$\left\{T_{1}^{i},T_{2}^{i},\ldots,T_{k}^{i},\ldots\right\},$$ entonces, consideremos solamente los primeros tiempos de arribo a cada una de las colas, es decir, $$\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ se sabe que cada uno de estos tiempos se distribuye de manera exponencial con par\'ametro $1/mu_{i}$. Adem\'as se sabe que para $$T^{*}=\min\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ $T^{*}$ se distribuye de manera exponencial con par\'ametro $$\mu^{*}=\sum_{i=1}^{4}\mu_{i}.$$ Ahora, dado que 
\begin{center}
\begin{tabular}{lcl}
$\tilde{r}=r_{1}+r_{2}$ & y &$\hat{r}=r_{3}+r_{4}.$
\end{tabular}
\end{center}


Supongamos que $$\tilde{r},\hat{r}<\mu^{*},$$ entonces si tomamos $$r^{*}=\min\left\{\tilde{r},\hat{r}\right\},$$ se tiene que para  $$t^{*}\in\left(0,r^{*}\right)$$ se cumple que 
\begin{center}
\begin{tabular}{lcl}
$\tau_{1}\left(1\right)=0$ & y por tanto & $\overline{\tau}_{1}=0,$
\end{tabular}
\end{center}
entonces para la segunda cola en este primer ciclo se cumple que $$\tau_{2}=\overline{\tau}_{1}+r_{1}=r_{1}<\mu^{*},$$ y por tanto se tiene que  $$\overline{\tau}_{2}=\tau_{2}.$$ Por lo tanto, nuevamente para la primer cola en el segundo ciclo $$\tau_{1}\left(2\right)=\tau_{2}\left(1\right)+r_{2}=\tilde{r}<\mu^{*}.$$ An\'alogamente para el segundo sistema se tiene que ambas colas est\'an vac\'ias, es decir, existe un valor $t^{*}$ tal que en el intervalo $\left(0,t^{*}\right)$ no ha llegado ning\'un usuario, es decir, $$L_{i}\left(t^{*}\right)=0$$ para $i=1,2,3,4$.

\subsection{Resultados para Procesos de Salida}

En \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}


%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

\subsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Obs}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Obs}

\begin{Obs}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Obs}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}
%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}


%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}
%
%___________________________________________________________________________________________
%\vspace{5.5cm}
%\chapter{Cadenas de Markov estacionarias}
%\vspace{-1.0cm}
%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}




%__________________________________________________________________________________________
\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

%______________________________________________________________________
\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
\subsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}



%___________________________________________________________________________________________
%
\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}
%_____________________________________________________
\subsection{Puntos de Renovaci\'on}
%_____________________________________________________

Para cada cola $Q_{i}$ se tienen los procesos de arribo a la cola, para estas, los tiempos de arribo est\'an dados por $$\left\{T_{1}^{i},T_{2}^{i},\ldots,T_{k}^{i},\ldots\right\},$$ entonces, consideremos solamente los primeros tiempos de arribo a cada una de las colas, es decir, $$\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ se sabe que cada uno de estos tiempos se distribuye de manera exponencial con par\'ametro $1/mu_{i}$. Adem\'as se sabe que para $$T^{*}=\min\left\{T_{1}^{1},T_{1}^{2},T_{1}^{3},T_{1}^{4}\right\},$$ $T^{*}$ se distribuye de manera exponencial con par\'ametro $$\mu^{*}=\sum_{i=1}^{4}\mu_{i}.$$ Ahora, dado que 
\begin{center}
\begin{tabular}{lcl}
$\tilde{r}=r_{1}+r_{2}$ & y &$\hat{r}=r_{3}+r_{4}.$
\end{tabular}
\end{center}


Supongamos que $$\tilde{r},\hat{r}<\mu^{*},$$ entonces si tomamos $$r^{*}=\min\left\{\tilde{r},\hat{r}\right\},$$ se tiene que para  $$t^{*}\in\left(0,r^{*}\right)$$ se cumple que 
\begin{center}
\begin{tabular}{lcl}
$\tau_{1}\left(1\right)=0$ & y por tanto & $\overline{\tau}_{1}=0,$
\end{tabular}
\end{center}
entonces para la segunda cola en este primer ciclo se cumple que $$\tau_{2}=\overline{\tau}_{1}+r_{1}=r_{1}<\mu^{*},$$ y por tanto se tiene que  $$\overline{\tau}_{2}=\tau_{2}.$$ Por lo tanto, nuevamente para la primer cola en el segundo ciclo $$\tau_{1}\left(2\right)=\tau_{2}\left(1\right)+r_{2}=\tilde{r}<\mu^{*}.$$ An\'alogamente para el segundo sistema se tiene que ambas colas est\'an vac\'ias, es decir, existe un valor $t^{*}$ tal que en el intervalo $\left(0,t^{*}\right)$ no ha llegado ning\'un usuario, es decir, $$L_{i}\left(t^{*}\right)=0$$ para $i=1,2,3,4$.

\subsection{Resultados para Procesos de Salida}

En \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}




%_______________________________________________________________________________________________________
\subsection{Ya revisado}
%_______________________________________________________________________________________________________


Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}




Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}


\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}



En nuestra notaci\'on $V\left(t\right)\equiv C_{i}$ y $X_{i}=C_{i}^{(m)}$ para nuestra segunda definici\'on, mientras que para la primera la notaci\'on es: $X\left(t\right)\equiv C_{i}$ y $R_{i}\equiv C_{i}^{(m)}$.


%___________________________________________________________________________________________
%\section{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}

\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}



\begin{Note}\label{Cita1.Stidham}
En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}

{\centering{\Huge{\textbf{Nota incompleta!!}}}}
\end{Note}

%_______________________________________________________________________________________
\subsection{Procesos de Renovaci\'on y Regenerativos}
%_______________________________________________________________________________________



Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que



%___________________________________________________________________________________________
%\subsection{Longitudes de la Cola en cualquier tiempo}
%___________________________________________________________________________________________
Sea 
\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Consideremos una cola de la red de sistemas de visitas c\'iclicas fija, $Q_{l}$.


Conforme a la definici\'on dada al principio del cap\'itulo, definici\'on (\ref{Def.Tn}), sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{l}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Entonces, 

\begin{Def}
Al intervalo de tiempo entre dos puntos regenerativos se le llamar\'a ciclo regenerativo.
\end{Def}

\begin{Def}
Para $T_{i}$ se define, $M_{i}$, el n\'umero de ciclos de visita a la cola $Q_{l}$, durante el ciclo regenerativo, es decir, $M_{i}$ es un proceso de renovaci\'on.
\end{Def}

\begin{Def}
Para cada uno de los $M_{i}$'s, se definen a su vez la duraci\'on de cada uno de estos ciclos de visita en el ciclo regenerativo, $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$, que a su vez, tambi\'en es n proceso de renovaci\'on.
\end{Def}

En nuestra notaci\'on $V\left(t\right)\equiv C_{i}$ y $X_{i}=C_{i}^{(m)}$ para nuestra segunda definici\'on, mientras que para la primera la notaci\'on es: $X\left(t\right)\equiv C_{i}$ y $R_{i}\equiv C_{i}^{(m)}$.


%___________________________________________________________________________________________
%\subsection{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}



Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

 por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}

Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}
%___________________________________________________________________________________________
%\subsection{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}

\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}

Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}


%___________________________________________________________________________________________
%\subsection{Longitudes de la Cola en cualquier tiempo}
%___________________________________________________________________________________________

Sea
$V_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\frac{I_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}$

%{\esp\lef[I_{i}\right]}\frac{1-\mu_{i}}{z-P_{i}\left(z\right)}

\begin{eqnarray*}
\frac{\partial V_{i}\left(z\right)}{\partial z}&=&\frac{1}{\esp\left[C_{i}\right]}\left[\frac{I_{i}{'}\left(z\right)\left(z-P_{i}\left(z\right)\right)}{z-P_{i}\left(z\right)}-\frac{\left(I_{i}\left(z\right)-1\right)\left(1-P_{i}{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\right]
\end{eqnarray*}


La FGP para el tiempo de espera para cualquier usuario en la cola est\'a dada por:
\[U_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\]

entonces


\begin{eqnarray*}
\frac{d}{dz}V_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{d}{dz}\left(\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\right)\frac{I_{i}\left(z\right)-1}{1-z}+\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{-P_{i}\left(z\right)\left(z-P_{i}\left(z\right)\right)-\left(1-P_{i}\left(z\right)\right)\left(1-P_{i}^{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\right\}\\
&+&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}^{'}\left(z\right)\left(1-z\right)+\left(I_{i}\left(z\right)-1\right)}{\left(1-z\right)^{2}}\right\}
\end{eqnarray*}
%\frac{I_{i}\left(z\right)-1}{1-z}
%+\frac{1-P_{i}\left(z\right)}{z-P_{i}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)


\begin{eqnarray*}
\frac{\partial U_{i}\left(z\right)}{\partial z}&=&\frac{(-1+I_{i}[z]) (1-P_{i}[z])}{(1-z)^2 \esp[I_{i}] (z-P_{i}[z])}+\frac{(1-P_{i}[z]) I_{i}^{'}[z]}{(1-z) \esp[I_{i}] (z-P_{i}[z])}-\frac{(-1+I_{i}[z]) (1-P_{i}[z])\left(1-P{'}[z]\right)}{(1-z) \esp[I_{i}] (z-P_{i}[z])^2}\\
&-&\frac{(-1+I_{i}[z]) P_{i}{'}[z]}{(1-z) \esp[I_{i}](z-P_{i}[z])}
\end{eqnarray*}
%___________________________________________________________________________________________
%\subsection{Longitudes de la Cola en cualquier tiempo}
%___________________________________________________________________________________________
Sea 
\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}




%_______________________________________________________________________________________________________
\subsection{Tiempo de Ciclo Promedio}
%_______________________________________________________________________________________________________

Consideremos una cola de la red de sistemas de visitas c\'iclicas fija, $Q_{l}$.


Conforme a la definici\'on dada al principio del cap\'itulo, definici\'on (\ref{Def.Tn}), sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{l}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Entonces, 

\begin{Def}
Al intervalo de tiempo entre dos puntos regenerativos se le llamar\'a ciclo regenerativo.
\end{Def}

\begin{Def}
Para $T_{i}$ se define, $M_{i}$, el n\'umero de ciclos de visita a la cola $Q_{l}$, durante el ciclo regenerativo, es decir, $M_{i}$ es un proceso de renovaci\'on.
\end{Def}

\begin{Def}
Para cada uno de los $M_{i}$'s, se definen a su vez la duraci\'on de cada uno de estos ciclos de visita en el ciclo regenerativo, $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$, que a su vez, tambi\'en es n proceso de renovaci\'on.
\end{Def}

En nuestra notaci\'on $V\left(t\right)\equiv C_{i}$ y $X_{i}=C_{i}^{(m)}$ para nuestra segunda definici\'on, mientras que para la primera la notaci\'on es: $X\left(t\right)\equiv C_{i}$ y $R_{i}\equiv C_{i}^{(m)}$.


%___________________________________________________________________________________________
\subsection{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}

\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}

Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}


%___________________________________________________________________________________________
\subsection{Longitudes de la Cola en cualquier tiempo}
%___________________________________________________________________________________________
Sea 
\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}

\subsection{Por resolver}



\begin{eqnarray*}
&&\frac{\partial Q_{i}\left(z\right)}{\partial z}=\frac{1}{\esp\left[C_{i}\right]}\frac{\partial}{\partial z}\left\{\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{\partial}{\partial z}\left(\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\right)\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\partial}{\partial z}\left(\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\right)\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\cdot\frac{\partial}{\partial z}\left(\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\right)+\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\partial}{\partial z}\left(\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\right)\\
&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\cdot\frac{-F_{i}^{'}\left(z\right)\left(P_{i}\left(z\right)-z\right)-\left(1-F_{i}\left(z\right)\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}^{'}\left(z\right)-P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}}
\end{eqnarray*}



\begin{eqnarray*}
Q_{i}^{(1)}\left(z\right)&=& \frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}
-\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}+\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}
%___________________________________________________________________________________________
%\subsection{Operaciones Matemathica: Tiempos de Espera}
%___________________________________________________________________________________________
Sea
$V_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\frac{I_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}$

%{\esp\lef[I_{i}\right]}\frac{1-\mu_{i}}{z-P_{i}\left(z\right)}

\begin{eqnarray*}
\frac{\partial V_{i}\left(z\right)}{\partial z}&=&\frac{1}{\esp\left[C_{i}\right]}\left[\frac{I_{i}{'}\left(z\right)\left(z-P_{i}\left(z\right)\right)}{z-P_{i}\left(z\right)}-\frac{\left(I_{i}\left(z\right)-1\right)\left(1-P_{i}{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\right]
\end{eqnarray*}


La FGP para el tiempo de espera para cualquier usuario en la cola est\'a dada por:
\[U_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\]

entonces


\begin{eqnarray*}
\frac{d}{dz}V_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{d}{dz}\left(\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\right)\frac{I_{i}\left(z\right)-1}{1-z}+\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{-P_{i}\left(z\right)\left(z-P_{i}\left(z\right)\right)-\left(1-P_{i}\left(z\right)\right)\left(1-P_{i}^{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\right\}\\
&+&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}^{'}\left(z\right)\left(1-z\right)+\left(I_{i}\left(z\right)-1\right)}{\left(1-z\right)^{2}}\right\}
\end{eqnarray*}
%\frac{I_{i}\left(z\right)-1}{1-z}
%+\frac{1-P_{i}\left(z\right)}{z-P_{i}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)


\begin{eqnarray*}
\frac{\partial U_{i}\left(z\right)}{\partial z}&=&\frac{(-1+I_{i}[z]) (1-P_{i}[z])}{(1-z)^2 \esp[I_{i}] (z-P_{i}[z])}+\frac{(1-P_{i}[z]) I_{i}^{'}[z]}{(1-z) \esp[I_{i}] (z-P_{i}[z])}-\frac{(-1+I_{i}[z]) (1-P_{i}[z])\left(1-P{'}[z]\right)}{(1-z) \esp[I_{i}] (z-P_{i}[z])^2}\\
&-&\frac{(-1+I_{i}[z]) P_{i}{'}[z]}{(1-z) \esp[I_{i}](z-P_{i}[z])}
\end{eqnarray*}

%___________________________________________________________________________________________
\subsection{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}

\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}

Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}

%___________________________________________________________________________________________
\subsection{Longitudes de la Cola en cualquier tiempo}
%___________________________________________________________________________________________

Sea
$V_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\frac{I_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}$

%{\esp\lef[I_{i}\right]}\frac{1-\mu_{i}}{z-P_{i}\left(z\right)}

\begin{eqnarray*}
\frac{\partial V_{i}\left(z\right)}{\partial z}&=&\frac{1}{\esp\left[C_{i}\right]}\left[\frac{I_{i}{'}\left(z\right)\left(z-P_{i}\left(z\right)\right)}{z-P_{i}\left(z\right)}-\frac{\left(I_{i}\left(z\right)-1\right)\left(1-P_{i}{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\right]
\end{eqnarray*}


La FGP para el tiempo de espera para cualquier usuario en la cola est\'a dada por:
\[U_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\]

entonces


\begin{eqnarray*}
\frac{d}{dz}V_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{d}{dz}\left(\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\right)\frac{I_{i}\left(z\right)-1}{1-z}+\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{-P_{i}\left(z\right)\left(z-P_{i}\left(z\right)\right)-\left(1-P_{i}\left(z\right)\right)\left(1-P_{i}^{'}\left(z\right)\right)}{\left(z-P_{i}\left(z\right)\right)^{2}}\cdot\frac{I_{i}\left(z\right)-1}{1-z}\right\}\\
&+&\frac{1}{\esp\left[C_{i}\right]}\left\{\frac{1-P_{i}\left(z\right)}{z-P_{i}\left(z\right)}\cdot\frac{I_{i}^{'}\left(z\right)\left(1-z\right)+\left(I_{i}\left(z\right)-1\right)}{\left(1-z\right)^{2}}\right\}
\end{eqnarray*}
%\frac{I_{i}\left(z\right)-1}{1-z}
%+\frac{1-P_{i}\left(z\right)}{z-P_{i}\frac{d}{dz}\left(\frac{I_{i}\left(z\right)-1}{1-z}\right)


\begin{eqnarray*}
\frac{\partial U_{i}\left(z\right)}{\partial z}&=&\frac{(-1+I_{i}[z]) (1-P_{i}[z])}{(1-z)^2 \esp[I_{i}] (z-P_{i}[z])}+\frac{(1-P_{i}[z]) I_{i}^{'}[z]}{(1-z) \esp[I_{i}] (z-P_{i}[z])}-\frac{(-1+I_{i}[z]) (1-P_{i}[z])\left(1-P{'}[z]\right)}{(1-z) \esp[I_{i}] (z-P_{i}[z])^2}\\
&-&\frac{(-1+I_{i}[z]) P_{i}{'}[z]}{(1-z) \esp[I_{i}](z-P_{i}[z])}
\end{eqnarray*}


\subsection{Material por agregar}


\begin{Teo}
Dada una Red de Sistemas de Visitas C\'iclicas (RSVC), conformada por dos Sistemas de Visitas C\'iclicas (SVC), donde cada uno de ellos consta de dos colas tipo $M/M/1$. Los dos sistemas est\'an comunicados entre s\'i por medio de la transferencia de usuarios entre las colas $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$. Se definen los eventos para los procesos de arribos al tiempo $t$, $A_{j}\left(t\right)=\left\{0 \textrm{ arribos en }Q_{j}\textrm{ al tiempo }t\right\}$ para alg\'un tiempo $t\geq0$ y $Q_{j}$ la cola $j$-\'esima en la RSVC, para $j=1,2,3,4$.  Existe un intervalo $I\neq\emptyset$ tal que para $T^{*}\in I$, tal que $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$.
\end{Teo}



\begin{proof}
Sin p\'erdida de generalidad podemos considerar como base del an\'alisis a la cola $Q_{1}$ del primer sistema que conforma la RSVC.\medskip 

Sea $n\geq1$, ciclo en el primer sistema en el que se sabe que $L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, pues la pol\'itica de servicio con que atienden los servidores es la exhaustiva. Como es sabido, para trasladarse a la siguiente cola, el servidor incurre en un tiempo de traslado $r_{1}\left(n\right)>0$, entonces tenemos que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.\medskip 


Definamos el intervalo $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ de longitud $\xi_{1}=r_{1}\left(n\right)$.

Dado que los tiempos entre arribo son exponenciales con tasa $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ ($\mu_{1}$ son los arribos a $Q_{1}$ por primera vez al sistema, mientras que $\hat{\mu}_{1}$ son los arribos de traslado procedentes de $Q_{3}$) se tiene que la probabilidad del evento $A_{1}\left(t\right)$ est\'a dada por 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 


Por otra parte, para la cola $Q_{2}$ el tiempo $\overline{\tau}_{2}\left(n-1\right)$ es tal que $L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, es decir, es el tiempo en que la cola queda totalmente vac\'ia en el ciclo anterior a $n$. \medskip 


Entonces tenemos un sgundo intervalo $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Por lo tanto la probabilidad del evento $A_{2}\left(t\right)$ tiene probabilidad dada por

\begin{eqnarray}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},\\
\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)
\end{eqnarray}
%\end{equation} 

%donde $$.

Ahora, dado que $I_{1}\left(n\right)\subset I_{2}\left(n\right)$, se tiene que

\begin{eqnarray*}
\xi_{1}\left(n\right)\leq\xi_{2}\left(n\right)&\Leftrightarrow& -\xi_{1}\left(n\right)\geq-\xi_{2}\left(n\right)
\\
-\tilde{\mu}_{2}\xi_{1}\left(n\right)\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{2}\xi_{1}\left(n\right)}\geq e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}\\
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&\geq&
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}.
\end{eqnarray*}


Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}}


Es decir, 

\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}
En lo que respecta a la relaci\'on entre los dos SVC que conforman la RSVC para alg\'un $m\geq1$ se tiene que $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$ por lo tanto se cumple cualquiera de los siguientes cuatro casos
\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$
\end{itemize}


Sea el intervalo $I_{3}\left(m\right)\equiv\left[\tau_{3}\left(m\right),\overline{\tau}_{3}\left(m\right)\right]$ tal que $\tau_{2}\left(n\right)\in I_{3}\left(m\right)$, con longitud de intervalo $\xi_{3}\equiv\overline{\tau}_{3}\left(m\right)-\tau_{3}\left(m\right)$, entonces se tiene que para $Q_{3}$
\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}.
\end{equation} 

mientras que para $Q_{4}$ consideremos el intervalo $I_{4}\left(m\right)\equiv\left[\tau_{4}\left(m-1\right),\overline{\tau}_{3}\left(m\right)\right]$, entonces por construcci\'on  $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, por lo tanto


\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}.
\end{eqnarray*}



Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}
\left(m\right)}
=e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}.
\end{eqnarray*}}

Es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\geq
e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}>0.
\end{equation}


Sea el intervalo $I_{3}\left(m\right)\equiv\left[\overline{\tau}_{3}\left(m\right),\tau_{4}\left(m\right)\right]$ con longitud $\xi_{3}\equiv\tau_{4}\left(m\right)-\overline{\tau}_{3}\left(m\right)$, entonces se tiene que para $Q_{3}$
\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}.
\end{equation} 

mientras que para $Q_{4}$ consideremos el intervalo $I_{4}\left(m\right)\equiv\left[\overline{\tau}_{4}\left(m-1\right),\tau_{4}\left(m\right)\right]$, entonces por construcci\'on  $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, y al igual que en el caso anterior se tiene que 

\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}.
\end{eqnarray*}


Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}\left(m\right)}
=e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}.
\end{eqnarray*}}

Es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\geq
e^{-\left(\tilde{\mu}_{3}+\tilde{\mu}_{4}\right)\xi_{3}\left(m\right)}>0.
\end{equation}


Para el intervalo $I_{3}\left(m\right)=\left[\tau_{4}\left(m\right),\overline{\tau}_{4}\left(m\right)\right]$, se tiene que este caso es an\'alogo al caso (a).


Para el intevalo $I_{3}\left(m\right)\equiv\left[\overline{\tau}_{4}\left(m\right),\tau_{4}\left(m+1\right)\right]$, se tiene que es an\'alogo al caso (b).


Por construcci\'on se tiene que $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$,entonces en particular se tienen las contenciones $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ y $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, por lo tanto si definimos $\xi_{n,m}\equiv\ell\left(I\left(n,m\right)\right)$ tenemos que

\begin{eqnarray*}
\xi_{n,m}\leq\xi_{1}\left(n\right)\textrm{ y }\xi_{n,m}\leq\xi_{3}\left(m\right)\textrm{ entonces }\\
-\xi_{n,m}\geq-\xi_{1}\left(n\right)\textrm{ y }-\xi_{n,m}\leq-\xi_{3}\left(m\right)\\
\end{eqnarray*}
por lo tanto tenemos las desigualdades 


\begin{eqnarray*}
\begin{array}{ll}
-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right),&
-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right),\\
-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right),&
-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).
\end{array}
\end{eqnarray*}

Sea $T^{*}\in I\left(n,m\right)$, entonces dado que en particular $T^{*}\in I_{1}\left(n\right)$, se cumple con probabilidad positiva que no hay arribos a las colas $Q_{1}$ y $Q_{2}$, en consecuencia, tampoco hay usuarios de transferencia para $Q_{3}$ y $Q_{4}$, es decir, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, es decir, los eventos $Q_{1}$ y $Q_{3}$ son condicionalmente independientes en el intervalo $I\left(n,m\right)$; lo mismo ocurre para las colas $Q_{2}$ y $Q_{4}$, por lo tanto tenemos que
%\small{
\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}\\
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}\\
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}\\
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}


Ahora solo resta demostrar que para $n\ge1$, existe $m\geq1$ tal que se cumplen cualquiera de los cuatro casos arriba mencionados: 

\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$
\end{itemize}

Consideremos nuevamente el primer caso. Supongamos que no existe $m\geq1$, tal que $I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$, es decir, para toda $m\geq1$, $I_{1}\left(n\right)\cap I_{3}\left(m\right)=\emptyset$, entonces se tiene que ocurren cualquiera de los dos casos

\begin{itemize}
\item[a)] $\tau_{2}\left(n\right)\leq\tau_{3}\left(m\right)$: Recordemos que $\tau_{2}\left(m\right)=\overline{\tau}_{1}+r_{1}\left(m\right)$ donde cada una de las variables aleatorias son tales que $\esp\left[\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)\right]<\infty$, $\esp\left[R_{1}\right]<\infty$ y $\esp\left[\tau_{3}\left(m\right)\right]<\infty$, lo cual contradice el hecho de que no exista un ciclo $m\geq1$ que satisfaga la condici\'on deseada.

\item[b)] $\tau_{2}\left(n\right)\geq\overline{\tau}_{3}\left(m\right)$: por un argumento similar al anterior se tiene que no es posible que no exista un ciclo $m\geq1$ tal que satisaface la condici\'on deseada.

\end{itemize}

Para el resto de los casos la demostraci\'on es an\'aloga. Por lo tanto, se tiene que efectivamente existe $m\geq1$ tal que $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$.
\end{proof}
\newpage

En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R1}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}



%________________________________________________________________________
%\subsection{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman1}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
%___________________________________________________________________________________________
%
\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}


%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}
%
%___________________________________________________________________________________________
%\vspace{5.5cm}
%\chapter{Cadenas de Markov estacionarias}
%\vspace{-1.0cm}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.


%______________________________________________________________________
%\subsection{Ejemplos, Notas importantes}


Sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{j}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$\footnote{En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito, es decir: $\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty$, como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que $\esp\left[C_{i}\right]<\infty$,
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por $\sum_{k=1}^{N}\mu_{k}<1.$}, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Haciendo las siguientes sustituciones en la ecuaci\'on (\ref{Corolario2}): $n\rightarrow t-\tau_{i}\left(m\right)$, $T \rightarrow \overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)$, $L_{n}\rightarrow L_{i}\left(t\right)$ y $F\left(z\right)=\esp\left[z^{L_{0}}\right]\rightarrow F_{i}\left(z\right)=\esp\left[z^{L_{i}\tau_{i}\left(m\right)}\right]$, se puede ver que

\begin{eqnarray}\label{Eq.Arribos.Primera}
\esp\left[\sum_{n=0}^{T-1}z^{L_{n}}\right]=
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray}

Por otra parte durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&
\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Por lo tanto

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}
\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}
z^{L_{i}\left(t\right)}\right]
+\esp\left[\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}
z^{L_{i}\left(t\right)}\right]\right\}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}
{1-P_{i}\left(z\right)}
\right\}
\end{eqnarray*}

es decir

\begin{equation}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{equation}

\begin{Teo}
Dada una Red de Sistemas de Visitas C\'iclicas (RSVC), conformada por dos Sistemas de Visitas C\'iclicas (SVC), donde cada uno de ellos consta de dos colas tipo $M/M/1$. Los dos sistemas est\'an comunicados entre s\'i por medio de la transferencia de usuarios entre las colas $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$. Se definen los eventos para los procesos de arribos al tiempo $t$, $A_{j}\left(t\right)=\left\{0 \textrm{ arribos en }Q_{j}\textrm{ al tiempo }t\right\}$ para alg\'un tiempo $t\geq0$ y $Q_{j}$ la cola $j$-\'esima en la RSVC, para $j=1,2,3,4$.  Existe un intervalo $I\neq\emptyset$ tal que para $T^{*}\in I$, tal que $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$.
\end{Teo}

\begin{proof}
Sin p\'erdida de generalidad podemos considerar como base del an\'alisis a la cola $Q_{1}$ del primer sistema que conforma la RSVC.

Sea $n>0$, ciclo en el primer sistema en el que se sabe que $L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, pues la pol\'itica de servicio con que atienden los servidores es la exhaustiva. Como es sabido, para trasladarse a la siguiente cola, el servidor incurre en un tiempo de traslado $r_{1}\left(n\right)>0$, entonces tenemos que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.


Definamos el intervalo $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ de longitud $\xi_{1}=r_{1}\left(n\right)$. Dado que los tiempos entre arribo son exponenciales con tasa $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ ($\mu_{1}$ son los arribos a $Q_{1}$ por primera vez al sistema, mientras que $\hat{\mu}_{1}$ son los arribos de traslado procedentes de $Q_{3}$) se tiene que la probabilidad del evento $A_{1}\left(t\right)$ est\'a dada por 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 

Por otra parte, para la cola $Q_{2}$, el tiempo $\overline{\tau}_{2}\left(n-1\right)$ es tal que $L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, es decir, es el tiempo en que la cola queda totalmente vac\'ia en el ciclo anterior a $n$. Entonces tenemos un sgundo intervalo $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Por lo tanto la probabilidad del evento $A_{2}\left(t\right)$ tiene probabilidad dada por

\begin{equation}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},
\end{equation} 

donde $\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)$.



Entonces, se tiene que

\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}

En lo que respecta a la relaci\'on entre los dos SVC que conforman la RSVC, se afirma que existe $m>0$ tal que $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$.

Para $Q_{3}$ sea $I_{3}=\left[\overline{\tau}_{3}\left(m\right),\tau_{4}\left(m\right)\right]$ con longitud  $\xi_{3}\left(m\right)=r_{3}\left(m\right)$, entonces 

\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(n\right)}.
\end{equation} 

An\'alogamente que como se hizo para $Q_{2}$, tenemos que para $Q_{4}$ se tiene el intervalo $I_{4}=\left[\overline{\tau}_{4}\left(m-1\right),\tau_{4}\left(m\right)\right]$ con longitud $\xi_{4}\left(m\right)=\tau_{4}\left(m\right)-\overline{\tau}_{4}\left(m-1\right)$, entonces


\begin{equation}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}=e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}.
\end{equation} 

Al igual que para el primer sistema, dado que $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, se tiene que

\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(m\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}
\end{eqnarray*}

Entonces, dado que los eventos $A_{3}$ y $A_{4}$ son independientes, se tiene que

\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}
\left(m\right)}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{equation}

Por construcci\'on se tiene que $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$,entonces en particular se tienen las contenciones $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ y $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, por lo tanto si definimos $\xi_{n,m}\equiv\ell\left(I\left(n,m\right)\right)$ tenemos que

\begin{eqnarray*}
\xi_{n,m}\leq\xi_{1}\left(n\right)\textrm{ y }\xi_{n,m}\leq\xi_{3}\left(m\right)\textrm{ entonces }
-\xi_{n,m}\geq-\xi_{1}\left(n\right)\textrm{ y }-\xi_{n,m}\leq-\xi_{3}\left(m\right)\\
\end{eqnarray*}
por lo tanto tenemos las desigualdades 



\begin{eqnarray*}
\begin{array}{ll}
-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right),&
-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right),\\
-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right),&
-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).
\end{array}
\end{eqnarray*}

Sea $T^{*}\in I_{n,m}$, entonces dado que en particular $T^{*}\in I_{1}\left(n\right)$ se cumple con probabilidad positiva que no hay arribos a las colas $Q_{1}$ y $Q_{2}$, en consecuencia, tampoco hay usuarios de transferencia para $Q_{3}$ y $Q_{4}$, es decir, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, es decir, los eventos $Q_{1}$ y $Q_{3}$ son condicionalmente independientes en el intervalo $I_{n,m}$; lo mismo ocurre para las colas $Q_{2}$ y $Q_{4}$, por lo tanto tenemos que


\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}
\end{proof}


Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}


%\section{Resultados para Procesos de Salida}

En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}
%\newpage
%________________________________________________________________________
%\section{Redes de Sistemas de Visitas C\'iclicas}
%________________________________________________________________________

Sean $Q_{1},Q_{2},Q_{3}$ y $Q_{4}$ en una Red de Sistemas de Visitas C\'iclicas (RSVC). Supongamos que cada una de las colas es del tipo $M/M/1$ con tasa de arribo $\mu_{i}$ y que la transferencia de usuarios entre los dos sistemas ocurre entre $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$ con respectiva tasa de arribo igual a la tasa de salida $\hat{\mu}_{i}=\mu_{i}$, esto se sabe por lo desarrollado en la secci\'on anterior.  

Consideremos, sin p\'erdida de generalidad como base del an\'alisis, la cola $Q_{1}$ adem\'as supongamos al servidor lo comenzamos a observar una vez que termina de atender a la misma para desplazarse y llegar a $Q_{2}$, es decir al tiempo $\tau_{2}$.

Sea $n\in\nat$, $n>0$, ciclo del servidor en que regresa a $Q_{1}$ para dar servicio y atender conforme a la pol\'itica exhaustiva, entonces se tiene que $\overline{\tau}_{1}\left(n\right)$ es el tiempo del servidor en el sistema 1 en que termina de dar servicio a todos los usuarios presentes en la cola, por lo tanto se cumple que $L_{1}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, entonces el servidor para llegar a $Q_{2}$ incurre en un tiempo de traslado $r_{1}$ y por tanto se cumple que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}$. Dado que los tiempos entre arribos son exponenciales se cumple que 

\begin{eqnarray*}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}=e^{-\tilde{\mu}_{1}r_{1}},\\
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}=e^{-\tilde{\mu}_{2}r_{1}}.
\end{eqnarray*}

El evento que nos interesa consiste en que no haya arribos desde que el servidor abandon\'o $Q_{2}$ y regresa nuevamente para dar servicio, es decir en el intervalo de tiempo $\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Entonces, si hacemos


\begin{eqnarray*}
\varphi_{1}\left(n\right)&\equiv&\overline{\tau}_{1}\left(n\right)+r_{1}=\overline{\tau}_{2}\left(n-1\right)+r_{1}+r_{2}+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)\\
&=&\overline{\tau}_{2}\left(n-1\right)+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r,,
\end{eqnarray*}

y longitud del intervalo

\begin{eqnarray*}
\xi&\equiv&\overline{\tau}_{1}\left(n\right)+r_{1}-\overline{\tau}_{2}\left(n-1\right)
=\overline{\tau}_{2}\left(n-1\right)+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r-\overline{\tau}_{2}\left(n-1\right)\\
&=&\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r.
\end{eqnarray*}


Entonces, determinemos la probabilidad del evento no arribos a $Q_{2}$ en $\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]$:

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{2}\xi}.
\end{eqnarray}

De manera an\'aloga, tenemos que la probabilidad de no arribos a $Q_{1}$ en $\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]$ esta dada por

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{1}\xi},
\end{eqnarray}

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{2}\xi}.
\end{eqnarray}

Por tanto 

\begin{eqnarray}
\begin{array}{l}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ y }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}\\
=\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}\\
\times
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}=e^{-\tilde{\mu}_{1}\xi}e^{-\tilde{\mu}_{2}\xi}
=e^{-\tilde{\mu}\xi}.
\end{array}
\end{eqnarray}

Para el segundo sistema, consideremos nuevamente $\overline{\tau}_{1}\left(n\right)+r_{1}$, sin p\'erdida de generalidad podemos suponer que existe $m>0$ tal que $\overline{\tau}_{3}\left(m\right)<\overline{\tau}_{1}+r_{1}<\tau_{4}\left(m\right)$, entonces

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\textrm{ en el intervalo }\left[\overline{\tau}_{3}\left(m\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}
=e^{-\tilde{\mu}_{3}\xi_{3}},
\end{eqnarray}
donde 
\begin{eqnarray}
\xi_{3}=\overline{\tau}_{1}\left(n\right)+r_{1}-\overline{\tau}_{3}\left(m\right)=
\overline{\tau}_{1}\left(n\right)-\overline{\tau}_{3}\left(m\right)+r_{1},
\end{eqnarray}

mientras que para $Q_{4}$ al igual que con $Q_{2}$ escribiremos $\tau_{4}\left(m\right)$ en t\'erminos de $\overline{\tau}_{4}\left(m-1\right)$:

$\varphi_{2}\equiv\tau_{4}\left(m\right)=\overline{\tau}_{4}\left(m-1\right)+r_{4}+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)+r_{3}=\overline{\tau}_{4}\left(m-1\right)+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)+\hat{r}$, adem\'as,

$\xi_{2}\equiv\varphi_{2}\left(m\right)-\overline{\tau}_{1}-r_{1}=\overline{\tau}_{4}\left(m-1\right)+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)-\overline{\tau}_{1}\left(n\right)+\hat{r}-r_{1}$. 

Entonces


\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{4}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\tilde{\mu}_{4}\xi_{2}},
\end{eqnarray}

mientras que para $Q_{3}$ se tiene que 

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\tilde{\mu}_{3}\xi_{2}}
\end{eqnarray}

Por tanto

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\wedge Q_{4}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\hat{\mu}\xi_{2}}
\end{eqnarray}
donde $\hat{\mu}=\tilde{\mu}_{3}+\tilde{\mu}_{4}$.

Ahora, definamos los intervalos $\mathcal{I}_{1}=\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{1}\left(n\right)\right]$  y $\mathcal{I}_{2}=\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]$, entonces, sea $\mathcal{I}=\mathcal{I}_{1}\cap\mathcal{I}_{2}$ el intervalo donde cada una de las colas se encuentran vac\'ias, es decir, si tomamos $T^{*}\in\mathcal{I}$, entonces  $L_{1}\left(T^{*}\right)=L_{2}\left(T^{*}\right)=L_{3}\left(T^{*}\right)=L_{4}\left(T^{*}\right)=0$.

Ahora, dado que por construcci\'on $\mathcal{I}\neq\emptyset$ y que para $T^{*}\in\mathcal{I}$ en ninguna de las colas han llegado usuarios, se tiene que no hay transferencia entre las colas, por lo tanto, el sistema 1 y el sistema 2 son condicionalmente independientes en $\mathcal{I}$, es decir

\begin{eqnarray}
\prob\left\{L_{1}\left(T^{*}\right),L_{2}\left(T^{*}\right),L_{3}\left(T^{*}\right),L_{4}\left(T^{*}\right)|T^{*}\in\mathcal{I}\right\}=\prod_{j=1}^{4}\prob\left\{L_{j}\left(T^{*}\right)\right\},
\end{eqnarray}

para $T^{*}\in\mathcal{I}$. 

%\newpage























%________________________________________________________________________
%\section{Procesos Regenerativos}
%________________________________________________________________________

%________________________________________________________________________
%\subsection*{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman1}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
%\subsection*{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
%\section{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection*{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection*{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection*{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}

%______________________________________________________________________

%\section{Ejemplos, Notas importantes}
%______________________________________________________________________
%\section*{Ap\'endice A}
%__________________________________________________________________

%________________________________________________________________________
%\subsection*{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.


\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}
%
%___________________________________________________________________________________________
%\vspace{5.5cm}
%\chapter{Cadenas de Markov estacionarias}
%\vspace{-1.0cm}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente. Entonces 



Es decir, es posible determinar las longitudes de las colas a cualquier tiempo $t$. Entonces, determinando el primer momento es posible ver que


\begin{Def}
El tiempo de Ciclo $C_{i}$ es el periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}


\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si $I_{i}\left(z\right)=\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]$
se tiene que $F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]$
para $i=1,2$.

Conforme a la definici\'on dada al principio del cap\'itulo, definici\'on (\ref{Def.Tn}), sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{j}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Entonces, 

\begin{Def}
Al intervalo de tiempo entre dos puntos regenerativos se le llamar\'a ciclo regenerativo.
\end{Def}

\begin{Def}
Para $T_{i}$ se define, $M_{i}$, el n\'umero de ciclos de visita a la cola $Q_{l}$, durante el ciclo regenerativo, es decir, $M_{i}$ es un proceso de renovaci\'on.
\end{Def}

\begin{Def}
Para cada uno de los $M_{i}$'s, se definen a su vez la duraci\'on de cada uno de estos ciclos de visita en el ciclo regenerativo, $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$, que a su vez, tambi\'en es n proceso de renovaci\'on.
\end{Def}

\footnote{In Stidham and  Heyman \cite{Stidham} shows that is sufficient for the regenerative process to be stationary that the mean regenerative cycle time is finite: $\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty$, 


 como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que $\esp\left[C_{i}\right]<\infty$,
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por $\sum_{k=1}^{N}\mu_{k}<1.$}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.

\begin{Def}
Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$.
\end{Def}

\begin{Note}
Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto
$\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$
\end{Def}

\begin{Def}
Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.
\end{Def}

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.


\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo, es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.
\end{Def}


\begin{Def}
Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.
\end{Def}

\begin{Def}
Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$.
\end{Def}

\begin{Note}
Cualquier espacio Polaco es un espacio est\'andar.
\end{Note}


\begin{Def}
Un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.
\end{Def}

\begin{Def}
Un proceso estoc\'astico \textit{one-sided contiuous time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}


Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$.

\begin{Note}
La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}

\begin{Note}
En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales

\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}
\end{Note}

\begin{Note}
Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$.
\end{Def}

\begin{Note}
Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}
\end{Note}


\begin{Note}
$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$.
\end{Note}

\begin{Note}
La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.
\end{Note}


\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es conjuntamente medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}


\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es can\'onicamente conjuntamente medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

\begin{Note}
Un PEOSCTCCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.
\end{Note}

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es internamente shift-invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCTISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es shift-medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

\begin{Note}
Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es shift-medible si y s\'olo si es CCM
\end{Note}

\begin{Note}
\begin{itemize}
\item Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM.

\item Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas.

\end{itemize}
\end{Note}


\begin{Note}
Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.
\end{Note}

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

\begin{Note}
Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Note}

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

\begin{Note}
Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\end{Note}

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.

\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.

\end{Def}



\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{wide-sense regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$.
Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}


\begin{Note}
\begin{itemize}
\item El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico.

\item Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico

\end{itemize}

\end{Note}


\begin{Note}
Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.
\end{Note}



\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}





%_________________________________________________________________________
%
%\subsection{Una vez que se tiene estabilidad}
%_________________________________________________________________________
%

Also the intervisit time $I_{i}$ is defined as the period beginning at the time of its service completion in a cycle and ending at the time when it is polled in the next cycle; its duration is given by $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.

So we the following are still true 

\begin{eqnarray}
\begin{array}{ll}
\esp\left[L_{i}\right]=\mu_{i}\esp\left[I_{i}\right], &
\esp\left[C_{i}\right]=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)},\\
\esp\left[S_{i}\right]=\mu_{i}\esp\left[C_{i}\right],&
\esp\left[I_{i}\right]=\left(1-\mu_{i}\right)\esp\left[C_{i}\right],\\
Var\left[L_{i}\right]= \mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right],& 
Var\left[C_{i}\right]=\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}},\\
Var\left[S_{i}\right]= \frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}},&
Var\left[I_{i}\right]= \frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{array}
\end{eqnarray}
\begin{Def}
El tiempo de Ciclo $C_{i}$ es el periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}


\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si $I_{i}\left(z\right)=\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]$
se tiene que $F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]$
para $i=1,2$.

Conforme a la definici\'on dada al principio del cap\'itulo, definici\'on (\ref{Def.Tn}), sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{j}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Entonces, 

\begin{Def}
Al intervalo de tiempo entre dos puntos regenerativos se le llamar\'a ciclo regenerativo.
\end{Def}

\begin{Def}
Para $T_{i}$ se define, $M_{i}$, el n\'umero de ciclos de visita a la cola $Q_{l}$, durante el ciclo regenerativo, es decir, $M_{i}$ es un proceso de renovaci\'on.
\end{Def}

\begin{Def}
Para cada uno de los $M_{i}$'s, se definen a su vez la duraci\'on de cada uno de estos ciclos de visita en el ciclo regenerativo, $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$, que a su vez, tambi\'en es n proceso de renovaci\'on.
\end{Def}


Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$\footnote{En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito, es decir: $\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty$, como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que $\esp\left[C_{i}\right]<\infty$,
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por $\sum_{k=1}^{N}\mu_{k}<1.$}, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Haciendo las siguientes sustituciones en la ecuaci\'on (\ref{Corolario2}): $n\rightarrow t-\tau_{i}\left(m\right)$, $T \rightarrow \overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)$, $L_{n}\rightarrow L_{i}\left(t\right)$ y $F\left(z\right)=\esp\left[z^{L_{0}}\right]\rightarrow F_{i}\left(z\right)=\esp\left[z^{L_{i}\tau_{i}\left(m\right)}\right]$, se puede ver que

\begin{eqnarray}\label{Eq.Arribos.Primera}
\esp\left[\sum_{n=0}^{T-1}z^{L_{n}}\right]=
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray}

Por otra parte durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&
\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Por lo tanto

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
=\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}
+\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\left\{
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
+\esp\left[\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\right\}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\left\{
z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

es decir

\begin{equation}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{equation}


Si hacemos:

\begin{eqnarray}
S\left(z\right)&=&1-F\left(z\right)\\
T\left(z\right)&=&z-P\left(z\right)\\
U\left(z\right)&=&1-P\left(z\right)
\end{eqnarray}
entonces 

\begin{eqnarray}
\esp\left[C_{i}\right]Q\left(z\right)=\frac{\left(z-1\right)S\left(z\right)P\left(z\right)}{T\left(z\right)U\left(z\right)}
\end{eqnarray}

A saber, si $a_{k}=P\left\{L\left(t\right)=k\right\}$
\begin{eqnarray*}
S\left(z\right)=1-F\left(z\right)=1-\sum_{k=0}^{+\infty}a_{k}z^{k}
\end{eqnarray*}
entonces

%\begin{eqnarray}
%\begin{array}{ll}
%S^{'}\left(z\right)=-\sum_{k=1}^{+\infty}ka_{k}z^{k-1},& %S^{(1)}\left(1\right)=-\sum_{k=1}^{+\infty}ka_{k}=-\esp\left[L\left(t\right)\right],\\
%S^{''}\left(z\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}z^{k-2},& S^{(2)}\left(1\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}=\esp\left[L\left(L-1\right)\right],\\
%S^{'''}\left(z\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}z^{k-3},&
%S^{(3)}\left(1\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}\\
%&=-\esp\left[L\left(L-1\right)\left(L-2\right)\right]\\
%&=-\esp\left[L^{3}\right]+3-\esp\left[L^{2}\right]-2-\esp\left[L\right];
%\end{array}
%\end{eqnarray}

$S^{'}\left(z\right)=-\sum_{k=1}^{+\infty}ka_{k}z^{k-1}$, por tanto $S^{(1)}\left(1\right)=-\sum_{k=1}^{+\infty}ka_{k}=-\esp\left[L\left(t\right)\right]$,
luego $S^{''}\left(z\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}z^{k-2}$ y $S^{(2)}\left(1\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}=\esp\left[L\left(L-1\right)\right]$;
de la misma manera $S^{'''}\left(z\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}z^{k-3}$ y $S^{(3)}\left(1\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}=-\esp\left[L\left(L-1\right)\left(L-2\right)\right]
=-\esp\left[L^{3}\right]+3-\esp\left[L^{2}\right]-2-\esp\left[L\right]$. 

Es decir

\begin{eqnarray*}
S^{(1)}\left(1\right)&=&-\esp\left[L\left(t\right)\right],\\ S^{(2)}\left(1\right)&=&-\esp\left[L\left(L-1\right)\right]
=-\esp\left[L^{2}\right]+\esp\left[L\right],\\
S^{(3)}\left(1\right)&=&-\esp\left[L\left(L-1\right)\left(L-2\right)\right]
=-\esp\left[L^{3}\right]+3\esp\left[L^{2}\right]-2\esp\left[L\right].
\end{eqnarray*}


Expandiendo alrededor de $z=1$

\begin{eqnarray*}
S\left(z\right)&=&S\left(1\right)+\frac{S^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{S^{'}\left(1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}\\
&=&\left(z-1\right)R_{1}\left(z\right)
\end{eqnarray*}
con $R_{1}\left(z\right)\neq0$, pues

\begin{eqnarray}\label{Eq.R1}
R_{1}\left(z\right)=-\esp\left[L\right]
\end{eqnarray}
entonces

\begin{eqnarray}
R_{1}\left(z\right)&=&S^{'}\left(1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{S^{iv}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}
Calculando las derivadas y evaluando en $z=1$

\begin{eqnarray}
R_{1}\left(1\right)&=&S^{(1)}\left(1\right)=-\esp\left[L\right]\\
R_{1}^{(1)}\left(1\right)&=&\frac{1}{2}S^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[L^{2}\right]+\frac{1}{2}\esp\left[L\right]\\
R_{1}^{(2)}\left(1\right)&=&\frac{2}{3!}S^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[L^{3}\right]+\esp\left[L^{2}\right]-\frac{2}{3}\esp\left[L\right]
\end{eqnarray}

De manera an\'aloga se puede ver que para $T\left(z\right)=z-P\left(z\right)$ se puede encontrar una expanci\'on alrededor de $z=1$

Expandiendo alrededor de $z=1$

\begin{eqnarray*}
T\left(z\right)&=&T\left(1\right)+\frac{T^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{T^{'}\left(1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}\\
&=&\left(z-1\right)R_{2}\left(z\right)
\end{eqnarray*}

donde 
\begin{eqnarray*}
T^{(1)}\left(1\right)&=&-\esp\left[X\left(t\right)\right]=-\mu,\\ T^{(2)}\left(1\right)&=&-\esp\left[X\left(X-1\right)\right]
=-\esp\left[X^{2}\right]+\esp\left[X\right]=-\esp\left[X^{2}\right]+\mu,\\
T^{(3)}\left(1\right)&=&-\esp\left[X\left(X-1\right)\left(X-2\right)\right]
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\esp\left[X\right]\\
&=&-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\mu.
\end{eqnarray*}

Por lo tanto $R_{2}\left(1\right)\neq0$, pues

\begin{eqnarray}\label{Eq.R2}
R_{2}\left(1\right)=1-\esp\left[X\right]=1-\mu
\end{eqnarray}
entonces

\begin{eqnarray}
R_{2}\left(z\right)&=&T^{'}\left(1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{T^{(iv)}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}
Calculando las derivadas y evaluando en $z=1$

\begin{eqnarray}
R_{2}\left(1\right)&=&T^{(1)}\left(1\right)=1-\mu\\
R_{2}^{(1)}\left(1\right)&=&\frac{1}{2}T^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\\
R_{2}^{(2)}\left(1\right)&=&\frac{2}{3!}T^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[X^{3}\right]+\esp\left[X^{2}\right]-\frac{2}{3}\mu
\end{eqnarray}

Finalmente para de manera an\'aloga se puede ver que para $U\left(z\right)=1-P\left(z\right)$ se puede encontrar una expanci\'on alrededor de $z=1$

\begin{eqnarray*}
U\left(z\right)&=&U\left(1\right)+\frac{U^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{U^{'}\left(1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}\\
&=&\left(z-1\right)R_{3}\left(z\right)
\end{eqnarray*}

donde 
\begin{eqnarray*}
U^{(1)}\left(1\right)&=&-\esp\left[X\left(t\right)\right]=-\mu,\\ U^{(2)}\left(1\right)&=&-\esp\left[X\left(X-1\right)\right]
=-\esp\left[X^{2}\right]+\esp\left[X\right]=-\esp\left[X^{2}\right]+\mu,\\
U^{(3)}\left(1\right)&=&-\esp\left[X\left(X-1\right)\left(X-2\right)\right]
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\esp\left[X\right]\\
&=&-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\mu.
\end{eqnarray*}

Por lo tanto $R_{3}\left(1\right)\neq0$, pues

\begin{eqnarray}\label{Eq.R2}
R_{3}\left(1\right)=-\esp\left[X\right]=-\mu
\end{eqnarray}
entonces

\begin{eqnarray}
R_{3}\left(z\right)&=&U^{'}\left(1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{U^{(iv)}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}

Calculando las derivadas y evaluando en $z=1$

\begin{eqnarray}
R_{3}\left(1\right)&=&U^{(1)}\left(1\right)=-\mu\\
R_{3}^{(1)}\left(1\right)&=&\frac{1}{2}U^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\\
R_{3}^{(2)}\left(1\right)&=&\frac{2}{3!}U^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[X^{3}\right]+\esp\left[X^{2}\right]-\frac{2}{3}\mu
\end{eqnarray}

Por lo tanto

\begin{eqnarray}
\esp\left[C_{i}\right]Q\left(z\right)&=&\frac{\left(z-1\right)\left(z-1\right)R_{1}\left(z\right)P\left(z\right)}{\left(z-1\right)R_{2}\left(z\right)\left(z-1\right)R_{3}\left(z\right)}
=\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\equiv\frac{R_{1}P}{R_{2}R_{3}}
\end{eqnarray}

Entonces

\begin{eqnarray}\label{Eq.Primer.Derivada.Q}
\left[\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\right]^{'}&=&\frac{PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}-R_{2}R_{1}PR_{3}^{'}}{\left(R_{2}R_{3}\right)^{2}}
\end{eqnarray}
Evaluando en $z=1$
\begin{eqnarray*}
&=&\frac{R_{2}(1)R_{3}(1)R_{1}^{(1)}(1)+R_{1}(1)R_{2}(1)R_{3}(1)P^{'}(1)-R_{3}(1)R_{1}(1)R_{2}(1)^{(1)}-R_{2}(1)R_{1}(1)R_{3}^{'}(1)}{\left(R_{2}(1)R_{3}(1)\right)^{2}}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{\left(-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\right)\left(1-\mu\right)\left(-\mu\right)+\left(-\esp L\right)\left(1-\mu\right)\left(-\mu\right)\mu\right.\\
&&\left.-\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\left(-\mu\right)\left(-\esp L\right)-\left(1-\mu\right)\left(-\esp L\right)\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{\left(-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\right)\left(\mu^{2}-\mu\right)
+\left(\mu^{2}-\mu^{3}\right)\esp L\right.\\
&&\left.-\mu\esp L\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)
+\left(\esp L-\mu\esp L\right)\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{-\frac{1}{2}\mu^{2}\esp L^{2}
+\frac{1}{2}\mu\esp L^{2}
+\frac{1}{2}\mu^{2}\esp L
-\mu^{3}\esp L
+\mu\esp L\esp X^{2}
-\frac{1}{2}\esp L\esp X^{2}\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{
\frac{1}{2}\mu\esp L^{2}\left(1-\mu\right)
+\esp L\left(\frac{1}{2}-\mu\right)\left(\mu^{2}-\esp X^{2}\right)\right\}\\
&=&\frac{1}{2\mu\left(1-\mu\right)}\esp L^{2}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)^{2}\mu^{2}}\sigma^{2}\esp L
\end{eqnarray*}

por lo tanto (para Takagi)

\begin{eqnarray*}
Q^{(1)}=\frac{1}{\esp C}\left\{\frac{1}{2\mu\left(1-\mu\right)}\esp L^{2}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)^{2}\mu^{2}}\sigma^{2}\esp L\right\}
\end{eqnarray*}
donde 

\begin{eqnarray*}
\esp C = \frac{\esp L}{\mu\left(1-\mu\right)}
\end{eqnarray*}
entonces

\begin{eqnarray*}
Q^{(1)}&=&\frac{1}{2}\frac{\esp L^{2}}{\esp L}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)\mu}\sigma^{2}
=\frac{\esp L^{2}}{2\esp L}-\frac{\sigma^{2}}{2}\left\{\frac{2\mu-1}{\left(1-\mu\right)\mu}\right\}\\
&=&\frac{\esp L^{2}}{2\esp L}+\frac{\sigma^{2}}{2}\left\{\frac{1}{1-\mu}+\frac{1}{\mu}\right\}
\end{eqnarray*}

Mientras que para nosotros

\begin{eqnarray*}
Q^{(1)}=\frac{1}{\mu\left(1-\mu\right)}\frac{\esp L^{2}}{2\esp C}
-\sigma^{2}\frac{\esp L}{2\esp C}\cdot\frac{1-2\mu}{\left(1-\mu\right)^{2}\mu^{2}}
\end{eqnarray*}

Retomando la ecuaci\'on (\ref{Eq.Primer.Derivada.Q})

\begin{eqnarray*}
\left[\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\right]^{'}&=&\frac{PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}-R_{2}R_{1}PR_{3}^{'}}{\left(R_{2}R_{3}\right)^{2}}
=\frac{F\left(z\right)}{G\left(z\right)}
\end{eqnarray*}

donde 

\begin{eqnarray*}
F\left(z\right)&=&PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}^{'}-R_{2}R_{1}PR_{3}^{'}\\
G\left(z\right)&=&R_{2}^{2}R_{3}^{2}\\
G^{2}\left(z\right)&=&R_{2}^{4}R_{3}^{4}=\left(1-\mu\right)^{4}\mu^{4}
\end{eqnarray*}
y por tanto

\begin{eqnarray*}
G^{'}\left(z\right)&=&2R_{2}R_{3}\left[R_{2}^{'}R_{3}+R_{2}R_{3}^{'}\right]\\
G^{'}\left(1\right)&=&-2\left(1-\mu\right)\mu\left[\left(-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\right)\left(-\mu\right)+\left(1-\mu\right)\left(-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\right)\right]
\end{eqnarray*}


\begin{eqnarray*}
F^{'}\left(z\right)&=&\left[\left(R_{2}R_{3}\right)R_{1}^{''}
-\left(R_{1}R_{3}\right)R_{2}^{''}
-\left(R_{1}R_{2}\right)R_{3}^{''}
-2\left(R_{2}^{'}R_{3}^{'}\right)R_{1}\right]P
+2\left(R_{2}R_{3}\right)R_{1}^{'}P^{'}
+\left(R_{1}R_{2}R_{3}\right)P^{''}
\end{eqnarray*}

Por lo tanto, encontremos $F^{'}\left(z\right)G\left(z\right)+F\left(z\right)G^{'}\left(z\right)$:

\begin{eqnarray*}
&&F^{'}\left(z\right)G\left(z\right)+F\left(z\right)G^{'}\left(z\right)=
\left\{\left[\left(R_{2}R_{3}\right)R_{1}^{''}
-\left(R_{1}R_{3}\right)R_{2}^{''}
-\left(R_{1}R_{2}\right)R_{3}^{''}
-2\left(R_{2}^{'}R_{3}^{'}\right)R_{1}\right]P\right.\\
&&\left.+2\left(R_{2}R_{3}\right)R_{1}^{'}P^{'}
+\left(R_{1}R_{2}R_{3}\right)P^{''}\right\}R_{2}^{2}R_{3}^{2}
-\left\{\left[PR_{2}R_{3}R_{1}^{'}+R_{1}R_{2}R_{3}P^{'}
-R_{3}R_{1}PR_{2}^{'}\right.\right.\\
&&\left.\left.
-R_{2}R_{1}PR_{3}^{'}\right]\left[2R_{2}R_{3}\left(R_{2}^{'}R_{3}+R_{2}R_{3}^{'}\right)\right]\right\}
\end{eqnarray*}
Evaluando en $z=1$

\begin{eqnarray*}
&=&\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}^{''}-\left(1+R_{3}\right)^{2}R_{1}R_{3}^{3}R_{3}^{''}
-\left(1+R_{3}\right)^{3}R_{3}^{2}R_{1}R_{3}^{''}-2\left(1+R_{3}\right)^{2}R_{3}^{2}
\left(R_{3}^{'}\right)^{2}\\
&+&2\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}^{'}P^{'}
+\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}P^{''}
-2\left(1+R_{3}\right)^{2}R_{3}^{2}\left(1+2R_{3}\right)R_{3}^{'}R_{1}^{'}\\
&-&2\left(1+R_{3}\right)^{2}R_{3}^{2}R_{1}R_{3}^{'}\left(1+2R_{3}\right)P^{'}
+2\left(1+R_{3}\right)\left(1+2R_{3}\right)R_{3}^{3}R_{1}\left(R_{3}^{'}\right)^{2}\\
&+&2\left(1+R_{3}\right)^{2}\left(1+2R_{3}\right)R_{1}R_{3}R_{3}^{'}\\
&=&-\left(1-\mu\right)^{3}\mu^{3}R_{1}^{''}-\left(1-\mu\right)^{2}\mu^{2}R_{1}\left(1-2\mu\right)R_{3}^{''}
-\left(1-\mu\right)^{3}\mu^{3}R_{1}P^{''}\\
&+&2\left(1-\mu\right)\mu^{2}\left[\left(1-2\mu\right)R_{1}-\left(1-\mu\right)\right]\left(R_{3}^{'}\right)^{2}
-2\left(1-\mu\right)^{2}\mu R_{1}\left(1-2\mu\right)R_{3}^{'}\\
&-&2\left(1-\mu\right)^{3}\mu^{4}R_{1}^{'}-2\mu\left(1-\mu\right)\left(1-2\mu\right)R_{3}^{'}R_{1}^{'}
-2\mu^{3}\left(1-\mu\right)^{2}\left(1-2\mu\right)R_{1}R_{1}^{'}
\end{eqnarray*}

por tanto

\begin{eqnarray*}
\left[\frac{F\left(z\right)}{G\left(z\right)}\right]^{'}&=&\frac{1}{\mu^{3}\left(1-\mu\right)^{3}}\left\{
-\left(1-\mu\right)^{2}\mu^{2}R_{1}^{''}-\mu\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{3}^{''}
-\mu^{2}\left(1-\mu\right)^{2}R_{1}P^{''}\right.\\
&&\left.+2\mu\left[\left(1-2\mu\right)R_{1}-\left(1-\mu\right)\right]\left(R_{3}^{'}\right)^{2}
-2\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{3}^{'}-2\mu^{3}\left(1-\mu\right)^{2}R_{1}^{'}\right.\\
&&\left.-2\left(1-2\mu\right)R_{3}^{'}R_{1}^{'}-2\mu^{2}\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{1}^{'}\right\}
\end{eqnarray*}

recordemos que


\begin{eqnarray*}
R_{1}&=&-\esp L\\
R_{3}&=& -\mu\\
R_{1}^{'}&=&-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\\
R_{3}^{'}&=&-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\\
R_{1}^{''}&=&-\frac{1}{3}\esp L^{3}+\esp L^{2}-\frac{2}{3}\esp L\\
R_{3}^{''}&=&-\frac{1}{3}\esp X^{3}+\esp X^{2}-\frac{2}{3}\mu\\
R_{1}R_{3}^{'}&=&\frac{1}{2}\esp X^{2}\esp L-\frac{1}{2}\esp X\esp L\\
R_{1}R_{1}^{'}&=&\frac{1}{2}\esp L^{2}\esp L+\frac{1}{2}\esp^{2}L\\
R_{3}^{'}R_{1}^{'}&=&\frac{1}{4}\esp X^{2}\esp L^{2}-\frac{1}{4}\esp X^{2}\esp L-\frac{1}{4}\esp L^{2}\esp X+\frac{1}{4}\esp X\esp L\\
R_{1}R_{3}^{''}&=&\frac{1}{6}\esp X^{3}\esp L^{2}-\frac{1}{6}\esp X^{3}\esp L-\frac{1}{2}\esp L^{2}\esp X^{2}+\frac{1}{2}\esp X^{2}\esp L+\frac{1}{3}\esp X\esp L^{2}-\frac{1}{3}\esp X\esp L\\
R_{1}P^{''}&=&-\esp X^{2}\esp L\\
\left(R_{3}^{'}\right)^{2}&=&\frac{1}{4}\esp^{2}X^{2}-\frac{1}{2}\esp X^{2}\esp X+\frac{1}{4}\esp^{2} X
\end{eqnarray*}




\begin{Def}
Let $L_{i}^{*}$ be the number of users at queue $Q_{i}$ when it is polled, then
\begin{eqnarray}
\begin{array}{cc}
\esp\left[L_{i}^{*}\right]=f_{i}\left(i\right), &
Var\left[L_{i}^{*}\right]=f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{array}
\end{eqnarray}
\end{Def}

\begin{Def}
The cycle time $C_{i}$ for the queue $Q_{i}$ is the period beginning at the time when it is polled in a cycle and ending at the time when it is polled in the next cycle; it's duration is given by $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, equivalently $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ under steady state assumption.
\end{Def}

\begin{Def}
The intervisit time $I_{i}$ is defined as the period beginning at the time of its service completion in a cycle and ending at the time when it is polled in the next cycle; its duration is given by $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}

The intervisit time duration $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$ given the number of users found at queue $Q_{i}$ at time $t=\tau_{i}\left(m+1\right)$ is equal to the number of arrivals during the preceding intervisit time $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$. 

So we have



\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

if $I_{i}\left(z\right)=\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]$
we have $F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]$
for $i=1,2$. Futhermore can be proved that

\begin{eqnarray}
\begin{array}{ll}
\esp\left[L_{i}\right]=\mu_{i}\esp\left[I_{i}\right], &
\esp\left[C_{i}\right]=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)},\\
\esp\left[S_{i}\right]=\mu_{i}\esp\left[C_{i}\right],&
\esp\left[I_{i}\right]=\left(1-\mu_{i}\right)\esp\left[C_{i}\right],\\
Var\left[L_{i}\right]= \mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right],& 
Var\left[C_{i}\right]=\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}},\\
Var\left[S_{i}\right]= \frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}},&
Var\left[I_{i}\right]= \frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{array}
\end{eqnarray}

Let consider the points when the process $\left[L_{1}\left(1\right),L_{2}\left(1\right),L_{3}\left(1\right),L_{4}\left(1\right)
\right]$ becomes zero at the same time, this points, $T_{1},T_{2},\ldots$ will be denoted as regeneration points, then we have that

\begin{Def}
the interval between two such succesive regeneration points will be called regenerative cycle.
\end{Def}

\begin{Def}
Para $T_{i}$ se define, $M_{i}$, el n\'umero de ciclos de visita a la cola $Q_{l}$, durante el ciclo regenerativo, es decir, $M_{i}$ es un proceso de renovaci\'on.
\end{Def}

\begin{Def}
Para cada uno de los $M_{i}$'s, se definen a su vez la duraci\'on de cada uno de estos ciclos de visita en el ciclo regenerativo, $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$, que a su vez, tambi\'en es n proceso de renovaci\'on.
\end{Def}



Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente. Entonces 

\begin{equation}\label{Eq.Longitud.Tiempo.t}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}.
\end{equation}

Es decir, es posible determinar las longitudes de las colas a cualquier tiempo $t$. Entonces, determinando el primer momento es posible ver que


$M_{i}$ is an stopping time for the regenerative process with $\esp\left[M_{i}\right]<\infty$, from Wald's lemma follows that:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}
therefore 

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

Doing the following substitutions en (\ref{Corolario2}): $n\rightarrow t-\tau_{i}\left(m\right)$, $T \rightarrow \overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)$, $L_{n}\rightarrow L_{i}\left(t\right)$ and $F\left(z\right)=\esp\left[z^{L_{0}}\right]\rightarrow F_{i}\left(z\right)=\esp\left[z^{L_{i}\tau_{i}\left(m\right)}\right]$, 
we obtain

\begin{eqnarray}\label{Eq.Arribos.Primera}
\esp\left[\sum_{n=0}^{T-1}z^{L_{n}}\right]=
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray}



Por otra parte durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&
\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Por lo tanto

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
=\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}
+\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\left\{
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
+\esp\left[\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\right\}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\left\{
z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\right\}\\
&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

es decir

\begin{eqnarray}
\begin{array}{ll}
S^{'}\left(z\right)=-\sum_{k=1}^{+\infty}ka_{k}z^{k-1},& S^{(1)}\left(1\right)=-\sum_{k=1}^{+\infty}ka_{k}=-\esp\left[L\left(t\right)\right],\\
S^{''}\left(z\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}z^{k-2},& S^{(2)}\left(1\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}=\esp\left[L\left(L-1\right)\right],\\
S^{'''}\left(z\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}z^{k-3},&
S^{(3)}\left(1\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}\\
&=-\esp\left[L\left(L-1\right)\left(L-2\right)\right]\\
&=-\esp\left[L^{3}\right]+3-\esp\left[L^{2}\right]-2-\esp\left[L\right];
\end{array}
\end{eqnarray}






%\section{Existencia de Tiempos de Regeneraci\'on}
%___________________________________________________________
%


\section{Introduction}
%______________________________________________________________________

A cyclic polling system consists of multiple queues that are served by a single server in cyclic order. Users arrive at each queue according to independent processes, which also are independent of the service times. The server attends each queue according to a service policy previously established. The most commonly service policies studied are the exhaustive, gated and the k-limited. The exhaustive policy consists in attending all users until the queue is emptied. When the server finishes, it moves to the next queue incurring in a switchover time that is an independent and identically distributed random variable. An exhaustive analysis have been made in this subject. For an overview of the literature on polling systems, their applications and standard results we refer to surveys such as: \cite{Boxma, Kleinrock, LevySidi, Semenova, TakagiI, Takagi}. 

Bos and Boon \cite{BosBoon} published a report where they studied a Network of Polling Systems applied to a traffic problem, there they analyzed a network of intersections and followed a path in it. Their objective was to predict if the costumers can pass through the network in a finite time or not. The buffer occupancy method was used in this analysis and simulation techniques were also used to verify the results. It is important to remark that the heavy traffic case was studied in this report, as well as the cyclic case was not considered.

In this work, we study a Network of Cyclic Polling Systems (NCPS) that consists of two cyclic polling systems, each of them conformed by two queues attended by a single server. We apply the buffer occupancy method described by Kleinrock and Takagi \cite{TakagiI}. This method is based on the use of the Probability Generating Function (PGF) of the joint distribution function of the queues lengths at the moment the server starts a visit period in each of the queues that conform the system.

We present a theorem that guarantees the stability for the NCPS under specific conditions, also we obtain explicit expressions for the queue lengths at the moment the server arrives. With this results we obtain the queue lengths of the NCPS at any time for the servers.

We believe these results can be generalized for the continuous case and from the point of view of applications, the results are useful because they allow us to obtain analytical expressions for the performance measures, and also give us the keys to determine waiting times and queue lengths for any time during the operation of the network. Initially our main goal was studying the system of public transportation, which can be seen as a network consisting of several cyclic polling systems.

%_________________________________________________________________________
%
\section{Construcci\'on del Modelo e Hip\'otesis}
%_________________________________________________________________________
%
\begin{figure}[H]\caption{Network of Cyclic Polling System with simple transfer}
\centering
\includegraphics[width=7cm]{Grafica3.jpg}
\end{figure}\label{FigureRSVC}

Consider a Network consisting of two cyclic polling systems with two queues each, $Q_{1}, Q_{2}$ for the first system and $\hat{Q}_{1},\hat{Q}_{2}$ for the second one, each of them with infinite-sized buffer. In each system a single server visits the queues in cyclic order, where it applies the exhaustive policy, i.e., when the server polls a queue, it serves all the customers present until the queue becomes empty. This case is illustrated in \texttt{Figure 1}. 

The second system's users at queue 2, can moves to the first system after being attended, also we assume that the network is open; that is, all customers eventually leave the network. As usually in polling systems theory we assume the arrivals in each queue are Poisson processes from with independent identical distributed (i.i.d.) inter arrival exponential times. The service times are exponential independent and identically distributed random variables. Finally upon completion of a visit at any queue, the servers incurs in a random switchover time according to an arbitrary distribution. We define a cycle to be the time interval between two consecutive polling instants, the time period in a cycle during which the server is attending a queue is called a service period. We are considering the case where the server visit the queues in cyclic order.

Time is slotted with slot size equal to the service time of a fixed costumer, we call the time interval $\left[t,t+1\right]$ the $t$-th slot. The arrival processes are denoted by $X_{1}\left(t\right),X_{2}\left(t\right)$ for the first system and $\hat{X}_{1}\left(t\right)$, $\hat{X}_{2}\left(t\right)$ for the second, the arrival rate at $Q_{i}$ and $\hat{Q}_{i}$ is denoted by $\mu_{i}$ and $\hat{\mu}_{i}$ respectively, with the condition $\mu_{i}<1$ and $\hat{\mu}_{i}<1$. The second system's users pass to the first one according to a process $Y_{2}$, with arrival rate $\tilde{\mu}_{2}$. 

Let's denote by $\tau_{i}$ the polling instant at queue $Q_{1}$ and by $\overline{\tau}_{i}$ the instant when the servers leaves to queue and starts a switchover time. Like the rest of the random variables the swithcover period is an i.i.d random variable $R_{i}$ with general distribution. 


To determine the length of the queues, i.e., the number of users in the queue at the moment the server arrives we define the process $L_{i}$ and $\hat{L}_{i}$ for the first and second system, respectively, in the sequel we use the buffer occupancy method to obtain the generating function, first and second moments of queue size distributions at polling instants. At each of the queues in the network the number of users is the number of users at the time the server arrives plus the numbers of users from the other system. 


In order to obtain the joint probability generating function (PGF) for the number or users residing in queue $i$ when the queue is polled in the NCPS, we define for each of the arrival processes $X_{1},X_{2},\hat{X}_{1},\hat{X}_{2},Y_{2}$, and $\tilde{X}_{2}$ with $\tilde{X}_{2}=X_{2}+Y_{2}$, their PGF

\begin{eqnarray*}
\begin{array}{cc}
P_{i}\left(z_{i}\right)=\esp\left[z_{i}^{X_{i}\left(t\right)}\right],&
\hat{P}_{i}\left(w_{i}\right)=\esp\left[w_{i}^{\hat{X}_{i}\left(t\right)}\right]
\end{array}
\end{eqnarray*}
for $i=1,2$, and
\begin{eqnarray*}
\begin{array}{cc}
\check{P}_{2}\left(z_{2}\right)=\esp\left[z_{2}^{Y_{2}\left(t\right)}\right],& \tilde{P}_{2}\left(z_{2}\right)=\esp\left[z_{2}^{\tilde{X}_{2}\left(t\right)}
\right],
\end{array}
\end{eqnarray*}

for $i=1,2$, and
\begin{eqnarray*} 
\begin{array}{cc}
\check{\mu}_{2}=\esp\left[Y_{2}\left(t\right)\right]=\check{P}_{2}^{(1)}
\left(1\right),&
\tilde{\mu}_{2}=\esp\left[\tilde{X}_{2}\left(t\right)\right]
=\tilde{P}_{2}^{(1)}\left(1\right).
\end{array}
\end{eqnarray*} The PGF For the service time is defined by:

\begin{eqnarray*}
\begin{array}{cc}
S_{i}\left(z_{i}\right)=\esp\left[z_{i}^{\overline{\tau}_{i}-\tau_{i}}
\right], &
\hat{S}_{i}\left(w_{i}\right)=\esp\left[w_{i}^{\overline{\zeta}_{i}-\zeta_{i}}\right]
\end{array}
\end{eqnarray*} with first moment 
\begin{eqnarray*}
\begin{array}{cc}
s_{i}=\esp\left[\overline{\tau}_{i}-\tau_{i}\right],&\hat{s}_{i}=\esp\left[\overline{\zeta}_{i}-\zeta_{i}\right]
\end{array}
\end{eqnarray*} for $i=1,2$. In a similar manner the PGF for the switchover time of the server from the moment it ends to attend a queue, to the time of arrival to the next queue is given by 
\begin{eqnarray*}
\begin{array}{cc}
R_{i}\left(z_{i}\right)=\esp\left[z_{1}^{\tau_{i+1}-\overline{\tau}_{i}}\right],&
\hat{R}_{i}\left(w_{i}\right)=\esp\left[w_{i}^{\zeta_{i+1}-\overline{\zeta}_{i}}\right]
\end{array}
\end{eqnarray*} with first moment 

\begin{eqnarray*}
\begin{array}{cc}
r_{i}=\esp\left[\tau_{i+1}-\overline{\tau}_{i}\right],&
\hat{r}_{i}=\esp\left[\zeta_{i+1}-\overline{\zeta}_{i}\right]
\end{array}
\end{eqnarray*} for $i=1,2$. The number of users in the queue at times $\overline{\tau}_{1},\overline{\tau}_{2}, \overline{\zeta}_{1},\overline{\zeta}_{2}$, it's zero, i.e.,
 $L_{i}\left(\overline{\tau_{i}}\right)=0,$ and $\hat{L}_{i}\left(\overline{\zeta_{i}}\right)=0$ for $i=1,2$. Then the number of users in the queue of the second system at the moment the server ends attending in the queue is given by the number of users present at the moment it arrives plus the number of arrivals during the service time, i.e.,
$$\hat{L}_{i}\left(\overline{\tau}_{j}\right)=\hat{L}_{i}\left(\tau_{j}\right)+\hat{X}_{i}\left(\overline{\tau}_{j}-\tau_{j}\right),$$
for $i,j=1,2$, meanwhile for the first system : $$L_{1}\left(\overline{\tau}_{j}\right)=L_{1}\left(\tau_{j}\right)+X_{1}\left(\overline{\tau}_{j}-\tau_{j}\right).$$ Specifically for the second queue of the first system we need to consider the users of transfer becoming from the second queue in the second system while the server its in the other queue attending, it means that this users have been already attended by the server before they can go to the first queue:

\begin{equation}\label{Eq.UsuariosTotalesZ2}
L_{2}\left(\overline{\tau}_{1}\right)=L_{2}\left(\tau_{1}\right)+X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)+Y_{2}\left(\overline{\tau}_{1}-\tau_{1}\right).
\end{equation}

As is know, the gambler's ruin problem can be used to model the server's busy period in a cyclic polling system, so let $\tilde{L}_{0}\geq0$ be the number of users present at the moment the server arrive to start attending, also let $T$ be the time the server need to attend the users in the queue starting with $\tilde{L}_{0}$ users. Suppose the gambler has two independent and simultaneous moves, such events are independent and identical to each other for each realization. The gain on the $n$-th game is $\tilde{\mathsf{X}}_{n}=\mathsf{X}_{n}+\mathsf{Y}_{n}$ units from which is substracted a playing fee of 1 unit for each move. His PGF is given by $F\left(z\right)=\esp\left[z^{\tilde{L}_{0}}\right]$, futhermore
%$\tilde{\mathrm{X}}$, $\tilde{\mathit{X}}$, $\tilde{\mathcal{X}}$, $\tilde{\mathfrak{X}}$,$\tilde{\mathbb{X}}$,$\tilde{\mathtt{X}}$,$\tilde{\mathsf{X}}$,

$$\tilde{P}\left(z\right)=\esp\left[z^{\tilde{\mathsf{X}}_{n}}\right]=\esp\left[z^{\mathsf{X}_{n}+\mathsf{X}_{n}}\right]=\esp\left[z^{\mathsf{X}_{n}}z^{\mathsf{X}_{n}}\right]=\esp\left[z^{\mathsf{X}_{n}}\right]\esp\left[z^{\mathsf{X}_{n}}\right]=P\left(z\right)\check{P}\left(z\right),$$ with $\tilde{\mu}=\esp\left[\tilde{\mathsf{X}}_{n}\right]=\tilde{P}\left[z\right]<1$. If  $\tilde{L}_{n}$ denotes the capital remaining after the $n$-th game, then $\tilde{L}_{n}=\tilde{L}_{0}+\tilde{\mathsf{X}}_{1}+\tilde{\mathsf{X}}_{2}+\cdots+\tilde{\mathsf{X}}_{n}-2n$. The result that relates the gambler's ruin problem with the busy period of the server it's a generalization of the result given in Takagi \cite{Takagi} chapter 3.

\begin{Prop}
Let's $G_{n}\left(z\right)$ and $G\left(z,w\right)$ defined as in 
(\ref{Eq.3.16.b.2S}), then $G_{n}\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right)$. Futhermore $G\left(z,w\right)=\frac{zF\left(z\right)-wP\left(z\right)G\left(0,w\right)}{z-wR\left(z\right)}$, with a unique pole in the unit circle, also the pole is of the form $z=\theta\left(w\right)$ and satisfies 
\begin{multicols}{3}
\begin{itemize}
\item[i)]$\tilde{\theta}\left(1\right)=1$,

\item[ii)] $\tilde{\theta}^{(1)}\left(1\right)=\frac{1}{1-\tilde{\mu}}$,

\item[iii)]
$\tilde{\theta}^{(2)}\left(1\right)=\frac{\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}+\frac{\tilde{\sigma}}{\left(1-\tilde{\mu}\right)^{3}}$.
\end{itemize}
\end{multicols}
\end{Prop}
%_________________________________________________________________________
%
\subsection{Description of the model: Probability Generating Function}
%_________________________________________________________________________
%

In order to model the network of cyclic polling system it's necessary to consider the users arrivals to each queue in one of the system, but on times the other system's server arrival, $\zeta_{i}$. In the case of the first system and the server arrives to a queue in the second one: $$F_{i,j}\left(z_{i};\zeta_{j}\right)=\esp\left[z_{i}^{L_{i}\left(\zeta_{j}\right)}\right]=
\sum_{k=0}^{\infty}\prob\left[L_{i}\left(\zeta_{j}\right)
=k\right]z_{i}^{k},$$ for $i,j=1,2$. Now consider the case of the queues in the second system and the server arrive to a queue in the first system $$\hat{F}_{i,j}\left(w_{i};\tau_{j}\right)=\esp\left[w_{i}^{\hat{L}_{i}\left(\tau_{j}\right)}\right] =\sum_{k=0}^{\infty}\prob\left[\hat{L}_{i}\left(\tau_{j}\right)
=k\right]w_{i}^{k},$$ for $i,j=1,2$. With the developed we can define the joint PGF for the second system:
$$\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{j}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{j}\right)}\right]
=\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{j}\right)}\right]
\esp\left[w_{2}^{\hat{L}_{2}\left(\tau_{j}\right)}\right]=\hat{F}_{1,j}\left(w_{1};\tau_{j}\right)\hat{F}_{2,j}\left(w_{2};\tau_{j}\right)\equiv\hat{\mathbf{F}}_{j}\left(w_{1},w_{2};\tau_{j}\right).$$
%\end{eqnarray*}

In a similar manner we define the joint PGF for the first system, and the second system's server:
%\begin{eqnarray*}
$$\esp\left[z_{1}^{L_{1}\left(\zeta_{j}\right)}z_{2}^{L_{2}\left(\zeta_{j}\right)}\right]
=\esp\left[z_{1}^{L_{1}\left(\zeta_{j}\right)}\right]
\esp\left[z_{2}^{L_{2}\left(\zeta_{j}\right)}\right]=F_{1,j}\left(z_{1};\zeta_{j}\right)F_{2,j}\left(z_{2};\zeta_{j}\right)\equiv\mathbf{F}_{j}\left(z_{1},z_{2};\zeta_{j}\right).$$
%\end{eqnarray*}

Now we proceed to determine the joint PGF for the times that the server visit each queue in their corresponding system, i.e., $t=\left\{\tau_{1},\tau_{2},\zeta_{1},\zeta_{2}\right\}$:

\begin{eqnarray}\label{Eq.Conjuntas}
\begin{array}{l}
\mathbf{F}_{j}\left(z_{1},z_{2},w_{1},w_{2}\right)=\esp\left[\prod_{i=1}^{2}z_{i}^{L_{i}\left(\tau_{j}
\right)}\prod_{i=1}^{2}w_{i}^{\hat{L}_{i}\left(\tau_{j}\right)}\right],\\
\hat{\mathbf{F}}_{j}\left(z_{1},z_{2},w_{1},w_{2}\right)=\esp\left[\prod_{i=1}^{2}z_{i}^{L_{i}
\left(\zeta_{j}\right)}\prod_{i=1}^{2}w_{i}^{\hat{L}_{i}\left(\zeta_{j}\right)}\right],
\end{array}
\end{eqnarray} for $j=1,2$. Then with the purpose of find the number of users present in the netwotk when the server ends attending one of the queues in any of the systems we have that

\begin{eqnarray*}
&&\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}w_{1}^{\hat{L}_{1}\left(\overline{\tau}_{1}\right)}w_{2}^{\hat{L}_{2}\left(\overline{\tau}_{1}\right)}\right]
=\esp\left[z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}w_{1}^{\hat{L}_{1}\left(\overline{\tau}_{1}
\right)}w_{2}^{\hat{L}_{2}\left(\overline{\tau}_{1}\right)}\right]\\
&=&\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)+X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)+Y_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)+\hat{X}_{1}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)+\hat{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right]
\end{eqnarray*}

using the equation (\ref{Eq.UsuariosTotalesZ2}) we have


\begin{eqnarray*}
&=&\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}z_{2}^{X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}z_{2}^{Y_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{1}^{\hat{X}_{1}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}w_{2}^{\hat{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right]\\
&=&\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\left\{w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right\}\left\{z_{2}^{X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}
z_{2}^{Y_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{1}^{\hat{X}_{1}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{2}^{\hat{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right\}\right]
\end{eqnarray*}

applying the fact that the arrivals processes in the queues in each systems are independent:

$$=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\left\{z_{2}^{X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}z_{2}^{Y_{2}\left(\overline{\tau}_{1}-
\tau_{1}\right)}w_{1}^{\hat{X}_{1}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{2}^{\hat{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right\}\right]
\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right]$$ given that the arrival processes in the queues are independent, it's possible to separate the expectation for the arrival processes in $Q_{1}$ and $Q_{2}$ at time $\tau_{1}$, which is the time the server visits $Q_{1}$. Considering
$\tilde{X}_{2}\left(z_{2}\right)=X_{2}\left(z_{2}\right)+Y_{2}\left(z_{2}\right)$ we have


\begin{eqnarray*}
\begin{array}{l}
=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\left\{z_{2}^{\tilde{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}w_{1}^{\hat{X}_{1}\left(\overline{\tau}_{1}
-\tau_{1}\right)}
w_{2}^{\hat{X}_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right\}\right]\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}
w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right]\\
=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\left\{\tilde{P}_{2}\left(z_{2}\right)
^{\overline{\tau}_{1}-\tau_{1}}\hat{P}_{1}\left(w_{1}\right)^{\overline{\tau}_{1}-
\tau_{1}}\hat{P}_{2}\left(w_{2}\right)^{\overline{\tau}_{1}-\tau_{1}}\right\}\right]
\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right]\\
=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\left\{\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right\}^{\overline{\tau}_{1}-\tau_{1}}\right]\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right]\\
=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)}\theta_{1}\left(\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right)
^{L_{1}\left(\tau_{1}\right)}\right]\esp\left[w_{1}^{\hat{L}_{1}\left(\tau_{1}\right)}w_{2}^{\hat{L}_{2}\left(\tau_{1}\right)}\right]\\
=F_{1}\left(\theta_{1}\left(\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),z_{2}\right)\cdot
\hat{F}_{1}\left(w_{1},w_{2};\tau_{1}\right)\\
\equiv \mathbf{F}_{1}\left(\theta_{1}\left(\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),z_{2},w_{1},w_{2}\right).
\end{array}
\end{eqnarray*}

The last equalities  are true because the number of arrivals to $\hat{Q}_{2}$ 
during the time interval $\left[\tau_{1},\overline{\tau}_{1}\right]$ still haven't been attended by the server in the system 2, then the users can't pass to the first system through the queue $Q_{2}$. Therefore the number of users switching from $\hat{Q}_{2}$ to $Q_{2}$ during the time interval $\left[\tau_{1},\overline{\tau}_{1}\right]$ depends on the policy of transfer between the two systems, according to the last section
%{\small{
\begin{eqnarray*}\label{Eq.Fs}
\begin{array}{l}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}
\right)}w_{1}^{\hat{L}_{1}\left(\overline{\tau}_{1}\right)}w_{2}^{\hat{L}_{2}\left(
\overline{\tau}_{1}\right)}\right]
=\mathbf{F}_{1}\left(\theta_{1}\left(\tilde{P}_{2}\left(z_{2}\right)
\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),z_{2},w_{1},w_{2}\right)\\
\equiv F_{1}\left(\theta_{1}\left(\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),z_{2}\right)\hat{F}_{1}\left(w_{1},w_{2};\tau_{1}\right).
\end{array}
\end{eqnarray*}%}}

Using similar reasoning for the rest of the server's arrival times we have that

\begin{eqnarray*}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{2}\right)}w_{1}^{\hat{L}_{1}\left(\overline{\tau}_{2}\right)}w_{2}^{\hat{L}_{2}\left(\overline{\tau}_{2}\right)}\right]&=&F_{2}\left(z_{1},\tilde{\theta}_{2}\left(P_{1}\left(z_{1}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right)\right)
\hat{F}_{2}\left(w_{1},w_{2};\tau_{2}\right)\\
&\equiv& \mathbf{F}_{2}\left(z_{1},\tilde{\theta}_{2}\left(P_{1}\left(z_{1}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),w_{1},w_{2}\right),\\
\esp\left[z_{1}^{L_{1}\left(\overline{\zeta}_{1}\right)}z_{2}^{L_{2}\left(\overline{\zeta}_{1}
\right)}w_{1}^{\hat{L}_{1}\left(\overline{\zeta}_{1}\right)}w_{2}^{\hat{L}_{2}\left(\overline{\zeta}_{1}\right)}\right]
&=&F_{1}\left(z_{1},z_{2};\zeta_{1}\right)\hat{F}_{1}\left(\hat{\theta}_{1}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{2}\left(w_{2}\right)\right),w_{2}\right)\\
&\equiv&\hat{\mathbf{F}}_{1}\left(z_{1},z_{2},\hat{\theta}_{1}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{2}\left(w_{2}\right)\right),w_{2}\right),\\
\esp\left[z_{1}^{L_{1}\left(\overline{\zeta}_{2}\right)}z_{2}^{L_{2}\left(\overline{\zeta}_{2}\right)}w_{1}^{\hat{L}_{1}\left(\overline{\zeta}_{2}\right)}w_{2}^{\hat{L}_{2}\left(\overline{\zeta}_{2}\right)}\right]
&=&F_{2}\left(z_{1},z_{2};\zeta_{2}\right)\hat{F}_{2}\left(w_{1},\hat{\theta}_{2}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\right)\right)\\
&\equiv&\hat{\mathbf{F}}_{2}\left(z_{1},z_{2},w_{1},\hat{\theta}_{2}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}\right)\right)\right).
\end{eqnarray*}

Now we are in conditions to obtain the recursive equations that model the NCPS. We need to consider the switchover times that the server need to translate from one queue to another and, the number or user presents in the system at the time the server leaves to the queue to start attending the next. Thus far developed, we can find that for the NCPS:

\begin{eqnarray}\label{Recursive.Equations.First.Casse}
\begin{array}{r}
\mathbf{F}_{2}\left(z_{1},z_{2},w_{1},w_{2}\right)=R_{1}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}
\left(z_{2}\right)\prod_{i=1}^{2}
\hat{P}_{i}\left(w_{i}\right)\right)\mathbf{F}_{1}\left(\theta_{1}\left(\tilde{P}_{2}\left(z_{2}
\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}\right)\right),z_{2},w_{1},w_{2}\right),\\
\mathbf{F}_{1}\left(z_{1},z_{2},w_{1},w_{2}\right)=R_{2}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}
\left(z_{2}\right)\prod_{i=1}^{2}
\hat{P}_{i}\left(w_{i}\right)\right)\mathbf{F}_{2}\left(z_{1},\tilde{\theta}_{2}\left(P_{1}\left(z_{1}\right)\hat{P}_{1}\left(w_{1}\right)\hat{P}_{2}\left(w_{2}
\right)\right),w_{1},w_{2}\right),\\
\hat{\mathbf{F}}_{2}\left(z_{1},z_{2},w_{1},w_{2}\right)=\hat{R}_{1}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\prod_{i=1}^{2}
\hat{P}_{i}\left(w_{i}\right)\right)\hat{\mathbf{F}}_{1}\left(z_{1},z_{2},\hat{\theta}_{1}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{2}\left(w_{2}
\right)\right),w_{2}\right),\\
\hat{\mathbf{F}}_{1}\left(z_{1},z_{2},w_{1},w_{2}\right)=\hat{R}_{2}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\prod_{i=1}^{2}
\hat{P}_{i}\left(w_{i}\right)\right)\hat{\mathbf{F}}_{2}\left(z_{1},z_{2},w_{1},\hat{\theta}_{2}\left(P_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\hat{P}_{1}\left(w_{1}
\right)\right)\right).
\end{array}
\end{eqnarray}


\begin{figure}[H]\caption{Network of Cyclic Polling System with double bidirectional transfer}
\centering
\includegraphics[width=9cm]{Grafica4.jpg}
\end{figure}\label{FigureRSVC3}


%_____________________________________________________
%\subsubsection{Server Switchover times}
%_____________________________________________________
It's necessary to give an step ahead, considering the case illustrated in \texttt{Figure 2}, where just like before, the server's switchover times are given by the generals equations
$R_{i}\left(\mathbf{z,w}\right)=R_{i}\left(\tilde{P}_{1}\left(z_{1}\right)
\tilde{P}_{2}\left(z_{2}\right)\tilde{P}_{3}\left(z_{3}\right)
\tilde{P}_{4}\left(z_{4}\right)\right)$, with first order derivatives given by $D_{i}R_{i}=r_{i}\tilde{\mu}_{i}$, and second order partial derivatives $D_{j}D_{i}R_{k}=R_{k}^{(2)}\tilde{\mu}_{i}\tilde{\mu}_{j}+\indora_{i=j}r_{k}P_{i}^{(2)}+\indora_{i\neq j}r_{k}\tilde{\mu}_{i}\tilde{\mu}_{j}$ for any $i,j,k$. According to the equations given before and the queue lengths for the other system's server times, we can obtain general expressions

\begin{eqnarray}\label{Ec.Gral.Primer.Momento.Ind.Exh}
\begin{array}{ll}
D_{j}\mathbf{F}_{i}\left(z_{1},z_{2};\tau_{i+2}\right)=\indora_{j\leq2}F_{j,i+2}^{(1)},&
D_{j}\mathbf{F}_{i}\left(z_{3},z_{4};\tau_{i-2}\right)=\indora_{j\geq3}F_{j,i-2}^{(1)},
\end{array}
\end{eqnarray}

for $i,j=1,2,3,4$; with second order derivatives given by

\begin{eqnarray}\label{Ec.Gral.Segundo.Momento.Ind.Exh}
\begin{array}{l}
D_{j}D_{i}\mathbf{F}_{k}\left(z_{1},z_{2};\tau_{k+2}\right)=\indora_{i\geq3}\indora_{j=i}F_{i,k+2}^{(2)}+\indora_{i\geq 3}\indora_{j\neq i}F_{j,k-2}^{(1)}F_{i,k+2}^{(1)},\\
D_{j}D_{i}\mathbf{F}_{k}\left(z_{3},z_{4};\tau_{k-2}\right)=\indora_{i\geq3}\indora_{j=i}F_{i,k-2}^{(2)}+\indora_{i\geq 3}\indora_{j\neq i}F_{j,k-2}^{(1)}F_{i,k-2}^{(1)}.
\end{array}
\end{eqnarray}


 According with the developed at the moment, we can get the recursive equations which are of the following form

\begin{eqnarray}\label{General.System.Double.Transfer}
\begin{array}{l}
\mathbf{F}_{1}\left(z_{1},z_{2},z_{3},z_{4}\right)=R_{2}\left(\prod_{i=1}^{4}\tilde{P}_{i}\left(z_{i}
\right)\right)\mathbf{F}_{2}\left(z_{1},\tilde{\theta}_{2}\left(\tilde{P}_{1}\left(z_{1}\right)\tilde{P}_{3}\left(z_{3}\right)\tilde{P}_{4}
\left(z_{4}\right)\right),z_{3},z_{4}\right),\\
\mathbf{F}_{2}\left(z_{1},z_{2},z_{3},z_{4}\right)=R_{1}\left(\prod_{i=1}^{4}\tilde{P}_{i}\left(z_{i}
\right)\right)
\mathbf{F}_{1}\left(\tilde{\theta}_{1}\left(\tilde{P}_{2}\left(z_{2}\right)\tilde{P}_{3}\left(z_{3}
\right)\tilde{P}_{4}\left(z_{4}\right)\right),z_{2},z_{3},z_{4}\right),\\
\mathbf{F}_{3}\left(z_{1},z_{2},z_{3},z_{4}\right)=R_{4}\left(\prod_{i=1}^{4}\tilde{P}_{i}\left(z_{i}
\right)\right)\mathbf{F}_{4}\left(z_{1},z_{2},z_{3},\tilde{\theta}_{4}\left(\tilde{P}_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\tilde{P}_{3}\left(z_{3}\right)
\right)\right),\\
\mathbf{F}_{4}\left(z_{1},z_{2},z_{3},z_{4}\right)=R_{3}\left(\prod_{i=1}^{4}\tilde{P}_{i}\left(z_{i}
\right)\right)
\mathbf{F}_{3}\left(z_{1},z_{2},\tilde{\theta}_{3}\left(\tilde{P}_{1}\left(z_{1}\right)\tilde{P}_{2}\left(z_{2}\right)\tilde{P}_{4}
\left(z_{4}\right)\right),z_{4}\right).
\end{array}
\end{eqnarray}
%_________________________________________________________________________
%
%\subsection{Hipotesis sobre las colas}
%_________________________________________________________________________
%


So we have the first theorem

\begin{Teo}
Suppose  $\tilde{\mu}=\tilde{\mu}_{1}+\tilde{\mu}_{2}<1$, $\hat{\mu}=\tilde{\mu}_{3}+\tilde{\mu}_{4}<1$, then the number of users in the queues conforming the network of cyclic polling system (\ref{General.System.Double.Transfer}), when the server visit a queue can be found solving the linear system given by equations (\ref{Ec.Primer.Orden.General.Impar}) and (\ref{Ec.Primer.Orden.General.Par}):

\begin{eqnarray}\label{Ec.Primer.Orden.General.Impar}
\begin{array}{l}
f_{j}\left(i\right)=r_{j+1}\tilde{\mu}_{i}
+\indora_{i\neq j+1}f_{j+1}\left(j+1\right)\frac{\tilde{\mu}_{i}}{1-\tilde{\mu}_{j+1}}
+\indora_{i=j}f_{j+1}\left(i\right)
+\indora_{j=1}\indora_{i\geq3}F_{i,j+1}^{(1)}
+\indora_{j=3}\indora_{i\leq2}F_{i,j+1}^{(1)}
\end{array}
\end{eqnarray}
$j=1,3$ and $i=1,2,3,4$.

\begin{eqnarray}\label{Ec.Primer.Orden.General.Par}
\begin{array}{l}
f_{j}\left(i\right)=r_{j-1}\tilde{\mu}_{i}
+\indora_{i\neq j-1}f_{j-1}\left(j-1\right)\frac{\tilde{\mu}_{i}}{1-\tilde{\mu}_{j-1}}
+\indora_{i=j}f_{j-1}\left(i\right)
+\indora_{j=2}\indora_{i\geq3}F_{i,j-1}^{(1)}
+\indora_{j=4}\indora_{i\leq2}F_{i,j-1}^{(1)}
\end{array}
\end{eqnarray}
$j=2,4$ and $i=1,2,3,4$, whose solutions are:
%{\footnotesize{


\begin{eqnarray}
\begin{array}{l}
f_{i}\left(j\right)=\left(\indora_{j=i-1}+\indora_{j=i+1}\right)r_{j}\tilde{\mu}_{j}+\indora_{i=j}\left(\indora_{i\leq2}\frac{r\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)}{1-\tilde{\mu}}+\indora_{i\geq2}\frac{\hat{r}\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)}{1-\hat{\mu}}\right)\\
+\indora_{i=1}\indora_{j\geq3}\left(\tilde{\mu}_{j}\left(r_{i+1}+\frac{r\tilde{\mu}_{i+1}}{1-\tilde{\mu}}\right)+F_{j,i+1}^{(1)}\right)
+\indora_{i=3}\indora_{j\geq3}\left(\tilde{\mu}_{j}\left(r_{i+1}+\frac{\hat{r}\tilde{\mu}_{i+1}}{1-\hat{\mu}}\right)+F_{j,i+1}^{(1)}\right)\\
+\indora_{i=2}\indora_{j\leq2}\left(\tilde{\mu}_{j}\left(r_{i-1}+\frac{r\tilde{\mu}_{i-1}}{1-\tilde{\mu}}\right)+F_{j,i-1}^{(1)}\right)
+\indora_{i=4}\indora_{j\leq2}\left(\tilde{\mu}_{j}\left(r_{i-1}+\frac{\hat{r}\tilde{\mu}_{i-1}}{1-\hat{\mu}}\right)+F_{j,i-1}^{(1)}\right).
\end{array}
\end{eqnarray}
\end{Teo}
%______________________________________________________________________

\begin{Teo}
For the system given in (\ref{General.System.Double.Transfer}) we have that the second moments are in their general form

%{\small{
\begin{eqnarray}\label{Eq.Gral.Second.Order.Exhaustive}
\begin{array}{r}
f_{1}\left(i,k\right)=D_{k}D_{i}\left(R_{2}+\mathbf{F}_{2}+\indora_{i\geq3}\mathbf{F}_{4}\right)
+D_{i}R_{2}D_{k}\left(\mathbf{F}_{2}+\indora_{k\geq3}\mathbf{F}_{4}\right)
+D_{i}F_{2}D_{k}\left(R_{2}+\indora_{k\geq3}\mathbf{F}_{4}\right)\\
+\indora_{i\geq3}D_{i}\mathbf{F}_{4}D_{k}\left(R_{2}+\mathbf{F}_{2}\right)\\
f_{2}\left(i,k\right)=D_{k}D_{i}\left(R_{1}+\mathbf{F}_{1}+\indora_{i\geq3}\mathbf{F}_{3}\right)+D_{i}R_{1}D_{k}\left(\mathbf{F}_{1}+\indora_{k\geq3}\mathbf{F}_{3}\right)+D_{i}\mathbf{F}_{1}D_{k}\left(R_{1}+\indora_{k\geq3}\mathbf{F}_{3}\right)\\
+\indora_{i\geq3}D_{i}\mathbf{F}_{3}D_{k}\left(R_{1}+\mathbf{F}_{1}\right)\\
f_{3}\left(i,k\right)=D_{k}D_{i}\left(R_{4}+\indora_{i\leq2}\mathbf{F}_{2}+\mathbf{F}_{4}\right)+D_{i}\tilde{R}_{4}D_{k}\left(\indora_{k\leq2}\mathbf{F}_{2}+\mathbf{F}_{4}\right)+D_{i}\mathbf{F}_{4}D_{k}\left(R_{4}+\indora_{k\leq2}\mathbf{F}_{2}\right)\\
+\indora_{i\leq2}D_{i}\mathbf{F}_{2}D_{k}\left(R_{4}+\mathbf{F}_{4}\right)\\
f_{4}\left(i,k\right)=D_{k}D_{i}\left(R_{3}+\indora_{i\leq2}\mathbf{F}_{1}+\mathbf{F}_{3}\right)+D_{i}R_{3}D_{k}\left(\indora_{k\leq2}\mathbf{F}_{1}+\mathbf{F}_{3}\right)+D_{i}\mathbf{F}_{3}D_{k}\left(R_{3}+\indora_{k\leq2}\mathbf{F}_{1}\right)\\
+\indora_{i\leq2}D_{i}\mathbf{F}_{1}D_{k}\left(R_{3}+\mathbf{F}_{3}\right)
\end{array}
\end{eqnarray}%}}

\end{Teo}


\begin{Coro}\label{Coro.Second.Order.Eqs}
Conforming the equations given in (\ref{Eq.Gral.Second.Order.Exhaustive}) the second order moments are obtained solving the linear systems given by  (\ref{System.Second.Order.Moments.uno}). These solutions are 

\begin{eqnarray}\label{Sol.System.Second.Order.Exhaustive}
\begin{array}{ll}
f_{1}\left(1,1\right)=b_{3},&
f_{2}\left(2,2\right)=\frac{b_{2}}{1-b_{1}},\\
f_{1}\left(1,3\right)=a_{4}\left(\frac{b_{2}}{1-b_{1}}\right)+a_{5}K_{12}+K_{3},&
f_{1}\left(1,4\right)=a_{6}\left(\frac{b_{2}}{1-b_{1}}\right)+a_{7}K_{12}+K_{4},\\
f_{1}\left(3,3\right)=a_{8}\left(\frac{b_{2}}{1-b_{1}}\right)+K_{8},&
f_{1}\left(3,4\right)=a_{9}\left(\frac{b_{2}}{1-b_{1}}\right)+K_{9},\\
f_{1}\left(4,4\right)=a_{10}\left(\frac{b_{2}}{1-b_{1}}\right)+a_{5}K_{12}+K_{10},&
f_{2}\left(2,3\right)=a_{14}b_{3}+a_{15}K_{2}+K_{16},\\
f_{2}\left(2,4\right)=a_{16}b_{3}+a_{17}K_{2}+K_{17},&
f_{2}\left(3,3\right)=a_{18}b_{3}+K_{18},\\
f_{2}\left(3,4\right)=a_{19}b_{3}+K_{19},&
f_{2}\left(4,4\right)=a_{20}b_{3}+K_{20},\\
f_{3}\left(3,3\right)=\frac{b_{5}}{1-b_{4}},&
f_{4}\left(4,4\right)=b_{6},\\
f_{3}\left(1,1\right)=a_{21}b_{6}+K_{21},&
f_{3}\left(1,2\right)=a_{22}b_{6}+K_{22},\\
f_{3}\left(1,3\right)=a_{23}b_{6}+a_{24}K_{39}+K_{23},&
f_{3}\left(2,2\right)=a_{25}b_{6}+K_{25},\\
f_{3}\left(2,3\right)=a_{26}b_{6}+a_{27}K_{39}+K_{26},&
f_{4}\left(1,1\right)=a_{31}\left(\frac{b_{5}}{1-b_{4}}\right)+K_{31},\\
f_{4}\left(1,2\right)=a_{32}\left(\frac{b_{5}}{1-b_{4}}\right)+K_{32},&
f_{4}\left(1,4\right)=a_{33}\left(\frac{b_{5}}{1-b_{4}}\right)+a_{34}K_{29}+K_{31},\\
f_{4}\left(2,2\right)=a_{35}\left(\frac{b_{5}}{1-b_{4}}\right)+K_{35},&
f_{4}\left(2,4\right)=a_{36}\left(\frac{b_{5}}{1-b_{4}}\right)+a_{37}K_{29}+K_{37}.
\end{array}
\end{eqnarray}

where
\begin{eqnarray*}
\begin{array}{lll}
N_{1}=a_{2}K_{12}+a_{3}K_{11}+K_{1},&
N_{2}=a_{12}K_{2}+a_{13}K_{5}+K_{15},&
b_{1}=a_{1}a_{11},\\
b_{2}=a_{11}N_{1}+N_{2},&
b_{3}=a_{1}\left(\frac{b_{2}}{1-b_{1}}\right)+N_{1},&
N_{3}=a_{29}K_{39}+a_{30}K_{38}+K_{28},\\
N_{4}=a_{39}K_{29}+a_{40}K_{30}+K_{40},&
b_{4}=a_{28}a_{38},&
b_{5}=a_{28}N_{4}+N_{3},\\
&b_{6}=a_{38}\left(\frac{b_{5}}{1-b_{4}}\right)+N_{4}.&
\end{array}
\end{eqnarray*}

\end{Coro}
The values for the $a_{i}$'s and $K_{i}$ can be found in \textit{Appendix B}. Finally 

\begin{Def}
Let $L_{i}^{*}$ be the number of users at queue $Q_{i}$ when it is polled, then
\begin{eqnarray}
\begin{array}{cc}
\esp\left[L_{i}^{*}\right]=f_{i}\left(i\right), &
Var\left[L_{i}^{*}\right]=f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{array}
\end{eqnarray}
\end{Def}

%_________________________________________________________________________
%
\subsection{Stability Analysis}
%_________________________________________________________________________
%

We are interested in determine the queue lengths at any time, not just when the server arrives to the queue to start attending according to the exhaustive policy. For this purpose we need to make assumptions over the processes involved in order to guarantee the stability of the Network.



First of all we are going to assume the arrival processes are Poisson, the service time are exponential. In 1973 Disney \cite{Disney} prove that the only stationary system $M/G/1/L$, with renewal departure process are the $M/M/1$ y $M/D/1/1$ systems, also this implies that the output process is Poisson with the same rate of the arrival process. The switchover times has no particular distribution, the only condition they have to satisfy is the first moment finite.

Sigman, Thorison and Wolff \cite{Sigman2} proved that if there is a first regeneration time then exist a non decreasing infinite sequence of regeneration times. With this in consideration we have the following theorem 


\begin{Teo}\label{First.Regeneration.Time.Theorem}
Given a Network of Cyclic Polling Systems (NCPS) conformed by two cyclic polling systems, each of them with $M/M/1$ queues. Both systems are related by users transfer between the queues $Q_{1},Q_{3}$ and $Q_{2},Q_{4}$. Suppose $\tilde{\mu},\hat{\mu}<1$. Let's define the following events for the arrival processes at time $t$: $A_{j}\left(t\right)=\left\{0 \textrm{ arrivals on }Q_{j}\textrm{ at time }t\right\}$, for some $t\geq0$ and queue $Q_{j}$ in the NCPS for $j=1,2,3,4$. Then there exist an non empty interval $I$ such that for $T^{*}\in I$ the $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$ is satisfied.

\end{Teo}
\begin{proof}

Without of loss of generality we are going to consider as base of the analysis the queue $Q_{1}$ from the first system.

Let's $n\geq1$ cycle for the first system, so let's be $\overline{\tau}_{1}\left(n\right)$ time the server ends attending en queue $Q_{1}$, it means 
$L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$. The server incurrs in a switchover time to traslate to the other queue, which is a random variable whose realitation is $r_{1}\left(n\right)>0$, then we have that $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.

Let's be $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ the intreval with length $\xi_{1}=r_{1}\left(n\right)$. Given that the arrival times are exponentials with rate $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ and the transfer users process from queue $Q_{3}$ are exponentials with rate $\hat{\mu}_{1}$, we have that the event $A_{1}\left(t\right)$ has probability given by 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 

In the other side, for the queue $Q_{2}$, the time 
$\overline{\tau}_{2}\left(n-1\right)$ is such that 
$L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, it means, it's the time when the queue is emptied by the server en the previous cycle. So we have a second time interval $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$ so the event $A_{2}\left(t\right)$ has probability

\begin{equation}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},
\end{equation} 
with length 
$\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)$. Given the time intervals construction we have that $I_{1}\left(n\right)\subset I_{2}\left(n\right)$, therefore  $\xi_{1}\left(n\right)\leq\xi_{2}\left(n\right)$ so $-\xi_{1}\left(n\right)\geq-\xi_{2}\left(n\right)$ then $-\tilde{\mu}_{2}\xi_{1}\left(n\right)\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right)$ and finally $e^{-\tilde{\mu}_{2}\xi_{1}\left(n\right)}\geq e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}$, then

\begin{equation}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\geq
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}.
\end{equation}

Now we can determine the joint conditional probability on the interval $I_{1}\left(n\right)$
\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}

It means 
\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}

With respect the relation between both systems, there exists some $m\geq1$ such that $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$ therefore we have the following cases for $\tau_{2}\left(n\right)$:

\begin{multicols}{2}
\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$,

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$,

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$,

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$.
\end{itemize}
\end{multicols}

First consider the time interval $I_{3}\left(m\right)\equiv\left[\tau_{3}\left(m\right),\overline{\tau}_{3}\left(m\right)\right]$ such that $\tau_{2}\left(n\right)\in I_{3}\left(m\right)$, with length $\xi_{3}\equiv\overline{\tau}_{3}\left(m\right)-\tau_{3}\left(m\right)$, then we have for the queue $Q_{3}$
\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}.
\end{equation} 

whereas for $Q_{4}$ lets consider the time interval $I_{4}\left(m\right)\equiv\left[\tau_{4}\left(m-1\right),\overline{\tau}_{3}\left(m\right)\right]$, then we have that $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, therefore in a similar manner that we have done for $Q_{1}$ and $Q_{2}$ we obtain


\begin{equation}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\geq
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}
\end{equation}

and

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\geq
e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}>0.
\end{equation}


For the rest of the cases the demonstration is similar. It means we always can find a time interval where we can guarantee there is no arrivals to the queues in each system with positive probability.  


By construction we have that $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$, then in particular we have the following contentions $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ and $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, therefore if we define $\xi\left(n,m\right)$ as the length of the interval $I\left(n,m\right)$ we have $\xi\left(n,m\right)\leq\xi_{1}\left(n\right)$, $\xi\left(n,m\right)\leq\xi_{3}\left(m\right)$, then $-\xi\left(n,m\right)\geq-\xi_{1}\left(n\right)$ and finally $-\xi\left(n,m\right)\leq-\xi_{3}\left(m\right)$ therefore we have the following
\begin{multicols}{2}
\begin{enumerate}
\item $-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right)$,
\item $-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right)$,
\item $-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right)$,
\item $-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).$
\end{enumerate}
\end{multicols}

Let's $T^{*}\in I\left(n,m\right)$, then given that in particular $T^{*}\in I_{1}\left(n\right)$, there is no arrivals to the queues $Q_{1}$ and $Q_{2}$, therefore there is no transfer users from $Q_{3}$ and $Q_{4}$, it means, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, thats it, the events $A_{1}$ and $A_{3}$ are conditionally independent in the interval $I\left(n,m\right)$; the same goes for the events $A_{2}$ and $A_{4}$, therefore we have
%\small{
\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}

Now we only need to prove that for $n\ge1$, there exist an $m\geq1$ such that the cases mentioned before are satisfied: 

\begin{multicols}{2}
\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$,

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$,

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$,

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$.
\end{itemize}
\end{multicols}
We only give the proof for the fist case, for the rest the demonstration are similar. Suppose there is no $m\geq1$, with $I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$, it means that for all $m\geq1$, $I_{1}\left(n\right)\cap I_{3}\left(m\right)=\emptyset$, then we have only two cases

\begin{itemize}
\item[a)] $\tau_{2}\left(n\right)\leq\tau_{3}\left(m\right)$: Recall that $\tau_{2}\left(m\right)=\overline{\tau}_{1}+r_{1}\left(m\right)$ 
where each of the random variables are such that $\esp\left[\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)\right]<\infty$, $\esp\left[R_{1}\right]<\infty$ y $\esp\left[\tau_{3}\left(m\right)\right]<\infty$, which contradicts the fact that there is no such $m\geq1$.

\item[b)] $\tau_{2}\left(n\right)\geq\overline{\tau}_{3}\left(m\right)$: the reasoning is similar to the previous given.

\end{itemize}

\end{proof}


According to the stablished in Sigman, Thorison and Wolff \cite{Sigman2} theorem (\ref{First.Regeneration.Time.Theorem}) allow us to ensure that there is an infinite sequence of regeneration times, let $T_{1},T_{2},\ldots$ considered as the regeneration points, then we have that just like in Takagi \cite{Takagi}, the following definition

\begin{Def}
the interval between two such succesive regeneration points will be called regenerative cycle.
\end{Def}

And for the regeneration points 

\begin{Def}
Let $M_{i}$ be the number of polling cycles in a regenerative cycle.
\end{Def}

\begin{Def}
Considering the $M_{i}$'s, the duration of the $m$-th polling cycle in a regeneration cycle will be denoted by $C_{i}^{(m)}$, for $m=1,2,\ldots,M_{i}$.
\end{Def}

And finally, the mean polling cycle time is defined by

\begin{Def}
\begin{equation}
\esp\left[C_{i}\right]=\frac{\sum_{m=1}^{M_{i}}\esp\left[C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{equation}
\end{Def}

\begin{Teo}
The process $\left\{C_{i}:i=1,2,\ldots,M_{i}\right\}$ is a regenerative process. Also there exists a regenerative and stationary process as function of this process.
\end{Teo}

With this in mind let denote by $L_{i}$ the number of users at queue $Q_{i}$ at arbitrary times. Their generating probability function  will be denoted by $Q_{i}\left(z\right)$ which is also given by the time average of $z^{L_{i}\left(t\right)}$ over the regenerative cycled defined before so we have

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

which can be rewritten as

\begin{equation}\label{Eq.Long.Caulquier.Tiempo}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{equation}

If we define the following
\begin{eqnarray}
\begin{array}{ccc}
S\left(z\right)=1-F\left(z\right),&
T\left(z\right)=z-P\left(z\right),&
U\left(z\right)=1-P\left(z\right).
\end{array}
\end{eqnarray}
then 

\begin{eqnarray}
\esp\left[C_{i}\right]Q\left(z\right)=\frac{\left(z-1\right)S\left(z\right)P\left(z\right)}{T\left(z\right)U\left(z\right)}.
\end{eqnarray}

Where if we define $a_{k}=P\left\{L\left(t\right)=k\right\}$ then 
\begin{eqnarray*}
S\left(z\right)=1-F\left(z\right)=1-\sum_{k=0}^{+\infty}a_{k}z^{k}
\end{eqnarray*}
therefore $S^{'}\left(z\right)=-\sum_{k=1}^{+\infty}ka_{k}z^{k-1}$, with $S^{(1)}\left(1\right)=-\sum_{k=1}^{+\infty}ka_{k}=-\esp\left[L\left(t\right)\right]$,
and $S^{''}\left(z\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}z^{k-2}$ so  $S^{(2)}\left(1\right)=-\sum_{k=2}^{+\infty}k(k-1)a_{k}=\esp\left[L\left(L-1\right)\right]$;
in the same way we obtain $S^{'''}\left(z\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}z^{k-3}$ and $S^{(3)}\left(1\right)=-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}=-\esp\left[L\left(L-1\right)\left(L-2\right)\right]
=-\esp\left[L^{3}\right]+3-\esp\left[L^{2}\right]-2-\esp\left[L\right]$. 

it means

\begin{eqnarray}
\begin{array}{l}
S^{(1)}\left(1\right)=-\esp\left[L\left(t\right)\right],\\ S^{(2)}\left(1\right)=-\esp\left[L\left(L-1\right)\right]
=-\esp\left[L^{2}\right]+\esp\left[L\right],\\
S^{(3)}\left(1\right)=-\esp\left[L\left(L-1\right)\left(L-2\right)\right]
=-\esp\left[L^{3}\right]+3\esp\left[L^{2}\right]-2\esp\left[L\right].
\end{array}
\end{eqnarray}


expanding around $z=1$

\begin{eqnarray*}
S\left(z\right)&=&S\left(1\right)+\frac{S^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{S^{'}\left(1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}\\
&=&\left(z-1\right)R_{1}\left(z\right)
\end{eqnarray*}
with $R_{1}\left(z\right)\neq0$, given that $R_{1}\left(z\right)=-\esp\left[L\right]$ then

\begin{eqnarray}
R_{1}\left(z\right)&=&S^{'}\left(1\right)+\frac{S^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{S^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{S^{iv}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}
Calculating the derivatives and evaluating in $z=1$

\begin{eqnarray}
\begin{array}{l}
R_{1}\left(1\right)=S^{(1)}\left(1\right)=-\esp\left[L\right]\\
R_{1}^{(1)}\left(1\right)=\frac{1}{2}S^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[L^{2}\right]+\frac{1}{2}\esp\left[L\right]\\
R_{1}^{(2)}\left(1\right)=\frac{2}{3!}S^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[L^{3}\right]+\esp\left[L^{2}\right]-\frac{2}{3}\esp\left[L\right]
\end{array}
\end{eqnarray}

In a similar manner for $T\left(z\right)=z-P\left(z\right)$ can be found an expansion around $z=1$:

\begin{eqnarray*}
T\left(z\right)&=&T\left(1\right)+\frac{T^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{T^{'}\left(1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}\\
&=&\left(z-1\right)R_{2}\left(z\right)
\end{eqnarray*}

where
\begin{eqnarray}
\begin{array}{l}
T^{(1)}\left(1\right)=-\esp\left[X\left(t\right)\right]=-\mu,\\ T^{(2)}\left(1\right)=-\esp\left[X\left(X-1\right)\right]
=-\esp\left[X^{2}\right]+\esp\left[X\right]=-\esp\left[X^{2}\right]+\mu,\\
T^{(3)}\left(1\right)=-\esp\left[X\left(X-1\right)\left(X-2\right)\right]
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\esp\left[X\right]\\
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\mu.
\end{array}
\end{eqnarray}

therefore $R_{2}\left(1\right)\neq0$, because

\begin{eqnarray}\label{Eq.R2}
R_{2}\left(1\right)=1-\esp\left[X\right]=1-\mu
\end{eqnarray}
then 

\begin{eqnarray}
R_{2}\left(z\right)&=&T^{'}\left(1\right)+\frac{T^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{T^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{T^{(iv)}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}
Calculating the derivatives and evaluating $z=1$

\begin{eqnarray}
\begin{array}{l}
R_{2}\left(1\right)=T^{(1)}\left(1\right)=1-\mu\\
R_{2}^{(1)}\left(1\right)=\frac{1}{2}T^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\\
R_{2}^{(2)}\left(1\right)=\frac{2}{3!}T^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[X^{3}\right]+\esp\left[X^{2}\right]-\frac{2}{3}\mu
\end{array}
\end{eqnarray}
Finally proceeding in analogous manner for $U\left(z\right)=1-P\left(z\right)$ also can be found an expansion around $z=1$

\begin{eqnarray*}
\begin{array}{l}
U\left(z\right)=U\left(1\right)+\frac{U^{'}\left(1\right)}{1!}\left(z-1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
=\left(z-1\right)\left\{U^{'}\left(1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}
=\left(z-1\right)R_{3}\left(z\right)
\end{array}
\end{eqnarray*}

where

\begin{eqnarray*}
\begin{array}{l}
U^{(1)}\left(1\right)=-\esp\left[X\left(t\right)\right]=-\mu,\\ U^{(2)}\left(1\right)=-\esp\left[X\left(X-1\right)\right]
=-\esp\left[X^{2}\right]+\esp\left[X\right]=-\esp\left[X^{2}\right]+\mu,\\
U^{(3)}\left(1\right)=-\esp\left[X\left(X-1\right)\left(X-2\right)\right]
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\esp\left[X\right]\\
=-\esp\left[X^{3}\right]+3\esp\left[X^{2}\right]-2\mu.
\end{array}
\end{eqnarray*}

Therefore $R_{3}\left(1\right)\neq0$, because

\begin{eqnarray}\label{Eq.R3}
R_{3}\left(1\right)=-\esp\left[X\right]=-\mu
\end{eqnarray}
then

\begin{eqnarray}
R_{3}\left(z\right)&=&U^{'}\left(1\right)+\frac{U^{''}\left(1\right)}{2!}\left(z-1\right)+\frac{U^{'''}\left(1\right)}{3!}\left(z-1\right)^{2}+\frac{U^{(iv)}\left(1\right)}{4!}\left(z-1\right)^{3}+\ldots+
\end{eqnarray}

calculating the derivatives and evaluating in $z=1$

\begin{eqnarray}
\begin{array}{l}
R_{3}\left(1\right)=U^{(1)}\left(1\right)=-\mu\\
R_{3}^{(1)}\left(1\right)=\frac{1}{2}U^{(2)}\left(1\right)=-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\\
R_{3}^{(2)}\left(1\right)=\frac{2}{3!}U^{(3)}\left(1\right)
=-\frac{1}{3}\esp\left[X^{3}\right]+\esp\left[X^{2}\right]-\frac{2}{3}\mu
\end{array}
\end{eqnarray}

Then we have that 

\begin{eqnarray}
\esp\left[C_{i}\right]Q\left(z\right)&=&\frac{\left(z-1\right)\left(z-1\right)R_{1}\left(z\right)P\left(z\right)}{\left(z-1\right)R_{2}\left(z\right)\left(z-1\right)R_{3}\left(z\right)}
=\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\equiv\frac{R_{1}P}{R_{2}R_{3}}
\end{eqnarray}

Calcuating the derivative with respect $z$

\begin{eqnarray}\label{Ec.Primer.Derivada.Q}
\left[\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\right]^{'}&=&\frac{PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}-R_{2}R_{1}PR_{3}^{'}}{\left(R_{2}R_{3}\right)^{2}}
\end{eqnarray}
evauatong in $z=1$
\begin{eqnarray*}
&=&\frac{R_{2}(1)R_{3}(1)R_{1}^{(1)}(1)+R_{1}(1)R_{2}(1)R_{3}(1)P^{'}(1)-R_{3}(1)R_{1}(1)R_{2}(1)^{(1)}-R_{2}(1)R_{1}(1)R_{3}^{'}(1)}{\left(R_{2}(1)R_{3}(1)\right)^{2}}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{\left(-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\right)\left(1-\mu\right)\left(-\mu\right)+\left(-\esp L\right)\left(1-\mu\right)\left(-\mu\right)\mu\right.\\
&&\left.-\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\left(-\mu\right)\left(-\esp L\right)-\left(1-\mu\right)\left(-\esp L\right)\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{\left(-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\right)\left(\mu^{2}-\mu\right)
+\left(\mu^{2}-\mu^{3}\right)\esp L\right.\\
&&\left.-\mu\esp L\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)
+\left(\esp L-\mu\esp L\right)\left(-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\right)\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{-\frac{1}{2}\mu^{2}\esp L^{2}
+\frac{1}{2}\mu\esp L^{2}
+\frac{1}{2}\mu^{2}\esp L
-\mu^{3}\esp L
+\mu\esp L\esp X^{2}
-\frac{1}{2}\esp L\esp X^{2}\right\}\\
&=&\frac{1}{\left(1-\mu\right)^{2}\mu^{2}}\left\{
\frac{1}{2}\mu\esp L^{2}\left(1-\mu\right)
+\esp L\left(\frac{1}{2}-\mu\right)\left(\mu^{2}-\esp X^{2}\right)\right\}\\
&=&\frac{1}{2\mu\left(1-\mu\right)}\esp L^{2}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)^{2}\mu^{2}}\sigma^{2}\esp L
\end{eqnarray*}

Then we get (Takagi's formula)

\begin{eqnarray*}
Q^{(1)}=\frac{1}{\esp C}\left\{\frac{1}{2\mu\left(1-\mu\right)}\esp L^{2}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)^{2}\mu^{2}}\sigma^{2}\esp L\right\}
\end{eqnarray*}
with

\begin{eqnarray*}
\esp C = \frac{\esp L}{\mu\left(1-\mu\right)}
\end{eqnarray*}
therefore

\begin{eqnarray*}
Q^{(1)}&=&\frac{1}{2}\frac{\esp L^{2}}{\esp L}-\frac{\frac{1}{2}-\mu}{\left(1-\mu\right)\mu}\sigma^{2}
=\frac{\esp L^{2}}{2\esp L}-\frac{\sigma^{2}}{2}\left\{\frac{2\mu-1}{\left(1-\mu\right)\mu}\right\}\\
&=&\frac{\esp L^{2}}{2\esp L}+\frac{\sigma^{2}}{2}\left\{\frac{1}{1-\mu}+\frac{1}{\mu}\right\}
\end{eqnarray*}

while for us

\begin{eqnarray*}
Q^{(1)}=\frac{1}{\mu\left(1-\mu\right)}\frac{\esp L^{2}}{2\esp C}
-\sigma^{2}\frac{\esp L}{2\esp C}\cdot\frac{1-2\mu}{\left(1-\mu\right)^{2}\mu^{2}}.
\end{eqnarray*}

Now, reconsider the equation (\ref{Ec.Primer.Derivada.Q})

\begin{eqnarray*}
\left[\frac{R_{1}\left(z\right)P\left(z\right)}{R_{2}\left(z\right)R_{3}\left(z\right)}\right]^{'}&=&\frac{PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}-R_{2}R_{1}PR_{3}^{'}}{\left(R_{2}R_{3}\right)^{2}}
\equiv\frac{F\left(z\right)}{G\left(z\right)}
\end{eqnarray*}

where

\begin{eqnarray}
\begin{array}{l}
F\left(z\right)=PR_{2}R_{3}R_{1}^{'}
+R_{1}R_{2}R_{3}P^{'}-R_{3}R_{1}PR_{2}^{'}-R_{2}R_{1}PR_{3}^{'}\\
G\left(z\right)=R_{2}^{2}R_{3}^{2}\\
G^{2}\left(z\right)=R_{2}^{4}R_{3}^{4}=\left(1-\mu\right)^{4}\mu^{4}
\end{array}
\end{eqnarray}
so 

\begin{eqnarray}
\begin{array}{l}
G^{'}\left(z\right)=2R_{2}R_{3}\left[R_{2}^{'}R_{3}+R_{2}R_{3}^{'}\right]\\
G^{'}\left(1\right)=-2\left(1-\mu\right)\mu\left[\left(-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\right)\left(-\mu\right)+\left(1-\mu\right)\left(-\frac{1}{2}\esp\left[X^{2}\right]+\frac{1}{2}\mu\right)\right]\\
F^{'}\left(z\right)=\left[\left(R_{2}R_{3}\right)R_{1}^{''}
-\left(R_{1}R_{3}\right)R_{2}^{''}
-\left(R_{1}R_{2}\right)R_{3}^{''}
-2\left(R_{2}^{'}R_{3}^{'}\right)R_{1}\right]P
+2\left(R_{2}R_{3}\right)R_{1}^{'}P^{'}
+\left(R_{1}R_{2}R_{3}\right)P^{''}.
\end{array}
\end{eqnarray}

Now, let us calculate $F^{'}\left(z\right)G\left(z\right)+F\left(z\right)G^{'}\left(z\right)$:

\begin{eqnarray*}
&&F^{'}\left(z\right)G\left(z\right)+F\left(z\right)G^{'}\left(z\right)=
\left\{\left[\left(R_{2}R_{3}\right)R_{1}^{''}
-\left(R_{1}R_{3}\right)R_{2}^{''}
-\left(R_{1}R_{2}\right)R_{3}^{''}
-2\left(R_{2}^{'}R_{3}^{'}\right)R_{1}\right]P\right.\\
&&\left.+2\left(R_{2}R_{3}\right)R_{1}^{'}P^{'}
+\left(R_{1}R_{2}R_{3}\right)P^{''}\right\}R_{2}^{2}R_{3}^{2}
-\left\{\left[PR_{2}R_{3}R_{1}^{'}+R_{1}R_{2}R_{3}P^{'}
-R_{3}R_{1}PR_{2}^{'}\right.\right.\\
&&\left.\left.
-R_{2}R_{1}PR_{3}^{'}\right]\left[2R_{2}R_{3}\left(R_{2}^{'}R_{3}+R_{2}R_{3}^{'}\right)\right]\right\}
\end{eqnarray*}
now evaluate in $z=1$

\begin{eqnarray*}
F^{'}\left(1\right)G\left(1\right)&+&F\left(1\right)G^{'}\left(1\right)
=\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}^{''}-\left(1+R_{3}\right)^{2}R_{1}R_{3}^{3}R_{3}^{''}
-\left(1+R_{3}\right)^{3}R_{3}^{2}R_{1}R_{3}^{''}\\
&-&2\left(1+R_{3}\right)^{2}R_{3}^{2}
\left(R_{3}^{'}\right)^{2}\\
&+&2\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}^{'}P^{'}
+\left(1+R_{3}\right)^{3}R_{3}^{3}R_{1}P^{''}
-2\left(1+R_{3}\right)^{2}R_{3}^{2}\left(1+2R_{3}\right)R_{3}^{'}R_{1}^{'}\\
&-&2\left(1+R_{3}\right)^{2}R_{3}^{2}R_{1}R_{3}^{'}\left(1+2R_{3}\right)P^{'}
+2\left(1+R_{3}\right)\left(1+2R_{3}\right)R_{3}^{3}R_{1}\left(R_{3}^{'}\right)^{2}\\
&+&2\left(1+R_{3}\right)^{2}\left(1+2R_{3}\right)R_{1}R_{3}R_{3}^{'}\\
&=&-\left(1-\mu\right)^{3}\mu^{3}R_{1}^{''}-\left(1-\mu\right)^{2}\mu^{2}R_{1}\left(1-2\mu\right)R_{3}^{''}
-\left(1-\mu\right)^{3}\mu^{3}R_{1}P^{''}\\
&+&2\left(1-\mu\right)\mu^{2}\left[\left(1-2\mu\right)R_{1}-\left(1-\mu\right)\right]\left(R_{3}^{'}\right)^{2}
-2\left(1-\mu\right)^{2}\mu R_{1}\left(1-2\mu\right)R_{3}^{'}\\
&-&2\left(1-\mu\right)^{3}\mu^{4}R_{1}^{'}-2\mu\left(1-\mu\right)\left(1-2\mu\right)R_{3}^{'}R_{1}^{'}
-2\mu^{3}\left(1-\mu\right)^{2}\left(1-2\mu\right)R_{1}R_{1}^{'}
\end{eqnarray*}
therefore
\begin{eqnarray*}
\left[\frac{F\left(z\right)}{G\left(z\right)}\right]^{'}&=&\frac{1}{\mu^{3}\left(1-\mu\right)^{3}}\left\{
-\left(1-\mu\right)^{2}\mu^{2}R_{1}^{''}-\mu\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{3}^{''}
-\mu^{2}\left(1-\mu\right)^{2}R_{1}P^{''}\right.\\
&&\left.+2\mu\left[\left(1-2\mu\right)R_{1}-\left(1-\mu\right)\right]\left(R_{3}^{'}\right)^{2}
-2\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{3}^{'}-2\mu^{3}\left(1-\mu\right)^{2}R_{1}^{'}\right.\\
&&\left.-2\left(1-2\mu\right)R_{3}^{'}R_{1}^{'}-2\mu^{2}\left(1-\mu\right)\left(1-2\mu\right)R_{1}R_{1}^{'}\right\}
\end{eqnarray*}
recall that


\begin{eqnarray*}
R_{1}&=&-\esp L\\
R_{3}&=& -\mu\\
R_{1}^{'}&=&-\frac{1}{2}\esp L^{2}+\frac{1}{2}\esp L\\
R_{3}^{'}&=&-\frac{1}{2}\esp X^{2}+\frac{1}{2}\mu\\
R_{1}^{''}&=&-\frac{1}{3}\esp L^{3}+\esp L^{2}-\frac{2}{3}\esp L\\
R_{3}^{''}&=&-\frac{1}{3}\esp X^{3}+\esp X^{2}-\frac{2}{3}\mu\\
R_{1}R_{3}^{'}&=&\frac{1}{2}\esp X^{2}\esp L-\frac{1}{2}\esp X\esp L\\
R_{1}R_{1}^{'}&=&\frac{1}{2}\esp L^{2}\esp L+\frac{1}{2}\esp^{2}L\\
R_{3}^{'}R_{1}^{'}&=&\frac{1}{4}\esp X^{2}\esp L^{2}-\frac{1}{4}\esp X^{2}\esp L-\frac{1}{4}\esp L^{2}\esp X+\frac{1}{4}\esp X\esp L\\
R_{1}R_{3}^{''}&=&\frac{1}{6}\esp X^{3}\esp L^{2}-\frac{1}{6}\esp X^{3}\esp L-\frac{1}{2}\esp L^{2}\esp X^{2}+\frac{1}{2}\esp X^{2}\esp L+\frac{1}{3}\esp X\esp L^{2}-\frac{1}{3}\esp X\esp L\\
R_{1}P^{''}&=&-\esp X^{2}\esp L\\
\left(R_{3}^{'}\right)^{2}&=&\frac{1}{4}\esp^{2}X^{2}-\frac{1}{2}\esp X^{2}\esp X+\frac{1}{4}\esp^{2} X
\end{eqnarray*}









\newpage
%______________________________________________________________________
\section{Appendix A: General Case Calculations Exhaustive Policy}\label{Secc.Append.B}
%______________________________________________________________________

%_______________________________________________________________
%\subsection{Calculations}
%_______________________________________________________________


Remember the equations given in equations (\ref{Ec.Gral.Primer.Momento.Ind.Exh}) and (\ref{Eq.Gral.Second.Order.Exhaustive}) for the first and second order partial derivatives respectively. The first moments equations for the queue lengths as before for the times the server arrives to the queue to start attending are obtained solving the system given by $f_{1}\left(i\right)=D_{i}R_{2}+D_{i}\mathbf{F}_{2}+\indora_{i\geq3}D_{i}\mathbf{F}_{4}$, similar expressions of the queues for the rest give us the linear system



\begin{eqnarray*}
\begin{array}{ll}
f_{1}\left(1\right)=r_{2}\tilde{\mu}_{1}+\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{2}}f_{2}\left(2\right)+f_{2}\left(1\right),&
f_{1}\left(2\right)=r_{2}\tilde{\mu}_{2},\\
f_{1}\left(3\right)=r_{2}\tilde{\mu}_{3}+\frac{\tilde{\mu}_{3}}{1-\tilde{\mu}_{2}}f_{2}\left(2\right)+F_{3,2}^{(1)}\left(1\right),&
f_{1}\left(4\right)=r_{2}\tilde{\mu}_{4}+\frac{\tilde{\mu}_{4}}{1-\tilde{\mu}_{2}}f_{2}\left(2\right)+F_{4,2}^{(1)}\left(1\right),\\
f_{2}\left(1\right)=r_{1}\tilde{\mu}_{1},&
f_{2}\left(2\right)=r_{1}\tilde{\mu}_{2}+\frac{\tilde{\mu}_{2}}{1-\tilde{\mu}_{1}}f_{1}\left(1\right)+f_{1}\left(2\right),\\
f_{2}\left(3\right)=r_{1}\tilde{\mu}_{3}+\frac{\tilde{\mu}_{3}}{1-\tilde{\mu}_{1}}f_{1}\left(1\right)+F_{3,1}^{(1)}\left(1\right),&
f_{2}\left(4\right)=r_{1}\tilde{\mu}_{4}+\frac{\tilde{\mu}_{4}}{1-\tilde{\mu}_{1}}f_{1}\left(1\right)+F_{4,1}^{(1)}\left(1\right),\\
f_{3}\left(1\right)=\tilde{r}_{4}\tilde{\mu}_{1}+\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{4}}f_{4}\left(4\right)+F_{1,4}^{(1)}\left(1\right),&
f_{3}\left(2\right)=\tilde{r}_{4}\tilde{\mu}_{2}+\frac{\tilde{\mu}_{2}}{1-\tilde{\mu}_{4}}f_{4}\left(4\right)+F_{2,4}^{(1)}\left(1\right),\\
f_{3}\left(3\right)=\tilde{r}_{4}\tilde{\mu}_{3}+\frac{\tilde{\mu}_{3}}{1-\tilde{\mu}_{4}}f_{4}\left(4\right)+f_{4}\left(3\right),&
f_{3}\left(4\right)=\tilde{r}_{4}\tilde{\mu}_{4}\\
f_{4}\left(1\right)=\tilde{r}_{3}\tilde{\mu}_{1}+\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{3}}f_{3}\left(3\right)+F_{1,3}^{(1)}\left(1\right),&
f_{4}\left(2\right)=\tilde{r}_{3}\mu_{2}+\frac{\tilde{\mu}_{2}}{1-\tilde{\mu}_{3}}f_{3}\left(3\right)+F_{2,3}^{(1)}\left(1\right),\\
f_{4}\left(3\right)=\tilde{r}_{3}\tilde{\mu}_{3},&
f_{4}\left(4\right)=\tilde{r}_{3}\tilde{\mu}_{4}+\frac{\tilde{\mu}_{4}}{1-\tilde{\mu}_{3}}f_{3}\left(3\right)+f_{3}\left(4\right),\\
\end{array}
\end{eqnarray*}

Then we have that if $\mu=\tilde{\mu}_{1}+\tilde{\mu}_{2}<1$, $\hat{\mu}=\tilde{\mu}_{3}+\tilde{\mu}_{4}<1$, $r=r_{1}+r_{2}$ and $\hat{r}=\tilde{r}_{3}+\tilde{r}_{4}$  the system's solution are obtained by direct calculations:

\begin{eqnarray*}
\begin{array}{ll}
f_{2}\left(1\right)=r_{1}\tilde{\mu}_{1},&
f_{1}\left(2\right)=r_{2}\tilde{\mu}_{2},\\
f_{3}\left(4\right)=r_{4}\tilde{\mu}_{4},&
f_{4}\left(3\right)=r_{3}\tilde{\mu}_{3},\\
f_{1}\left(1\right)=r\frac{\tilde{\mu}_{1}\left(1-\tilde{\mu}_{1}\right)}{1-\mu},&
f_{2}\left(2\right)=r\frac{\tilde{\mu}_{2}\left(1-\tilde{\mu}_{2}\right)}{1-\mu},\\
f_{1}\left(3\right)=\tilde{\mu}_{3}\left(r_{2}+\frac{r\tilde{\mu}_{2}}{1-\mu}\right)+F_{3,2}^{(1)}\left(1\right),&
f_{1}\left(4\right)=\tilde{\mu}_{4}\left(r_{2}+\frac{r\tilde{\mu}_{2}}{1-\mu}\right)+F_{4,2}^{(1)}\left(1\right),\\
f_{2}\left(3\right)=\tilde{\mu}_{3}\left(r_{1}+\frac{r\tilde{\mu}_{1}}{1-\tilde{\mu}}\right)+F_{3,1}^{(1)}\left(1\right),&
f_{2}\left(4\right)=\tilde{\mu}_{4}\left(r_{1}+\frac{r\tilde{\mu}_{1}}{1-\mu}\right)+F_{4,,1}^{(1)}\left(1\right),\\
f_{3}\left(1\right)=\tilde{\mu}_{1}\left(r_{4}+\frac{\hat{r}\tilde{\mu}_{4}}{1-\hat{\mu}}\right)+F_{1,4}^{(1)}\left(1\right),&
f_{3}\left(2\right)=\tilde{\mu}_{2}\left(r_{4}+\frac{\hat{r}\tilde{\mu}_{4}}{1-\hat{\mu}}\right)+F_{2,4}^{(1)}\left(1\right),\\
f_{3}\left(3\right)=\hat{r}\frac{\tilde{\mu}_{3}\left(1-\tilde{\mu}_{3}\right)}{1-\hat{\mu}},&
f_{4}\left(1\right)=\tilde{\mu}_{1}\left(r_{3}+\frac{\hat{r}\tilde{\mu}_{3}}{1-\hat{\mu}}\right)+F_{1,3}^{(1)}\left(1\right),\\
f_{4}\left(2\right)=\tilde{\mu}_{2}\left(r_{3}+\frac{\hat{r}\tilde{\mu}_{3}}{1-\hat{\mu}}\right)+F_{2,3}^{(1)}\left(1\right),&
f_{4}\left(4\right)=\hat{r}\frac{\tilde{\mu}_{4}\left(1-\tilde{\mu}_{4}\right)}{1-\hat{\mu}}.
\end{array}
\end{eqnarray*}

Now, developing the equations given in (\ref{Eq.Gral.Second.Order.Exhaustive}) we obtain for instance $f_{1}\left(1,1\right)=\left(\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{2}}\right)^{2}f_{2}\left(2,2\right)
+2\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{2}}f_{2}\left(2,1\right)
+f_{2}\left(1,1\right)
+\tilde{\mu}_{1}^{2}\left(R_{2}^{(2)}+f_{2}\left(2\right)\theta_{2}^{(2)}\right)
+\tilde{P}_{1}^{(2)}\left(\frac{f_{2}\left(2\right)}{1-\tilde{\mu}_{2}}+r_{2}\right)+2r_{2}\tilde{\mu}_{2}f_{2}\left(1\right)$; similar reasoning lead us the following general expressions

\begin{eqnarray}\label{Eq.Sdo.Orden.Exh.uno}
\begin{array}{l}
f_{1}\left(i,j\right)=\indora_{i=1}f_{2}\left(1,1\right)
+\left[\left(1-\indora_{i=j=3}\right)\indora_{i+j\leq6}\indora_{i\leq j}\frac{\mu_{j}}{1-\tilde{\mu}_{2}}
+\left(1-\indora_{i=j=3}\right)\indora_{i+j\leq6}\indora_{i>j}\frac{\mu_{i}}{1-\tilde{\mu}_{2}}\right.\\
\left.+\indora_{i=1}\frac{\mu_{i}}{1-\tilde{\mu}_{2}}\right]f_{2}\left(1,2\right)+\indora_{i,j\neq2}\left(\frac{1}{1-\tilde{\mu}_{2}}\right)^{2}\mu_{i}\mu_{j}f_{2}\left(2,2\right)
+\left[\indora_{i,j\neq2}\tilde{\theta}_{2}^{(2)}\tilde{\mu}_{i}\tilde{\mu}_{j}
+\indora_{i,j\neq2}\indora_{i=j}\frac{\tilde{P}_{i}^{(2)}}{1-\tilde{\mu}_{2}}\right.\\
\left.+\indora_{i,j\neq2}\indora_{i\neq j}\frac{\tilde{\mu}_{i}\tilde{\mu}_{j}}{1-\tilde{\mu}_{2}}\right]f_{2}\left(2\right)
+\left[r_{2}\tilde{\mu}_{i}
+\indora_{i\geq3}F_{i,2}^{(1)}\right]f_{2}\left(j\right)
+\left[r_{2}\tilde{\mu}_{j}
+\indora_{j\geq3}F_{j,2}^{(1)}\right]f_{2}\left(i\right)\\
+\left[R_{2}^{(2)}
+\indora_{i=j}r_{2}\right]\tilde{\mu}_{i}\mu_{j}+\indora_{j\geq3}F_{j,2}^{(1)}\left[\indora_{j\neq i}F_{i,2}^{(1)}
+r_{2}\tilde{\mu}_{i}\right]
+r_{2}\left[\indora_{i=j}P_{i}^{(2)}
+\indora_{i\geq3}F_{i,2}^{(1)}\tilde{\mu}_{j}\right]\\
+\indora_{i\geq3}\indora_{j=i}F_{i,2}^{(2)}
\end{array}
\end{eqnarray}

in a similar manner we obtain expressions for $f_{2}\left(i,j\right)$, $f_{3}\left(i,j\right)$ and $f_{4}\left(i,j\right)$

for $i,k=1,2,3,4$; from which we obtain the linear equations system
\begin{eqnarray}\label{System.Second.Order.Moments.uno}
\begin{array}{ll}
f_{1}\left(1,1\right)=a_{1}f_{2}\left(2,2\right)
+a_{2}f_{2}\left(2,1\right)
+a_{3}f_{2}\left(1,1\right)
+K_{1},&
f_{1}\left(1,2\right)=K_{2},\\
f_{1}\left(1,3\right)=a_{4}f_{2}\left(2,2\right)+a_{5}f\left(2,1\right)+K_{3},&
f_{1}\left(1,4\right)=a_{6}f_{2}\left(2,2\right)+a_{7}f_{2}\left(2,1\right)+K_{4},\end{array}
\end{eqnarray}
for the rest equations, similar reasoning lead us to a linear system equations whose solutions are described in corolary (\ref{Coro.Second.Order.Eqs}) with coefficients given by, we just show a few of them


%Which can be reduced to solve the system given in (\ref{System.Second.Order.Moments.uno}) and (\ref{System.Second.Order.Moments.dos}).

with values for $a_{i}$ and $K_{i}$  
%{\small{
\begin{eqnarray}\label{Coefficients.Ais.Exh.uno}
\begin{array}{llll}
a_{1}=\left(\frac{\tilde{\mu}_{1}}{1-\tilde{\mu}_{2}}\right)^{2},&
a_{2}=\frac{2\tilde{\mu}_{1}}{1-\tilde{\mu}_{2}},&
a_{3}=1,&
a_{4}=\left(\frac{1}{1-\tilde{\mu}_{2}}\right)^{2}\tilde{\mu}_{1}\tilde{\mu}_{3},\\
a_{5}=\frac{\tilde{\mu}_{3}}{1-\tilde{\mu}_{2}},&
a_{6}=\left(\frac{1}{1-\tilde{\mu}_{2}}\right)^{2}\tilde{\mu}_{1}\tilde{\mu}_{4},&
a_{7}=\frac{\tilde{\mu}_{4}}{1-\tilde{\mu}_{2}},&\\
\end{array}
\end{eqnarray}%}}





\begin{eqnarray}\label{Coefficients.kis.Exh.uno}
\begin{array}{l}
K_{1}=\tilde{\mu}_{1}^{2}\left(R_{2}^{(2)}+f_{2}\left(2\right)\theta_{2}^{(2)}\right)
+\tilde{P}_{1}^{(2)}\left(\frac{f_{2}\left(2\right)}{1-\tilde{\mu}_{2}}+r_{2}\right)
+2r_{2}\tilde{\mu}_{2}f_{2}\left(1\right),\\
K_{2}=\tilde{\mu}_{1}\tilde{\mu}_{2}\left[R_{2}^{(2)}
+r_{2}\right]
+r_{2}\left[\tilde{\mu}_{1}f_{2}\left(2\right)
+\tilde{\mu}_{2}f_{2}\left(1\right)\right],\\
K_{3}=\tilde{\mu}_{1}\tilde{\mu}_{3}\left[R_{2}^{(2)}+r_{2}+f_{2}\left(2\right)\left(\tilde{\theta}_{2}^{(2)}+\frac{1}{1-\tilde{\mu}_{2}}\right)\right]
+r_{2}\tilde{\mu}_{1}\left[F_{3,2}^{(1)}+f_{2}\left(1\right)\right]
+\left[r_{2}\tilde{\mu}_{3}+F_{3,2}^{(1)}\right]f_{2}\left(1\right),\\
K_{4}=\tilde{\mu}_{1}\tilde{\mu}_{4}\left[R_{2}^{(2)}
+r_{2}+f_{2}\left(2\right)\left(\tilde{\theta}_{2}^{(2)}
+\frac{1}{1-\tilde{\mu}_{2}}\right)\right]
+r_{2}\tilde{\mu}_{1}\left[f_{2}\left(4\right)+F_{4,2}^{(1)}\right]
+f_{2}\left(1\right)\left[r_{2}\tilde{\mu}_{4}+F_{4,2}^{(1)}\right],
\end{array}
\end{eqnarray}

\newpage
%______________________________________________________________________
\section{Appendix B: Stability Analysis for a NCPS}
%__________________________________________________________________
%
\begin{Teo}
Dada una Red de Sistemas de Visitas C\'iclicas (RSVC), conformada por dos Sistemas de Visitas C\'iclicas (SVC), donde cada uno de ellos consta de dos colas tipo $M/M/1$. Los dos sistemas est\'an comunicados entre s\'i por medio de la transferencia de usuarios entre las colas $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$. Se definen los eventos para los procesos de arribos al tiempo $t$, $A_{j}\left(t\right)=\left\{0 \textrm{ arribos en }Q_{j}\textrm{ al tiempo }t\right\}$ para alg\'un tiempo $t\geq0$ y $Q_{j}$ la cola $j$-\'esima en la RSVC, para $j=1,2,3,4$.  Existe un intervalo $I\neq\emptyset$ tal que para $T^{*}\in I$, tal que $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$.
\end{Teo}



\begin{proof}
Sin p\'erdida de generalidad podemos considerar como base del an\'alisis a la cola $Q_{1}$ del primer sistema que conforma la RSVC.\medskip 

Sea $n\geq1$, ciclo en el primer sistema en el que se sabe que $L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, pues la pol\'itica de servicio con que atienden los servidores es la exhaustiva. Como es sabido, para trasladarse a la siguiente cola, el servidor incurre en un tiempo de traslado $r_{1}\left(n\right)>0$, entonces tenemos que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.\medskip 


Definamos el intervalo $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ de longitud $\xi_{1}=r_{1}\left(n\right)$.

Dado que los tiempos entre arribo son exponenciales con tasa $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ ($\mu_{1}$ son los arribos a $Q_{1}$ por primera vez al sistema, mientras que $\hat{\mu}_{1}$ son los arribos de traslado procedentes de $Q_{3}$) se tiene que la probabilidad del evento $A_{1}\left(t\right)$ est\'a dada por 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 


Por otra parte, para la cola $Q_{2}$ el tiempo $\overline{\tau}_{2}\left(n-1\right)$ es tal que $L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, es decir, es el tiempo en que la cola queda totalmente vac\'ia en el ciclo anterior a $n$. \medskip 


Entonces tenemos un sgundo intervalo $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Por lo tanto la probabilidad del evento $A_{2}\left(t\right)$ tiene probabilidad dada por

\begin{eqnarray}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},\\
\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)
\end{eqnarray}
%\end{equation} 

%donde $$.

Ahora, dado que $I_{1}\left(n\right)\subset I_{2}\left(n\right)$, se tiene que

\begin{eqnarray*}
\xi_{1}\left(n\right)\leq\xi_{2}\left(n\right)&\Leftrightarrow& -\xi_{1}\left(n\right)\geq-\xi_{2}\left(n\right)
\\
-\tilde{\mu}_{2}\xi_{1}\left(n\right)\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{2}\xi_{1}\left(n\right)}\geq e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}\\
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&\geq&
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}.
\end{eqnarray*}


Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}}


Es decir, 

\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}
En lo que respecta a la relaci\'on entre los dos SVC que conforman la RSVC para alg\'un $m\geq1$ se tiene que $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$ por lo tanto se cumple cualquiera de los siguientes cuatro casos
\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$
\end{itemize}


Sea el intervalo $I_{3}\left(m\right)\equiv\left[\tau_{3}\left(m\right),\overline{\tau}_{3}\left(m\right)\right]$ tal que $\tau_{2}\left(n\right)\in I_{3}\left(m\right)$, con longitud de intervalo $\xi_{3}\equiv\overline{\tau}_{3}\left(m\right)-\tau_{3}\left(m\right)$, entonces se tiene que para $Q_{3}$
\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}.
\end{equation} 

mientras que para $Q_{4}$ consideremos el intervalo $I_{4}\left(m\right)\equiv\left[\tau_{4}\left(m-1\right),\overline{\tau}_{3}\left(m\right)\right]$, entonces por construcci\'on  $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, por lo tanto


\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}.
\end{eqnarray*}



Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}
\left(m\right)}
=e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}.
\end{eqnarray*}}

Es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\geq
e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}>0.
\end{equation}


Sea el intervalo $I_{3}\left(m\right)\equiv\left[\overline{\tau}_{3}\left(m\right),\tau_{4}\left(m\right)\right]$ con longitud $\xi_{3}\equiv\tau_{4}\left(m\right)-\overline{\tau}_{3}\left(m\right)$, entonces se tiene que para $Q_{3}$
\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}.
\end{equation} 

mientras que para $Q_{4}$ consideremos el intervalo $I_{4}\left(m\right)\equiv\left[\overline{\tau}_{4}\left(m-1\right),\tau_{4}\left(m\right)\right]$, entonces por construcci\'on  $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, y al igual que en el caso anterior se tiene que 

\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}.
\end{eqnarray*}


Entonces se tiene que
\small{
\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}\left(m\right)}
=e^{-\left(\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}\left(m\right)\right)}.
\end{eqnarray*}}

Es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}\geq
e^{-\left(\tilde{\mu}_{3}+\tilde{\mu}_{4}\right)\xi_{3}\left(m\right)}>0.
\end{equation}


Para el intervalo $I_{3}\left(m\right)=\left[\tau_{4}\left(m\right),\overline{\tau}_{4}\left(m\right)\right]$, se tiene que este caso es an\'alogo al caso (a).


Para el intevalo $I_{3}\left(m\right)\equiv\left[\overline{\tau}_{4}\left(m\right),\tau_{4}\left(m+1\right)\right]$, se tiene que es an\'alogo al caso (b).


Por construcci\'on se tiene que $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$,entonces en particular se tienen las contenciones $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ y $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, por lo tanto si definimos $\xi_{n,m}\equiv\ell\left(I\left(n,m\right)\right)$ tenemos que

\begin{eqnarray*}
\xi_{n,m}\leq\xi_{1}\left(n\right)\textrm{ y }\xi_{n,m}\leq\xi_{3}\left(m\right)\textrm{ entonces }\\
-\xi_{n,m}\geq-\xi_{1}\left(n\right)\textrm{ y }-\xi_{n,m}\leq-\xi_{3}\left(m\right)\\
\end{eqnarray*}
por lo tanto tenemos las desigualdades 


\begin{eqnarray*}
\begin{array}{ll}
-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right),&
-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right),\\
-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right),&
-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).
\end{array}
\end{eqnarray*}

Sea $T^{*}\in I\left(n,m\right)$, entonces dado que en particular $T^{*}\in I_{1}\left(n\right)$, se cumple con probabilidad positiva que no hay arribos a las colas $Q_{1}$ y $Q_{2}$, en consecuencia, tampoco hay usuarios de transferencia para $Q_{3}$ y $Q_{4}$, es decir, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, es decir, los eventos $Q_{1}$ y $Q_{3}$ son condicionalmente independientes en el intervalo $I\left(n,m\right)$; lo mismo ocurre para las colas $Q_{2}$ y $Q_{4}$, por lo tanto tenemos que
%\small{
\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}\\
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I\left(n,m\right)\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}\\
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}\\
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}


Ahora solo resta demostrar que para $n\ge1$, existe $m\geq1$ tal que se cumplen cualquiera de los cuatro casos arriba mencionados: 

\begin{itemize}
\item[a)] $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\overline{\tau}_{3}\left(m\right)$

\item[b)] $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{4}\left(m\right)$

\item[c)] $\tau_{4}\left(m\right)<\tau_{2}\left(n\right)<
\overline{\tau}_{4}\left(m\right)$

\item[d)] $\overline{\tau}_{4}\left(m\right)<\tau_{2}\left(n\right)
<\tau_{3}\left(m+1\right)$
\end{itemize}

Consideremos nuevamente el primer caso. Supongamos que no existe $m\geq1$, tal que $I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$, es decir, para toda $m\geq1$, $I_{1}\left(n\right)\cap I_{3}\left(m\right)=\emptyset$, entonces se tiene que ocurren cualquiera de los dos casos

\begin{itemize}
\item[a)] $\tau_{2}\left(n\right)\leq\tau_{3}\left(m\right)$: Recordemos que $\tau_{2}\left(m\right)=\overline{\tau}_{1}+r_{1}\left(m\right)$ donde cada una de las variables aleatorias son tales que $\esp\left[\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)\right]<\infty$, $\esp\left[R_{1}\right]<\infty$ y $\esp\left[\tau_{3}\left(m\right)\right]<\infty$, lo cual contradice el hecho de que no exista un ciclo $m\geq1$ que satisfaga la condici\'on deseada.

\item[b)] $\tau_{2}\left(n\right)\geq\overline{\tau}_{3}\left(m\right)$: por un argumento similar al anterior se tiene que no es posible que no exista un ciclo $m\geq1$ tal que satisaface la condici\'on deseada.

\end{itemize}

Para el resto de los casos la demostraci\'on es an\'aloga. Por lo tanto, se tiene que efectivamente existe $m\geq1$ tal que $\tau_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$.
\end{proof}
\newpage

%_________________________________________________________________________
%
\section{Appendix C: Output Process and Regenerative Processes}
%_________________________________________________________________________
%
En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R1}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}



%________________________________________________________________________
%\subsection{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman1}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
%___________________________________________________________________________________________
%
\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}


%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}
%
%___________________________________________________________________________________________
%\vspace{5.5cm}
%\chapter{Cadenas de Markov estacionarias}
%\vspace{-1.0cm}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.


%______________________________________________________________________
%\subsection{Ejemplos, Notas importantes}


Sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{j}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$\footnote{En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito, es decir: $\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty$, como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que $\esp\left[C_{i}\right]<\infty$,
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por $\sum_{k=1}^{N}\mu_{k}<1.$}, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Haciendo las siguientes sustituciones en la ecuaci\'on (\ref{Corolario2}): $n\rightarrow t-\tau_{i}\left(m\right)$, $T \rightarrow \overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)$, $L_{n}\rightarrow L_{i}\left(t\right)$ y $F\left(z\right)=\esp\left[z^{L_{0}}\right]\rightarrow F_{i}\left(z\right)=\esp\left[z^{L_{i}\tau_{i}\left(m\right)}\right]$, se puede ver que

\begin{eqnarray}\label{Eq.Arribos.Primera}
\esp\left[\sum_{n=0}^{T-1}z^{L_{n}}\right]=
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray}

Por otra parte durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&
\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Por lo tanto

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}
\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}
z^{L_{i}\left(t\right)}\right]
+\esp\left[\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}
z^{L_{i}\left(t\right)}\right]\right\}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}
{1-P_{i}\left(z\right)}
\right\}
\end{eqnarray*}

es decir

\begin{equation}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{equation}

\begin{Teo}
Dada una Red de Sistemas de Visitas C\'iclicas (RSVC), conformada por dos Sistemas de Visitas C\'iclicas (SVC), donde cada uno de ellos consta de dos colas tipo $M/M/1$. Los dos sistemas est\'an comunicados entre s\'i por medio de la transferencia de usuarios entre las colas $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$. Se definen los eventos para los procesos de arribos al tiempo $t$, $A_{j}\left(t\right)=\left\{0 \textrm{ arribos en }Q_{j}\textrm{ al tiempo }t\right\}$ para alg\'un tiempo $t\geq0$ y $Q_{j}$ la cola $j$-\'esima en la RSVC, para $j=1,2,3,4$.  Existe un intervalo $I\neq\emptyset$ tal que para $T^{*}\in I$, tal que $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$.
\end{Teo}

\begin{proof}
Sin p\'erdida de generalidad podemos considerar como base del an\'alisis a la cola $Q_{1}$ del primer sistema que conforma la RSVC.

Sea $n>0$, ciclo en el primer sistema en el que se sabe que $L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, pues la pol\'itica de servicio con que atienden los servidores es la exhaustiva. Como es sabido, para trasladarse a la siguiente cola, el servidor incurre en un tiempo de traslado $r_{1}\left(n\right)>0$, entonces tenemos que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.


Definamos el intervalo $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ de longitud $\xi_{1}=r_{1}\left(n\right)$. Dado que los tiempos entre arribo son exponenciales con tasa $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ ($\mu_{1}$ son los arribos a $Q_{1}$ por primera vez al sistema, mientras que $\hat{\mu}_{1}$ son los arribos de traslado procedentes de $Q_{3}$) se tiene que la probabilidad del evento $A_{1}\left(t\right)$ est\'a dada por 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 

Por otra parte, para la cola $Q_{2}$, el tiempo $\overline{\tau}_{2}\left(n-1\right)$ es tal que $L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, es decir, es el tiempo en que la cola queda totalmente vac\'ia en el ciclo anterior a $n$. Entonces tenemos un sgundo intervalo $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Por lo tanto la probabilidad del evento $A_{2}\left(t\right)$ tiene probabilidad dada por

\begin{equation}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},
\end{equation} 

donde $\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)$.



Entonces, se tiene que

\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}

En lo que respecta a la relaci\'on entre los dos SVC que conforman la RSVC, se afirma que existe $m>0$ tal que $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$.

Para $Q_{3}$ sea $I_{3}=\left[\overline{\tau}_{3}\left(m\right),\tau_{4}\left(m\right)\right]$ con longitud  $\xi_{3}\left(m\right)=r_{3}\left(m\right)$, entonces 

\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(n\right)}.
\end{equation} 

An\'alogamente que como se hizo para $Q_{2}$, tenemos que para $Q_{4}$ se tiene el intervalo $I_{4}=\left[\overline{\tau}_{4}\left(m-1\right),\tau_{4}\left(m\right)\right]$ con longitud $\xi_{4}\left(m\right)=\tau_{4}\left(m\right)-\overline{\tau}_{4}\left(m-1\right)$, entonces


\begin{equation}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}=e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}.
\end{equation} 

Al igual que para el primer sistema, dado que $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, se tiene que

\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(m\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}
\end{eqnarray*}

Entonces, dado que los eventos $A_{3}$ y $A_{4}$ son independientes, se tiene que

\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}
\left(m\right)}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{equation}

Por construcci\'on se tiene que $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$,entonces en particular se tienen las contenciones $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ y $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, por lo tanto si definimos $\xi_{n,m}\equiv\ell\left(I\left(n,m\right)\right)$ tenemos que

\begin{eqnarray*}
\xi_{n,m}\leq\xi_{1}\left(n\right)\textrm{ y }\xi_{n,m}\leq\xi_{3}\left(m\right)\textrm{ entonces }
-\xi_{n,m}\geq-\xi_{1}\left(n\right)\textrm{ y }-\xi_{n,m}\leq-\xi_{3}\left(m\right)\\
\end{eqnarray*}
por lo tanto tenemos las desigualdades 



\begin{eqnarray*}
\begin{array}{ll}
-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right),&
-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right),\\
-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right),&
-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).
\end{array}
\end{eqnarray*}

Sea $T^{*}\in I_{n,m}$, entonces dado que en particular $T^{*}\in I_{1}\left(n\right)$ se cumple con probabilidad positiva que no hay arribos a las colas $Q_{1}$ y $Q_{2}$, en consecuencia, tampoco hay usuarios de transferencia para $Q_{3}$ y $Q_{4}$, es decir, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, es decir, los eventos $Q_{1}$ y $Q_{3}$ son condicionalmente independientes en el intervalo $I_{n,m}$; lo mismo ocurre para las colas $Q_{2}$ y $Q_{4}$, por lo tanto tenemos que


\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}
\end{proof}


Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}


%\section{Resultados para Procesos de Salida}

En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}
%\newpage
%________________________________________________________________________
%\section{Redes de Sistemas de Visitas C\'iclicas}
%________________________________________________________________________

Sean $Q_{1},Q_{2},Q_{3}$ y $Q_{4}$ en una Red de Sistemas de Visitas C\'iclicas (RSVC). Supongamos que cada una de las colas es del tipo $M/M/1$ con tasa de arribo $\mu_{i}$ y que la transferencia de usuarios entre los dos sistemas ocurre entre $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$ con respectiva tasa de arribo igual a la tasa de salida $\hat{\mu}_{i}=\mu_{i}$, esto se sabe por lo desarrollado en la secci\'on anterior.  

Consideremos, sin p\'erdida de generalidad como base del an\'alisis, la cola $Q_{1}$ adem\'as supongamos al servidor lo comenzamos a observar una vez que termina de atender a la misma para desplazarse y llegar a $Q_{2}$, es decir al tiempo $\tau_{2}$.

Sea $n\in\nat$, $n>0$, ciclo del servidor en que regresa a $Q_{1}$ para dar servicio y atender conforme a la pol\'itica exhaustiva, entonces se tiene que $\overline{\tau}_{1}\left(n\right)$ es el tiempo del servidor en el sistema 1 en que termina de dar servicio a todos los usuarios presentes en la cola, por lo tanto se cumple que $L_{1}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, entonces el servidor para llegar a $Q_{2}$ incurre en un tiempo de traslado $r_{1}$ y por tanto se cumple que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}$. Dado que los tiempos entre arribos son exponenciales se cumple que 

\begin{eqnarray*}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}=e^{-\tilde{\mu}_{1}r_{1}},\\
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}=e^{-\tilde{\mu}_{2}r_{1}}.
\end{eqnarray*}

El evento que nos interesa consiste en que no haya arribos desde que el servidor abandon\'o $Q_{2}$ y regresa nuevamente para dar servicio, es decir en el intervalo de tiempo $\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Entonces, si hacemos


\begin{eqnarray*}
\varphi_{1}\left(n\right)&\equiv&\overline{\tau}_{1}\left(n\right)+r_{1}=\overline{\tau}_{2}\left(n-1\right)+r_{1}+r_{2}+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)\\
&=&\overline{\tau}_{2}\left(n-1\right)+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r,,
\end{eqnarray*}

y longitud del intervalo

\begin{eqnarray*}
\xi&\equiv&\overline{\tau}_{1}\left(n\right)+r_{1}-\overline{\tau}_{2}\left(n-1\right)
=\overline{\tau}_{2}\left(n-1\right)+\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r-\overline{\tau}_{2}\left(n-1\right)\\
&=&\overline{\tau}_{1}\left(n\right)-\tau_{1}\left(n\right)+r.
\end{eqnarray*}


Entonces, determinemos la probabilidad del evento no arribos a $Q_{2}$ en $\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]$:

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{2}\xi}.
\end{eqnarray}

De manera an\'aloga, tenemos que la probabilidad de no arribos a $Q_{1}$ en $\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]$ esta dada por

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{1}\xi},
\end{eqnarray}

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}
=e^{-\tilde{\mu}_{2}\xi}.
\end{eqnarray}

Por tanto 

\begin{eqnarray}
\begin{array}{l}
\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ y }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}\\
=\prob\left\{0 \textrm{ arribos en }Q_{1}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}\\
\times
\prob\left\{0 \textrm{ arribos en }Q_{2}\textrm{ en el intervalo }\left[\overline{\tau}_{2}\left(n-1\right),\varphi_{1}\left(n\right)\right]\right\}=e^{-\tilde{\mu}_{1}\xi}e^{-\tilde{\mu}_{2}\xi}
=e^{-\tilde{\mu}\xi}.
\end{array}
\end{eqnarray}

Para el segundo sistema, consideremos nuevamente $\overline{\tau}_{1}\left(n\right)+r_{1}$, sin p\'erdida de generalidad podemos suponer que existe $m>0$ tal que $\overline{\tau}_{3}\left(m\right)<\overline{\tau}_{1}+r_{1}<\tau_{4}\left(m\right)$, entonces

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\textrm{ en el intervalo }\left[\overline{\tau}_{3}\left(m\right),\overline{\tau}_{1}\left(n\right)+r_{1}\right]\right\}
=e^{-\tilde{\mu}_{3}\xi_{3}},
\end{eqnarray}
donde 
\begin{eqnarray}
\xi_{3}=\overline{\tau}_{1}\left(n\right)+r_{1}-\overline{\tau}_{3}\left(m\right)=
\overline{\tau}_{1}\left(n\right)-\overline{\tau}_{3}\left(m\right)+r_{1},
\end{eqnarray}

mientras que para $Q_{4}$ al igual que con $Q_{2}$ escribiremos $\tau_{4}\left(m\right)$ en t\'erminos de $\overline{\tau}_{4}\left(m-1\right)$:

$\varphi_{2}\equiv\tau_{4}\left(m\right)=\overline{\tau}_{4}\left(m-1\right)+r_{4}+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)+r_{3}=\overline{\tau}_{4}\left(m-1\right)+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)+\hat{r}$, adem\'as,

$\xi_{2}\equiv\varphi_{2}\left(m\right)-\overline{\tau}_{1}-r_{1}=\overline{\tau}_{4}\left(m-1\right)+\overline{\tau}_{3}\left(m\right)
-\tau_{3}\left(m\right)-\overline{\tau}_{1}\left(n\right)+\hat{r}-r_{1}$. 

Entonces


\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{4}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\tilde{\mu}_{4}\xi_{2}},
\end{eqnarray}

mientras que para $Q_{3}$ se tiene que 

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\tilde{\mu}_{3}\xi_{2}}
\end{eqnarray}

Por tanto

\begin{eqnarray}
\prob\left\{0 \textrm{ arribos en }Q_{3}\wedge Q_{4}\textrm{ en el intervalo }\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]\right\}
=e^{-\hat{\mu}\xi_{2}}
\end{eqnarray}
donde $\hat{\mu}=\tilde{\mu}_{3}+\tilde{\mu}_{4}$.

Ahora, definamos los intervalos $\mathcal{I}_{1}=\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{1}\left(n\right)\right]$  y $\mathcal{I}_{2}=\left[\overline{\tau}_{1}\left(n\right)+r_{1},\varphi_{2}\left(m\right)\right]$, entonces, sea $\mathcal{I}=\mathcal{I}_{1}\cap\mathcal{I}_{2}$ el intervalo donde cada una de las colas se encuentran vac\'ias, es decir, si tomamos $T^{*}\in\mathcal{I}$, entonces  $L_{1}\left(T^{*}\right)=L_{2}\left(T^{*}\right)=L_{3}\left(T^{*}\right)=L_{4}\left(T^{*}\right)=0$.

Ahora, dado que por construcci\'on $\mathcal{I}\neq\emptyset$ y que para $T^{*}\in\mathcal{I}$ en ninguna de las colas han llegado usuarios, se tiene que no hay transferencia entre las colas, por lo tanto, el sistema 1 y el sistema 2 son condicionalmente independientes en $\mathcal{I}$, es decir

\begin{eqnarray}
\prob\left\{L_{1}\left(T^{*}\right),L_{2}\left(T^{*}\right),L_{3}\left(T^{*}\right),L_{4}\left(T^{*}\right)|T^{*}\in\mathcal{I}\right\}=\prod_{j=1}^{4}\prob\left\{L_{j}\left(T^{*}\right)\right\},
\end{eqnarray}

para $T^{*}\in\mathcal{I}$. 

%\newpage























%________________________________________________________________________
%\section{Procesos Regenerativos}
%________________________________________________________________________

%________________________________________________________________________
%\subsection*{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman1}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
%\subsection*{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
%\section{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection*{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection*{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection*{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
\section{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
%___________________________________________________________________________________________
%
\begin{Def}\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}

%______________________________________________________________________

%\section{Ejemplos, Notas importantes}
%______________________________________________________________________
%\section*{Ap\'endice A}
%__________________________________________________________________

%________________________________________________________________________
%\subsection*{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.


\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}iudad de M\'exico\\}}

\noindent{\bf{Academia de Matem\'aticas}}

\noindent{\bf{Colegio de Ciencia y Tecnolog\'ia}}

\vspace{1.5in} \noindent{\centerline{\bf{\Large{
Revisi\'on de Procesos Regenerativos Estacionarios}}}}
\vspace{.5in} \noindent{\centerline{{\bf{\large{Carlos Ernesto
Mart\'inez Rodr\'iguez}}}}}

\vspace{.5in} \vfill \hfill {\bf{Agosto, 2016}}
%______________________________________________________________________
%
%\makeindex
\renewcommand{\contentsname}{Index}
\maketitle \tableofcontents
%\newpage
%________________________________________________________________________

%___________________________________________________________
%
\section{Existencia de Tiempos de Regeneraci\'on}
%___________________________________________________________
%

%________________________________________________________________________
%\subsection{Procesos Regenerativos: Thorisson}
%________________________________________________________________________

Un elemento aleatorio en un espacio medible $\left(E,\mathcal{E}\right)$ en un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ a $\left(E,\mathcal{E}\right)$, es decir,
para $A\in \mathcal{E}$,  se tiene que $\left\{Y\in A\right\}\in\mathcal{F}$, donde $\left\{Y\in A\right\}:=\left\{w\in\Omega:Y\left(w\right)\in A\right\}=:Y^{-1}A$. Tambi\'en se dice que $Y$ est\'a soportado por el espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ y que $Y$ es un mapeo medible de $\Omega$ en $E$, es decir, es $\mathcal{F}/\mathcal{E}$ medible. Para cada $i\in \mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Se define el espacio producto $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right):=\left(\prod_{i\in\mathbb{I}}E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}\right)$, donde $\prod_{i\in\mathbb{I}}E_{i}$ es el producto cartesiano de los $E_{i}$'s, y $\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}$ es la $\sigma$-\'algebra producto, es decir, es la $\sigma$-\'algebra m\'as peque\~na en $\prod_{i\in\mathbb{I}}E_{i}$ que hace al $i$-\'esimo mapeo proyecci\'on en $E_{i}$ medible para toda $i\in\mathbb{I}$ es la $\sigma$-\'algebra inducida por los mapeos proyecci\'on. $$\otimes_{i\in\mathbb{I}}\mathcal{E}_{i}:=\sigma\left\{\left\{y:y_{i}\in A\right\}:i\in\mathbb{I}\textrm{ y }A\in\mathcal{E}_{i}\right\}.$$ Un espacio de probabilidad $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ es una extensi\'on de otro espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$ si $\left(\tilde{\Omega},\tilde{\mathcal{F}},\tilde{\prob}\right)$ soporta un elemento aleatorio $\xi\in\left(\Omega,\mathcal{F}\right)$ que tienen a $\prob$ como distribuci\'on.

\begin{Teo}
Sea $\mathbb{I}$ un conjunto de \'indices arbitrario. Para cada $i\in\mathbb{I}$ sea $P_{i}$ una medida de probabilidad en un espacio medible $\left(E_{i},\mathcal{E}_{i}\right)$. Entonces existe una \'unica medida de probabilidad $\otimes_{i\in\mathbb{I}}P_{i}$ en $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i}\right)$ tal que 

\begin{eqnarray*}
\otimes_{i\in\mathbb{I}}P_{i}\left(y\in\prod_{i\in\mathbb{I}}E_{i}:y_{i}\in A_{i_{1}},\ldots,y_{n}\in A_{i_{n}}\right)=P_{i_{1}}\left(A_{i_{n}}\right)\cdots P_{i_{n}}\left(A_{i_{n}}\right)
\end{eqnarray*}
para todos los enteros $n>0$, toda $i_{1},\ldots,i_{n}\in\mathbb{I}$ y todo $A_{i_{1}}\in\mathcal{E}_{i_{1}},\ldots,A_{i_{n}}\in\mathcal{E}_{i_{n}}$
\end{Teo}

La medida $\otimes_{i\in\mathbb{I}}P_{i}$ es llamada la medida producto y $\otimes_{i\in\mathbb{I}}\left(E_{i},\mathcal{E}_{i},P_{i}\right):=\left(\prod_{i\in\mathbb{I}},E_{i},\otimes_{i\in\mathbb{I}}\mathcal{E}_{i},\otimes_{i\in\mathbb{I}}P_{i}\right)$, es llamado espacio de probabilidad producto.

\begin{Def}
Un espacio medible $\left(E,\mathcal{E}\right)$ es \textit{Polaco} si existe una m\'etrica en $E$ tal que $E$ es completo. (es decir cada sucesi\'on de Cauchy converge a un l\'imite en $E$, y \textit{separable}, $E$ tienen un subconjunto denso numerable, y tal que $\mathcal{E}$ es generado por conjuntos abiertos.)
\end{Def}

Dos espacios medibles $\left(E,\mathcal{E}\right)$ y $\left(G,\mathcal{G}\right)$ son Borel equivalentes \textit{isomorfos} si existe una biyecci\'on $f:E\rightarrow G$ tal que $f$ es $\mathcal{E}/\mathcal{G}$ medible y su inversa $f^{-1}$ es $\mathcal{G}/\mathcal{E}$ medible. La biyecci\'on es una equivalencia de Borel.  Un espacio medible  $\left(E,\mathcal{E}\right)$ es un \textit{espacio est\'andar} si es Borel equivalente a $\left(G,\mathcal{G}\right)$, donde $G$ es un subconjunto de Borel de $\left[0,1\right]$ y $\mathcal{G}$ son los subconjuntos de Borel de $G$. Cualquier espacio Polaco es un espacio est\'andar. Un proceso estoc\'astico (\textbf{PE}) con conjunto de \'indices $\mathbb{I}$ y espacio de estados $\left(E,\mathcal{E}\right)$ es una familia $Z=\left(\mathbb{Z}_{s}\right)_{s\in\mathbb{I}}$ donde $\mathbb{Z}_{s}$ son elementos aleatorios definidos en un espacio de probabilidad com\'un $\left(\Omega,\mathcal{F},\prob\right)$ y todos toman valores en $\left(E,\mathcal{E}\right)$.

\begin{Def}
Un Proceso Estoc\'astico \textit{One-Sided Contiuous Time} (\textbf{PEOSCT}) es un proceso estoc\'astico con conjunto de \'indices $\mathbb{I}=\left[0,\infty\right)$.
\end{Def}

Sea $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ denota el espacio producto $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right):=\otimes_{s\in\mathbb{I}}\left(E,\mathcal{E}\right)$. Vamos a considerar $\mathbb{Z}$ como un mapeo aleatorio, es decir, como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ definido por $Z\left(w\right)=\left(Z_{s}\left(w\right)\right)_{s\in\mathbb{I}}$ y $w\in\Omega$. La distribuci\'on de un proceso estoc\'astico $Z$ es la distribuci\'on de $Z$ como un elemento aleatorio en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$. La distribuci\'on de $Z$ esta determinada de manera \'unica por las distribuciones finito dimensionales. En particular cuando $Z$ toma valores reales, es decir, $\left(E,\mathcal{E}\right)=\left(\mathbb{R},\mathcal{B}\right)$ las distribuciones finito dimensionales est\'an determinadas por las funciones de distribuci\'on finito dimensionales
\begin{eqnarray}
\prob\left(Z_{t_{1}}\leq x_{1},\ldots,Z_{t_{n}}\leq x_{n}\right),x_{1},\ldots,x_{n}\in\mathbb{R},t_{1},\ldots,t_{n}\in\mathbb{I},n\geq1.
\end{eqnarray}

Para espacios polacos $\left(E,\mathcal{E}\right)$ el Teorema de Consistencia de Kolmogorov asegura que dada una colecci\'on de distribuciones finito dimensionales consistentes, siempre existe un proceso estoc\'astico que posee tales distribuciones finito dimensionales. Las trayectorias de $Z$ son las realizaciones $Z\left(w\right)$ para $w\in\Omega$ del mapeo aleatorio $Z$. Algunas restricciones se imponen sobre las trayectorias, por ejemplo que sean continuas por la derecha, o continuas por la derecha con l\'imites por la izquierda, o de manera m\'as general, se pedir\'a que caigan en alg\'un subconjunto $H$ de $E^{\mathbb{I}}$. En este caso es natural considerar a $Z$ como un elemento aleatorio que no est\'a en $\left(E^{\mathbb{I}},\mathcal{E}^{\mathbb{I}}\right)$ sino en $\left(H,\mathcal{H}\right)$, donde $\mathcal{H}$ es la $\sigma$-\'algebra generada por los mapeos proyecci\'on que toman a $z\in H$ a $z_{t}\in E$ para $t\in\mathbb{I}$. A $\mathcal{H}$ se le conoce como la traza de $H$ en $E^{\mathbb{I}}$, es decir,
\begin{eqnarray}
\mathcal{H}:=E^{\mathbb{I}}\cap H:=\left\{A\cap H:A\in E^{\mathbb{I}}\right\}.
\end{eqnarray}

$Z$ tiene trayectorias con valores en $H$ y cada $Z_{t}$ es un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ a $\left(H,\mathcal{H}\right)$. Cuando se considera un espacio de trayectorias en particular $H$, al espacio $\left(H,\mathcal{H}\right)$ se le llama el espacio de trayectorias de $Z$. La distribuci\'on del proceso estoc\'astico $Z$ con espacio de trayectorias $\left(H,\mathcal{H}\right)$ es la distribuci\'on de $Z$ como  un elemento aleatorio en $\left(H,\mathcal{H}\right)$. La distribuci\'on, nuevemente, est\'a determinada de manera \'unica por las distribuciones finito dimensionales.

\begin{Def}
Sea $Z$ un PEOSCT  con espacio de estados $\left(E,\mathcal{E}\right)$ y sea $T$ un tiempo aleatorio en $\left[0,\infty\right)$. Por $Z_{T}$ se entiende el mapeo con valores en $E$ definido en $\Omega$ en la manera obvia:
\begin{eqnarray*}
Z_{T}\left(w\right):=Z_{T\left(w\right)}\left(w\right). w\in\Omega.
\end{eqnarray*}
\end{Def}

\begin{Def}
Un PEOSCT $Z$ es Conjuntamente Medible (\textbf{CM}) si el mapeo que toma $\left(w,t\right)\in\Omega\times\left[0,\infty\right)$ a $Z_{t}\left(w\right)\in E$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

Un PEOSCT-CM implica que el proceso es medible, dado que $Z_{T}$ es una composici\'on  de dos mapeos continuos: el primero que toma $w$ en $\left(w,T\left(w\right)\right)$ es $\mathcal{F}/\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)$ medible, mientras que el segundo toma $\left(w,T\left(w\right)\right)$ en $Z_{T\left(w\right)}\left(w\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.

\begin{Def}
Un PEOSCT con espacio de estados $\left(H,\mathcal{H}\right)$ es Can\'onicamente Conjuntamente Medible (\textbf{CCM}) si el mapeo $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $Z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.
\end{Def}

Un PEOSCT-CCM implica que el proceso es CM, dado que un PECCM $Z$ es un mapeo de $\Omega\times\left[0,\infty\right)$ a $E$, es la composici\'on de dos mapeos medibles: el primero, toma $\left(w,t\right)$ en $\left(Z\left(w\right),t\right)$ es $\mathcal{F}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)$ medible, y el segundo que toma $\left(Z\left(w\right),t\right)$  en $Z_{t}\left(w\right)$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible. Por tanto CCM es una condici\'on m\'as fuerte que CM.

\begin{Def}
Un conjunto de trayectorias $H$ de un PEOSCT $Z$, es Internamente Shift-Invariante (\textbf{ISI}) si 
\begin{eqnarray*}
\left\{\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}:z\in H\right\}=H\textrm{, }t\in\left[0,\infty\right).
\end{eqnarray*}
\end{Def}


\begin{Def}
Dado un PEOSCT-ISI, se define el mapeo-shift $\theta_{t}$, $t\in\left[0,\infty\right)$, de $H$ a $H$ por 
\begin{eqnarray*}
\theta_{t}z=\left(z_{t+s}\right)_{s\in\left[0,\infty\right)}\textrm{, }z\in H.
\end{eqnarray*}
\end{Def}

\begin{Def}
Se dice que un proceso $Z$ es Shift-Medible (\textbf{SM}) si $Z$ tiene un conjunto de trayectorias $H$ que es ISI y adem\'as el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $\theta_{t}z\in H$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{H}$ medible.
\end{Def}

Un proceso estoc\'astico con conjunto de trayectorias $H$ ISI es SM si y s\'olo si es CCM. Dado el espacio polaco $\left(E,\mathcal{E}\right)$ se tiene el  conjunto de trayectorias $D_{E}\left[0,\infty\right)$ que es ISI, entonces cumpe con ser CCM. Si $G$ es abierto, podemos cubrirlo por bolas abiertas cuay cerradura este contenida en $G$, y como $G$ es segundo numerable como subespacio de $E$, lo podemos cubrir por una cantidad numerable de bolas abiertas. Los procesos estoc\'asticos $Z$ a tiempo discreto con espacio de estados polaco, tambi\'en tiene un espacio de trayectorias polaco y por tanto tiene distribuciones condicionales regulares.

\begin{Teo}
El producto numerable de espacios polacos es polaco.
\end{Teo}


\begin{Def}
Sea $\left(\Omega,\mathcal{F},\prob\right)$ espacio de probabilidad que soporta al proceso $Z=\left(Z_{s}\right)_{s\in\left[0,\infty\right)}$ y $S=\left(S_{k}\right)_{0}^{\infty}$ donde $Z$ es un PEOSCTM con espacio de estados $\left(E,\mathcal{E}\right)$  y espacio de trayectorias $\left(H,\mathcal{H}\right)$  y adem\'as $S$ es una sucesi\'on de tiempos aleatorios one-sided que satisfacen la condici\'on $0\leq S_{0}<S_{1}<\cdots\rightarrow\infty$. Considerando $S$ como un mapeo medible de $\left(\Omega,\mathcal{F}\right)$ al espacio sucesi\'on $\left(L,\mathcal{L}\right)$, donde 
\begin{eqnarray*}
L=\left\{\left(s_{k}\right)_{0}^{\infty}\in\left[0,\infty\right)^{\left\{0,1,\ldots\right\}}:s_{0}<s_{1}<\cdots\rightarrow\infty\right\},
\end{eqnarray*}
donde $\mathcal{L}$ son los subconjuntos de Borel de $L$, es decir, $\mathcal{L}=L\cap\mathcal{B}^{\left\{0,1,\ldots\right\}}$.

As\'i el par $\left(Z,S\right)$ es un mapeo medible de  $\left(\Omega,\mathcal{F}\right)$ en $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$. El par $\mathcal{H}\otimes\mathcal{L}^{+}$ denotar\'a la clase de todas las funciones medibles de $\left(H\times L,\mathcal{H}\otimes\mathcal{L}\right)$ en $\left(\left[0,\infty\right),\mathcal{B}\left[0,\infty\right)\right)$.
\end{Def}


\begin{Def}
Sea $\theta_{t}$ el mapeo-shift conjunto de $H\times L$ en $H\times L$ dado por
\begin{eqnarray*}
\theta_{t}\left(z,\left(s_{k}\right)_{0}^{\infty}\right)=\theta_{t}\left(z,\left(s_{n_{t-}+k}-t\right)_{0}^{\infty}\right)
\end{eqnarray*}
donde 
$n_{t-}=inf\left\{n\geq1:s_{n}\geq t\right\}$.
\end{Def}

Con la finalidad de poder realizar los shift's sin complicaciones de medibilidad, se supondr\'a que $Z$ es shit-medible, es decir, el conjunto de trayectorias $H$ es invariante bajo shifts del tiempo y el mapeo que toma $\left(z,t\right)\in H\times\left[0,\infty\right)$ en $z_{t}\in E$ es $\mathcal{H}\otimes\mathcal{B}\left[0,\infty\right)/\mathcal{E}$ medible.

\begin{Def}
Dado un proceso \textbf{PEOSSM} (Proceso Estoc\'astico One Side Shift Medible) $Z$, se dice regenerativo cl\'asico con tiempos de regeneraci\'on $S$ si 

\begin{eqnarray*}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0
\end{eqnarray*}
y adem\'as $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(\left(Z_{s}\right)s\in\left[0,S_{n}\right),S_{0},\ldots,S_{n}\right)$
Si lo anterior se cumple, al par $\left(Z,S\right)$ se le llama regenerativo cl\'asico.
\end{Def}

Si el par $\left(Z,S\right)$ es regenerativo cl\'asico, entonces las longitudes de los ciclos $X_{1},X_{2},\ldots,$ son i.i.d. e independientes de la longitud del retraso $S_{0}$, es decir, $S$ es un proceso de renovaci\'on. Las longitudes de los ciclos tambi\'en son llamados tiempos de inter-regeneraci\'on y tiempos de ocurrencia.

\begin{Teo}
Sup\'ongase que el par $\left(Z,S\right)$ es regenerativo cl\'asico con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de $\left(Z,S\right)$. Adem\'as, si $X_{1}$ es lattice con span $d$, entonces $\left(Z^{**},S^{**}\right)$ en el teorema 2.2 es una versi\'on periodicamente estacionaria de $\left(Z,S\right)$ con periodo $d$.
\end{Teo}

\begin{Def}
Una variable aleatoria $X_{1}$ es \textit{spread out} si existe una $n\geq1$ y una  funci\'on $f\in\mathcal{B}^{+}$ tal que $\int_{\rea}f\left(x\right)dx>0$ con $X_{2},X_{3},\ldots,X_{n}$ copias i.i.d  de $X_{1}$, $$\prob\left(X_{1}+\cdots+X_{n}\in B\right)\geq\int_{B}f\left(x\right)dx$$ para $B\in\mathcal{B}$.
\end{Def}

\begin{Def}
Dado un proceso estoc\'astico $Z$ se le llama \textit{Wide-Sense Regenerative} (\textbf{WSR}) con tiempos de regeneraci\'on $S$ si $\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right)$ para $n\geq0$ en distribuci\'on y $\theta_{S_{n}}\left(Z,S\right)$ es independiente de $\left(S_{0},S_{1},\ldots,S_{n}\right)$ para $n\geq0$. Se dice que el par $\left(Z,S\right)$ es WSR si lo anterior se cumple.
\end{Def}

El proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es WSR con tiempos de regeneraci\'on $S$ pero no es regenerativo cl\'asico. Si $Z$ es cualquier proceso estacionario y $S$ es un proceso de renovaci\'on que es independiente de $Z$, entonces $\left(Z,S\right)$ es WSR pero en general no es regenerativo cl\'asico. Para cualquier proceso estoc\'astico $Z$, el proceso de trayectorias $\left(\theta_{s}Z\right)_{s\in\left[0,\infty\right)}$ es siempre un proceso de Markov.

\begin{Teo}
Supongase que el par $\left(Z,S\right)$ es WSR con $\esp\left[X_{1}\right]<\infty$. Entonces $\left(Z^{*},S^{*}\right)$ en el teorema 2.1 es una versi\'on estacionaria de 
$\left(Z,S\right)$.
\end{Teo}


\begin{Teo}
Supongase que $\left(Z,S\right)$ es cycle-stationary con $\esp\left[X_{1}\right]<\infty$. Sea $U$ distribuida uniformemente en $\left[0,1\right)$ e independiente de $\left(Z^{0},S^{0}\right)$ y sea $\prob^{*}$ la medida de probabilidad en $\left(\Omega,\prob\right)$ definida por $$d\prob^{*}=\frac{X_{1}}{\esp\left[X_{1}\right]}d\prob$$. Sea $\left(Z^{*},S^{*}\right)$ con distribuci\'on $\prob^{*}\left(\theta_{UX_{1}}\left(Z^{0},S^{0}\right)\in\cdot\right)$. Entonces $\left(Z^{}*,S^{*}\right)$ es estacionario,
\begin{eqnarray*}
\esp\left[f\left(Z^{*},S^{*}\right)\right]=\esp\left[\int_{0}^{X_{1}}f\left(\theta_{s}\left(Z^{0},S^{0}\right)\right)ds\right]/\esp\left[X_{1}\right]
\end{eqnarray*}
$f\in\mathcal{H}\otimes\mathcal{L}^{+}$, and $S_{0}^{*}$ es continuo con funci\'on distribuci\'on $G_{\infty}$ definida por $$G_{\infty}\left(x\right):=\frac{\esp\left[X_{1}\right]\wedge x}{\esp\left[X_{1}\right]}$$ para $x\geq0$ y densidad $\prob\left[X_{1}>x\right]/\esp\left[X_{1}\right]$, con $x\geq0$.

\end{Teo}


\begin{Teo}
Sea $Z$ un Proceso Estoc\'astico un lado shift-medible \textit{one-sided shift-measurable stochastic process}, (PEOSSM),
y $S_{0}$ y $S_{1}$ tiempos aleatorios tales que $0\leq S_{0}<S_{1}$ y
\begin{equation}
\theta_{S_{1}}Z=\theta_{S_{0}}Z\textrm{ en distribuci\'on}.
\end{equation}

Entonces el espacio de probabilidad subyacente $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on de tiempos aleatorios $S$ tales que

\begin{eqnarray}
\theta_{S_{n}}\left(Z,S\right)=\left(Z^{0},S^{0}\right),n\geq0,\textrm{ en distribuci\'on},\\
\left(Z,S_{0},S_{1}\right)\textrm{ depende de }\left(X_{2},X_{3},\ldots\right)\textrm{ solamente a traves de }\theta_{S_{1}}Z.
\end{eqnarray}
\end{Teo}
%________________________________________________________________________________
\section{Main Theorem: Article}
%__________________________________________________________________________________

The authors are interested in determining the means of the queue lengths at any time, for the exhaustive policy. For this purpose, it is necessary to make assumptions over the processes involved in order to guarantee the stationarity of the queue lengths processes in the NCPS. 
\begin{Sup}\label{Supuestos.Estabilidad}\medskip
%\textbf{Assumption 1}\label{Supuestos.Estabilidad}
\begin{itemize}
\item[\textit{(i)} ] Each of the queues of the NCPS is an $M/M/1$ system, with  $\tilde{\rho}_{i}:=\tilde{\mu}_{i}/\lambda_{i}<1$, for $i=1,2,3,4$ (observe that in the case considered $\tilde{\rho}_{i}=\tilde{\mu}_{i}$, for $i=1,2,3,4$, given that the service time is assumed to be proportional to the length of the slot).
\item[\textit{(ii)} ]  The switchover times have a finite first moment.
\end{itemize}
\end{Sup}
\begin{Remark}\label{Observacion.1}
In \cite{Disney} conditions are given which guarantee that the $M/M/1$ system has a renewal departure process (see Theorem 3.4 (4) in this reference). This will be used in the proofs of Theorems \ref{First.Regeneration.Time.Theorem} and \ref{Tma.Stability.Regenerative.Process}.
\end{Remark}

Consider the processes  $\mathbb{L}\left(t\right)=\left(L_{1}\left(t\right),L_{2}\left(t\right),L_{3}\left(t\right),L_{4}\left(t\right)\right)$, $\mathbb{B}\left(t\right)=\left(B_{1}\left(t\right),B_{2}\left(t\right),\right.$ $\left.B_{3}\left(t\right),B_{4}\left(t\right)\right)$, $\mathbb{K}\left(t\right)=\left(K_{1}\left(t\right),K_{2}\left(t\right),K_{3}\left(t\right),K_{4}\left(t\right)\right)$, and $\mathbb{V}\left(t\right)=\left(V_{1}\left(t\right),V_{2}\left(t\right),V_{3}\left(t\right),\right.$ $\left.V_{4}\left(t\right)\right)$, $t\geq0$, for the queue lengths, switchover times, service times and polling instants, respectively. Associated to  the queue length processes, the state spaces $\mathbb{D}_{i}=\left\{0,1,2,\ldots,\right\}$ and $\mathcal{D}_{i}=\mathcal{P}\left(\mathbb{D}_{i}\right)$, are considered, where $\mathcal{P}\left(\mathbb{D}_{i}\right)$ is the class of all subsets of $\mathbb{D}_{i}$, for $i=1,2,3,4$. For the following processes: switchover times, service times, and polling instants, consider the state space $\mathbb{G}=\left[0,\infty\right)$ with $\mathcal{G}=\mathcal{B}\left(\mathbb{G}\right)$, where $\mathcal{B}\left(\mathbb{G}\right)$ is the Borel $\sigma$-algebra generated by the open subsets of $\mathbb{G}$. Then the general process $$\mathbb{W}\left(t\right)=\left(\mathbb{L}\left(t\right),\mathbb{B}\left(t\right),\mathbb{K}\left(t\right),\mathbb{V}\left(t\right)\right)\textrm{,  }t>0,$$ is obtained, with state spaces $\Xi=\mathbb{D}_{i}^{4}\times \mathbb{G}^{12}$ and $\Im=\mathcal{B}\left(\Xi\right)$. In the sequel, the random variables taken into account are supposed to be defined in the measurable space $\left(\Xi,\Im\right)$. For a random variable $\eta$, $\eta\left[\Xi\right]:=\left\{\eta\left(t\right):t\geq0\right\}$ will be denoted. Besides, the following events for the arrival processes will be defined for some $t\geq0$ and queue $Q_{i}$ in the NCPS:  $A_{i}\left(t\right)=\left\{0 \textrm{ arrivals on }Q_{i}\textrm{ at time }t\right\}$,  for $i=1,2,3,4$.\medskip
\begin{Teo}\label{First.Regeneration.Time.Theorem}
Suppose that Assumption 1 holds. Given an NCPS, there exists a random variable $T^{*}$, such that $$\prob\left\{A_{1}\left(T^{*}\right)\cap A_{2}\left(T^{*}\right)\cap
A_{3}\left(T^{*}\right)\cap A_{4}\left(T^{*}\right)|T^{*}=t^{*}\right\}>0\textrm{, }t^{*}\in T^{*}\left[\Xi\right]$$  is satisfied.
\end{Teo}
\begin{proof}
The proof is divided into four steps given from a) to d).
\begin{itemize}
\item[a) ] 
In this incise it is going to be proved that both queues of system $\Gamma_{1}$ become empty at certain time. \\\\
The index $j=1,2,3,\ldots$, is used to denote the cycle when the server of system $\Gamma_{1}$ visits a queue. Denote its switchover times  by $r_{1}\left(j\right)$ and by $r_{2}\left(j\right)$, and its service times by $K_{1}\left(j\right)$, $K_{2}\left(j\right)$, for the queues $Q_{1}$ and $Q_{2}$,  respectively.\medskip

It is also necessary to define appropriate random variables which are going to help calculating the joint probability for the events $A_{1}\left(t\right)$ and $A_{2}\left(t\right)$ for certain times $\tilde{t}>0$. When the server arrives to the queue $Q_{1}$, at $t=0$, $\tau_{1}\left(1\right)=0$, there are no users in the queue, so that $K_{1}\left(1\right)=0$, therefore $\overline{\tau}_{1}\left(1\right)=\tau_{1}\left(1\right)=0$. Then the server moves to $Q_{2}$ according to the random variable $r_{1}\left(1\right)$ so that the arrival time to queue $Q_{2}$ is given by $\tau_{2}\left(1\right)=r_{1}\left(1\right)$.\medskip

There are two  possible situations when the server arrives to $Q_{2}$: the queue is empty or not. This means that $K_{2}\left(1\right)$ could be equal or greater than $0$. Here the authors just present the case when $K_{2}\left(1\right)>0$; the proof when $ K_{2}\left(1\right)=0$ is similar to the case of $K_{2}\left(1\right)>0$. Suppose $K_{2}\left(1\right)>0$, then $$\overline{\tau}_{2}\left(1\right)=\tau_{2}\left(1\right)+K_{2}\left(1\right),$$ consequently the server moves to $Q_{1}$ incurring in a switchover time $r_{2}\left(1\right)$, so that $$\tau_{1}\left(2\right)=\overline{\tau}_{2}\left(1\right)+r_{2}\left(1\right).$$
For $\tau_{1}\left(2\right)$ there are two possibilities: $Q_{1}$ is still empty or not. This means that $K_{1}\left(2\right)=0$ or $K_{1}\left(2\right)>0$, therefore $\overline{\tau}_{1}\left(2\right)=\tau_{1}\left(2\right)$ or  $\overline{\tau}_{1}\left(2\right)=\tau_{1}\left(2\right)+K_{1}\left(2\right)$. In both cases $$\tau_{2}\left(2\right)=\overline{\tau}_{1}\left(2\right)+r_{1}\left(2\right).$$

If $K_{1}\left(2\right)$ is not equal to zero, it is necessary to consider the period of time when it is possible to guarantee that both queues are empty at the same time. If $K_{1}\left(1\right)=K_{2}\left(1\right)=K_{1}\left(2\right)=K_{2}\left(2\right)=0$,  the calculations are simple, then it is supposed that they are not equal to zero. 
Let $\alpha$ be fixed with $\alpha\in\left[0,1\right]$. Consider the random variables
\begin{eqnarray}\medskip
\begin{array}{ll}
T_{1}=\left(1-\alpha\right)\overline{\tau}_{1}\left(2\right)+\alpha\tau_{2}\left(2\right),&
T_{2}=\left(1-\alpha\right)\overline{\tau}_{2}\left(1\right)+\alpha\tau_{2}\left(2\right).
\end{array}
\end{eqnarray}
For $t_{1}\in T_{1}\left[\Xi\right]$ and $t_{2}\in T_{2}\left[\Xi\right]$, it is obtained that
\begin{eqnarray}
\begin{array}{ll}
\prob\left\{A_{1}\left(T_{1}\right)|T_{1}=t_{1}\right\}=e^{-\tilde{\mu}_{1}t_{1}}\textrm{, and }&
\prob\left\{A_{2}\left(T_{2}\right)|T_{2}=t_{2}\right\}=e^{-\tilde{\mu}_{2}t_{2}}.
\end{array}
\end{eqnarray}
By construction it is gotten that $T_{1}\left[\Xi\right]\subseteq T_{2}\left[\Xi\right]$, therefore  $T_{1}\left[\Xi\right]\cap T_{2}\left[\Xi\right]=T_{1}\left[\Xi\right]\subseteq T_{2}\left[\Xi\right]$, so that, if $\tilde{t}\in T_{1}\left[\Xi\right]\cap T_{2}\left[\Xi\right]$ is considered, then $$\prob\left\{A_{2}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}\geq\prob\left\{A_{2}\left(T_{2}\right)|T_{2}=\tilde{t}\right\}.$$ Therefore the joint probability is given by
\begin{eqnarray*}\medskip
\prob\left\{A_{1}\left(T_{1}\right)\cap A_{2}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}&=&\prob\left\{A_{1}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}\prob\left\{A_{2}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}\\\medskip
&\geq&\prob\left\{A_{1}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}\prob\left\{A_{2}\left(T_{2}\right)|T_{2}=\tilde{t}\right\}\\
&=& e^{-\tilde{\mu}_{1}\tilde{t}}e^{-\tilde{\mu}_{2}\tilde{t}}
=e^{-\left(\tilde{\mu}_{1}+\tilde{\mu}_{2}\right)\tilde{t}}>0.
\end{eqnarray*}
(Note that events $A_{1}\left(t\right)$ and $A_{2}\left(t\right)$ are conditionally independent under $T_{1}$.)  Hence,
\begin{eqnarray}
\prob\left\{A_{1}\left(T_{1}\right)\cap A_{2}\left(T_{1}\right)|T_{1}=\tilde{t}\right\}>0,\textrm{ for }\tilde{t}\in T_{1}\left[\Xi\right]\cap T_{2}\left[\Xi\right].
\end{eqnarray}
\item[b) ] Now it will be demonstrated that for the time of departure of the server in system $\Gamma_{1}$ it is always possible to find a cycle such that the server in system $\Gamma_{2}$ has just finished to attend one of the queues. So let us prove that for $\tau_{2}\left(2\right)$ there exists an $n\geq1$ such that one of the following inequalities is satisfied:
\begin{eqnarray}\label{Eq.Casos.Ciclos}
\begin{array}{ll}\medskip
\textrm{a) }\tau_{3}\left(n\right)<\tau_{2}\left(2\right)
<\overline{\tau}_{3}\left(n\right),&
\textrm{b) }\overline{\tau}_{3}\left(n\right)<\tau_{2}\left(2\right)
<\tau_{4}\left(n\right),\\
\textrm{c) }\tau_{4}\left(n\right)<\tau_{2}\left(2\right)<
\overline{\tau}_{4}\left(n\right), &
\textrm{d) }\overline{\tau}_{4}\left(n\right)<\tau_{2}\left(2\right)
<\tau_{3}\left(n+1\right).
\end{array}
\end{eqnarray}
The authors only give the proof for the case a); the proofs for the rest of the cases are similar. 
Suppose that for all $n\geq1$, $\tau_{2}\left(2\right)\leq\overline{\tau}_{3}\left(n\right)$ or $\overline{\tau}_{3}\left(n\right)\leq\tau_{2}\left(2\right)$. Consider $\tau_{3}\left(n\right)=0$ and $\tau_{2}\left(2\right)>0$, with $\overline{\tau}_{3}\left(n\right)\leq\tau_{2}\left(2\right)$ for all $n\geq1$ (the proof of the case $\tau_{2}\left(2\right)\leq\overline{\tau}_{3}\left(n\right)$ is analogous). It implies that all arrivals take place before $\tau_{2}\left(2\right)$, but this is not possible. Hence, case a) holds.\medskip
\item[c) ] In this part two random variables will be constructed for the system $\Gamma_{2}$ such that it will be possible to determine the joint probability for the events $A_{3}\left(t\right)$ and $A_{4}\left(t\right)$ for certain times $\hat{t}$. Without loss of generality, consider that $\tau_{3}\left(n\right)<\tau_{2}\left(2\right)<\overline{\tau}_{3}\left(n\right)$ for $n$ whose existence is guaranteed in (b), and define the random variables
\begin{eqnarray}
\begin{array}{l}\medskip
T_{3}=\left(1-\alpha\right)\tau_{3}\left(n-1\right)
+\alpha\overline{\tau}_{3}\left(n\right)\textrm{ and}\\
T_{4}=\left(1-\alpha\right)\overline{\tau}_{4}\left(n-1\right)+\alpha
\overline{\tau}_{3}\left(n\right).
\end{array}
\end{eqnarray}
Again, as above, for $\hat{t}\in  T_{3}\left[\Xi\right]\cap T_{4}\left[\Xi\right]$, the joint probability is given by
\begin{eqnarray*}\medskip
\prob\left\{A_{3}\left(T_{4}\right)\cap
A_{4}\left(T_{4}\right)|T_{4}=\hat{t}\right\}&\geq&
\prob\left\{A_{3}\left(T_{3}\right)|T_{3}=\hat{t}\right\}\cdot
\prob\left\{A_{4}\left(T_{4}\right)|T_{4}=\hat{t}\right\}\\
&=&e^{-\left(\tilde{\mu}_{3}+\tilde{\mu}_{4}\right)\hat{t}}>0.
\end{eqnarray*}%}
\item[d)] Finally, with the random variables $T_{1},T_{2},T_{3}$, and $T_{4}$, a new random variable $T^{*}$ is constructed, such that all the queues of both systems become empty for $T^{*}$. For $n$, whose existence is guaranteed in (b), let
\begin{eqnarray}
\begin{array}{lc}
T^{+}:=\overline{\tau}_{3}\left(n\right),\textrm{ and }&
T^{-}:=\min\left\{\overline{\tau}_{2}\left(1\right),\overline{\tau}_{3}\left(n-1\right)\right\}\\
\end{array}
\end{eqnarray}
and observe that  $$T^{-}\left[\Xi\right]\subset T_{i}\left[\Xi\right]\subset T^{+}\left[\Xi\right],\textrm{ for }i=1,2,3,4.$$
Define the random variable
\begin{eqnarray}
T^{*}:=\left(1-\alpha\right)T^{-}+\alpha T^{+},
\end{eqnarray}
such that for all $i=1,2,3,4$, it satisfies that $T^{*}\left[\Xi\right]\subset T_{i}\left[\Xi\right]$, so  $T^{*}\left[\Xi\right]\subset \cap_{i=1}^{4}T_{i}\left[\Xi\right]$. This implies that
\begin{equation}
\prob\left\{A_{i}\left(T^{*}\right)|T^{*}=t^{*}\right\}\geq\prob\left\{A_{i}\left(T_{i}\right)|T_{i}=t^{*}\right\}=e^{-\tilde{\mu}_{i}t^{*}}>0,\textrm{ for }t^{*}\in T^{*}\left[\Xi\right].
\end{equation}
This means that for $t^{*}\in T^{*}\left[\Xi\right]$ there are no arrivals to the queues $Q_{1}$ and $Q_{2}$, it results that there are no transfer users from $Q_{3}$ and $Q_{4}$, so $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, and $\tilde{\mu}_{4}=\mu_{4}$. Consequently the events $A_{1}\left(T^{*}\right)$ and $A_{3}\left(T^{*}\right)$ are conditionally independent for $T^{*}$; the same argument can be applied for the events $A_{2}\left(T^{*}\right)$ and $A_{4}\left(T^{*}\right)$. Therefore, it follows that
\begin{eqnarray}
\begin{array}{c}\medskip
\prob\left\{A_{1}\left(T^{*}\right)\cap A_{2}\left(T^{*}\right)\cap
A_{3}\left(T^{*}\right)\cap A_{4}\left(T^{*}\right)
|T^{*}=t^{*}\right\}\geq\prod_{i=1}^{4}
\prob\left\{A_{i}\left(T_{i}\right)
|T_{i}=t_{i}\right\}\\
=\prod_{i=1}^{4}e^{-\mu_{i}t_{i}}
=e^{-\sum_{i=1}^{4}\mu_{i}t_{i}}>0,\textrm{ for }t^{*}\in T^{*}\left[\Xi\right].
\end{array}
\end{eqnarray}
\end{itemize}%\qed
\end{proof}
\begin{Remark}\label{Obs.Primer.Momento.Finito}
Note that it is easy to prove that $T^{*}$ has a finite first moment. This is a consequence of the fact that each of the variables involved in the definition of $T^{*}$ has a finite first moment, given that each of the queues in the NCPS is an $M/M/1$ system.
\end{Remark}
Now, the stationarity of the stochastic process related to the NCPS will be proved. Definitions very close to the ones given in Chapters 2, 3, 4, and 10 in Thorisson \cite{Thorisson} with respect to the stationarity of regenerative processes will be followed. Consider the processes $\mathbb{L}\left(t\right)=\left(L_{1}\left(t\right),L_{2}\left(t\right),L_{3}\left(t\right),L_{4}\left(t\right)\right)$, $t\geq0$, defined previously. Observe that the process $\mathbb{L}\left(t\right)$, $t\geq0$, takes values in the product space given by $$\left(\mathbf{E},\tilde{\mathcal{E}}\right)=\left(\prod_{i=1}^{4}D_{i},\prod_{i=1}^{4}\mathcal{D}_{i}\right),$$ which also results to be a polish space, and $\tilde{\mathcal{E}}$ is the corresponding product $\sigma$-algebra. 
\begin{Teo}\label{Tma.Stability.Regenerative.Process}
Given the stochastic process $\mathbb{L}\left(t\right)$, $t\geq0$, there is an infinite sequence of regeneration times $\Phi_{n},n\geq0$ defined on $\left(\Xi,\Im\right)$, such that for $\phi_{n}\in \Phi_{n}\left[\Xi\right]$,
\begin{eqnarray}\label{Eq.Regeneracion}
\mathbb{L}\left(\phi_{n}\right)=\left(L_{1}\left(\phi_{n}\right),L_{2}\left(\phi_{n}\right),L_{3}\left(\phi_{n}\right),L_{4}\left(\phi_{n}\right)\right)=\left(0,0,0,0\right),n\geq0.
\end{eqnarray}
Furthermore, there exists a stationary version of the process $\mathbb{L}\left(t\right)$, $t\geq0$.
\end{Teo}
\begin{proof}
Suppose that the process $\mathbf{L}=\left\{\mathbb{L}\left(t\right),t\geq0\right\}$ has been constructed in a canonical way on a probability space $\left(\overline{\Omega},\overline{\mathcal{F}},\overline{\prob}\right)$.
Given that the queue length processes $\mathbb{L}\left(t\right)$, $t\geq0$ are counting processes, it follows that they have right continuous paths with left hand limits. Hence, it is obtained that the process $\mathbf{L}$ is a continuous time one sided process, with path set $H:=D_{\mathbf{E}}\left[0,\infty\right)$, where  $D_{\mathbf{E}}\left[0,\infty\right)$ is the set of right continuous  maps from $\left[0,\infty\right)$ to $\mathbf{E}$ with left hand limits (see Section 2.1,  p. 126 in \cite{Thorisson}).

According to the second paragraph, Section 2.8, p. 131 in \cite{Thorisson}, the path set $H$ is internally shift-invariant and therefore canonically jointly measurable. By Section 2.7, p. 130 in \cite{Thorisson}, the stochastic process $\mathbf{L}$ is shift-measurable. 

Hence, by Theorem \ref{First.Regeneration.Time.Theorem} it is obtained that the hypothesis of Theorem 4.5, p. 362 in \cite{Thorisson} are satisfied, so that the underlying probability space $\left(\overline{\Omega},\overline{\mathcal{F}},\overline{\prob}\right)$ can be extended to support a sequence of random times $\left\{\Phi_{n}:n\geq1\right\}$ such that the stochastic process regenerates in these points. In the case discussed here, each of the queues becomes empty at $\phi_{n}\in\Phi_{n}\left[\Xi\right]$.

Finally, by Remark \ref{Obs.Primer.Momento.Finito} and Definition 3.1, p. 346 in \cite{Thorisson} (in fact, comparing the equations (3.1) and (3.2) with equations (4.6) and (4.7) in Theorem 4.5, p. 362 in \cite{Thorisson}), it is gotten that the stochastic process $\mathbf{L}$ is {\it{classical regenerative}} with finite first moment for the cycle lengths, therefore it is possible to apply Theorem 3.1, p. 348 in \cite{Thorisson}, in order to obtain that there exists a stationary version of the stochastic processes $\mathbf{L}$ and $\left\{\Phi_{n}:n\geq0\right\}$ satisfies (\ref{Eq.Regeneracion}).
\end{proof}%\qed
\medskip
Now, the probability generating functions that model the NCPS will be determined to calculate the expected queue lengths at any time.

In this section it is supposed that Assumption \ref{Supuestos.Estabilidad} holds. Here, the idea given in \cite{Takagi} is followed, in order to find the expected queue lengths at any time for the NCPS. 

Fix $i\in\left\{1,2,3,4\right\}$. Let $L_{i}^{*}$ be the number of users at queue $Q_{i}$ at polling instants, then, following Section \ref{CuerpoTrabajo:Explicits}, it is obtained that
\begin{eqnarray}
\begin{array}{cc}
\esp\left[L_{i}^{*}\right]=f_{i}\left(i\right), &
Var\left[L_{i}^{*}\right]=\mathbf{f}_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{array}
\end{eqnarray}
Consider the cycle time $C_{i}$ for the queue $Q_{i}$ with duration given by $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$ for $m\geq1$. The intervisit time $I_{i}$ of the queue $Q_{i}$ is defined as the period beginning at the time the server leaves $Q_{i}$ in a cycle and ends at the time when the queue $Q_{i}$ is polled in the next cycle; its duration is given by $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$. The interval between two successive regeneration points will be called regenerative cycle. Observe that Theorem \ref{Tma.Stability.Regenerative.Process} guarantees its existence. Let $M_{i}$ be the number of polling cycles in a regenerative cycle. The duration of the $m$-th polling cycle in a regeneration cycle will be denoted by $C_{i}^{(m)}$, for $m=1,2,\ldots,M_{i}$. The mean polling cycle time is defined by
\begin{equation}\label{Eq.FGP.Ciclos}
\esp\left[C_{i}\right]=\frac{\sum_{m=1}^{M_{i}}\esp\left[C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}.
\end{equation}
Again, note that Theorem \ref{Tma.Stability.Regenerative.Process} guarantees that all the terms in the right-hand side of (\ref{Eq.FGP.Ciclos}) are well defined.
%{\Large{
For the process $L_{i}\left(t\right)$, $t\geq0$, their PGF will be denoted by $\mathcal{Q}_{i}\left(z\right)$, $z\in\mathbb{C}$, which is also given by the time average of $z^{L_{i}\left(t\right)}$ over the regenerative cycle defined before, so it is obtained that
\begin{eqnarray}\label{Eq.Q.any.time}
\mathcal{Q}_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\left(\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right)\right]},
\end{eqnarray}
which can be rewritten in the form 
\begin{equation}\label{Eq.Long.Caulquier.Tiempo}
\mathcal{Q}_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)},
\end{equation}%}}
(see Section 3 in \cite{Takagi}). The following proposition provides the expected queue lengths for each of the queues in the NCPS at any time.
\begin{Teo}
For the queue lengths in the NCPS at any time, with PGF given in (\ref{Eq.Long.Caulquier.Tiempo}), the first and second order moments are given by
\begin{eqnarray}
\mathcal{Q}_{i}^{(1)}\left(1\right)=\frac{1}{\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)}\frac{\esp (L_{i}^{*})^{2}}{2\esp\left[C_{i}\right]}
-\sigma_{i}^{2}\frac{\esp\left[L_{i}^{*}\right]}{2\esp \left[C_{i}\right]}\cdot\frac{1-2\tilde{\mu}_{i}}{\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}},
\end{eqnarray}
where $\sigma_{i}^{2}=\left(Var\left[\tilde{X}_{i}\left(t\right)\right]\right)^{2}$, and 
\begin{eqnarray}
\begin{array}{l}
\esp\left[C_{i}\right]\mathcal{Q}_{i}^{(2)}\left(1\right)=\frac{1}{\tilde{\mu}_{i}^{3}\left(1-\tilde{\mu}_{i}\right)^{3}}\left\{
-\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}O_{1,i}^{(2)}(1)\right.\\
-\left.\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{3,i}^{(2)}(1)
%\right.\\&-&\left.
-\tilde{\mu}_{i}^{2}\left(1-\tilde{\mu}_{i}\right)^{2}O_{1,i}(1)P_{i}^{(2)}(1)\right.\\
+\left.2\tilde{\mu}_{i}\left[\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)-\left(1-\tilde{\mu}_{i}\right)\right]\left(O_{3,i}^{(1)}(1)\right)^{2}
\right.\\-\left.
2\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{3,i}^{(1)}(1)
%\right.\\&-&\left.
-2\tilde{\mu}_{i}^{3}\left(1-\tilde{\mu}_{i}\right)^{2}O_{1,i}^{(1)}(1)
\right.\\-\left.
2\left(1-2\tilde{\mu}_{i}\right)O_{3,i}^{(1)}(1)O_{1,i}^{(1)}(1)
%\right.\\&-&\left.
-2\tilde{\mu}_{i}^{2}\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{1,i}^{(1)}(1)\right\},
\end{array}
\end{eqnarray}
for $i=1,2,3,4$. 
\end{Teo}
\begin{proof}
Fix $i\in\left\{1,2,3,4\right\}$ and $z\in\mathbb{C}$. To remove the singularities in (\ref{Eq.Long.Caulquier.Tiempo}) it is necessary to define the following analytic functions:
\begin{eqnarray}
\begin{array}{ccc}
\varphi_{i}\left(z\right)=1-F_{i}\left(z\right),&
\psi_{i}\left(z\right)=z-P_{i}\left(z\right),&\textrm{ and }
\varsigma_{i}\left(z\right)=1-P_{i}\left(z\right),
\end{array}
\end{eqnarray}
then
\begin{eqnarray}
\esp\left[C_{i}\right]\mathcal{Q}_{i}\left(z\right)=\frac{\left(z-1\right)\varphi_{i}\left(z\right)P_{i}\left(z\right)}{\psi_{i}\left(z\right)\varsigma_{i}\left(z\right)}.
\end{eqnarray}
For $k\geq0$, define $a_{k}=P\left\{L_{i}^{*}\left(t\right)=k\right\}$. It is obtained that
\begin{eqnarray*}
\varphi_{i}\left(z\right)=1-F_{i}\left(z\right)=1-\sum_{k=0}^{+\infty}a_{k}z^{k},
\end{eqnarray*}
therefore 
\begin{eqnarray*}
\varphi_{i}^{(1)}\left(z\right)&=&-\sum_{k=1}^{+\infty}ka_{k}z^{k-1},\textrm{ with }\varphi_{i}^{(1)}\left(1\right)=-\esp\left[L_{i}^{*}\left(t\right)\right],\textrm{ and}\\
\varphi_{i}^{(2)}\left(z\right)&=&-\sum_{k=2}^{+\infty}k(k-1)a_{k}z^{k-2},\textrm{ hence }\varphi_{i}^{(2)}\left(1\right)=\esp\left[L_{i}^{*}\left(L_{i}^{*}-1\right)\right].
\end{eqnarray*}
In the same way it is gotten that
\begin{eqnarray*}
\varphi_{i}^{(3)}\left(z\right)&=&-\sum_{k=3}^{+\infty}k(k-1)(k-2)a_{k}z^{k-3}\textrm{ and }\varphi_{i}^{(3)}\left(1\right)=-\esp\left[L_{i}^{*}\left(L_{i}^{*}-1\right)\left(L_{i}^{*}-2\right)\right].
\end{eqnarray*}
Expanding $\varphi_{i}\left(z\right)$ around $z=1$,
\begin{eqnarray*}
\varphi_{i}\left(z\right)&=&\varphi_{i}\left(1\right)+\frac{\varphi_{i}^{(1)}\left(1\right)}{1!}\left(z-1\right)+\frac{\varphi_{i}^{(2)}\left(1\right)}{2!}\left(z-1\right)^{2}+\frac{\varphi^{(3)}\left(1\right)}{3!}\left(z-1\right)^{3}+\ldots+\\
&=&\left(z-1\right)\left\{\varphi_{i}^{(1)}\left(1\right)+\frac{\varphi^{(2)}\left(1\right)}{2!}\left(z-1\right)+\frac{\varphi_{i}^{(3)}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+\right\}=\left(z-1\right)O_{1,i}\left(z\right)
\end{eqnarray*}
with $O_{1,i}\left(z\right)\neq0$, given that $O_{1,i}\left(z\right)=-\esp\left[L^{*}_{i}\right]$, where
\begin{eqnarray}
O_{1,i}\left(z\right)&=&\varphi_{i}^{(1)}\left(1\right)+\frac{\varphi_{i}^{(2)}\left(1\right)}{2!}\left(z-1\right)+\frac{\varphi_{i}^{(3)}\left(1\right)}{3!}\left(z-1\right)^{2}+\ldots+.
\end{eqnarray}
Calculating the derivatives of $O_{1,i}\left(z\right)$, and evaluating in $z=1$, it is obtained that 
\begin{eqnarray*}
O_{1,i}\left(1\right)&=&-\esp\left[L_{i}^{*}\right]\textrm{, }O_{1,i}^{(1)}\left(1\right)=-\frac{1}{2}\esp\left[(L_{i}^{*})^{2}\right]+\frac{1}{2}\esp\left[L_{i}^{*}\right]\\
\textrm{ and }O_{1,i}^{(2)}\left(1\right)&=&-\frac{1}{3}\esp\left[(L_{i}^{*})^{3}\right]+\esp\left[(L_{i}^{*})^{2}\right]-\frac{2}{3}\esp\left[L_{i}^{*}\right].
\end{eqnarray*}
Proceeding in a similar manner for $\psi_{i}\left(z\right)=z-P_{i}\left(z\right)$ and $\varsigma_{i}\left(z\right)=1-P_{i}\left(z\right)$, it is gotten that
\begin{eqnarray}
\esp\left[C_{i}\right]Q_{i}\left(z\right)&=&\frac{O_{1,i}\left(z\right)P_{i}\left(z\right)}{O_{2,i}\left(z\right)O_{3,i}\left(z\right)}.
\end{eqnarray}
Calculating the derivative with respect to $z$, and evaluating in $z=1$,
\begin{eqnarray*}\label{Ec.Primer.Derivada.Q}
\esp\left[C_{i}\right]\mathcal{Q}_{i}^{(1)}\left(1\right)
&=&\frac{1}{\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}}\left\{\left(-\frac{1}{2}\esp \left[(L_{i}^{*})^{2}\right]+\frac{1}{2}\esp\left[L_{i}^{*}\right]\right)\left(1-\tilde{\mu}_{i}\right)\left(-\tilde{\mu}_{i}\right)\right.\\
&+&\left.
\left(-\esp\left[ L_{i}^{*}\right]\right)\left(1-\tilde{\mu}_{i}\right)\left(-\tilde{\mu}_{i}\right)\tilde{\mu}_{i}%\right.\\
%&-&\left.
-\left(-\frac{1}{2}\esp\left[\tilde{X}_{i}^{2}\left(t\right)\right]+\frac{1}{2}\tilde{\mu}_{i}\right)\left(-\tilde{\mu}_{i}\right)\left(-\esp\left[ L_{i}^{*}\right]\right)\right.\\
&-&\left.\left(1-\tilde{\mu}_{i}\right)\left(-\esp\left[ L_{i}^{*}\right]\right)\left(-\frac{1}{2}\esp\left[\tilde{X}_{i}^{2}\left(t\right)\right]+\frac{1}{2}\tilde{\mu}_{i}\right)\right\}\\
&=&\frac{1}{\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}}\left\{-\frac{1}{2}\tilde{\mu}_{i}^{2}\esp\left[ (L_{i}^{*})^{2}\right]
+\frac{1}{2}\tilde{\mu}_{i}\esp\left[(L_{i}^{*})^{2}\right]
+\frac{1}{2}\tilde{\mu}_{i}^{2}\esp\left[ L_{i}^{*}\right]
-\tilde{\mu}_{i}^{3}\esp\left[ L_{i}^{*}\right]\right.\\
&+&\left.\tilde{\mu}_{i}\esp\left[ L_{i}^{*}\right]\esp\left[\tilde{X}_{i}^{2}\left(t\right)\right]%\right.\\
%&-&\left.
-\frac{1}{2}\esp\left[ L_{i}^{*}\right]\esp \left[\tilde{X}_{i}^{2}\left(t\right)\right]\right\}\\
&=&\frac{1}{2\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)}\esp\left[ (L_{i}^{*})^{2}\right]-\frac{\frac{1}{2}-\tilde{\mu}_{i}}{\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}}\sigma_{i}^{2}\esp\left[ L_{i}^{*}\right].
\end{eqnarray*}
It means that 
\begin{eqnarray*}
\mathcal{Q}_{i}^{(1)}\left(1\right)=\frac{1}{\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)}\frac{\esp\left[ (L_{i}^{*})^{2}\right]}{2\esp\left[C_{i}\right]}
-\sigma_{i}^{2}\frac{\esp L_{i}^{*}}{2\esp \left[C_{i}\right]}\cdot\frac{1-2\tilde{\mu}_{i}}{\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}}.
\end{eqnarray*}
Deriving again and evaluating in $z=1$, it follows that
\begin{eqnarray*}
\esp\left[C_{i}\right]\mathcal{Q}_{i}^{(2)}\left(1\right)&=&\frac{1}{\tilde{\mu}_{i}^{3}\left(1-\tilde{\mu}_{i}\right)^{3}}\left\{
-\left(1-\tilde{\mu}_{i}\right)^{2}\tilde{\mu}_{i}^{2}O_{1,i}^{(2)}(1)\right.\\
&-&\left.\tilde{\mu}_{i}\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{3,i}^{(2)}(1)
%\right.\\&-&\left.
-\tilde{\mu}_{i}^{2}\left(1-\tilde{\mu}_{i}\right)^{2}O_{1,i}(1)P_{i}^{(2)}(1)\right.\\
&+&\left.2\tilde{\mu}_{i}\left[\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)-\left(1-\tilde{\mu}_{i}\right)\right]\left(O_{3,i}^{(1)}(1)\right)^{2}
\right.\\&-&\left.
2\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{3,i}^{(1)}(1)
%\right.\\&-&\left.
-2\tilde{\mu}_{i}^{3}\left(1-\tilde{\mu}_{i}\right)^{2}O_{1,i}^{(1)}(1)
\right.\\&-&\left.
2\left(1-2\tilde{\mu}_{i}\right)O_{3,i}^{(1)}(1)O_{1,i}^{(1)}(1)
%\right.\\&-&\left.
-2\tilde{\mu}_{i}^{2}\left(1-\tilde{\mu}_{i}\right)\left(1-2\tilde{\mu}_{i}\right)O_{1,i}(1)O_{1,i}^{(1)}(1)\right\},
\end{eqnarray*}
where $O_{1,i}\left(1\right),O_{1,i}^{(1)}\left(1\right),O_{3,i}^{(1)}(1),O_{3,i}^{(2)}(1),P_{i}^{(2)}(1)$ can be obtained using direct operations.
\end{proof}%\qed
\begin{Remark}
To determine the second order moments for the queue lengths, it is necessary to calculate the third derivative of the arrival processes for each of the queues.
\end{Remark}

  %_____________________________________________________________________
\begin{thebibliography}{99}

\bibitem{Asmussen} Asmussen Soren, Applied Probability and
Queues, John Wiley and Sons, 1987.%[1]

\bibitem{Bhat} Bhat Narayan, An Introduction to Queueing Theory
Modelling and Analysis in Applications, Birkhauser, 2008.

\bibitem{Boxma} Boxma J. O., Analysis and Optimization of Polling
Systems, Queueing, Performance and Control in ATM, pp. 173-183,
1991.

\bibitem{Boxma2} Boxma J. O., Pseudoconservation Laws in Cyclic
Service Systems, Journal of Applied Probability, vol. 24, 1987,
pp. 949-964.

\bibitem{Borovkov} Borovkov. A. A. and Schassberger R., Ergodicity
of a Polling Network, Stochastic Processes and their Applications,
vol. 50, no. 2, 1995, pp. 253-262.

\bibitem{BosBoon}Laurent van den Bos and Marko Boon, Networks of Polling Systems (report), Eindhoven University of Technology, 2013.

\bibitem{BoonMeiWinands} M.A.A. Boon, R.D. van der Mei and E.M.M. Winands, Applications of Polling Systems, February 24, 2011.

\bibitem{HookHee} Chee-Hook Ng. y Boon-Hee Soong, Queueing
Modelling Fundemantals with Applications in Communications
Networks, John-Wiley and Sons, Ltd, 2008.

\bibitem{Chen} H. Chen, 1995, Fluid approximations and stability of multiclass queueing networks I: Work-conserving disciplines, Annals Applied Probab., to appear.

\bibitem{CooperII} R.B. Cooper, Queues served in cyclic order: waiting times (The
Bell System Technical Journal, 49 (1970) 399-413).

\bibitem{Dai} Dai Jean G., On positive Harris Recurrence of Multiclass Queueing
Networks: A Unified Approach Via Fluid Limit Models, The Annals of
Applied Probability, vol. 5, No. 1, 1995, pp. 49-77.

\bibitem{DaiSean} Dai Jim G. and Meyn Sean P., Stability and Convergence of Moments
for Multiclass Queueing Networks via Fluid Limit Models, IEEE
transactions on Automatic Control, vol. 40, No. 11, 1995, pp.
1889-1904.

\bibitem{DaiWeiss}
Dai Jim G.  and Weiss G., Stability and Inestability of Fluid
Models for Reentrant Lines, Mathematics of Operation Research,
vol. 21, no. 1, 1996, pp. 115-134.

\bibitem{Daley68} D.J. Daley, The correlation structure of the output process of
 some single server queueing systems, The Annals of Mathematical Statistics, Vol. 39. No. 3, pp. 1007-1019, 1968.

\bibitem{Davis} Davis, M. H. A., Piecewise Deterministic Markov
Processes: A General Class of Nondifussion Stochastic Models.
Journal of Royal Statistics Society Serie B, vol. 46, no. 3, 1984,
pp. 353-388.

\bibitem{Down} Down D., On the Stability of Polling Models with Multiple Servers,
Journal of Applied Probability, vol. 35, no. 3, 1998, pp. 925-935.

\bibitem{Disney} Ralph L. Disney, Robert L. Farrell and Paulo Renato Morais, A Characterization of $M/G/1$ Queues with Renewal Departure Processes,  Manage of Science, Vol. 19, No. 11, Theory Series, pp. 1222-1228, 1973.

%\bibitem{DaiSean}
%Jim G. Dai and Sean P. Meyn, Stability and convergence of Moments
%for Multiclass Queueing Networks via Fluid Limit Models, IEEE
%transactions on Automatic Control, vol. 40, No. 11, November 1995.

%\bibitem{Dai} J. G. Dai, 1995, On positive Harris recurrence of multiclass queueing networks: A unified approach via fluid limit models, Annals Applied Probab., vol. 5, pp.49-77.

%\bibitem{DaiWeiss}
%Jim G. Dai and G. Weiss, 1996, Stability and Inestability of Fluid
%Models for Reentrant Lines, Mathematics of Operation Research,
%Vol. 21, No. 1.

\bibitem{Eisenberg} M. Eisenberg, Queues with periodic service and changeover time
(Operations Research, 20 (2)(1972) 440-451).

\bibitem{FrickerJaibi}
Fricker Christine and Ja{\"\i}bi M.R., Monotonicity and Stability
of Periodic Polling Models,  Queueing Systems, vol. 15, no. 1-4,
1994, pp. 211-238.

%\bibitem{Getoor} R. K. Getoor, 1979, {Transience and recurrence of Markov processes, Siminaire de Probabilitis XIV, J. Azema and M Yor, Eds. New York Springer-Verlag, pp. 397-409}.


\bibitem{Getoor} Getoor R. K., Transience and recurrence of
Markov processes, Siminaire de Probabilitis XIV, J. Azema and M
Yor, Eds. New York Springer-Verlag, 1979.

\bibitem{Gut} Gut A., Stopped Random Walks: Limit Theorems and
Applications, Applied Probability, 1995.

%\bibitem{HookHee} Chee-Hook Ng. y Boon-Hee Soong, Queueing
Modelling Fundemantals with Applications in Communications
Networks, John-Wiley and Sons, Ltd, 2008.

\bibitem{KaspiMandelbaum} Kaspi H. and Mandelbaum A., Regenerative Closed Queueing
Networks, Stochastics: An International Journal of Probability and
Stochastic Processes, vol. 39, no. 4, 1992, pp. 239-258.

%\bibitem{Konheim} A.G. Konheim, H. Levy, M.M. Srinivasan, Descendant set: an efficient
approach for the analysis of polling systems (IEEE Transactions
on Communications, 42 (2/3/4)(1994) 1245-1253).

\bibitem{Kleinrock} Leonard Kleinrock, Theory, Volume 1, Queueing Systems Wiley-Interscience, 1975,


\bibitem{Konheim} A. G. Konheim, h. Levy and M. M. Srinivasan. Descendant set: an efficient approach for the analysis of polling systems. IEEE Trabsanctions on Communications, 42(2-4): pp. 1245-1253, 1994.

\bibitem{Lang} Serge Lang, Calculus of Several Variables, Addison-Wesley Publishing Company, 1973.

\bibitem{LevySidi}
Levy Hanoch y Sidi Moshe , Polling Systems: Applications, Modeling, and Optimization, IEEE Transactions on Communications, vol. 30, no. 10, 1990, pp. 1750-1760.


\bibitem{Stability}
Christine Fricker and M.R. Ja{\"\i}bi, Stability of multi-server
polling models, Institute National de Recherche en Informatique et
en Automatique, Enero 1998.

%\bibitem{MeiBorst} van der Mei, R.D. and Borst, S. C., Analysis of Multiple-Server Polling Systems by Means of the Power-Series Algorithm, Stochastic Models,vol. 13, no. 2, 1997, pp. 339-369.

%\bibitem{Meyn} Meyn Sean P., Transience of Multiclass Queueing Networks via FluidLimit Models, The Annals of Applied Probability, vol. 5, no. 4,1995, pp.946-957.

%\bibitem{MeynTweedie} Meyn S. P. and Tweedie R. L., Stability of Markovian Processes II:Continuous Time Processes and Sample Chains, Advanced Applied Pobability, vol. 25, 1993, pp. 487-517.

\bibitem{MeynTweedie2} Meyn S. P. and Tweedie R. L., Markov Chains and Stochastic Stability,
1993.

\bibitem{MeynDown} Meyn, S.P. and Down, D., Stability of Generalized Jackson
Networks, The Annals of Applied Probability, 1994.

\bibitem{MeiBorst} Van der Mei, R.D. and Borst, S. C., Analysis of multiple-server polling systems by means of the power-series
algorithm, Stochastic Models, vol. 13, no. 2, 1997

\bibitem{Meyn2}
Sean P. Meyn, Transience of Multiclass Queueing Networks via fluid
Limit Models, The Annals of Applied Probability, vol. 5, No. 4,
nov. 1995.

\bibitem{MeynTweedie} S. P. Meyn and R. L. Tweedie, 1993, Stability of Markovian processes II:Continuous time processes and sample chains, Adv. Appl.Pobab., vol.25, pp. 487-517.

\bibitem{Meyn} Sean P. Meyn, 1995, Transience of Multiclass Queueing Networks Via Fluid Limit Models, Annals Appl. Probab., Vol. 5, No. 4, pp. 946-957.


%\bibitem{Rouche} I.J.B.F. Adan, J.S.H. van Leeuwaarden, and E.M.M. Winands. On the application of Rouches theorem in queueing theory. Operations Research Letters, 34(3):355-360, 2006.


%\bibitem{SidiLevy2} M. Sidi and h. Levy. Polling Systems with simultaneus arrivals. IEEEE Transactions on Communications, 39(6):823-827, 1991.


\bibitem{TesisRoubos}
Roubos Alex, Polling Systems and their Applications, Vrije
Universiteit Amsterdam, 2007.

\bibitem{Rouche} I.J.B.F. Adan, J.S.H. van Leeuwaarden and E.M.M. Winands, On the application of Rouche’s theorem in queueing theory, Operation Research Letters, Vol. 34, Issue 3, pp. 355-360, 2006. EURANDOM

\bibitem{RepTec}
Saavedra B. P., Informe T\'ecnico del Microsimulador, Departamento
de Matem\'atias, 2011.

\bibitem{Semenova}
Vishnevskii V.M. and Semenova O.V., Mathematical Methods to Study the Polling Systems, Automation and Remote Control, vol. 67, no. 2, 2006, pp. 173-220.

\bibitem{Serfozo} Richard Serfozo, Basics of Applied Stochastic Processes, Springer-Verlag, 2009.


\bibitem{Sharpe} Sharpe Michael , General Theory of Markov Processes. Boston, M.A.
Academic, 1998.


\bibitem{Sigma} Sigman Karl, The Stability of Open Queueing
Networks, Stochastic Processes and their Applications, vol. 35,
no. 1, 1990, pp. 11-15.

\bibitem{SidiLevy1} Sidi M.  and Levy H.,  Customer Routing in Polling Systems, In: P. King, I. Mitrani, and R. Pooley (Eds.), Proceedings
Performance '90, North-Holland, Amsterdam, 1990.


\bibitem{SidiLevy2} Sidi M.  and Levy H., Polling Systems with Simultaneus Arrivals. IEEE Transactions on Communications, vol. 39, no. 6, 1991, pp.
823-827.

\bibitem{Sigman2} Karl Sigman, Hermann Thorisson and Ronald W. Wolff, A Note on the Existence of Regeneration Times, Journal of Applied Probability, vol. 31, pp. 1116-1122, 1994.


\bibitem{Stidham} Shaler Stidham, Jr., Regenerative Processes in the theory ow queues, with applications to the alternating priority queue, Advances in Applied Probability,  Vol. 4, no. 3, 1972,pp. 542-577.
\bibitem{234} Takagi H., Analysis of Polling Systems, Cambdrige: MIT Press, 1986

\bibitem{TakagiI} Takagi H. and Kleinrock, Analysis of Polling Systems, Cambdrige:
MIT Press, 1986

\bibitem{Takagi}Takagi Hideaki, Queueing Analysis of Polling Models, ACM computing Surveys, vol. 20, no. 1, 1988, pp. 5-28.

\bibitem{Thorisson} Hermann Thorisson, Coupling, Stationarity, and Regeneration, Probability and its Applications, Springer-Verlag, 2000.

\bibitem{Winands} E.M.M. Winands, I.J.B.F. Adan adn G.J. van Houtum, Mean value analysis for polling systems,
Queueing Systems (2006), 54:35-44,

\end{thebibliography}
