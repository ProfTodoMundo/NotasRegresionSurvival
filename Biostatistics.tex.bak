

\subsection{Parte I. Introducci\'on a la Bioestad\'istica}

\section{Introducci\'on}
%\begin{frame}\frametitle{Introducci\'on}
%____________________________________________________________
\subsection{Definici\'on de Estad\'istica}
%____________________________________________________________
\begin{itemize}
\item La Estad\'istica es una ciencia formal que estudia la recolecci\'on, an\'alisis e interpretaci\'on de datos de una muestra representativa, ya sea para ayudar en la toma de decisiones o para explicar condiciones regulares o irregulares de alg\'un fen\'omeno o estudio aplicado, de ocurrencia en forma aleatoria o condicional. 

\item Sin embargo, la estad\'istica es m\'as que eso, es decir, es el veh\'iculo que permite llevar a cabo el proceso relacionado con la investigaci\'on cient\'ifica. 

\item Es transversal a una amplia variedad de disciplinas, desde la f\'isica hasta las ciencias sociales, desde las ciencias de la salud hasta el control de calidad. Se usa para la toma de decisiones en \'areas de negocios o instituciones gubernamentales.

\end{itemize}




%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item Como dijera Huntsberger: \textit{La palabra estad\'istica a menudo nos trae a la mente im\'agenes de n\'umeros apilados en grandes arreglos y tablas, de vol\'umenes de cifras relativas a nacimientos, muertes, impuestos, poblaciones, ingresos, deudas, cr\'editos y as\'i sucesivamente}.  Huntsberger tiene raz\'on pues al instante de escuchar esta palabra estas son las im\'agenes que llegan a nuestra cabeza.

\item La Estad\'istica es mucho m\'as que s\'olo n\'umeros apilados y gr\'aficas bonitas.  

\item Es una ciencia con tanta antiguedad como la escritura, y es por s\'i misma auxiliar de todas las dem\'as ciencias. 

\item Los mercados, la medicina, la ingenier\'ia, los gobiernos, etc. Se nombran entre los m\'as destacados clientes de \'esta. 


\end{itemize}



%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}

\begin{itemize}
\item La ausencia de \'esta conllevar\'ia a un caos generalizado, dejando a los administradores y ejecutivos sin informaci\'on vital a la hora de tomar decisiones en tiempos de incertidumbre.

\item La Estad\'istica que conocemos hoy en d\'ia debe gran parte de su realizaci\'on a los trabajos matem\'aticos de aquellos hombres que desarrollaron la teor\'ia de las probabilidades, con la cual se adhiri\'o a la Estad\'istica a las ciencias formales. 


\end{itemize}

%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}

\begin{Def}
La Estad\'istica es la ciencia cuyo objetivo es reunir una informaci\'on cuantitativa concerniente a individuos, grupos, series de hechos, etc. y deducir de ello gracias al an\'alisis de estos datos unos significados precisos o unas previsiones para el futuro.
\end{Def}

\begin{itemize}
\item La estad\'istica, en general, es la ciencia que trata de la recopilaci\'on, organizaci\'on presentaci\'on, an\'alisis e interpretaci\'on de datos num\'ericos con el fin de realizar una toma de decisi\'on m\'as efectiva.

\end{itemize}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item Otros autores la definen como la expresi\'on cuantitativa del conocimiento dispuesta en forma adecuada para el escrutinio y an\'alisis.

\item Los estudiantes confunden com\'unmente los dem\'as t\'erminos asociados con las Estad\'isticas, una confusi\'on que es conveniente aclarar debido a que esta palabra tiene tres significados: 

\begin{itemize}
\item la palabra estad\'istica, en primer t\'ermino se usa para referirse a la informaci\'on estad\'istica; 
\item tambi\'en se utiliza para referirse al conjunto de t\'ecnicas y m\'etodos que se utilizan para analizar la informaci\'on estad\'istica; y
\item  el t\'ermino estad\'istico, en singular y en masculino, se refiere a una medida derivada de una muestra.
\end{itemize}
\end{itemize}
%\end{frame}


%____________________________________________________________
\subsection{Utilidad e Importancia}
%____________________________________________________________


%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item Los m\'etodos estad\'isticos tradicionalmente se utilizan para prop\'ositos descriptivos, para organizar y resumir datos num\'ericos. La estad\'istica descriptiva, por ejemplo trata de la tabulaci\'on de datos, su presentaci\'on en forma gr\'afica o ilustrativa y el c\'alculo de medidas descriptivas.

\item Ahora bien, las t\'ecnicas estad\'isticas se aplican de manera amplia en mercadotecnia, contabilidad, control de calidad y en otras actividades; estudios de consumidores; an\'alisis de resultados en deportes; administradores de instituciones; en la educaci\'on; organismos pol\'iticos; m\'edicos; y por otras personas que intervienen en la toma de decisiones.

\end{itemize}

%\end{frame}

%____________________________________________________________
\subsection{Historia de la Estad\'istica}
%____________________________________________________________

%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Es dif\'icil conocer los or\'igenes de la Estad\'istica. Desde los comienzos de la civilizaci\'on han existido formas sencillas de estad\'istica, pues ya se utilizaban representaciones gr\'aficas y otros s\'imbolos en pieles, rocas, palos de madera y paredes de cuevas para contar el n\'umero de personas, animales o ciertas cosas. 
\item Su origen empieza posiblemente en la isla de Cerde\~na, donde existen monumentos prehist\'oricos pertenecientes a los Nuragas, las primeros habitantes de la isla; estos monumentos constan de bloques de basalto superpuestos sin mortero y en cuyas paredes de encontraban grabados toscos signos que han sido interpretados con mucha verosimilidad como muescas que serv\'ian para llevar la cuenta del ganado y la caza.

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Los babilonios usaban ya peque\~nas tablillas de arcilla para recopilar datos en tablas sobre la producci\'on agr\'icola y los g\'eneros vendidos o cambiados mediante trueque. 
\item Otros vestigios pueden ser hallados en el antiguo Egipto, cuyos faraones lograron recopilar, hacia el a\~no 3050 antes de Cristo, prolijos datos relativos a la poblaci\'on y la riqueza del pa\'is. 
\item De acuerdo al historiador griego Her\'odoto, dicho registro de riqueza y poblaci\'on se hizo con el objetivo de preparar la construcci\'on de las pir\'amides. 



\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item En el mismo Egipto, Rams\'es II hizo un censo de las tierras con el objeto de verificar un nuevo reparto. 
\item En el antiguo Israel la Biblia da referencias, en el libro de los N\'umeros, de los datos estad\'isticos obtenidos en dos recuentos de la poblaci\'on hebrea. El rey David por otra parte, orden\'o a Joab, general del ej\'ercito hacer un censo de Israel con la finalidad de conocer el n\'umero de la poblaci\'on.

\item Tambi\'en los chinos efectuaron censos hace m\'as de cuarenta siglos. 
\item Los griegos efectuaron censos peri\'odicamente con fines tributarios, sociales (divisi\'on de tierras) y militares (c\'alculo de recursos y hombres disponibles). 

\end{itemize}


%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item La investigaci\'on hist\'orica revela que se realizaron 69 censos para calcular los impuestos, determinar los derechos de voto y ponderar la potencia guerrera.
\item Fueron los romanos, maestros de la organizaci\'on pol\'itica, quienes mejor supieron emplear los recursos de la estad\'istica. Cada cinco a\~nos realizaban un censo de la poblaci\'on y sus funcionarios p\'ublicos ten\'ian la obligaci\'on de anotar nacimientos, defunciones y matrimonios, sin olvidar los recuentos peri\'odicos del ganado y de las riquezas contenidas en las tierras conquistadas. 
\item Para el nacimiento de Cristo suced\'ia uno de estos empadronamientos de la poblaci\'on bajo la autoridad del imperio. 

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Durante los mil a\~nos siguientes a la ca\'ida del imperio Romano se realizaron muy pocas operaciones Estad\'isticas, con la notable excepci\'on de las relaciones de tierras pertenecientes a la Iglesia, compiladas por Pipino el Breve en el 758 y por Carlomagno en el 762 DC. 
\item Durante el siglo IX se realizaron en Francia algunos censos parciales de siervos. 
\item En Inglaterra, Guillermo el Conquistador recopil\'o el Domesday Book o libro del Gran Catastro para el a\~no 1086, un documento de la propiedad, extensi\'on y valor de las tierras de Inglaterra. Esa obra fue el primer compendio estad\'istico de Inglaterra. 

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Aunque Carlomagno, en Francia; y Guillermo el Conquistador, en Inglaterra, trataron de revivir la t\'ecnica romana, los m\'etodos estad\'isticos permanecieron casi olvidados durante la Edad Media.

\item Durante los siglos XV, XVI, y XVII, hombres como Leonardo de Vinci, Nicol\'as Cop\'ernico, Galileo, Neper, William Harvey, Sir Francis Bacon y Ren\'e Descartes, hicieron grandes operaciones al m\'etodo cient\'ifico, de tal forma que cuando se crearon los Estados Nacionales y surgi\'o como fuerza el comercio internacional exist\'ia ya un m\'etodo capaz de aplicarse a los datos econ\'omicos. 

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Para el a\~no 1532 empezaron a registrarse en Inglaterra las defunciones debido al temor que Enrique VII ten\'ia por la peste.  M\'as o menos por la misma \'epoca, en Francia la ley exigi\'o a los cl\'erigos registrar los bautismos, fallecimientos y matrimonios. 
\item Durante un brote de peste que apareci\'o a fines de la d\'ecada de 1500, el gobierno ingl\'es comenz\'o a publicar estad\'istica semanales de los decesos. Esa costumbre continu\'o muchos a\~nos, y en 1632 estos Bills of Mortality (Cuentas de Mortalidad) conten\'ian los nacimientos y fallecimientos por sexo.

\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}

\item En 1662, el capit\'an John Graunt us\'o documentos que abarcaban treinta a\~nos y efectu\'o predicciones sobre el n\'umero de personas que morir\'ian de varias enfermedades y sobre las proporciones de nacimientos de varones y mujeres que cabr\'ia esperar. 

\item El trabajo de Graunt, condensado en su obra \textit{Natural and Political Observations...Made upon the Bills of Mortality}, fue un esfuerzo innovador en el an\'alisis estad\'istico. Por el a\~no 1540 el alem\'an Sebasti\'an Muster realiz\'o una compilaci\'on estad\'istica de los recursos nacionales, comprensiva de datos sobre organizaci\'on pol\'itica, instrucciones sociales, comercio y poder\'io militar. 
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}

\item Durante el siglo XVII aport\'o indicaciones m\'as concretas de m\'etodos de observaci\'on y an\'alisis cuantitativo y ampli\'o los campos de la inferencia y la teor\'ia Estad\'istica.
\item Los eruditos del siglo XVII demostraron especial inter\'es por la Estad\'istica Demogr\'afica como resultado de la especulaci\'on sobre si la poblaci\'on aumentaba, decrec\'ia o permanec\'ia est\'atica. 
\item En los tiempos modernos tales m\'etodos fueron resucitados por algunos reyes que necesitaban conocer las riquezas monetarias y el potencial humano de sus respectivos pa\'ises. 

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}


\item El primer empleo de los datos estad\'isticos para fines ajenos a la pol\'itica tuvo lugar en 1691 y estuvo a cargo de Gaspar Neumann, un profesor alem\'an que viv\'ia en Breslau. 
\item Este investigador se propuso destruir la antigua creencia popular de que en los a\~nos terminados en siete mor\'ia m\'as gente que en los restantes, y para lograrlo hurg\'o pacientemente en los archivos parroquiales de la ciudad. 
\item Despu\'es de revisar miles de partidas de defunci\'on pudo demostrar que en tales a\~nos no fallec\'ian m\'as personas que en los dem\'as. 
\item Los procedimientos de Neumann fueron conocidos por el astr\'onomo ingl\'es Halley, descubridor del cometa que lleva su nombre, quien los aplic\'o al estudio de la vida humana. 


\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item  Sus c\'alculos sirvieron de base para las tablas de mortalidad que hoy utilizan todas las compa\~n\'ias de seguros. 
\item Durante el siglo XVII y principios del XVIII, matem\'aticos como Bernoulli, Francis Maseres, Lagrange y Laplace desarrollaron la teor\'ia de probabilidades. 
\item No obstante durante cierto tiempo, la teor\'ia de las probabilidades limit\'o su aplicaci\'on a los juegos de azar y hasta el siglo XVIII no comenz\'o a aplicarse a los grandes problemas cient\'ificos.
\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item Godofredo Achenwall, profesor de la Universidad de Gotinga, acu\~n\'o en 1760 la palabra estad\'istica, que extrajo del t\'ermino italiano statista (estadista). 
\item Cre\'ia, y con sobrada raz\'on, que los datos de la nueva ciencia ser\'ian el aliado m\'as eficaz del gobernante consciente. 
\item La ra\'iz remota de la palabra se halla, por otra parte, en el t\'ermino latino status, que significa estado o situaci\'on; Esta etimolog\'ia aumenta el valor intr\'inseco de la palabra, por cuanto la estad\'istica revela el sentido cuantitativo de las m\'as variadas situaciones. 
\item Jacques Qu\'etelect es quien aplica las Estad\'isticas a las ciencias sociales. Este interpret\'o la teor\'ia de la probabilidad para su uso en las ciencias sociales y resolver la aplicaci\'on del principio de promedios y de la variabilidad a los fen\'omenos sociales.

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item  Qu\'etelect fue el primero en realizar la aplicaci\'on pr\'actica de todo el m\'etodo Estad\'istico, entonces conocido, a las diversas ramas de la ciencia.

\item  Entretanto, en el per\'iodo del 1800 al 1820 se desarrollaron dos conceptos matem\'aticos fundamentales para la teor\'ia Estad\'istica; la teor\'ia de los errores de observaci\'on, aportada por Laplace y Gauss; y la teor\'ia de los m\'inimos cuadrados desarrollada por Laplace, Gauss y Legendre. 
\item  A finales del siglo XIX, Sir Francis Gaston ide\'o el m\'etodo conocido por Correlaci\'on, que ten\'ia por objeto medir la influencia relativa de los factores sobre las variables.

\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
\begin{itemize}
\item De aqu\'i parti\'o el desarrollo del coeficiente de correlaci\'on creado por Karl Pearson y otros cultivadores de la ciencia biom\'etrica como J. Pease Norton, R. H. Hooker y G. Udny Yule, que efectuaron amplios estudios sobre la medida de las relaciones.

\item Los progresos m\'as recientes en el campo de la Estad\'istica se refieren al ulterior desarrollo del c\'alculo de probabilidades, particularmente en la rama denominada indeterminismo o relatividad, se ha demostrado que el determinismo fue reconocido en la F\'isica como resultado de las investigaciones at\'omicas y que este principio se juzga aplicable tanto a las ciencias sociales como a las f\'isicas.

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:Historia}
%____________________________________________________________
\subsection{Etapas de Desarrollo de la Estad\'istica}
%____________________________________________________________
La historia de la estad\'istica est\'a resumida en tres grandes etapas o fases.
\begin{itemize}
\item[Fase 1:] \textbf{Los Censos:}
Desde el momento en que se constituye una autoridad pol\'itica, la idea de inventariar de una forma m\'as o menos regular la poblaci\'on y las riquezas existentes en el territorio est\'a ligada a la conciencia de soberan\'ia y a los primeros esfuerzos administrativos.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item[Fase 2:] \textbf{De la Descripci\'on de los Conjuntos a la Aritm\'etica Pol\'itica:}
Las ideas mercantilistas extra\~nan una intensificaci\'on de este tipo de investigaci\'on. Colbert multiplica las encuestas sobre art\'iculos manufacturados, el comercio y la poblaci\'on: los intendentes del Reino env\'ian a Par\'is sus memorias. Vauban, m\'as conocido por sus fortificaciones o su Dime Royale, que es la primera propuesta de un impuesto sobre los ingresos, se se\~nala como el verdadero precursor de los sondeos. 
M\'as tarde, Buf\'on se preocupa de esos problemas antes de dedicarse a la historia natural. La escuela inglesa proporciona un nuevo progreso al superar la fase puramente descriptiva.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item[Fase 2:]
 Sus tres principales representantes son Graunt, Petty y Halley. El pen\'ultimo es autor de la famosa Aritm\'etica Pol\'itica. Chaptal, ministro del interior franc\'es, publica en 1801 el primer censo general de poblaci\'on, desarrolla los estudios industriales, de las producciones y los cambios, haci\'endose sistem\'aticos durantes las dos terceras partes del siglo XIX.
%\end{itemize}
%%\end{frame}
%%\begin{frame}\frametitle{Introducci\'on}
%\begin{itemize}

\item[Fase 3:] \textbf{Estad\'istica y C\'alculo de Probabilidades:}
El c\'alculo de probabilidades se incorpora r\'apidamente como un instrumento de an\'alisis extremadamente poderoso para el estudio de los fen\'omenos econ\'omicos y sociales y en general para el estudio de fen\'omenos cuyas causas son demasiados complejas para conocerlos totalmente y hacer posible su an\'alisis.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Estad\'istica Descriptiva}


%____________________________________________________________
\subsection{Divisi\'on de la Estad\'istica}
%____________________________________________________________
La Estad\'istica para su mejor estudio se ha dividido en dos grandes ramas: \textbf{la Estad\'istica Descriptiva y la Estad\'istica Inferencial}.
\begin{itemize}
\item \textbf{Descriptiva:} consiste sobre todo en la presentaci\'on de datos en forma de tablas y gr\'aficas. Esta comprende cualquier actividad relacionada con los datos y est\'a dise\~nada para resumir o describir los mismos sin factores pertinentes adicionales; esto es, sin intentar inferir nada que vaya m\'as all\'a de los datos, como tales.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Estad\'istica Inferencial}
\begin{itemize}
\item \textbf{Inferencial:} se deriva de muestras, de observaciones hechas s\'olo acerca de una parte de un conjunto numeroso de elementos y esto implica que su an\'alisis requiere de generalizaciones que van m\'as all\'a de los datos. Como consecuencia, la caracter\'istica m\'as importante del reciente crecimiento de la estad\'istica ha sido un cambio en el \'enfasis de los m\'etodos que describen a m\'etodos que sirven para hacer generalizaciones. La Estad\'istica Inferencial investiga o analiza una poblaci\'on partiendo de una muestra
tomada.
\end{itemize}
%\end{frame}
%____________________________________________________________
\subsection{Estad\'istica Inferencial}
%____________________________________________________________

%\begin{frame}\frametitle{Introducci\'on: Estad\'istica Inferencial}

Los m\'etodos b\'asicos de la estad\'istica inferencial son la estimaci\'on y el contrastede hip\'otesis, que juegan un papel fundamental en la investigaci\'on. Por tanto, algunos de los objetivos que se persiguen son:
\begin{itemize}
\item Calcular los par\'ametros de la distribuci\'on de medias o proporciones muestrales de tama\~no $n$, extra\'idas de una poblaci\'on de media y varianza conocidas.

\item Estimar la media o la proporci\'on de una poblaci\'on a partir de la media o proporci\'on muestral.

\item Utilizar distintos tama\~nos muestrales para controlar la confianza y el error admitido.
\item Contrastar los resultados obtenidos a partir de muestras.
\item Visualizar gr\'aficamente, mediante las respectivas curvas normales, las estimaciones realizadas.

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Estad\'istica Inferencial}
\begin{itemize}
\item En definitiva, la idea es, a partir de una poblaci\'on se extrae una muestra por algunos de los m\'etodos existentes, con la que se generan datos num\'ericos que se van a utilizar para generar estad\'isticos con los que realizar estimaciones o contrastes poblacionales. 
\item Existen dos formas de estimar par\'ametros: la \textit{estimaci\'on puntual} y la \textit{estimaci\'on por intervalo de confianza}. En la primera se busca, con base en los datos muestrales, un \'unico valor estimado para el par\'ametro. Para la segunda, se determina un intervalo dentro del cual se encuentra el valor del par\'ametro, con una probabilidad determinada.
\end{itemize}

%%\end{frame}
%%\begin{frame}\frametitle{Introducci\'on: Estimaci\'on de Par\'ametros}


%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Estimaci\'on de Par\'ametros}
\begin{itemize}
\item Si el objetivo del tratamiento estad\'istico inferencial, es efectuar generalizaciones acerca de la estructura, composici\'on o comportamiento de las poblaciones no observadas, a partir de una parte de la poblaci\'on, ser\'a necesario que la parcela de poblaci\'on examinada sea representativa del total. 

\item Por ello, la selecci\'on de la muestra requiere unos requisitos que lo garanticen, debe ser representativa y aleatoria. 

\item Adem\'as, la cantidad de elementos que integran la muestra (el tama\~no de la muestra) depende de m\'ultiples factores, como el dinero y el tiempo disponibles para el estudio, la importancia del tema analizado, la confiabilidad que se espera de los resultados, las caracter\'isticas propias del fen\'omeno analizado, etc\'etera. 
\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
\begin{itemize}
\item As\'i, a partir de la muestra seleccionada se realizan algunos c\'alculos y se estima el valor de los par\'ametros de la poblaci\'on tales como la media, la varianza, la desviaci\'on est\'andar, o la forma de la distribuci\'on, etc.

\end{itemize}
%\end{frame}
%____________________________________________________________
\subsection{M\'etodo Estad\'istico}
%____________________________________________________________

%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
El conjunto de los m\'etodos que se utilizan para medir las caracter\'isticas de la informaci\'on, para resumir los valores individuales, y para analizar los datos a fin de
extraerles el m\'aximo de informaci\'on, es lo que se llama \textit{m\'etodos estad\'isticos}. Los m\'etodos de an\'alisis para la informaci\'on cuantitativa se pueden dividir en los siguientes
seis pasos:
\begin{enumerate}
\item Definici\'on del problema.
\item Recopilaci\'on de la informaci\'on existente.
\item Obtenci\'on de informaci\'on original.
\item Clasificaci\'on.
\item Presentaci\'on.
\item An\'alisis.
\end{enumerate}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
\begin{itemize}
\item El centro de gravedad de la metodolog\'ia estad\'istica se empieza a desplazar t\'ecnicas de computaci\'on intensiva aplicadas a grandes masas de datos, y se empieza a considerar el m\'etodo estad\'istico como un proceso iterativo de b\'usqueda del modelo ideal.

\item Las aplicaciones en este periodo de la Estad\'istica a la Econom\'ia conducen a una disciplina con contenido propio: la Econometr\'ia. La investigaci\'on estad\'istica en problemas militares durante la segunda guerra mundial y los nuevos m\'etodos de programaci\'on matem\'atica, dan lugar a la Investigaci\'on Operativa

\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Errores Estad\'isticos}

%____________________________________________________________
\subsection{Errores Estad\'isticos Comunes}
%____________________________________________________________
Al momento de recopilar los datos que ser\'an procesados se es susceptible de cometer errores as\'i como durante los c\'omputos de los mismos. No obstante, hay otros errores que no tienen nada que ver con la digitaci\'on y que no son tan f\'acilmente identificables. Algunos de \'estos errores son:
\begin{itemize}
\item\textbf{Sesgo:} Es imposible ser completamente objetivo o no tener ideas preconcebidas antes de comenzar a estudiar un problema, y existen muchas maneras en que una perspectiva o estado mental pueda influir en la recopilaci\'on y en el an\'alisis de la informaci\'on. En estos casos se dice que hay un sesgo cuando el individuo da mayor peso a los datos que apoyan su opini\'on que a aquellos que la contradicen. Un caso extremo de sesgo ser\'ia la situaci\'on donde primero se toma una decisi\'on y despu\'es se utiliza el an\'alisis estad\'istico para justificar la decisi\'on ya tomada.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
\begin{itemize}

\item\textbf{Datos No Comparables:} el establecer comparaciones es una de las partes m\'as importantes del an\'alisis estad\'istico, pero es extremadamente importante que tales comparaciones se hagan entre datos que sean comparables.
\item \textbf{Proyecci\'on descuidada de tendencias:} la proyecci\'on simplista de tendencias pasadas hacia el futuro es uno de los errores que m\'as ha desacreditado el uso del an\'alisis
estad\'istico.
%\end{itemize}
%%\end{frame}
%%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
%\begin{itemize}
\item\textbf{Muestreo Incorrecto:} en la mayor\'ia de los estudios sucede que el volumen de informaci\'on disponible es tan inmenso que se hace necesario estudiar muestras, para derivar conclusiones acerca de la poblaci\'on a que pertenece la muestra. Si la muestra se selecciona correctamente, tendr\'a b\'asicamente las mismas propiedades que la poblaci\'on de la cual fue extra\'ida; pero si el muestreo se realiza incorrectamente, entonces puede suceder que los resultados no signifiquen nada
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: M\'etodo Estad\'istico}
En resumen se puede decir que la Estad\'istica es un conjunto de procedimientos para reunir, clasificar, codificar, procesar, analizar y resumir informaci\'on num\'erica adquirida sistem\'aticamente (Ritchey, 2002). Permite hacer inferencias a partir de una muestra para extrapolarlas a una poblaci\'on. Aunque normalmente se asocia a muchos c\'alculos y operaciones aritm\'eticas, y aunque las matem\'aticas est\'an involucradas, en su mayor parte sus fundamentos y uso apropiado pueden dominarse sin hacer referencia a habilidades matem\'aticas avanzadas. 

De hecho se trata de una forma de ver la realidad basada en el an\'alisis cuidadoso de los hechos (Ritchey, 2002). Es necesaria sin embargo la sistematizaci\'on para reducir el efecto que las emociones y las experiencias individuales puedan tener al interpretar esa realidad.
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

De esta manera la estad\'istica se relaciona con el m\'etodo cient\'ifico complement\'andolo como herramienta de an\'alisis y, aunque la investigaci\'on cient\'ifica no requiere necesariamente de la estad\'istica, \'esta valida muchos de los resultados cuantitativos derivados de la investigaci\'on. 

La obtenci\'on del conocimiento debe hacerse de manera sistem\'atica por lo que deben planearse todos los pasos que llevan desde el planteamiento de un problema, pasando por la elaboraci\'on de hip\'otesis y la manera en que van a ser probadas; la selecci\'on de sujetos (muestreo), los escenarios, los instrumentos que se utilizar\'an para obtener los datos, definir el procedimiento que se seguir\'a para esto \'ultimo, los controles que se deben hacer para asegurar que las intervenciones son las causas m\'as probables de los cambios esperados (dise\~no); 
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

El tratamiento de los datos de la investigaci\'on cient\'ifica tiene varias etapas:
\begin{itemize}
\item En la etapa de recolecci\'on de datos del m\'etodo cient\'ifico, se define a la poblaci\'on de inter\'es y se selecciona una muestra o conjunto de personas representativas de la misma, se realizan experimentos o se emplean instrumentos ya existentes o de nueva creaci\'on, para medir los atributos de inter\'es necesarios para responder a las preguntas de investigaci\'on.Durante lo que es llamado trabajo de campo se obtienen los datos en crudo, es decir las respuestas directas de los sujetos uno por uno, se codifican (se les asignan valores a las respuestas), se capturan y se verifican para ser utilizados en las
siguientes etapas.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
\begin{itemize}

\item En la etapa de recuento, se organizan y ordenan los datos obtenidos de la muestra. Esta ser\'a descrita en la siguiente etapa utilizando la estad\'istica descriptiva, todas las investigaciones utilizan estad\'istica descriptiva, para conocer de manera organizada y resumida las caracter\'isticas de la muestra.

\item En la etapa de an\'alisis se utilizan las pruebas estad\'isticas (estad\'istica inferencial) y en la interpretaci\'on se acepta o rechaza la hip\'otesis nula.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}

\item En investigaci\'on, el fen\'omeno en estudio puede ser cualitativo que implicar\'ia comprenderlo y explicarlo, o cuantitativo para compararlo y hacer inferencias. Se puede decir que si se hace an\'alisis se usan m\'etodos cuantitativos y si se hace descripci\'on se usan m\'etodos cualitativos. 


\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}

Medici\'on Para poder emplear el m\'etodo estad\'istico en un estudio es necesario medir las variables. 
\begin{itemize}
\item Medir: es asignar valores a las propiedades de los objetos bajo ciertas reglas, esas reglas son los niveles de medici\'on

\item Cuantificar: es asignar valores a algo tomando un patr\'on de referencia. Por ejemplo, cuantificar es ver cu\'antos hombres y cu\'antas mujeres hay.

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
\begin{itemize}
\item Variable: es una caracter\'istica o propiedad que asume diferentes valores dentro de una poblaci\'on de
inter\'es y cuya variaci\'on es susceptible de medirse.
Las variables pueden clasificarse de acuerdo al tipo de valores que puede tomar como:
\begin{itemize}
\item Discretas o categ\'oricas.- en las que los valores se relacionan a nombres, etiquetas o categor\'ias, no existe un significado num\'erico directo
\item Continuas.- los valores tienen un correlato num\'erico directo, son continuos y susceptibles de fraccionarse y de poder utilizarse en operaciones aritm\'eticas De acuerdo a la cantidad de valores
\item Dicot\'omica.- s\'olo tienen dos valores posibles, la caracter\'istica est\'a ausente o presente
\item Policot\'omica.- pueden tomar tres valores o m\'as, pueden tomarse matices diferentes, en grados, jerarqu\'ias o magnitudes continuas.
\end{itemize}
\end{itemize}
%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item En cuanto a una clasificaci\'on estad\'istica
\begin{itemize}
\item Aleatoria.- Aquella en la cual desconocemos el valor porque fluct\'ua de acuerdo a un evento debido al azar
\item Determin\'istica.- Aquella variable de la que se conoce el valor
\item Independiente.- aquellas variables que son manipuladas por el investigador. Define los
grupos
\item Dependiente.- son mediciones que ocurren durante el experimento o tratamiento
(resultado de la independiente), es la que se mide y compara entre los grupos
\end{itemize}
\end{itemize}
%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'on}
Niveles de Medici\'on
\begin{itemize}
\item Nominal
Las propiedades de la medici\'on nominal son:
\begin{itemize}
\item Exhaustiva: implica a todas las opciones
\item A los sujetos se les asignan categor\'ias, por lo que son mutuamente excluyentes. Es decir, la
variable est\'a presente o no; tiene o no una caracter\'istica
\end{itemize}
\item Ordinal
Las propiedades de la medici\'on ordinal son:
\begin{itemize}
\item El nivel ordinal posee transitividad, por lo que se tiene la capacidad de identificar que es mejor o mayor que otra, en ese sentido se pueden establecer jerarqu\'ias
\item Las distancias entre un valor y otro no son iguales.
\end{itemize}
\end{itemize}

%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'ono}
\begin{itemize}

\item Intervalo
\begin{itemize}
\item  El nivel de medici\'on intervalar requiere distancias iguales entre cada valor. Por lo general
utiliza datos cuantitativos. Por ejemplo: temperatura, atributos psicol\'ogicos (CI, nivel de
autoestima, pruebas de conocimientos, etc.)
\item Las unidades de calificaci\'on son equivalentes en todos los puntos de la escala. Una escala de
intervalos implica: clasificaci\'on, magnitud y unidades de tama\~nos iguales (Brown, 2000).
\item Se pueden hacer operaciones aritm\'eticas
\item Cuando se le pide al sujeto que califique una situaci\'on del 0 al 10 puede tomarse como un
nivel de medici\'on de intervalo, siempre y cuando se incluya el 0.
\end{itemize}
\end{itemize}
%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
\begin{itemize}

\item Raz\'on
\begin{itemize}
\item La escala empieza a partir del 0 absoluto, por lo tanto incluye s\'olo los n\'umeros por su valor
en s\'i, por lo que no pueden existir los n\'umeros con signo negativo. Por ejemplo: Peso
corporal en kg., edad en a\~nos, estatura en cm.
\item Convencionalmente los datos que son de nivel absoluto o de raz\'on son manejados como los
datos intervalares.
\end{itemize}

\end{itemize}
%\end{frame}

\subsection{T\'erminos comunes utilizados en Estad\'istica}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}
\item \textbf{Variable: } Consideraciones que una variable son una caracter\'istica o fen\'omeno que puede tomar distintos valores.

\item \textbf{Dato: } Mediciones o cualidades que han sido recopiladas como resultado de observaciones.

\item \textbf{Poblaci\'on: } Se considera el \'area de la cual son extra\'idos los datos. Es decir, es el conjunto de elementos o individuos que poseen una caracter\'istica com\'un y medible acerca de lo cual se desea informaci\'on. Es tambi\'en llamado
Universo.
\item \textbf{Muestra: } Es un subconjunto de la poblaci\'on, seleccionado de acuerdo a una regla o alg\'un plan de muestreo.

\item \textbf{Censo: } Recopilaci\'on de todos los datos (de inter\'es para la investigaci\'on) de la poblaci\'on.

\item \textbf{Estad\'istica: } Es una funci\'on o f\'ormula que depende de los datos de la muestra (es variable).
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}

\item \textbf{Par\'ametro: } Caracter\'istica medible de la poblaci\'on. Es un resumen num\'erico de alguna variable observada de la poblaci\'on. Los par\'ametros normales que se estudian son: \textit{ La media poblacional, la media poblacional, Proporci\'on.}

\item \textbf{Estimador}: Un estimador  de un par\'ametro , es un estad\'istico que se emplea para conocer el par\'ametro desconocido.
\item \textbf{Estad\'istico}: Es una funci\'on de los valores de la muestra. Es una variable aleatoria, cuyos valores dependen de la muestra seleccionada. Su distribuci\'on de probabilidad, se conoce como \textit{Distribuci\'on muestral del estad\'istico}.
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Introducci\'ono}
\begin{itemize}
\item \textbf{Estimaci\'on}: Este t\'ermino indica que a partir de lo observado en una muestra (un resumen estad\'istico con las medidas que conocemos de Descriptiva) se extrapola o generaliza dicho resultado muestral a la poblaci\'on total, de modo que lo estimado es el valor generalizado a la poblaci\'on. Consiste en la b\'usqueda del valor de los par\'ametros poblacionales objeto de estudio. Puede ser puntual o por intervalo de confianza:
\begin{itemize}
\item\textit{Puntual:}  cuando buscamos un valor concreto. Un estimador de un par\'ametro poblacional es una funci\'on de los datos muestrales. En pocas palabras, es una f\'ormula que depende de los valores obtenidos de una muestra, para realizar estimaciones. Lo que se pretende obtener es el valor exacto de un par\'ametro. 
\end{itemize}
\end{itemize}

%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'on}

Las propiedades deseables de un estimador son los siguientes:
\begin{itemize}
\item Insesgado: Diremos que un estimador de un par\'ametro es insesgado si su esperanza coincide con el verdadero valor del par\'ametro. En el caso de que no coincidan, diremos que el estimador es sesgado.
\item  Eficiencia: Dados dos estimadores  para un mismo par\'ametro , se dice que uno es m\'a eficiente que el otro si tiene menor varianza.
\item Suficiencia: Se dice que un estimador de un par\'ametro es suficiente cuando para su c\'alculo utiliza toda la informaci\'on de la muestra.
\item Consistencia: Decimos que un estimador  de un par\'ametro  es consistente si la distribuci\'on del estimador tiende a concentrarse en un cierto punto cuando el tama\~no de la muestra tiende a infinito.
\end{itemize}

%\end{frame}
%\end{document}

%\begin{frame}\frametitle{Introducci\'on}
Demostrar que un cierto estimador cumple estas propiedades puede ser
complicado en determinadas ocasiones. Existen varios m\'etodos que nos van a permitir obtener los estimadores puntuales. Los m\'as importantes son:
\begin{itemize}
\item  M\'etodo de Momentos: se basa en que los momentos poblacionales y se estiman mediante los momentos muestrales. Suelen dar estimadores consistentes.
\item M\'etodo de M\'inimos Cuadrados: consiste en obtener un estimador que hace m\'inima una determinada funci\'on.
\item M\'etodo de M\'axima Verosimilitud: consiste en tomar como par\'ametro poblacional el valor de la muestra que sea m\'as probable, es decir, que tenga mayor probabilidad. Se suelen obtener estimadores consistentes y eficientes. Es el m\'as utilizado.
\end{itemize}
%\end{frame}
%\end{document}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}

\item\textit{Intervalo de confianza:}  cuando determinamos un intervalo, dentro del cual se supone que va a estar el valor del par\'ametro que se busca con una cierta probabilidad. El intervalo de confianza est\'a determinado por dos valores dentro de los cuales afirmamos que est\'a el verdadero par\'ametro con cierta probabilidad. Son unos l\'imites o margen de variabilidad que damos al valor estimado, para poder afirmar, bajo un
criterio de probabilidad, que el verdadero valor no los rebasar\'a.

Este intervalo contiene al par\'ametro estimado con una determinada certeza o nivel de confianza.
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
En la estimaci\'on por intervalos se usan los siguientes conceptos:
\begin{itemize}
\item Variabilidad del par\'ametro: Si no se conoce, puede obtenerse una
aproximaci\'on en los datos o en un estudio piloto. Tambi\'en hay m\'etodos para calcular el tama\~no de la muestra que prescinden de este aspecto. Habitualmente se usa como medida de esta variabilidad la desviaci\'on t\'ipica poblacional.
\item Error de la estimaci\'on: Es una medida de su precisi\'on que se corresponde con la amplitud del intervalo de confianza. Cuanta m\'as precisi\'on se desee en la estimaci\'on de un par\'ametro, m\'as estrecho deber\'a ser el intervalo de confianza y, por tanto, menor el error, y m\'as sujetos deber\'an incluirse en la muestra estudiada. 

\item Nivel de confianza: Es la probabilidad de que el verdadero valor del par\'ametro estimado en la poblaci\'on se sit\'ue en el intervalo de confianza obtenido. El nivel de confianza se denota por $1-\alpha$

\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}

\item $p$-value : Tambi\'en llamado nivel de significaci\'on. Es la probabilidad (en tanto por uno) de fallar en nuestra estimaci\'on, esto es, la diferencia entre la certeza (1) y el nivel de confianza $1-\alpha$. 

\item Valor cr\'itico: Se representa por $Z_{\alpha/2}$ . Es el valor de la abscisa en una determinada distribuci\'on que deja a su derecha un \'area igual a 1/2, siendo $1-\alpha$ el nivel de confianza. Normalmente los valores cr\'iticos est\'an tabulados o pueden calcularse en funci\'on de la distribuci\'on de la poblaci\'on. 
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
Para un tama\~no fijo de la muestra, los conceptos de error y nivel de confianza van relacionados. Si admitimos un error mayor, esto es, aumentamos el tama\~no del intervalo de confianza, tenemos tambi\'en una mayor probabilidad de \'exito en nuestra estimaci\'on, es decir, un mayor nivel de confianza. Por tanto, un aspecto que debe de tenerse en cuenta es el tama\~no muestral, ya que para disminuir el error que se comente habr\'a que aumentar el tama\~no muestral. Esto se resolver\'a, para un intervalo de confianza cualquiera, despejando el tama\~no de la muestra en cualquiera de las formulas de los intervalos de confianza que veremos a continuaci\'on, a partir del error m\'aximo permitido. Los intervalos de confianza pueden ser unilaterales o bilaterales:


%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}




\item \textbf{Contraste de Hip\'otesis}:  Consiste en determinar si es aceptable, partiendo de datos muestrales, que la caracter\'istica o el par\'ametro poblacional estudiado tome un determinado valor o est\'e dentro de unos determinados valores.

\item \textbf{Nivel de Confianza}: Indica la proporci\'on de veces que acertar\'iamos al afirmar que el par\'ametro est\'a dentro del intervalo al seleccionar muchas muestras.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}

\subsection{Muestreo:} 
Una muestra es representativa en la medida que es imagen de la poblaci\'on. 

En general, podemos decir que el tama\~no de una muestra depender\'a principalmente de: \textit{Nivel de precisi\'on deseado, Recursos disponibles,  Tiempo involucrado en la investigaci\'on.}.  Adem\'as el plan de muestreo debe considerar \textit{ La poblaci\'on, Par\'ametros a medir}.
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
Existe una gran cantidad de tipos de muestreo. En la pr\'actica los m\'as utilizados son los siguientes:
\begin{itemize}
\item \textbf{MUESTREO ALEATORIO SIMPLE: } Es un m\'etodo de selecci\'on de $n$ unidades extra\'idas de $N$, de tal manera que cada una de las posibles muestras tiene la misma probabilidad de ser escogida. (En la pr\'actica, se enumeran las unidades de 1 a $N$, y a continuaci\'on se seleccionan $n$ n\'umeros aleatorios entre 1 y $N$, ya sea de tablas o de alguna urna con fichas numeradas).
\item \textbf{MUESTREO ESTRATIFICADO ALEATORIO: } Se usa cuando la poblaci\'on est\'a agrupada en pocos estratos, cada uno de ellos son muchas entidades. Este muestreo consiste en sacar una muestra aleatoria simple de cada uno de los estratos. (Generalmente, de tama\~no proporcional al estrato).

\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}



\item \textbf{MUESTREO SISTEM\'aTICO :} Se utiliza cuando las unidades de la poblaci\'on est\'an de alguna manera totalmente ordenadas. Para seleccionar una muestra de $n$ unidades, se divide la poblaci\'on en $n$ subpoblaciones de tama\~no $K = N/n$ y se toma al azar una unidad de la $K$ primeras y de ah\'i en adelante cada $K$-\'esima unidad.

\item \textbf{MUESTREO POR CONGLOMERADO: } Se emplea cuando la poblaci\'on est\'a dividida en grupos o conglomerados peque\~nos. Consiste en obtener una muestra aleatoria simple de conglomerados y luego CENSAR cada uno de \'estos.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on:}
\begin{itemize}

\item \textbf{MUESTREO EN DOS ETAPAS (Biet\'apico): } En este caso la muestra se toma en dos pasos:
\begin{itemize}
\item Seleccionar una muestra de unidades primarias, y Seleccionar una muestra de elementos a partir de cada unidad primaria escogida.
\item Observaci\'on: En la realidad es posible encontrarse con situaciones en las cuales no es posible aplicar libremente un tipo de muestreo, incluso estaremos obligados a mezclarlas en ocasiones.
\end{itemize}
\end{itemize}
%\end{frame}
\subsection{Variables}
%\begin{frame}\frametitle{Introducci\'on}


Las variables se pueden clasificar en dos grandes grupos.
\begin{itemize}
\item \textbf{Variables categ\'oricas: } Son aquellas que pueden ser representadas a trav\'es de s\'imbolos, letras, palabras, etc. Los valores que toman se denominan categor\'ias, y los elementos que pertenecen a estas categor\'ias, se consideran id\'enticos respecto a la caracter\'istica que se est\'a midiendo. Las variables categ\'oricas de dividen en dos tipos: Ordinal y Nominal.

\begin{itemize}
\item \textbf{Las Ordinales}, son aquellas en que las categor\'ias tienen un orden impl\'icito. Admiten grados de calidad, es decir, existe una relaci\'on total entre las categor\'ias.

\item \textbf{Las nominales,} son aquellas donde no existe una relaci\'on de orden.

\end{itemize}
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on}
\begin{itemize}

\item \textbf{Variables Num\'ericas}: Son aquellas que pueden tomar valores num\'ericos exclusivamente (mediciones). Se  dividen en dos tipos: Discretas y continuas. 
\begin{itemize}
\item\textbf{Discretas:} son aquellas que toman sus valores en un conjunto finito o infinito numerable.
\item\textbf{Continuas:}  Son aquellas que toman sus valores en un subconjunto de los n\'umeros reales, es decir en un intervalo. En general para las variables continuas el hombre ha debido inventar una medida para
poder establecer una medici\'on de ellas.

\end{itemize}
\end{itemize}

%\end{frame}



\subsection{Malos Usos de la Estad\'istica}
%\begin{frame}\frametitle{Introducci\'on}

El prop\'osito de esta secci\'on es solamente indicar los malos usos comunes de datos estad\'isticos, sin incluir el uso de m\'etodos estad\'isticos complicados. Un estudiante deber\'ia estar alerta en relaci\'on con estos malos usos y deber\'ia hacer un gran esfuerzo para evitarlos a fin de ser un verdadero estad\'istico.

\textbf{Datos estad\'isticos inadecuados}
Los datos estad\'isticos son usados como la materia prima para un estudio estad\'istico. Cuando los datos son inadecuados, la conclusi\'on extra\'ida del estudio de los datos se vuelve obviamente inv\'alida. Por ejemplo, supongamos que deseamos encontrar el ingreso familiar t\'ipico del a\~no pasado en la ciudad Y de 50,000 familias y tenemos una muestra consistente del ingreso de solamente tres familias: 1 mill\'on, 2 millones y no ingreso. Si sumamos el ingreso de las tres familias y dividimos el total por 3, obtenemos un promedio de 1 mill\'on.
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

Entonces, extraemos una conclusi\'on basada en la muestra de que el ingreso familiar promedio durante el a\~no pasado en la ciudad fue de  1 mill\'on. 

Es obvio que la conclusi\'on es falsa, puesto que las cifras son extremas y el tama\~no de la muestra es demasiado peque\~no; por lo tanto la muestra no es representativa. 

Hay muchas otras clases de datos inadecuados. Por ejemplo, algunos datos son respuestas inexactas de una encuesta, porque las preguntas usadas en la misma son vagas o enga\~nosas, algunos datos son toscas estimaciones porque no hay disponibles datos exactos o es demasiado costosa su obtenci\'on, y algunos datos son irrelevantes en un problema dado, porque el estudio estad\'istico no est\'a bien planeado.
%\end{frame}


\subsection{Un sesgo del usuario}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

 Sesgo significa que un usuario d\'e los datos perjudicialmente de m\'as \'enfasis a los hechos, los cuales son empleados para mantener su predeterminada posici\'on u opini\'on. 
 
Los estad\'isticos son frecuentemente degradados por lemas tales como :Hay tres clases de mentiras: mentiras, mentiras reprobables y estad\'istica, y Las cifras no mienten, pero los mentirosos piensas.
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Sesgo}

Hay dos clases de sesgos: conscientes e inconscientes. Ambos son comunes en el an\'alisis estad\'istico. Hay numerosos ejemplos de sesgos conscientes. 

Un anunciante frecuentemente usa la estad\'istica para probar que su producto es muy superior al producto de su competidor. 

Un pol\'itico prefiere usar la estad\'istica para sostener su punto de vista. 

Gerentes y l\'ideres de trabajadores pueden simult\'aneamente situar sus respectivas cifras estad\'isticas sobre la misma tabla de trato para mostrar que sus rechazos o peticiones son justificadas. 
%\end{frame}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

Es casi imposible que un sesgo inconsciente est\'e completamente ausente en un trabajo estad\'istico. 

En lo que respecta al ser humano, es dif\'icil obtener una actitud completamente objetiva al abordar un problema, aun cuando un cient\'ifico deber\'ia tener una mente abierta. 

Un estad\'istico deber\'ia estar enterado del hecho de que su interpretaci\'on de los resultados del an\'alisis estad\'istico est\'a influenciado por su propia experiencia, conocimiento y antecedentes con relaci\'on al problema dado.
%\end{frame}

\subsection{ Supuestos falsos}
%\begin{frame}\frametitle{Introducci\'on: Refuerzo}

Es muy frecuente que un an\'alisis estad\'istico contemple supuestos. Un investigador debe
ser muy cuidadoso en este hecho, para evitar que \'estos sean falsos. Los supuestos falsos pueden ser originados por:
\begin{itemize}
\item Quien usa los datos
\item Quien est\'a tratando de confundir (con intencionalidad)
\item Ignorancia
\item Descuido.
\end{itemize}

%\end{frame}



%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
T\'ERMINOS COMUNES UTILIZADOS EN ESTAD\'ISTICA
\begin{itemize}
\item Variable: Consideraciones que una variable son una caracter\'istica o fen\'omeno que
puede tomar distintos valores.
\item Dato: Mediciones o cualidades que han sido recopiladas como resultado de
observaciones.
\item Poblaci\'on: Se considera el \'area de la cual son extra\'idos los datos. Es decir, es el
conjunto de elementos o individuos que poseen una caracter\'istica com\'un y
medible acerca de lo cual se desea informaci\'on. Es tambi\'en llamado
Universo.
\item Muestra: Es un subconjunto de la poblaci\'on, seleccionado de acuerdo a una regla o
alg\'un plan de muestreo.
\item Censo: Recopilaci\'on de todos los datos (de inter\'es para la investigaci\'on) de la
poblaci\'on.
\item Estad\'istica: Es una funci\'on o f\'ormula que depende de los datos de la muestra (es
variable).
\end{itemize}
%\end{frame}



%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
\begin{itemize}
\item Par\'ametro Caracter\'istica medible de la poblaci\'on.
\end{itemize}

\textbf{Ejemplo:} La universidad est\'a interesada en determinar el ingreso de las familias de
sus alumnos.
\begin{itemize}
\item Variable: Ingreso perc\'apita de las familias.
\item Dato: Ingreso perc\'apita de la familia de un alumno espec\'ifico.
\item Poblaci\'on: Las familias de todos los alumnos de la universidad.
\item Estad\'istica: Ingreso perc\'apita promedio de las familias seleccionadas en la
muestra.
\item Par\'ametro: Ingreso perc\'apita promedio de la poblaci\'on.
\end{itemize}
%\end{frame}


%\begin{frame}
\textbf{MUESTREO}
Una muestra es representativa en la medida que es imagen de la poblaci\'on.
En general, podemos decir que el tama\~no de una muestra depender\'a principalmente de:


\begin{itemize}
\item  Nivel de precisi\'on deseado.
\item Recursos disponibles.
\item Tiempo involucrado en la investigaci\'on.
\end{itemize}

Adem\'as el plan de muestreo debe considerar
\begin{itemize}
\item La poblaci\'on
\item Par\'ametros a medir.
\end{itemize}


%\end{frame}



%\begin{frame}\frametitle{Introducci\'on: Refuerzo}
Existe una gran cantidad de tipos de muestreo. En la pr\'actica los m\'as utilizados son los
siguientes:
\begin{itemize}
\item MUESTREO ALEATORIO SIMPLE:
Es un m\'etodo de selecci\'on de n unidades extra\'idas de $N$, de tal manera que cada una de
las posibles muestras tiene la misma probabilidad de ser escogida.
(En la pr\'actica, se enumeran las unidades de $1$ a $N$, y a continuaci\'on se seleccionan $n$
n\'umeros aleatorios entre $1$ y $N$, ya sea de tablas o de alguna urna con fichas numeradas).
\item MUESTREO ESTRATIFICADO ALEATORIO:
Se usa cuando la poblaci\'on est\'a agrupada en pocos estratos, cada uno de ellos son muchas
entidades. Este muestreo consiste en sacar una muestra aleatoria simple de cada uno de los
estratos. (Generalmente, de tama\~no proporcional al estrato).
\end{itemize}
%\end{frame}



%\begin{frame}
\begin{itemize}
\item MUESTREO SISTEM\'ATICO :
Se utiliza cuando las unidades de la poblaci\'on est\'an de alguna manera totalmente
ordenadas.
Para seleccionar una muestra de n unidades, se divide la poblaci\'on en $n$ subpoblaciones
de tama\~no $K = N/n$ y se toma al azar una unidad de la $K$ primeras y de ah\'i en adelante cada $K-$
\'esima unidad, es decir, siendo n o la primera unidad seleccionada de la sub-poblaci\'on $\left(1, 2,...K\right)$.
$\left\{n, n+ K, n+ 2K, .... , n+ (n-1) K \right\}$

\item MUESTREO POR CONGLOMERADO
Se emplea cuando la poblaci\'on est\'a dividida en grupos o conglomerados peque\~nos.
Consiste en obtener una muestra aleatoria simple de conglomerados y luego CENSAR cada uno
de \'estos.
\end{itemize}
%\end{frame}


%\begin{frame}
\begin{itemize}

\item MUESTREO EN DOS ETAPAS (Biet\'apico)
En este caso la muestra se toma en dos pasos:
\begin{itemize}
\item Seleccionar una muestra de unidades primarias, y
\item Seleccionar una muestra de elementos a partir de cada unidad primaria escogida.
\end{itemize}
\end{itemize}

\textbf{Observaci\'on}:
En la realidad es posible encontrarse con situaciones en las cuales no es posible aplicar
libremente un tipo de muestreo, incluso estaremos obligados a mezclarlas en ocasiones.
En general la Estad\'istica est\'a encargada de llevar a cabo el siguiente esquema:
\begin{itemize}
\item Recopilar
\item Organizar
\item Presentar
\item Analizar

\end{itemize}

%\end{frame}


%\begin{frame}
Tipos de variables
Las variables se pueden clasificar en dos grandes grupos.
\begin{itemize}
\item categ\'oricas:
Son aquellas que pueden ser representadas a trav\'es de s\'imbolos, letras, palabras, etc. Los
valores que toman se denominan categor\'ias, y los elementos que pertenecen a estas categor\'ias, se
consideran id\'enticos respecto a la caracter\'istica que se est\'a midiendo. 

Las variables categ\'oricas de dividen en dos tipos: Ordinal y Nominal.
\begin{itemize}
\item Las Ordinales, son aquellas en que las categor\'ias tienen un orden impl\'icito. Admiten
grados de calidad, es decir, existe una relaci\'on total entre las categor\'ias. A pesar de que esta variable admite grados de calidad, no es posible cuantificar la diferencia.
\item Las nominales, son aquellas donde no existe una relaci\'on de orden.
\end{itemize}
\end{itemize}
%\end{frame}


%\begin{frame}
\begin{itemize}
\item Variables num\'ericas. Son aquellas que pueden tomar valores num\'ericos exclusivamente (mediciones).
dividen en dos tipos. Discretas y continuas. 
\begin{itemize}
\item 
Discretas: son aquellas que toman sus valores en un conjunto finito o infinito numerable.
\item Continuas: Son aquellas que toman sus valores en un subconjunto de los n\'umeros reales,
es decir en un intervalo.
\end{itemize}
\end{itemize}
%\end{frame}
%\begin{frame}

\textbf{Observaci\'on:}
En general para las variables continuas el hombre ha debido inventar una medida para
poder establecer una medici\'on de ellas:
Ejemplo: El metro, la hora.
%\end{frame}


%\begin{frame}
Los m\'etodos b\'asicos de la estad\'istica inferencial son la estimaci\'on y el contraste
de hip\'otesis, que juegan un papel fundamental en la investigaci\'on. Por tanto, algunos de los objetivos que se persiguen en este tema son:Inferencia, estimaci\'on y contraste de hip\'otesis

\begin{itemize}
\item Calcular los par\'ametros de la distribuci\'on de medias o proporciones muestrales
de tama\~no n, extra\'idas de una poblaci\'on de media y varianza conocidas.
\item Estimar la media o la proporci\'on de una poblaci\'on a partir de la media o
proporci\'on muestral.
\item Utilizar distintos tama\~nos muestrales para controlar la confianza y el error
admitido.
\item Contrastar los resultados obtenidos a partir de muestras.
\item Visualizar gr\'aficamente, mediante las respectivas curvas normales, las
estimaciones realizadas.
\end{itemize}
%\end{frame}


%\begin{frame}

En la mayor\'ia de las investigaciones resulta imposible estudiar a todos y cada
uno de los individuos de la poblaci\'on ya sea por el coste que supondr\'ia, o por la
imposibilidad de acceder a ello. Mediante la t\'ecnica inferencial obtendremos
conclusiones para una poblaci\'on no observada en su totalidad, a partir de estimaciones o
res\'umenes num\'ericos efectuados sobre la base informativa extra\'ida de una muestra de
dicha poblaci\'on. 
\begin{itemize}
\item Por tanto, el esquema que se sigue es, a partir de una poblaci\'on se extrae una muestra por
algunos de los m\'etodos existentes, con la que se generan datos num\'ericos que se van a
utilizar para generar estad\'isticos con los que realizar estimaciones o contrastes
poblacionales.
\end{itemize}

%\end{frame}


%\begin{frame}
\begin{itemize}

\item Existen dos formas de estimar par\'ametros: la estimaci\'on puntual y la
estimaci\'on por intervalo de confianza. En la primera se busca, con base en los datos
muestrales, un \'unico valor estimado para el par\'ametro. Para la segunda, se determina un
intervalo dentro del cual se encuentra el valor del par\'ametro, con una probabilidad
determinada.
\item Si el objetivo del tratamiento estad\'istico inferencial, es efectuar generalizaciones
acerca de la estructura, composici\'on o comportamiento de las poblaciones no
observadas, a partir de una parte de la poblaci\'on, ser\'a necesario que la parcela de
poblaci\'on examinada sea representativa del total. Por ello, la selecci\'on de la muestra
requiere unos requisitos que lo garanticen, debe ser representativa y aleatoria.

\end{itemize}

%\end{frame}



%\begin{frame}
Adem\'as, la cantidad de elementos que integran la muestra (el tama\~no de la
muestra) depende de m\'ultiples factores, como el dinero y el tiempo disponibles para el
estudio, la importancia del tema analizado, la confiabilidad que se espera de los
resultados, las caracter\'isticas propias del fen\'omeno analizado, etc\'etera. As\'i, a partir de
la muestra seleccionada se realizan algunos c\'alculos y se estima el valor de los
par\'ametros de la poblaci\'on tales como la media, la varianza, la desviaci\'on est\'andar, o la
forma de la distribuci\'on, etc.

%\end{frame}



%\begin{frame}
Conceptos b\'asicos
\begin{itemize}
\item POBLACI\'ON: Conjunto de elementos sobre los que se observa un car\'acter com\'un. Se
representa con la letra $N$.
\item MUESTRA: Conjunto de unidades de una poblaci\'on. Cuanto m\'as significativa sea,
mejor ser\'a la muestra. Se representa con la letra $n$.
\item UNIDAD DE MUESTREO: Est\'a formada por uno o m\'as elementos de la poblaci\'on.
El total de unidades de muestreo constituyen la poblaci\'on. Estas unidades son disjuntas
entre s\'i y cada elemento de la poblaci\'on pertenece a una unidad de muestreo.
\item PAR\'AMETRO: Es un resumen num\'erico de alguna variable observada de la
poblaci\'on. 
\end{itemize}


%\end{frame}



%\begin{frame}
\begin{itemize}
\item ESTIMADOR: Un estimador  de un par\'ametro,  es un estad\'istico que se emplea
para conocer el par\'ametro desconocido.
\item ESTAD\'ISTICO: Es una funci\'on de los valores de la muestra. Es una variable aleatoria,
cuyos valores dependen de la muestra seleccionada. Su distribuci\'on de probabilidad, se
conoce como Distribuci\'on muestral del estad\'istico.
\item ESTIMACI\'ON: Este t\'ermino indica que a partir de lo observado en una muestra (un
resumen estad\'istico con las medidas que conocemos de Descriptiva) se extrapola o
generaliza dicho resultado muestral a la poblaci\'on total, de modo que lo estimado es el
valor generalizado a la poblaci\'on. Consiste en la b\'usqueda del valor de los par\'ametros
poblacionales objeto de estudio. Puede ser puntual o por intervalo de confianza:
\end{itemize}

%\end{frame}


%\begin{frame}
Estimaci\'on 
\begin{itemize}
\item Puntual: cuando buscamos un valor concreto.Inferencia, estimaci\'on y contraste de hip\'otesis
\item Intervalo de confianza: cuando determinamos un intervalo, dentro del cual se
supone que va a estar el valor del par\'ametro que se busca con una cierta
probabilidad.
\end{itemize}
%\end{frame}


%\begin{frame}

\begin{itemize}

\item CONTRATE DE HIP\'OTESIS: Consiste en determinar si es aceptable, partiendo de
datos muestrales, que la caracter\'istica o el par\'ametro poblacional estudiado tome un
determinado valor o est\'e dentro de unos determinados valores.

\item NIVEL DE CONFIANZA: Indica la proporci\'on de veces que acertar\'iamos al afirmar
que el par\'ametro est\'a dentro del intervalo al seleccionar muchas muestras.
\end{itemize}


EL CONCEPTO DE ESTAD\'iSTICO Y DISTRIBUCI\'ON MUESTRAL
\begin{itemize}
\item El objetivo de la inferencia es efectuar una generalizaci\'on de los resultados de la
muestra de la poblaci\'on. La tarea que nos ocupa ahora es conocer las distribuciones de
la probabilidad de ciertas funciones de la muestra, es decir, variables aleatorias
asociadas al muestreo o estad\'isticos muestrales. \'estos ser\'an \'utiles para hacer
inferencia respecto a los par\'ametros desconocidos de una poblaci\'on.

\end{itemize}
%\end{frame}


%\begin{frame}

\begin{itemize}
\item  Por ello se habla de distribuciones muestrales, ya que est\'an basados en el comportamiento de las
muestras.

\item El primer objetivo es conocer el concepto de distribuci\'on muestral de un
estad\'istico; su comportamiento probabil\'istico depender\'a del que tenga la variable $X$ y
del tama\~no de las muestras.

\item Sea una poblaci\'on donde se observa la variable aleatoria X. Esta variable X,
tendr\'a una distribuci\'on de probabilidad, que puede ser conocida o desconocida, y ciertas
caracter\'isticas o par\'ametros poblacionales. 

\item El problema ser\'a encontrar una funci\'on que proporcione el mejor estimador de El estimador, T, del par\'ametro debe tener una
distribuci\'on concentrada alrededor de la media  y la varianza debe ser lo menor posible.

\item Los estad\'isticos m\'as usuales en inferencia y su distribuci\'on asociada considerando una poblaci\'on P sobre la que se estudia un car\'acter cuantitativo son:

\end{itemize}
%\end{frame}


%\begin{frame}

\begin{itemize}
\item  CONTRATE DE HIP\'oTESIS: Consiste en determinar si es aceptable, partiendo de
datos muestrales, que la caracter\'istica o el par\'ametro poblacional estudiado tome un
determinado valor o est\'e dentro de unos determinados valores.

\item NIVEL DE CONFIANZA: Indica la proporci\'on de veces que acertar\'iamos al afirmar
que el par\'ametro est\'a dentro del intervalo al seleccionar muchas muestras.

\end{itemize}


El objetivo de la inferencia es efectuar una generalizaci\'on de los resultados de la
muestra de la poblaci\'on. La tarea que nos ocupa ahora es conocer las distribuciones de
la probabilidad de ciertas funciones de la muestra, es decir, variables aleatorias
asociadas al muestreo o estad\'isticos muestrales. \'estos ser\'an \'utiles para hacer
inferencia respecto a los par\'ametros desconocidos de una poblaci\'on. Por ello se habla de
distribuciones muestrales, ya que est\'an basados en el comportamiento de las
muestras.

El primer objetivo es conocer el concepto de distribuci\'on muestral de un
estad\'istico; su comportamiento probabil\'istico depender\'a del que tenga la variable $X$ y
del tama\~no de las muestras.


%\end{frame}
%---------------------------------------------------------
\section{2. Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{2.1 Tipos de errores}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}

\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}


%\end{frame}


%\begin{frame}\frametitle{Introducci\'on}
Una prueba de hip\'otesis est\'a formada por cinco partes
\begin{itemize}
\item La hip\'otesis nula, denotada por $H_{0}$.
\item La hip\'otesis alterativa, denorada por $H_{1}$.
\item El estad\'sitico de prueba y su valor $p$.
\item La regi\'on de rechazo.
\item La conclusi\'on.

\end{itemize}



%\end{frame}


%\begin{frame}\frametitle{Introducci\'on}
\begin{Def}
Las dos hip\'otesis en competencias son la \textbf{hip\'otesis alternativa $H_{1}$}, usualmente la que se desea apoyar, y la \textbf{hip\'otesis nula $H_{0}$}, opuesta a $H_{1}$.
\end{Def}


En general, es m\'as f\'acil presentar evidencia de que $H_{1}$ es cierta, que demostrar 	que $H_{0}$ es falsa, es por eso que por lo regular se comienza suponiendo que $H_{0}$ es cierta, luego se utilizan los datos de la muestra para decidir si existe evidencia a favor de $H_{1}$, m\'as que a favor de $H_{0}$, as\'i se tienen dos conclusiones:
\begin{itemize}
\item Rechazar $H_{0}$ y concluir que $H_{1}$ es verdadera.
\item Aceptar, no rechazar, $H_{0}$ como verdadera.

\end{itemize}


%\end{frame}


%\begin{frame}\frametitle{Introducci\'on}
\begin{Ejem}
Se desea demostrar que el salario promedio  por hora en cierto lugar es distinto de $19$usd, que es el promedio nacional. Entonces $H_{1}:\mu\neq19$, y $H_{0}:\mu=19$.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de dos colas}.


\begin{Ejem}
Un determinado proceso produce un promedio de $5\%$ de piezas defectuosas. Se est\'a interesado en demostrar que un simple ajuste en una m\'aquina reducir\'a $p$, la proporci\'on de piezas defectuosas producidas en este proceso. Entonces se tiene $H_{0}:p<0.3$ y $H_{1}:p=0.03$. Si se puede rechazar $H_{0}$, se concluye que el proceso ajustado produce menos del $5\%$ de piezas defectuosas.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de una cola}.
%\end{frame}


%\begin{frame}\frametitle{Introducci\'on}
La decisi\'on de rechazar o aceptar la hip\'otesis nula est\'a basada en la informaci\'on contenida en una muestra proveniente de la poblaci\'on de inter\'es. Esta informaci\'on tiene estas formas

\begin{itemize}
\item \textbf{Estad\'sitico de prueba:} un s\'olo n\'umero calculado a partir de la muestra.

\item \textbf{$p$-value:} probabilidad calculada a partir del estad\'stico de prueba.

\end{itemize}
%\end{frame}




%\begin{frame}\frametitle{Introducci\'on}
\begin{Def}
El $p$-value es la probabilidad de observar un estad\'istico de prueba tanto o m\'as alejado del valor obervado, si en realidad $H_{0}$ es verdadera.\medskip
Valores grandes del estad\'stica de prueba  y valores peque\~nos de $p$ significan que se ha observado un evento muy poco probable, si $H_{0}$ en realidad es verdadera.
\end{Def}

Todo el conjunto de valores que puede tomar el estad\'istico de prueba se divide en dos regiones. Un conjunto, formado de valores que apoyan la hip\'otesis alternativa y llevan a rechazar $H_{0}$, se denomina \textbf{regi\'on de rechazo}. El otro, conformado por los valores que sustentatn la hip\'otesis nula, se le denomina \textbf{regi\'on de aceptaci\'on}.\medskip



%\end{frame}


%\begin{frame}\frametitle{Introducci\'on}
Cuando la regi\'on de rechazo est\'a en la cola izquierda de la distribuci\'on, la  prueba se denomina \textbf{prueba lateral izquierda}. Una prueba con regi\'on de rechazo en la cola derecha se le llama \textbf{prueba lateral derecha}.\medskip

Si el estad\'stico de prueba cae en la regi\'on de rechazo, entonces se rechaza $H_{0}$. Si el estad\'stico de prueba cae en la regi\'on de aceptaci\'on, entonces la hip\'otesis nula se acepta o la prueba se juzga como no concluyente.\medskip

Dependiendo del nivel de confianza que se desea agregar a las conclusiones de la prueba, y el \textbf{nivel de significancia $\alpha$}, el riesgo que est\'a dispuesto a correr si se toma una decisi\'on incorrecta.
%\end{frame}

%\begin{frame}\frametitle{Introducci\'on}
\begin{Def}
Un \textbf{error de tipo I} para una prueba estad\'istica es el error que se tiene al rechazar la hip\'otesis nula cuando es verdadera. El \textbf{nivel de significancia} para una prueba estad\'istica de hip\'otesis es
\begin{eqnarray*}
\alpha&=&P\left\{\textrm{error tipo I}\right\}=P\left\{\textrm{rechazar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es verdadera}\right\}
\end{eqnarray*}

\end{Def}
Este valor $\alpha$ representa el valor m\'aximo de riesgo tolerable de rechazar incorrectamente $H_{0}$. Una vez establecido el nivel de significancia, la regi\'on de rechazo se define para poder determinar si se rechaza $H_{0}$ con un cierto nivel de confianza.

%\end{frame}
\section{2.2 Muestras grandes: una media poblacional}
\subsection{2.2.1 C\'alculo de valor $p$}

%\begin{frame}\frametitle{C\'alculo del valor de $p$}
\begin{Def}
El \textbf{valor de $p$} (\textbf{$p$-value}) o nivel de significancia observado de un estad\'istico de prueba es el valor m\'as peque\~ no de $\alpha$ para el cual $H_{0}$ se puede rechazar. El riesgo de cometer un error tipo $I$, si $H_{0}$ es rechazada con base en la informaci\'on que proporciona la muestra.
\end{Def}

\begin{Note}
Valores peque\~ nos de $p$ indican 	que el valor observado del estad\'stico de prueba se encuentra alejado del valor hipot\'etico de $\mu$, es decir se tiene evidencia de que $H_{0}$ es falsa y por tanto debe de rechazarse.
\end{Note}



%\end{frame}

%\begin{frame}\frametitle{C\'alculo del valor de $p$}
\begin{Note}
Valores grandes de $p$ indican que el estad\'istico de prueba observado no est\'a alejado de la medi hipot\'etica y no apoya el rechazo de $H_{0}$.
\end{Note}

\begin{Def}
Si el valor de $p$ es menor o igual que el nivel de significancia $\alpha$, determinado previamente, entonces $H_{0}$ es rechazada y se puede concluir que los resultados son estad\'isticamente significativos con un nivel de confianza del $100\left(1-\alpha\right)\%$.
\end{Def}
Es usual utilizar la siguiente clasificaci\'on de resultados



%\end{frame}

%\begin{frame}\frametitle{C\'alculo del valor de $p$}
\begin{tabular}{|c||c|l|}\hline
$p$& $H_{0}$&Significativa\\\hline\hline
$p<0.01$&Rechazar &Altamente\\\hline
$0.01\leq p<0.05$ & Rechazar&Estad\'isticamente\\\hline
$0.05\leq p <0.1$ & No rechazar & Tendencia estad\'istica\\\hline
$0.01\leq p$ & No rechazar & No son estad\'isticamente\\\hline
\end{tabular}

\begin{Note}
Para determinar el valor de $p$, encontrar el \'area en la cola despu\'es del estad\'istico de prueba. Si la prueba es de una cola, este es el valor de $p$. Si es de dos colas, \'este valor encontrado es la mitad del valor de $p$. Rechazar $H_{0}$ cuando el valor de $p<\alpha$.
\end{Note}

%\end{frame}
%\begin{frame}\frametitle{C\'alculo del valor de $p$}

Hay dos tipos de errores al realizar una prueba de hip\'otesis
\begin{center}
\begin{tabular}{c|cc}
& $H_{0}$ es Verdadera & $H_{0}$ es Falsa\\\hline\hline
Rechazar $H_{0}$ & Error tipo I & $\surd$\\
Aceptar $H_{0}$ & $\surd$ & Error tipo II
\end{tabular}
\end{center}
\begin{Def}
La probabilidad de cometer el error tipo II se define por $\beta$ donde
\begin{eqnarray*}
\beta&=&P\left\{\textrm{error tipo II}\right\}=P\left\{\textrm{Aceptar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{Aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}
\end{eqnarray*}
\end{Def}

%\end{frame}

%\begin{frame}\frametitle{Potencia de la prueba}


\begin{Note}
Cuando $H_{0}$ es falsa y $H_{1}$ es verdadera, no siempre es posible especificar un valor exacto de $\mu$, sino m\'as bien un rango de posibles valores.\medskip
En lugar de arriesgarse a tomar una decisi\'on incorrecta, es mejor conlcuir que \textit{no hay evidencia suficiente para rechazar $H_{0}$}, es decir en lugar de aceptar $H_{0}$, \textit{no rechazar $H_{0}$}.

\end{Note}
%\end{frame}


%\begin{frame}\frametitle{Potencia de la prueba}
La bondad de una prueba estad\'istica se mide por el tama\~ no de $\alpha$ y $\beta$, ambas deben de ser peque\~ nas. Una manera muy efectiva de medir la potencia de la prueba es calculando el complemento del error tipo $II$:
\begin{eqnarray*}
1-\beta&= &P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{1}\textrm{ es verdadera}\right\}
\end{eqnarray*}
\begin{Def}
La \textbf{potencia de la prueba}, $1-\beta$, mide la capacidad de que la prueba funciona como se necesita.
\end{Def}

%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
\begin{Ejem}
La producci\'on diariade una planta qu\'imica local ha promediado 880 toneladas en los \'ultimos a\~nos. A la gerente de control de calidad le gustar\'ia saber si este promedio ha cambiado en meses recientes. Ella selecciona al azar 50 d\'ias de la base de datos computarizada y calcula el promedio y la desviaci\'on est\'andar de las $n=50$  producciones como $\overline{x}=871$ toneladas y $s=21$ toneladas, respectivamente. Pruebe la hip\'otesis  apropiada usando $\alpha=0.05$.

\end{Ejem}

%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
\begin{Sol}
La hip\'otesis nula apropiada es:
\begin{eqnarray*}
H_{0}&:& \mu=880\\
&&\textrm{ y la hip\'otesis alternativa }H_{1}\textrm{ es }\\
H_{1}&:& \mu\neq880
\end{eqnarray*}
el estimador puntual para $\mu$ es $\overline{x}$, entonces el estad\'istico de prueba es\medskip
\begin{eqnarray*}
z&=&\frac{\overline{x}-\mu_{0}}{s/\sqrt{n}}\\
&=&\frac{871-880}{21/\sqrt{50}}=-3.03
\end{eqnarray*}
\end{Sol}


%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
\begin{Sol}
Para esta prueba de  dos colas, hay que determinar los dos valores de $z_{\alpha/2}$, es decir,  $z_{\alpha/2}=\pm1.96$, como $z>z_{\alpha/2}$, $z$  cae en la zona de rechazo, por lo tanto  la gerente puede rechazar la hip\'otesis nula y concluir que el promedio efectivamente ha cambiado.\medskip
La probabilidad de rechazar $H_{0}$ cuando esta es verdadera es de  $0.05$.


Recordemos que el valor observado del estad\'istico de prueba es $z=-3.03$, la regi\'on de rechazo m\'as peque\~na que puede usarse y todav\'ia seguir rechazando $H_{0}$ es $|z|>3.03$, \\
entonces $p=2(0.012)=0.0024$, que a su vez es menor que el nivel de significancia $\alpha$ asignado inicialmente, y adem\'as los resultados son  \textbf{altamente significativos}.


\end{Sol}
%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
Finalmente determinemos la potencia de la prueba cuando $\mu$ en realidad es igual a $870$ toneladas.

Recordar que la regi\'on de aceptaci\'on est\'a entre $-1.96$ y $1.96$, para $\mu=880$, equivalentemente $$874.18<\overline{x}<885.82$$
$\beta$ es la probabilidad de aceptar $H_{0}$ cuando $\mu=870$, calculemos los valores de $z$ correspondientes a $874.18$ y $885.82$ \medskip
Entonces
\begin{eqnarray*}
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{874.18-870}{21/\sqrt{50}}=1.41\\
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{885.82-870}{21/\sqrt{50}}=5.33
\end{eqnarray*}

%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
por lo tanto
\begin{eqnarray*}
\beta&=&P\left\{\textrm{aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{874.18<\mu<885.82\textrm{ cuando }\mu=870\right\}\\
&=&P\left\{1.41<z<5.33\right\}=P\left\{1.41<z\right\}\\
&=&1-0.9207=0.0793
\end{eqnarray*}
entonces, la potencia de la prueba es
$$1-\beta=1-0.0793=0.9207$$ que es la probabilidad de rechazar correctamente $H_{0}$ cuando $H_{0}$ es falsa.
%\end{frame}

%\begin{frame}\frametitle{Ejemplo ilustrativo}
Determinar la potencia de la prueba para distintos valores de $H_{1}$ y graficarlos, \textit{curva de potencia}
\begin{center}
\begin{tabular}{c||c}
$H_{1}$ & $\left(1-\beta\right)$ \\\hline 
\hline 
865 &  \\ \hline 
870 &  \\ \hline 
872 &  \\ \hline 
875 &  \\ \hline 
877 &  \\ \hline 
880 &  \\ \hline 
883 &  \\ \hline 
885 &  \\ \hline 
888 &  \\ \hline 
890 &  \\ \hline 
895 &  \\ \hline 
\end{tabular} 

\end{center}
%\end{frame}


%\begin{frame}\frametitle{List de Ejercicios}
\begin{enumerate}
\item Encontrar las regiones de rechazo para el estad\'istico $z$, para una prueba de
\begin{itemize}
\item[a) ]  dos colas para $\alpha=0.01,0.05,0.1$
\item[b) ]  una cola superior para $\alpha=0.01,0.05,0.1$
\item[c) ] una cola inferior para $\alpha=0.01,0.05,0.1$

\end{itemize}


\item Suponga que el valor del estad\'istico de prueba es 
\begin{itemize}
\item[a) ]$z=-2.41$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[b) ] $z=2.16$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[c) ] $z=1.15$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[d) ] $z=-2.78$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[e) ] $z=-1.81$, sacar las conclusiones correspondientes para los incisos anteriores.

\end{itemize}
\end{enumerate}
%\end{frame}


%\begin{frame}\frametitle{List de Ejercicios}
\begin{itemize}
\item[3. ] Encuentre el valor de $p$ para las pruebas de hip\'otesis correspondientes a los valores de $z$ del ejercicio anterior.

\item[4. ] Para las pruebas dadas en el ejercicio 2, utilice el valor de $p$, determinado en el ejercicio 3,  para determinar la significancia de los resultados.


\end{itemize}

%\end{frame}

%\begin{frame}\frametitle{Lista de Ejercicios}
\begin{itemize}
\item[5. ] Una muestra aleatoria de $n=45$ observaciones de una poblaci\'on con media $\overline{x}=2.4$, y desviaci\'on est\'andar $s=0.29$. Suponga que el objetivo es demostrar que la media poblacional $\mu$ excede $2.3$.
\begin{itemize}
\item[a) ] Defina la hip\'otesis nula y alternativa para la prueba.
\item[b) ] Determine la regi\'on de rechazo para un nivel de significancia de: $\alpha=0.1,0.05,0.01$.
\item[c) ] Determine el error est\'andar de la media muestral.
\item[d) ] Calcule el valor de $p$ para los estad\'isticos de prueba definidos en los incisos anteriores.
\item[e) ] Utilice el valor de $p$ pra sacar una conclusi\'on al nivel de significancia $\alpha$.
\item[f) ] Determine el valor de $\beta$ cuando $\mu=2.5$
\item[g) ] Graficar la curva de potencia para la prueba.

\end{itemize}
\end{itemize}

%\end{frame}
\subsection{2.2.2 Prueba de hip\'otesis para la diferencia entre dos medias poblacionales}

%\begin{frame}\frametitle{Diferencia entre dos medias poblacionales}
El estad\'istico que resume la informaci\'on muestral respecto a la diferencia en medias poblacionales $\left(\mu_{1}-\mu_{2}\right)$ es la diferencia de las medias muestrales $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, por tanto al probar la difencia entre las medias muestrales se verifica que la diferencia real entre las medias poblacionales difiere de un valor especificado, $\left(\mu_{1}-\mu_{2}\right)=D_{0}$, se puede usar el error est\'andar de $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, es decir
$$\sqrt{\frac{\sigma^{2}_{1}}{n_{1}}+\frac{\sigma^{2}_{2}}{n_{2}}}$$
cuyo estimador est\'a dado por
$$SE=\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}$$
%\end{frame}


%\begin{frame}\frametitle{Diferencia entre dos medias poblacionales}
El procedimiento para muestras grandes es:
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Diferencia entre dos medias poblacionales}
\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$z=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Diferencia entre dos medias poblacionales:Ejemplo}
\begin{Ejem}
Para determinar si ser propietario de un autom\'ovil afecta el rendimiento acad\'emico de un estudiante, se tomaron dos muestras aleatorias de 100 estudiantes varones. El promedio de calificaciones para los $n_{1}=100$ no propietarios de un auto tuvieron un promedio y varianza de $\overline{x}_{1}=2.7$ y $s_{1}^{2}=0.36$, respectivamente, mientras que para para la segunda muestra con $n_{2}=100$ propietarios de un auto, se tiene $\overline{x}_{2}=2.54$ y $s_{2}^{2}=0.4$. Los datos presentan suficiente evidencia para indicar una diferencia en la media en el rendimiento acad\'emico entre propietarios y no propietarios de un autom\'ovil? Hacer pruebas para $\alpha=0.01,0.05$ y $\alpha=0.1$.
\end{Ejem}
%\end{frame}

%\begin{frame}\frametitle{None}
\begin{Sol}
\begin{itemize}
\item Soluci\'on utilizando la t\'ecnica de regiones de rechazo:\medskip
realizando las operaciones
$z=1.84$, determinar si excede los valores de $z_{\alpha/2}$.
\item Soluci\'on utilizando el $p$-value:\medskip
Calcular el valor de $p$, la probabilidad de que $z$ sea mayor que $z=1.84$ o menor que $z=-1.84$, se tiene que $p=0.0658$. Concluir.
\end{itemize}
\end{Sol}
%\end{frame}

%\begin{frame}\frametitle{Pruebas de hip\'otesis e Intervalos de Confianza}
\begin{itemize}
\item Si el intervalo de confianza que se construye contiene el valor del par\'ametro especificado por $H_{0}$, entonces ese valor es uno de los posibles valores del par\'ametro y $H_{0}$ no debe ser rechazada.

\item Si el valor hipot\'etico se encuentra fuera de los l\'imites de confianza, la hip\'otesis nula es rechazada al nivel de significancia $\alpha$.
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Lista de Ejercicios}
\begin{enumerate}
\item Del libro Mendenhall resolver los ejercicios 9.18, 9.19 y 9.20(\href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall}).

\item Del libro \href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall} resolver los ejercicios: 9.23, 9.26 y 9.28.
\end{enumerate}

%\end{frame}

\subsection{2.2.3 Prueba de Hip\'otesis para una Proporci\'on Binomial}
%\begin{frame}\frametitle{Una proporci\'on Binomial}
Para una muestra aleatoria de $n$ intentos id\'enticos, de una poblaci\'on binomial, la proporci\'on muesrtal $\hat{p}$ tiene una distribuci\'on aproximadamente normal cuando $n$ es grande, con media $p$ y error est\'andar
$$SE=\sqrt{\frac{pq}{n}}.$$
La prueba de hip\'otesis de la forma
\begin{eqnarray*}
H_{0}&:&p=p_{0}\\
H_{1}&:&p>p_{0}\textrm{, o }p<p_{0}\textrm{ o }p\neq p_{0}
\end{eqnarray*}
El estad\'istico de prueba se construye con el mejor estimador de la proporci\'on verdadera, $\hat{p}$, con el estad\'istico de prueba $z$, que se distribuye normal est\'andar.
%\end{frame}
%\begin{frame}\frametitle{Una proporci\'on Binomial}
El procedimiento es
\begin{itemize}
\item[1) ] Hip\'otesis nula: $H_{0}:p=p_{0}$
\item[2) ] Hip\'otesis alternativa
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:p>p_{0}$ & $p\neq p_{0}$\\
$H_{1}:p<p_{0}$ & \\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\hat{p}-p_{0}}{\sqrt{\frac{pq}{n}}},\hat{p}=\frac{x}{n}
\end{eqnarray*}
donde $x$ es el n\'umero de \'exitos en $n$ intentos binomiales.

\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Una proporci\'on Binomial}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Una proporci\'on Binomial}
\begin{Ejem}
A cualquier edad, alrededor del $20\%$ de los adultos de cierto pa\'is realiza actividades de acondicionamiento f\'isico al menos dos veces por semana. En una encuesta local de $n=100$ adultos de m\'as de $40$ a\ ~nos, un total de 15 personas indicaron que realizaron actividad f\'isica al menos dos veces por semana. Estos datos indican que el porcentaje de participaci\'on para adultos de m\'as de 40 a\ ~nos de edad es  considerablemente menor a la cifra del $20\%$? Calcule el valor de $p$ y \'uselo para sacar las conclusiones apropiadas.
\end{Ejem}
%\end{frame}

%\begin{frame}\frametitle{Una proporci\'on Binomial}
\begin{enumerate}
\item Resolver los ejercicios: 9.30, 9.32, 9.33, 9.35 y 9.39.
\end{enumerate}

%\end{frame}


\subsection{2.2.4 Prueba de Hip\'otesis diferencia entre dos Proporciones Binomiales}
%\begin{frame}\frametitle{Dos proporciones binomiales}
\begin{Note}
Cuando se tienen dos muestras aleatorias independientes de dos poblaciones binomiales, el objetivo del experimento puede ser la diferencia $\left(p_{1}-p_{2}\right)$ en las proporciones de individuos u objetos que poseen una caracter\'istica especifica en las dos poblaciones. En este caso se pueden utilizar los estimadores de las dos proporciones $\left(\hat{p}_{1}-\hat{p}_{2}\right)$ con error est\'andar dado por
$$SE=\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}$$
considerando el estad\'istico $z$ con un nivel de significancia $\left(1-\alpha\right)100\%$

\end{Note}

%\end{frame}

%\begin{frame}\frametitle{Dos proporciones binomiales}
\begin{Note}
La hip\'otesis nula a probarse es de la forma
\begin{itemize}
\item[$H_{0}$: ] $p_{1}=p_{2}$ o equivalentemente $\left(p_{1}-p_{2}\right)=0$, contra una hip\'otesis alternativa $H_{1}$ de una o dos colas.
\end{itemize}
\end{Note}

\begin{Note}
Para estimar el error est\'andar del estad\'istico $z$, se debe de utilizar el hecho de que suponiendo que $H_{0}$ es verdadera, las dos proporciones son iguales a alg\'un valor com\'un, $p$. Para obtener el mejor estimador de $p$ es
$$p=\frac{\textrm{n\'umero total de \'exitos}}{\textrm{N\'umero total de pruebas}}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$$
\end{Note}

%\end{frame}



%\begin{frame}\frametitle{Prueba de Hip\'otesis para $\left(p_{1}-p_{2}\right)$}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\left(p_{1}-p_{2}\right)=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(p_{1}-p_{2}\right)>0$ & $H_{1}:\left(p_{1}-p_{2}\right)\neq 0$\\ 
$H_{1}:\left(p_{1}-p_{2}\right)<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}}=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{pq}{n_{1}}+\frac{pq}{n_{2}}}}
\end{eqnarray*}
donde $\hat{p_{1}}=x_{1}/n_{1}$ y $\hat{p_{2}}=x_{2}/n_{2}$ , dado que el valor com\'un para $p_{1}$ y $p_{2}$ es $p$, entonces $\hat{p}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$ y por tanto el estad\'istico de prueba es
\end{itemize}
%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis para $\left(p_{1}-p_{2}\right)$}
\begin{eqnarray*}
z=\frac{\hat{p}_{1}-\hat{p}_{2}}{\sqrt{\hat{p}\hat{q}}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}
\end{eqnarray*}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{\alpha}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

\end{itemize}

%\end{frame}


%\begin{frame}\frametitle{Dos proporciones binomiales: ejercicio}
\begin{Ejem}
Los registros de un hospital, indican que 52 hombres de una muestra de 1000 contra 23 mujeres de una muestra de 1000 fueron ingresados por enfermedad del coraz\'on. Estos datos presentan suficiente evidencia para indicar un porcentaje m\'as alto de enfermedades del coraz\'on entre hombres ingresados al hospital?, utilizar distintos niveles de confianza de $\alpha$.

\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios 9.42

\item Resolver los ejercicios: 9.45, 9.48, 9.50
\end{enumerate}

%\end{frame}


\section{2.3 Muestras Peque\~nas}

\subsection{2.3.1 Una media poblacional}
%\begin{frame}\frametitle{Una media poblacional}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu=\mu_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu>\mu_{0}$ & $H_{1}:\mu\neq \mu_{0}$\\ 
$H_{1}:\mu<\mu0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{x}-\mu_{0}}{\sqrt{\frac{s^{2}}{n}}}
\end{eqnarray*}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Ejercicio}
\begin{Ejem}
Las etiquetas en latas de un gal'on de pintura por lo general indican el tiempo de secado y el \'area puede cubrir una capa. Casi todas las marcas de pintura indican que, en una capa, un gal\'on cubrir\'a entre 250 y 500 pies cuadrados, dependiento de la textura de la superficie a pintarse, un fabricante, sin embargo afirma que un gal\'on de su pintura cubrir\'a 400 pies cuadrados de \'area superficial. Para probar su afirmaci\'on, una muestra aleatoria de 10 latas de un gal\'on de pintura blanca se emple\'o para pintar 10 \'areas id\'enticas usando la misma clase de equipo. Las \'areas reales en pies cuadrados cubiertas por estos 10 galones de pintura se dan a continuac\'on:
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline 
310 & 311 & 412 & 368 & 447 \\ 
\hline 
376 & 303 &410 &365 & 350 \\ 
\hline 
\end{tabular} 
\end{center}
\end{Ejem}
%\end{frame}

%\begin{frame}\frametitle{Ejercicio}
\begin{Ejem}
Los datos presentan suficiente evidencia para indicar que el promedio de la cobertura difiere de 400 pies cuadrados? encuentre el valor de $p$ para la prueba y \'uselo para evaluar la significancia de los resultados.
\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios: 10.2, 10.3,10.5, 10.7, 10.9, 10.13 y 10.16
\end{enumerate}
%\end{frame}



\subsection{2.3.2 Diferencia entre dos medias poblacionales: M.A.I.}
%\begin{frame}\frametitle{Diferencia entre dos medias: M.A.I.}
\begin{Note}
Cuando los tama\ ~nos de muestra son peque\ ~nos, no se puede asegurar que las medias muestrales sean normales, pero si las poblaciones originales son normales, entonces la distribuci\'on muestral de la diferencia de las medias muestales, $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, ser\'a normal con media $\left(\mu_{1}-\mu_{2}\right)$ y error est\'andar $$ES=\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}$$

\end{Note}
%\end{frame}

%\begin{frame}\frametitle{Diferencia entre dos medias: M.A.I.}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\item[3) ] Estad\'istico de prueba:
$$t=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Diferencia entre dos medias: M.A.I.}

donde $$s^{2}=\frac{\left(n_{1}-1\right)s_{1}^{2}+\left(n_{2}-1\right)s_{2}^{2}}{n_{1}+n_{2}-2}$$
\begin{itemize}

\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.


\end{itemize}


%\end{frame}

\subsection{2.3.3 Diferencia entre dos medias poblacionales: Diferencias Pareadas}
%\begin{frame}\frametitle{Diferencias pareadas}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu_{d}=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:\mu_{d}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu_{d}>0$ & $H_{1}:\mu_{d}\neq 0$\\ 
$H_{1}:\mu_{d}<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{d}}{\sqrt{\frac{s_{d}^{2}}{n}}}
\end{eqnarray*}
donde $n$ es el n\'umero de diferencias pareadas, $\overline{d}$ es la media de las diferencias muestrales, y $s_{d}$ es la desviaci\'on est\'andar de las diferencias muestrales.



\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Diferencias pareadas}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.

\end{itemize}
%\end{frame}

\subsection{2.3.4 Inferencias con respecto a la Varianza Poblacional}
%\begin{frame}\frametitle{Varianza poblacional}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\sigma^{2}=\sigma^{2}_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\sigma^{2}>\sigma^{2}_{0}$ & $H_{1}:\sigma^{2}\neq \sigma^{2}_{0}$\\ 
$H_{1}:\sigma^{2}<\sigma^{2}_{0}$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
\chi^{2}=\frac{\left(n-1\right)s^{2}}{\sigma^{2}_{0}}
\end{eqnarray*}

\end{itemize}
%\end{frame}

%\begin{frame}\frametitle{Varianza Poblacional}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$\chi^{2}>\chi^{2}_{\alpha}$ & \\
$\chi^{2}<\chi^{2}_{\left(1-\alpha\right)}$ cuando $H_{1}:\chi^{2}<\chi^{2}_{0}$&$\chi^{2}>\chi^{2}_{\alpha/2}$ o $\chi^{2}<\chi^{2}_{\left(1-\alpha/2\right)}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $\chi^{2}$,est\'an basados en $\left(n_{1}+\right)$ grados de libertad.

\end{itemize}

%\end{frame}
\subsection{2.3.5 Comparaci\'on de dos varianzas poblacionales}
%\begin{frame}\frametitle{Igualdad de dos varianzas}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)>D_{0}$ & $H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}

%\end{frame}
%\begin{frame}\frametitle{Diferencia entre dos medias poblacionales}
\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$F=\frac{s_{1}^{2}}{s_{2}^{2}}$$
donde $s_{1}^{2}$ es la varianza muestral m\'as grande.
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$F>F_{\alpha}$ & $F>F_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}

%\end{frame}

%---------------------------------------------------------
\section{3. An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------
%\begin{frame}\frametitle{Descripci\'on}
\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\end{itemize}

\end{Note}
%\end{frame}

\subsection{3.1 Regresi\'on Lineal Simple (RLS)}
%\begin{frame}\frametitle{RLS}
\begin{itemize}

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 

%\end{frame}

\subsection{3.2 M\'etodo de M\'inimos Cuadrados}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}
donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$, estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.
%\end{frame}


%\begin{frame}\frametitle{M\'inimos Cuadrados}
Entonces la ecuaci\'on \ref{Modelo.Regresion} se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}
%\end{frame}



%\begin{frame}\frametitle{M\'inimos Cuadrados}
Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$, $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$, igualar a cero y resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene
%\end{frame}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{M\'inimos Cuadrados}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}\label{Ecs.Estimadores.Regresion}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}
%\end{frame}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}
%\end{frame}
\subsection{3.3 Propiedades de los Estimadores $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$}
%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{Note}
\begin{itemize}
\item Las propiedades estad\'isticas de los estimadores de m\'inimos cuadrados son \'utiles para evaluar la suficiencia del modelo.

\item Dado que $\hat{\beta}_{0}$ y  $\hat{\beta}_{1}$ son combinaciones lineales de las variables aleatorias $y_{i}$, tambi\'en resultan ser variables aleatorias.
\end{itemize}
\end{Note}
A saber
\begin{eqnarray*}
E\left(\hat{\beta}_{1}\right)&=&E\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)\right)
\end{eqnarray*}
%\end{frame}


%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{eqnarray*}
&=&\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\right)\left(x_{i}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}}\left[\beta_{0}E\left(\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)\right)+E\left(\beta_{1}\sum_{k=1}^{n}x_{k}\left(x_{k}-\overline{x}\right)\right)\right.\\
&+&\left.E\left(\sum_{k=1}^{n}\epsilon_{k}\left(x_{k}-\overline{x}\right)\right)\right]=\frac{1}{S_{xx}}\beta_{1}S_{xx}=\beta_{1}
\end{eqnarray*}
por lo tanto 
\begin{equation}\label{Esperanza.Beta.1}
E\left(\hat{\beta}_{1}\right)=\beta_{1}
\end{equation}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{Note}
Es decir, $\hat{\beta_{1}}$ es un estimador insesgado.
\end{Note}
Ahora calculemos la varianza:
\begin{eqnarray*}
V\left(\hat{\beta}_{1}\right)&=&V\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}^{2}}V\left(\sum_{k=1}^{n}y_{k}\left(x_{k}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}V\left(y_{k}\left(x_{k}-\overline{x}\right)\right)=\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}\sigma^{2}\left(x_{k}-\overline{x}\right)^{2}\\
&=&\frac{\sigma^{2}}{S_{xx}^{2}}\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)^{2}=\frac{\sigma^{2}}{S_{xx}}
\end{eqnarray*}

%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
por lo tanto
\begin{equation}\label{Varianza.Beta.1}
V\left(\hat{\beta}_{1}\right)=\frac{\sigma^{2}}{S_{xx}}
\end{equation}
\begin{Prop}
\begin{eqnarray*}
E\left(\hat{\beta}_{0}\right)&=&\beta_{0},\\
V\left(\hat{\beta}_{0}\right)&=&\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right),\\
Cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right)&=&-\frac{\sigma^{2}\overline{x}}{S_{xx}}.
\end{eqnarray*}
\end{Prop}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
Para estimar $\sigma^{2}$ es preciso definir la diferencia entre la observaci\'on $y_{k}$, y el valor predecido $\hat{y}_{k}$, es decir
\begin{eqnarray*}
e_{k}=y_{k}-\hat{y}_{k},\textrm{ se le denomina \textbf{residuo}.}
\end{eqnarray*}
La suma de los cuadrados de los errores de los reisduos, \textit{suma de cuadrados del error}
\begin{eqnarray}
SC_{E}=\sum_{k=1}^{n}e_{k}^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
sustituyendo $\hat{y}_{k}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}$ se obtiene
\begin{eqnarray*}
SC_{E}&=&\sum_{k=1}^{n}y_{k}^{2}-n\overline{y}^{2}-\hat{\beta}_{1}S_{xy}=S_{yy}-\hat{\beta}_{1}S_{xy},\\
E\left(SC_{E}\right)&=&\left(n-2\right)\sigma^{2},\textrm{ por lo tanto}\\
\hat{\sigma}^{2}&=&\frac{SC_{E}}{n-2}=MC_{E}\textrm{ es un estimador insesgado de }\sigma^{2}.
\end{eqnarray*}
%\end{frame}

%\end{document}
\subsection{3.4 Prueba de Hip\'otesis en RLS}
%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{itemize}
\item Para evaluar la suficiencia del modelo de regresi\'on lineal simple, es necesario lleva a cabo una prueba de hip\'otesis respecto de los par\'ametros del modelo as\'i como de la construcci\'on de intervalos de confianza.

\item Para poder realizar la prueba de hip\'otesis sobre la pendiente y la ordenada al or\'igen de la recta de regresi\'on es necesario hacer el supuesto de que el error $\epsilon_{i}$ se distribuye normalmente, es decir $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$.

\end{itemize}

%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Suponga que se desea probar la hip\'otesis de que la pendiente es igual a una constante, $\beta_{0,1}$ las hip\'otesis Nula y Alternativa son:
\begin{centering}
\begin{itemize}
\item[$H_{0}$: ] $\beta_{1}=\beta_{1,0}$,

\item[$H_{1}$: ]$\beta_{1}\neq\beta_{1,0}$.

\end{itemize}
donde dado que las $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$, se tiene que $y_{i}$ son variables aleatorias normales $N\left(\beta_{0}+\beta_{1}x_{1},\sigma^{2}\right)$. 
\end{centering}
De las ecuaciones (\ref{Ecs.Estimadores.Regresion}) se desprende que $\hat{\beta}_{1}$ es combinaci\'on lineal de variables aleatorias normales independientes, es decir, $\hat{\beta}_{1}\sim N\left(\beta_{1},\sigma^{2}/S_{xx}\right)$, recordar las ecuaciones (\ref{Esperanza.Beta.1}) y (\ref{Varianza.Beta.1}).
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Entonces se tiene que el estad\'istico de prueba apropiado es
\begin{equation}\label{Estadistico.Beta.1}
t_{0}=\frac{\hat{\beta}_{1}-\hat{\beta}_{1,0}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
que se distribuye $t$ con $n-2$ grados de libertad bajo $H_{0}:\beta_{1}=\beta_{1,0}$. Se rechaza $H_{0}$ si 
\begin{equation}\label{Zona.Rechazo.Beta.1}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}

%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Para $\beta_{0}$ se puede proceder de manera an\'aloga para
\begin{itemize}
\item[$H_{0}:$] $\beta_{0}=\beta_{0,0}$,
\item[$H_{1}:$] $\beta_{0}\neq\beta_{0,0}$,
\end{itemize}
con $\hat{\beta}_{0}\sim N\left(\beta_{0},\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)\right)$, por lo tanto
\begin{equation}\label{Estadistico.Beta.0}
t_{0}=\frac{\hat{\beta}_{0}-\beta_{0,0}}{MC_{E}\left[\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right]},
\end{equation}
con el que rechazamos la hip\'otesis nula si
\begin{equation}\label{Zona.Rechazo.Beta.0}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}

%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{itemize}
\item No rechazar $H_{0}:\beta_{1}=0$ es equivalente a decir que no hay relaci\'on lineal entre $x$ y $y$.
\item Alternativamente, si $H_{0}:\beta_{1}=0$ se rechaza, esto implica que $x$ explica la variabilidad de $y$, es decir, podr\'ia significar que la l\'inea recta esel modelo adecuado.
\end{itemize}
El procedimiento de prueba para $H_{0}:\beta_{1}=0$ puede realizarse de la siguiente manera:
\begin{eqnarray*}
S_{yy}=\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}

%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
S_{yy}&=&\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}+\hat{y}_{k}-\overline{y}\right)^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)+\left(y_{k}-\hat{y}_{k}\right)\right]^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\left(y_{k}-\hat{y}_{k}\right)^{2}\right]\\
&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}
%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
&&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)=\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\sum_{k=1}^{n}\overline{y}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}\right)\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
&=&\sum_{k=1}^{n}\hat{\beta}_{0}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\sum_{k=1}^{n}\hat{\beta}_{1}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&=&\hat{\beta}_{0}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\hat{\beta}_{1}\sum_{k=1}^{n}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)=0+0+0=0.
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Por lo tanto, efectivamente se tiene
\begin{equation}\label{Suma.Total.Cuadrados}
S_{yy}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2},
\end{equation}
donde se hacen las definiciones
\begin{eqnarray}
SC_{E}&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}\cdots\textrm{Suma de Cuadrados del Error}\\
SC_{R}&=&\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}\cdots\textrm{ Suma de Regresi\'on de Cuadrados}
\end{eqnarray}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Por lo tanto la ecuaci\'on (\ref{Suma.Total.Cuadrados}) se puede reescribir como 
\begin{equation}\label{Suma.Total.Cuadrados.Dos}
S_{yy}=SC_{R}+SC_{E}
\end{equation}
recordemos que $SC_{E}=S_{yy}-\hat{\beta}_{1}S_{xy}$
\begin{eqnarray*}
S_{yy}&=&SC_{R}+\left( S_{yy}-\hat{\beta}_{1}S_{xy}\right)\\
S_{xy}&=&\frac{1}{\hat{\beta}_{1}}SC_{R}
\end{eqnarray*}
$S_{xy}$ tiene $n-1$ grados de libertad y $SC_{R}$ y $SC_{E}$ tienen 1 y $n-2$ grados de libertad respectivamente.
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
\begin{Prop}
\begin{equation}
E\left(SC_{R}\right)=\sigma^{2}+\beta_{1}S_{xx}
\end{equation}
adem\'as, $SC_{E}$ y $SC_{R}$ son independientes.
\end{Prop}
Recordemos que $\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}$. Para $H_{0}:\beta_{1}=0$ verdadera,
\begin{eqnarray*}
F_{0}=\frac{SC_{R}/1}{SC_{E}/(n-2)}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
se distribuye $F_{1,n-2}$, y se rechazar\'ia $H_{0}$ si $F_{0}>F_{\alpha,1,n-2}$.
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
El procedimiento de prueba de hip\'otesis puede presentarse como la tabla de an\'alisis de varianza siguiente\medskip

\begin{tabular}{lcccc}\hline
Fuente de & Suma de  &  Grados de  & Media  & $F_{0}$ \\ 
 variaci\'on & Cuadrados & Libertad & Cuadr\'atica & \\\hline
 Regresi\'on & $SC_{R}$ & 1 & $MC_{R}$  & $MC_{R}/MC_{E}$\\
 Error Residual & $SC_{E}$ & $n-2$ & $MC_{E}$ & \\\hline
 Total & $S_{yy}$ & $n-1$ & & \\\hline
\end{tabular} 
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
La prueba para la significaci\'on de la regresi\'on puede desarrollarse bas\'andose en la expresi\'on (\ref{Estadistico.Beta.1}), con $\hat{\beta}_{1,0}=0$, es decir
\begin{equation}\label{Estadistico.Beta.1.Cero}
t_{0}=\frac{\hat{\beta}_{1}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
Elevando al cuadrado ambos t\'erminos:
\begin{eqnarray*}
t_{0}^{2}=\frac{\hat{\beta}_{1}^{2}S_{xx}}{MC_{E}}=\frac{\hat{\beta}_{1}S_{xy}}{MC_{E}}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
Observar que $t_{0}^{2}=F_{0}$, por tanto la prueba que se utiliza para $t_{0}$ es la misma que para $F_{0}$.

%\end{frame}

%\end{document}
\subsection{Estimaci\'on de Intervalos en RLS}
%\begin{frame}\frametitle{Intervalos de Confianza}
\begin{itemize}
\item Adem\'as de la estimaci\'on puntual para los par\'ametros $\beta_{1}$ y $\beta_{0}$, es posible obtener estimaciones del intervalo de confianza de estos par\'ametros.

\item El ancho de estos intervalos de confianza es una medida de la calidad total de la recta de regresi\'on.

\end{itemize}


%\end{frame}

%\begin{frame}\frametitle{Intervalos de Confianza}
Si los $\epsilon_{k}$ se distribuyen normal e independientemente, entonces
\begin{eqnarray*}
\begin{array}{ccc}
\frac{\left(\hat{\beta}_{1}-\beta_{1}\right)}{\sqrt{\frac{MC_{E}}{S_{xx}}}}&y &\frac{\left(\hat{\beta}_{0}-\beta_{0}\right)}{\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}}
\end{array}
\end{eqnarray*}
se distribuyen $t$ con $n-2$ grados de libertad. Por tanto un intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\beta_{1}$ est\'a dado por
%\end{frame}
%\begin{frame}\frametitle{Intervalos de Confianza}
\begin{eqnarray}
\hat{\beta}_{1}-t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}\leq \beta_{1}\leq\hat{\beta}_{1}+t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}.
\end{eqnarray}
De igual manera, para $\beta_{0}$ un intervalo de confianza al $100\left(1-\alpha\right)\%$ es
\small{
\begin{eqnarray}
\begin{array}{l}
\hat{\beta}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}\leq\beta_{0}\leq\hat{\beta}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}
\end{array}
\end{eqnarray}}
%\end{frame}
\subsection{Predicci\'on}
%\begin{frame}\frametitle{Predicci\'on}
Supongamos que se tiene un valor $x_{0}$ de inter\'es, entonces la estimaci\'on puntual de este nuevo valor
\begin{equation}
\hat{y}_{0}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{0}
\end{equation}
\begin{Note}
Esta nueva observaci\'on es independiente de las utilizadas para obtener el modelo de regresi\'on, por tanto, el intervalo en torno a la recta de regresi\'on es inapropiado, puesto que se basa \'unicamente en los datos empleados para ajustar el modelo de regresi\'on.\\

El intervalo de confianza en torno a la recta de regresi\'on se refiere a la respuesta media verdadera $x=x_{0}$, no a observaciones futuras.
\end{Note}

%\end{frame}


%\begin{frame}\frametitle{Predicci\'on}
Sea $y_{0}$ la observaci\'on futura en $x=x_{0}$, y sea $\hat{y}_{0}$ dada en la ecuaci\'on anterior, el estimador de $y_{0}$. Si se define la variable aleatoria $$w=y_{0}-\hat{y}_{0},$$ esta se distribuye normalmente con media cero y varianza $$V\left(w\right)=\sigma^{2}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]$$
dado que $y_{0}$ es independiente de $\hat{y}_{0}$, por lo tanto el intervalo de predicci\'on al nivel $\alpha$ para futuras observaciones $x_{0}$ es

%\end{frame}

%\begin{frame}\frametitle{Predicci\'on}
\begin{eqnarray*}
\hat{y}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}\leq y_{0}\\
\leq \hat{y}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}.
\end{eqnarray*}
%\end{frame}


%\subsection{Prueba de falta de ajuste}
%%\begin{frame}\frametitle{Falta de ajuste}
%Es com\'un encontrar que el modelo ajustado no satisface totalmente el modelo necesario para los datos, en este caso es preciso saber qu\'e tan bueno es el modelo propuesto. Para esto se propone la siguiente prueba de hip\'otesis:
%\begin{itemize}
%\item[$H_{0}:$ ]El modelo propuesto se ajusta adecuademente a los datos.
%\item[$H_{1}:$ ]El modelo NO se ajusta a los datos.
%\end{itemize}
%La prueba implica dividir la suma de cuadrados del eror o del residuo en las siguientes dos componentes:
%\begin{eqnarray*}
%SC_{E}=SC_{EP}+SC_{FDA}
%\end{eqnarray*}

%%\end{frame}

%%\begin{frame}\frametitle{Falta de ajuste}
%donde $SC_{EP}$ es la suma de cuadrados atribuibles al error puro, y $SC_{FDA}$ es la suma de cuadrados atribuible a la falta de ajuste del modelo.
%%\end{frame}

%%\begin{frame}\frametitle{Falta de ajuste}
%%\end{frame}


\subsection{Coeficiente de Determinaci\'on}
%\begin{frame}\frametitle{Coeficiente de Determinaci\'on}
La cantidad
\begin{equation}
R^{2}=\frac{SC_{R}}{S_{yy}}=1-\frac{SC_{E}}{S_{yy}}
\end{equation}
se denomina coeficiente de determinaci\'on y se utiliza para saber si el modelo de regresi\'on es suficiente o no. Se puede demostrar que $0\leq R^{2}\leq1$, una manera de interpretar este valor es que si $R^{2}=k$, entonces el modelo de regresi\'on explica el $k*100\%$ de la variabilidad en los datos.
%\end{frame}

%\begin{frame}\frametitle{Coeficiente de Determinaci\'on}
$R^{2}$ 
\begin{itemize}
\item No mide la magnitud de la pendiente de la recta de regresi\'on
\item Un valor grande de $R^{2}$ no implica una pendiente empinada.
\item No mide la suficiencia del modelo.
\item Valores grandes de $R^{2}$ no implican necesariamente que el modelo de regresi\'on proporcionar\'a predicciones precisas para futuras observaciones.
\end{itemize}
%\end{frame}


\section{An\'alisis de Varianza}

%\begin{frame}\frametitle{An\'alisis de Varianza}
Para analizar el ajuste de regresi\'on se utiliza el m\'etodo de  \textbf{An\'alisis de Varianza} (\textbf{ANOVA}), el en cu\'al  se estudia la variaci\'on de la variable dependiente, subidividiendola en dos componentes significativos.
Recordemos las ecuaciones \ref{Suma.Total.Cuadrados} y \ref{Suma.Total.Cuadrados.Dos}:
\begin{eqnarray*}
S_{yy}=SC_{R}+SC_{E}.
\end{eqnarray*}

\begin{itemize}
\item[$SC_{R}$] Se le denomina \textbf{suma de cuadrados de la regresi\'on} y refleja la cantidad de variaci\'on de los valores de $y$ que es explicada por el modelo, para nuestro caso: la recta propuesta.

\item[$SC_{E}$] Se le denomina suma de cuadrados del error, que es la variaci\'on o diferencia que hay entre los valores originales y los obtenidos mediante el ajuste. 
\end{itemize}

%\end{frame}




%\begin{frame}\frametitle{An\'alisis de Varianza}
De lo anterior se desprende que estamos interesados en validar nuestro modelo dado en la ecuaci\'on (\ref{Modelo.Regresion}), es decir, 

\begin{eqnarray*}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray*}
que en realidad el par\'ametro $\beta_{1}$ ha sido bien estimado:

Supongamos que se desea probar la hip\'otesis
\begin{itemize}
\item[$H_{0}:$] $\beta_{1}=0$
\item[$H_{1}:$] $\beta_{1}\neq0$
\end{itemize}
%\end{frame}



%\begin{frame}\frametitle{An\'alisis de Varianza}
Donde la hip\'otesis nula nos dice que el modelo en realidad debe de ser: $\mu_{Y|x}=\beta_{0}$, es decir, las variaciones en los valores de $Y$ son independientes de los valores de $x$. Se puede demostrar que bajo la hip\'otesis nula los t\'erminos
\begin{itemize}
\item $SC_{R}/\sigma^{2}$ se distribuye $\chi^{2}$ con 1 grado de libertad
\item $SC_{E}/\sigma^{2}$ se distribuye $\chi^{2}$ con $n-2$ grado de libertad.
\end{itemize}
e independientes, y por tanto $S_{yy}$,  tambien llamada \textbf{suma total de cuadrados corregida: STCC}, se distribuye $\chi^{2}$ con $n-1$ grados de libertad.

%\end{frame}


%\begin{frame}\frametitle{An\'alisis de Varianza}

Para realizar esta prueba de hip\'otesis se calcula el cociente

\begin{eqnarray*}
f=\frac{SC_{R}/1}{SC_{E}/\left(n-2\right)}=\frac{SC_{R}}{s^{2}}
\end{eqnarray*}
y se rechaza $H_{0}$ a un nivel de significancia $\alpha$ si $f>f_{\alpha}\left(1,\left(n-2\right)\right)$, esto se puede realizar mediante una tabla, llamada tabla de an\'alisis de varianza, cuando a las distintas sumas de cuadrados se les divide por sus grados de libertad, se les denomina \textbf{cuadrados medios}.


%\end{frame}

%---------------------------------------------------------
\section{3. An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------
%\begin{frame}\frametitle{Descripci\'on}
\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\end{itemize}

\end{Note}
%\end{frame}

\subsection{3.1 Regresi\'on Lineal Simple (RLS)}
%\begin{frame}\frametitle{RLS}
\begin{itemize}

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 

%\end{frame}

\subsection{3.2 M\'etodo de M\'inimos Cuadrados}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}
donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$, estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.
%\end{frame}


%\begin{frame}\frametitle{M\'inimos Cuadrados}
Entonces la ecuaci\'on \ref{Modelo.Regresion} se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}
%\end{frame}



%\begin{frame}\frametitle{M\'inimos Cuadrados}
Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$, $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$, igualar a cero y resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene
%\end{frame}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{M\'inimos Cuadrados}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}\label{Ecs.Estimadores.Regresion}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}
%\end{frame}
%\begin{frame}\frametitle{M\'inimos Cuadrados}
Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}
%\end{frame}
\subsection{3.3 Propiedades de los Estimadores $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$}
%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{Note}
\begin{itemize}
\item Las propiedades estad\'isticas de los estimadores de m\'inimos cuadrados son \'utiles para evaluar la suficiencia del modelo.

\item Dado que $\hat{\beta}_{0}$ y  $\hat{\beta}_{1}$ son combinaciones lineales de las variables aleatorias $y_{i}$, tambi\'en resultan ser variables aleatorias.
\end{itemize}
\end{Note}
A saber
\begin{eqnarray*}
E\left(\hat{\beta}_{1}\right)&=&E\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)\right)
\end{eqnarray*}
%\end{frame}


%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{eqnarray*}
&=&\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\right)\left(x_{i}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}}\left[\beta_{0}E\left(\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)\right)+E\left(\beta_{1}\sum_{k=1}^{n}x_{k}\left(x_{k}-\overline{x}\right)\right)\right.\\
&+&\left.E\left(\sum_{k=1}^{n}\epsilon_{k}\left(x_{k}-\overline{x}\right)\right)\right]=\frac{1}{S_{xx}}\beta_{1}S_{xx}=\beta_{1}
\end{eqnarray*}
por lo tanto 
\begin{equation}\label{Esperanza.Beta.1}
E\left(\hat{\beta}_{1}\right)=\beta_{1}
\end{equation}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
\begin{Note}
Es decir, $\hat{\beta_{1}}$ es un estimador insesgado.
\end{Note}
Ahora calculemos la varianza:
\begin{eqnarray*}
V\left(\hat{\beta}_{1}\right)&=&V\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}^{2}}V\left(\sum_{k=1}^{n}y_{k}\left(x_{k}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}V\left(y_{k}\left(x_{k}-\overline{x}\right)\right)=\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}\sigma^{2}\left(x_{k}-\overline{x}\right)^{2}\\
&=&\frac{\sigma^{2}}{S_{xx}^{2}}\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)^{2}=\frac{\sigma^{2}}{S_{xx}}
\end{eqnarray*}

%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
por lo tanto
\begin{equation}\label{Varianza.Beta.1}
V\left(\hat{\beta}_{1}\right)=\frac{\sigma^{2}}{S_{xx}}
\end{equation}
\begin{Prop}
\begin{eqnarray*}
E\left(\hat{\beta}_{0}\right)&=&\beta_{0},\\
V\left(\hat{\beta}_{0}\right)&=&\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right),\\
Cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right)&=&-\frac{\sigma^{2}\overline{x}}{S_{xx}}.
\end{eqnarray*}
\end{Prop}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
Para estimar $\sigma^{2}$ es preciso definir la diferencia entre la observaci\'on $y_{k}$, y el valor predecido $\hat{y}_{k}$, es decir
\begin{eqnarray*}
e_{k}=y_{k}-\hat{y}_{k},\textrm{ se le denomina \textbf{residuo}.}
\end{eqnarray*}
La suma de los cuadrados de los errores de los reisduos, \textit{suma de cuadrados del error}
\begin{eqnarray}
SC_{E}=\sum_{k=1}^{n}e_{k}^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray}
%\end{frame}

%\begin{frame}\frametitle{Propiedades de los estimadores}
sustituyendo $\hat{y}_{k}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}$ se obtiene
\begin{eqnarray*}
SC_{E}&=&\sum_{k=1}^{n}y_{k}^{2}-n\overline{y}^{2}-\hat{\beta}_{1}S_{xy}=S_{yy}-\hat{\beta}_{1}S_{xy},\\
E\left(SC_{E}\right)&=&\left(n-2\right)\sigma^{2},\textrm{ por lo tanto}\\
\hat{\sigma}^{2}&=&\frac{SC_{E}}{n-2}=MC_{E}\textrm{ es un estimador insesgado de }\sigma^{2}.
\end{eqnarray*}
%\end{frame}

%\end{document}
\subsection{3.4 Prueba de Hip\'otesis en RLS}
%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{itemize}
\item Para evaluar la suficiencia del modelo de regresi\'on lineal simple, es necesario lleva a cabo una prueba de hip\'otesis respecto de los par\'ametros del modelo as\'i como de la construcci\'on de intervalos de confianza.

\item Para poder realizar la prueba de hip\'otesis sobre la pendiente y la ordenada al or\'igen de la recta de regresi\'on es necesario hacer el supuesto de que el error $\epsilon_{i}$ se distribuye normalmente, es decir $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$.

\end{itemize}

%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Suponga que se desea probar la hip\'otesis de que la pendiente es igual a una constante, $\beta_{0,1}$ las hip\'otesis Nula y Alternativa son:
\begin{centering}
\begin{itemize}
\item[$H_{0}$: ] $\beta_{1}=\beta_{1,0}$,

\item[$H_{1}$: ]$\beta_{1}\neq\beta_{1,0}$.

\end{itemize}
donde dado que las $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$, se tiene que $y_{i}$ son variables aleatorias normales $N\left(\beta_{0}+\beta_{1}x_{1},\sigma^{2}\right)$. 
\end{centering}
De las ecuaciones (\ref{Ecs.Estimadores.Regresion}) se desprende que $\hat{\beta}_{1}$ es combinaci\'on lineal de variables aleatorias normales independientes, es decir, $\hat{\beta}_{1}\sim N\left(\beta_{1},\sigma^{2}/S_{xx}\right)$, recordar las ecuaciones (\ref{Esperanza.Beta.1}) y (\ref{Varianza.Beta.1}).
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Entonces se tiene que el estad\'istico de prueba apropiado es
\begin{equation}\label{Estadistico.Beta.1}
t_{0}=\frac{\hat{\beta}_{1}-\hat{\beta}_{1,0}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
que se distribuye $t$ con $n-2$ grados de libertad bajo $H_{0}:\beta_{1}=\beta_{1,0}$. Se rechaza $H_{0}$ si 
\begin{equation}\label{Zona.Rechazo.Beta.1}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}

%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Para $\beta_{0}$ se puede proceder de manera an\'aloga para
\begin{itemize}
\item[$H_{0}:$] $\beta_{0}=\beta_{0,0}$,
\item[$H_{1}:$] $\beta_{0}\neq\beta_{0,0}$,
\end{itemize}
con $\hat{\beta}_{0}\sim N\left(\beta_{0},\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)\right)$, por lo tanto
\begin{equation}\label{Estadistico.Beta.0}
t_{0}=\frac{\hat{\beta}_{0}-\beta_{0,0}}{MC_{E}\left[\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right]},
\end{equation}
con el que rechazamos la hip\'otesis nula si
\begin{equation}\label{Zona.Rechazo.Beta.0}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}

%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{itemize}
\item No rechazar $H_{0}:\beta_{1}=0$ es equivalente a decir que no hay relaci\'on lineal entre $x$ y $y$.
\item Alternativamente, si $H_{0}:\beta_{1}=0$ se rechaza, esto implica que $x$ explica la variabilidad de $y$, es decir, podr\'ia significar que la l\'inea recta esel modelo adecuado.
\end{itemize}
El procedimiento de prueba para $H_{0}:\beta_{1}=0$ puede realizarse de la siguiente manera:
\begin{eqnarray*}
S_{yy}=\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}

%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
S_{yy}&=&\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}+\hat{y}_{k}-\overline{y}\right)^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)+\left(y_{k}-\hat{y}_{k}\right)\right]^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\left(y_{k}-\hat{y}_{k}\right)^{2}\right]\\
&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}
%\end{frame}


%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
&&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)=\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\sum_{k=1}^{n}\overline{y}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}\right)\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
\begin{eqnarray*}
&=&\sum_{k=1}^{n}\hat{\beta}_{0}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\sum_{k=1}^{n}\hat{\beta}_{1}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&=&\hat{\beta}_{0}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\hat{\beta}_{1}\sum_{k=1}^{n}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)=0+0+0=0.
\end{eqnarray*}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Por lo tanto, efectivamente se tiene
\begin{equation}\label{Suma.Total.Cuadrados}
S_{yy}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2},
\end{equation}
donde se hacen las definiciones
\begin{eqnarray}
SC_{E}&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}\cdots\textrm{Suma de Cuadrados del Error}\\
SC_{R}&=&\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}\cdots\textrm{ Suma de Regresi\'on de Cuadrados}
\end{eqnarray}
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}
Por lo tanto la ecuaci\'on (\ref{Suma.Total.Cuadrados}) se puede reescribir como 
\begin{equation}\label{Suma.Total.Cuadrados.Dos}
S_{yy}=SC_{R}+SC_{E}
\end{equation}
recordemos que $SC_{E}=S_{yy}-\hat{\beta}_{1}S_{xy}$
\begin{eqnarray*}
S_{yy}&=&SC_{R}+\left( S_{yy}-\hat{\beta}_{1}S_{xy}\right)\\
S_{xy}&=&\frac{1}{\hat{\beta}_{1}}SC_{R}
\end{eqnarray*}
$S_{xy}$ tiene $n-1$ grados de libertad y $SC_{R}$ y $SC_{E}$ tienen 1 y $n-2$ grados de libertad respectivamente.
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
\begin{Prop}
\begin{equation}
E\left(SC_{R}\right)=\sigma^{2}+\beta_{1}S_{xx}
\end{equation}
adem\'as, $SC_{E}$ y $SC_{R}$ son independientes.
\end{Prop}
Recordemos que $\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}$. Para $H_{0}:\beta_{1}=0$ verdadera,
\begin{eqnarray*}
F_{0}=\frac{SC_{R}/1}{SC_{E}/(n-2)}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
se distribuye $F_{1,n-2}$, y se rechazar\'ia $H_{0}$ si $F_{0}>F_{\alpha,1,n-2}$.
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
El procedimiento de prueba de hip\'otesis puede presentarse como la tabla de an\'alisis de varianza siguiente\medskip

\begin{tabular}{lcccc}\hline
Fuente de & Suma de  &  Grados de  & Media  & $F_{0}$ \\ 
 variaci\'on & Cuadrados & Libertad & Cuadr\'atica & \\\hline
 Regresi\'on & $SC_{R}$ & 1 & $MC_{R}$  & $MC_{R}/MC_{E}$\\
 Error Residual & $SC_{E}$ & $n-2$ & $MC_{E}$ & \\\hline
 Total & $S_{yy}$ & $n-1$ & & \\\hline
\end{tabular} 
%\end{frame}

%\begin{frame}\frametitle{Prueba de Hip\'otesis}													
La prueba para la significaci\'on de la regresi\'on puede desarrollarse bas\'andose en la expresi\'on (\ref{Estadistico.Beta.1}), con $\hat{\beta}_{1,0}=0$, es decir
\begin{equation}\label{Estadistico.Beta.1.Cero}
t_{0}=\frac{\hat{\beta}_{1}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
Elevando al cuadrado ambos t\'erminos:
\begin{eqnarray*}
t_{0}^{2}=\frac{\hat{\beta}_{1}^{2}S_{xx}}{MC_{E}}=\frac{\hat{\beta}_{1}S_{xy}}{MC_{E}}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
Observar que $t_{0}^{2}=F_{0}$, por tanto la prueba que se utiliza para $t_{0}$ es la misma que para $F_{0}$.

%\end{frame}

%\end{document}
\subsection{Estimaci\'on de Intervalos en RLS}
%\begin{frame}\frametitle{Intervalos de Confianza}
\begin{itemize}
\item Adem\'as de la estimaci\'on puntual para los par\'ametros $\beta_{1}$ y $\beta_{0}$, es posible obtener estimaciones del intervalo de confianza de estos par\'ametros.

\item El ancho de estos intervalos de confianza es una medida de la calidad total de la recta de regresi\'on.

\end{itemize}


%\end{frame}

%\begin{frame}\frametitle{Intervalos de Confianza}
Si los $\epsilon_{k}$ se distribuyen normal e independientemente, entonces
\begin{eqnarray*}
\begin{array}{ccc}
\frac{\left(\hat{\beta}_{1}-\beta_{1}\right)}{\sqrt{\frac{MC_{E}}{S_{xx}}}}&y &\frac{\left(\hat{\beta}_{0}-\beta_{0}\right)}{\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}}
\end{array}
\end{eqnarray*}
se distribuyen $t$ con $n-2$ grados de libertad. Por tanto un intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\beta_{1}$ est\'a dado por
%\end{frame}
%\begin{frame}\frametitle{Intervalos de Confianza}
\begin{eqnarray}
\hat{\beta}_{1}-t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}\leq \beta_{1}\leq\hat{\beta}_{1}+t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}.
\end{eqnarray}
De igual manera, para $\beta_{0}$ un intervalo de confianza al $100\left(1-\alpha\right)\%$ es
\small{
\begin{eqnarray}
\begin{array}{l}
\hat{\beta}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}\leq\beta_{0}\leq\hat{\beta}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}
\end{array}
\end{eqnarray}}
%\end{frame}
\subsection{Predicci\'on}
%\begin{frame}\frametitle{Predicci\'on}
Supongamos que se tiene un valor $x_{0}$ de inter\'es, entonces la estimaci\'on puntual de este nuevo valor
\begin{equation}
\hat{y}_{0}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{0}
\end{equation}
\begin{Note}
Esta nueva observaci\'on es independiente de las utilizadas para obtener el modelo de regresi\'on, por tanto, el intervalo en torno a la recta de regresi\'on es inapropiado, puesto que se basa \'unicamente en los datos empleados para ajustar el modelo de regresi\'on.\\

El intervalo de confianza en torno a la recta de regresi\'on se refiere a la respuesta media verdadera $x=x_{0}$, no a observaciones futuras.
\end{Note}

%\end{frame}


%\begin{frame}\frametitle{Predicci\'on}
Sea $y_{0}$ la observaci\'on futura en $x=x_{0}$, y sea $\hat{y}_{0}$ dada en la ecuaci\'on anterior, el estimador de $y_{0}$. Si se define la variable aleatoria $$w=y_{0}-\hat{y}_{0},$$ esta se distribuye normalmente con media cero y varianza $$V\left(w\right)=\sigma^{2}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]$$
dado que $y_{0}$ es independiente de $\hat{y}_{0}$, por lo tanto el intervalo de predicci\'on al nivel $\alpha$ para futuras observaciones $x_{0}$ es

%\end{frame}

%\begin{frame}\frametitle{Predicci\'on}
\begin{eqnarray*}
\hat{y}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}\leq y_{0}\\
\leq \hat{y}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}.
\end{eqnarray*}
%\end{frame}


%\subsection{Prueba de falta de ajuste}
%%\begin{frame}\frametitle{Falta de ajuste}
%Es com\'un encontrar que el modelo ajustado no satisface totalmente el modelo necesario para los datos, en este caso es preciso saber qu\'e tan bueno es el modelo propuesto. Para esto se propone la siguiente prueba de hip\'otesis:
%\begin{itemize}
%\item[$H_{0}:$ ]El modelo propuesto se ajusta adecuademente a los datos.
%\item[$H_{1}:$ ]El modelo NO se ajusta a los datos.
%\end{itemize}
%La prueba implica dividir la suma de cuadrados del eror o del residuo en las siguientes dos componentes:
%\begin{eqnarray*}
%SC_{E}=SC_{EP}+SC_{FDA}
%\end{eqnarray*}

%%\end{frame}

%%\begin{frame}\frametitle{Falta de ajuste}
%donde $SC_{EP}$ es la suma de cuadrados atribuibles al error puro, y $SC_{FDA}$ es la suma de cuadrados atribuible a la falta de ajuste del modelo.
%%\end{frame}

%%\begin{frame}\frametitle{Falta de ajuste}
%%\end{frame}


\subsection{Coeficiente de Determinaci\'on}
%\begin{frame}\frametitle{Coeficiente de Determinaci\'on}
La cantidad
\begin{equation}
R^{2}=\frac{SC_{R}}{S_{yy}}=1-\frac{SC_{E}}{S_{yy}}
\end{equation}
se denomina coeficiente de determinaci\'on y se utiliza para saber si el modelo de regresi\'on es suficiente o no. Se puede demostrar que $0\leq R^{2}\leq1$, una manera de interpretar este valor es que si $R^{2}=k$, entonces el modelo de regresi\'on explica el $k*100\%$ de la variabilidad en los datos.
%\end{frame}

%\begin{frame}\frametitle{Coeficiente de Determinaci\'on}
$R^{2}$ 
\begin{itemize}
\item No mide la magnitud de la pendiente de la recta de regresi\'on
\item Un valor grande de $R^{2}$ no implica una pendiente empinada.
\item No mide la suficiencia del modelo.
\item Valores grandes de $R^{2}$ no implican necesariamente que el modelo de regresi\'on proporcionar\'a predicciones precisas para futuras observaciones.
\end{itemize}
%\end{frame}


\section{An\'alisis de Varianza}

%\begin{frame}\frametitle{An\'alisis de Varianza}
Para analizar el ajuste de regresi\'on se utiliza el m\'etodo de  \textbf{An\'alisis de Varianza} (\textbf{ANOVA}), el en cu\'al  se estudia la variaci\'on de la variable dependiente, subidividiendola en dos componentes significativos.
Recordemos las ecuaciones \ref{Suma.Total.Cuadrados} y \ref{Suma.Total.Cuadrados.Dos}:
\begin{eqnarray*}
S_{yy}=SC_{R}+SC_{E}.
\end{eqnarray*}

\begin{itemize}
\item[$SC_{R}$] Se le denomina \textbf{suma de cuadrados de la regresi\'on} y refleja la cantidad de variaci\'on de los valores de $y$ que es explicada por el modelo, para nuestro caso: la recta propuesta.

\item[$SC_{E}$] Se le denomina suma de cuadrados del error, que es la variaci\'on o diferencia que hay entre los valores originales y los obtenidos mediante el ajuste. 
\end{itemize}

%\end{frame}




%\begin{frame}\frametitle{An\'alisis de Varianza}
De lo anterior se desprende que estamos interesados en validar nuestro modelo dado en la ecuaci\'on (\ref{Modelo.Regresion}), es decir, 

\begin{eqnarray*}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray*}
que en realidad el par\'ametro $\beta_{1}$ ha sido bien estimado:

Supongamos que se desea probar la hip\'otesis
\begin{itemize}
\item[$H_{0}:$] $\beta_{1}=0$
\item[$H_{1}:$] $\beta_{1}\neq0$
\end{itemize}
%\end{frame}



%\begin{frame}\frametitle{An\'alisis de Varianza}
Donde la hip\'otesis nula nos dice que el modelo en realidad debe de ser: $\mu_{Y|x}=\beta_{0}$, es decir, las variaciones en los valores de $Y$ son independientes de los valores de $x$. Se puede demostrar que bajo la hip\'otesis nula los t\'erminos
\begin{itemize}
\item $SC_{R}/\sigma^{2}$ se distribuye $\chi^{2}$ con 1 grado de libertad
\item $SC_{E}/\sigma^{2}$ se distribuye $\chi^{2}$ con $n-2$ grado de libertad.
\end{itemize}
e independientes, y por tanto $S_{yy}$,  tambien llamada \textbf{suma total de cuadrados corregida: STCC}, se distribuye $\chi^{2}$ con $n-1$ grados de libertad.

%\end{frame}


%\begin{frame}\frametitle{An\'alisis de Varianza}

Para realizar esta prueba de hip\'otesis se calcula el cociente

\begin{eqnarray*}
f=\frac{SC_{R}/1}{SC_{E}/\left(n-2\right)}=\frac{SC_{R}}{s^{2}}
\end{eqnarray*}
y se rechaza $H_{0}$ a un nivel de significancia $\alpha$ si $f>f_{\alpha}\left(1,\left(n-2\right)\right)$, esto se puede realizar mediante una tabla, llamada tabla de an\'alisis de varianza, cuando a las distintas sumas de cuadrados se les divide por sus grados de libertad, se les denomina \textbf{cuadrados medios}.


%\end{frame}

%\begin{frame}\frametitle{An\'alisis de Varianza}
\begin{table}[t!]
\begin{center}
\scalebox{0.65}{\begin{tabular}{| c | c | c | c| c | }
\hline 
\textbf{Fuente de Variaci\'on}&\textbf{Suma de Cuadrados}&\textbf{ Grados de Libertad }&\textbf{ Cuadrado Medio }&\textbf{ $f$ calculada }\\ 
\hline 
Regresi\'on & $SC_{R}$ & 1 & $SC_{R}$ & $\frac{SC_{R}}{s^{2}}$ \\ 
Error & $SC_{E}$ & $n-2$ & $s^{2}=\frac{SC_{E}}{n-2}$ &  \\\hline
Total & $STCC$ & $n-1$ &  &  \\ 
\hline 
\end{tabular}}
\caption{An\'alisis de Varianza para la prueba $\beta_{1}=0$}
\label{tab:ANOVA}
\end{center}
\end{table}
Se rechaza la hip\'otesis nula, cuando el estad\'istico $F$ calculado excede al valor cr\'itico $f_{\alpha}\left(1-n-2\right)$, y entonces se concluye que existe evidencia sobre la variaci\'on respecto al modelo ajustado. Si el estad\'istico $F$ est\'a en la regi\'on de no rechazo, se concluye que los datos no reflejan evidencia suficiente para sostener que el modelo ajustado.
%\end{frame}


%\begin{frame}\frametitle{An\'alisis de Varianza}
Para hacer la prueba de hip\'otesis 
\begin{itemize}
\item[$H_{0}$ :]$\beta_{1}=\beta_{10}$
\item[$H_{1}$ :]$\beta_{1}\neq\beta_{10}$
\end{itemize}
se utiliza el estad\'istico:
\begin{eqnarray*}
T=\frac{B_{1}-\beta_{10}}{S/\sqrt{S_{xx}}}
\end{eqnarray*}
donde $T$ se distribuye $t$ con $n-2$ grados de libertad. La hip\'otesis se rechaza si $|t|>t_{\alpha/2}$ con un nivel de confianza $\alpha$.
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
\begin{Note}
Para el caso en que $\beta_{10}=0$, se tiene que el valor del estad\'istico se convierte en 
\begin{eqnarray*}
T=\frac{b_{1}-\beta_{10}}{s/\sqrt{S_{xx}}}
\end{eqnarray*}
y entonces el an\'alisis es similar al dado en la tabla \ref{tab:ANOVA}, y lo que se est\'a diciendo es que la variaci\'on depende totalmente del azar.
\end{Note}
\begin{Note}
El An\'alisis de Varianza utiliza la distribuci\'on $F$ en lugar de la distribuci\'on $t$.
\end{Note}

%\end{frame}

%\begin{frame}\frametitle{An\'alisis de Varianza}
Supongamos que se tienen observaciones repetidas de las respuestas para $k$ valores distintos de $x$, es decir: para $x_{1},x_{2},\ldots,x_{k}$ se tienen $y_{1,1},y_{1,2},\ldots,y_{1,n_{1}}$ valores observados para la variable aleatoria $Y_{1}$, $y_{2,1},y_{2,2},\ldots,y_{2,n_{2}}$ valores observados para la variable aleatoria $Y_{2}$, y as\'i sucesivamente para $y_{k,1},y_{k,2},\ldots,y_{1,n_{k}}$ valores observados para la variable aleatoria $Y_{k}$, de tal manera que 
\begin{eqnarray*}
n=\sum_{i=1}^{k}n_{i}
\end{eqnarray*}
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
\begin{eqnarray*}
Y = \left[
\begin{matrix}
y_{1,1} & y_{2,1} & \cdots & Y_{k,1} \\ 
y_{1,2} & y_{2,2} & \cdots & Y_{k,2} \\ 
\vdots & \vdots &  \vdots & \vdots \\ 
 y_{1,j} &  y_{2,j} & y_{i,j} &  y_{k,j} \\ 
\vdots & \vdots & \vdots & \vdots \\ 
y_{1,n_{1}} & y_{2,n_{2}} & \cdots & Y_{k,n_{k}} 
\end{matrix} 
\right]
\end{eqnarray*}
entonces, si definimos $y_{i}=T_{i}=\sum_{j=1}^{n_{i}}y_{i,j}$, se tiene que $\overline{y}_{i}=\frac{T_{i}}{n_{i}}$
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
C\'omo se ve la matriz para el caso en que:
\begin{itemize}
\item $n_{4}=3$ mediciones de $Y$
\item Simular en R, para los casos en que $n_{1}=4$, $n_{2}=6$, $n_{3}=5$, y $n_{4}=8$,
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza: Falta de ajuste}
La suma de cuadrados del error se divide en dos partes: la cantidad debida a la variaci|'on entre los valores de $Y$ para los valores dados de $x$, y lo que se denomina \textbf{falta de ajuste} que es una medida de la variaci\'on sistem\'atica introducida por  los t\'erminos de orden superior. Para nuestro caso en espec\'ifico, estos son t\'erminos de $x$ distintos de la contribuci\'on lineal de primer orden.\medskip

Hasta el momento, dado que hemos considerado un modelo lineal, se asume que este segundo componente no existe, y por tanto la suma de cuadrados de error depende totalmente de los errores aleatorios. En consecuencia tenemos que $s^{2}=\frac{SCE}{\left(n-2\right)}$ es un estimador insesgado para $\sigma^{2}$.
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
Sin embargo, si el modelo no ajusta correctamente a los datos, lo que tenemos es una sobre estimaci\'on del valor de $\sigma^{2}$ y por tanto ser\'a un estimador sesgado del mismo.\medskip

Para obtener un estimador insesgado se calcula
\begin{eqnarray*}
s^{2}=\frac{\sum_{j=1}^{n_{i}}\left(y_{ij}-\overline{y}_{i}\right)^{2}}{n_{i}-1},\textrm{ para } i=1,2,\ldots,k
\end{eqnarray*}
despu\'es de hacer unas operaciones se puede obtener:

%\end{frame}

%\begin{frame}\frametitle{An\'alisis de Varianza}

\begin{eqnarray*}
s^{2}=\frac{\sum_{i=1}^{k}\left(n_{i}-1\right)s_{i}^{2}}{n_{i}-k}=\frac{\sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\overline{y}_{i}\right)^{2}}{n-k}.
\end{eqnarray*}
El numerador de $s^{2}$ es una medida del \textbf{error experimental puro} o \textbf{falta de ajuste}\medskip

Para determinar el cuadrado del error en: error puro y la falta de ajuste:
\begin{itemize}
\item Se calcula la suma de cuadrados del error puro:
\begin{eqnarray*}
\sum_{i=1}^{k}\sum_{j=1}^{n_{i}}\left(y_{ij}-\overline{y}_{i}\right)^{2}
\end{eqnarray*}

\end{itemize}


%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
esta suma de cuadrados tiene $n-k$ grados de libertad, y el cuadrado medio resultante es el estimador insesgado $s^{2}$ de $\sigma^{2}$.
\begin{itemize}
\item Restar la suma de cuadrados del error puro de la suma de cuadrados del error, SCE, resultando la suma de cuadrados por ajuste. Los grados de libertad de la  falta de ajuste se obtienen por la resta: $\left(n-2\right)-\left(n-k\right)=k-2$.
\end{itemize}
%\end{frame}
%\begin{frame}\frametitle{An\'alisis de Varianza}
La prueba de hip\'otesis en un problema de regresi\'on con mediciones repetidas de la respuesta se ilustra en la tabla \ref{tab:ANOVA}:
\begin{table}[t!]
\begin{center}
\scalebox{0.65}{\begin{tabular}{| c | c | c | c| c | }
\hline 
\textbf{Fuente de Variaci\'on}&\textbf{Suma de Cuadrados}&\textbf{ Grados de Libertad }&\textbf{ Cuadrado Medio }&\textbf{ $f$ calculada }\\ 
\hline 
Regresi\'on & $SC_{R}$ & 1 & $SC_{R}$ & $\frac{SC_{R}}{s^{2}}$ \\ 
Error & $SC_{E}$ & $n-2$ &  &  \\\hline
Falta de ajuste &$SCE-SCE (puro)$&$k-2$&$\frac{SCE-SCE (puro)}{k-2}$&$\frac{SCE-SCE(puro)}{s^{2}\left(k-2\right)}$\\\hline
Error Puro &$SCE(puro)$&$n-k$&$s^{2}=\frac{SCE(puro)}{n-k}$&\\\hline
Total & $STCC$ & $n-1$ &  &  \\ 
\hline 
\end{tabular}}
\caption{An\'alisis de Varianza para la prueba $\beta_{1}=0$}
\label{tab:ANOVA}
\end{center}
\end{table}
%\end{frame}


%---------------------------------------------------------
\section{Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{Tipos de errores}



%\begin{frame}

%%\begin{frame}\frametitle{Prueba de Hip\'otesis}

\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}

%\end{frame}



%\begin{frame}

Una prueba de hip\'otesis est\'a formada por cinco partes
\begin{itemize}
\item La hip\'otesis nula, denotada por $H_{0}$.
\item La hip\'otesis alterativa, denorada por $H_{1}$.
\item El estad\'sitico de prueba y su valor $p$.
\item La regi\'on de rechazo.
\item La conclusi\'on.

\end{itemize}

\begin{Def}
Las dos hip\'otesis en competencias son la \textbf{hip\'otesis alternativa $H_{1}$}, usualmente la que se desea apoyar, y la \textbf{hip\'otesis nula $H_{0}$}, opuesta a $H_{1}$.
\end{Def}

%\end{frame}




%\begin{frame}


En general, es m\'as f\'acil presentar evidencia de que $H_{1}$ es cierta, que demostrar 	que $H_{0}$ es falsa, es por eso que por lo regular se comienza suponiendo que $H_{0}$ es cierta, luego se utilizan los datos de la muestra para decidir si existe evidencia a favor de $H_{1}$, m\'as que a favor de $H_{0}$, as\'i se tienen dos conclusiones
\begin{itemize}
\item Rechazar $H_{0}$ y concluir que $H_{1}$ es verdadera.
\item Aceptar, no rechazar, $H_{0}$ como verdadera.

\end{itemize}

\begin{Ejem}
Se desea demostrar que el salario promedio  por hora en cierto lugar es distinto de $19$usd, que es el promedio nacional. Entonces $H_{1}:\mu\neq19$, y $H_{0}:\mu=19$.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de dos colas}.


%\end{frame}




%\begin{frame}


\begin{Ejem}
Un determinado proceso produce un promedio de $5\%$ de piezas defectuosas. Se est\'a interesado en demostrar que un simple ajuste en una m\'aquina reducir\'a $p$, la proporci\'on de piezas defectuosas producidas en este proceso. Entonces se tiene $H_{0}:p<0.3$ y $H_{1}:p=0.03$. Si se puede rechazar $H_{0}$, se concluye que el proceso ajustado produce menos del $5\%$ de piezas defectuosas.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de una cola}.

La decisi\'on de rechazar o aceptar la hip\'otesis nula est\'a basada en la informaci\'on contenida en una muestra proveniente de la poblaci\'on de inter\'es. Esta informaci\'on tiene estas formas
%\end{frame}

%\begin{frame}

\begin{itemize}
\item \textbf{Estad\'sitico de prueba:} un s\'olo n\'umero calculado a partir de la muestra.

\item \textbf{$p$-value:} probabilidad calculada a partir del estad\'stico de prueba.
\begin{Def}
El $p$-value es la probabilidad de observar un estad\'istico de prueba tanto o m\'as alejado del valor obervado, si en realidad $H_{0}$ es verdadera.\medskip
Valores grandes del estad\'stica de prueba  y valores peque\~nos de $p$ significan que se ha observado un evento muy poco probable, si $H_{0}$ en realidad es verdadera.
\end{Def}

\end{itemize}
%\end{frame}



%\begin{frame}

Todo el conjunto de valores que puede tomar el estad\'istico de prueba se divide en dos regiones. Un conjunto, formado de valores que apoyan la hip\'otesis alternativa y llevan a rechazar $H_{0}$, se denomina \textbf{regi\'on de rechazo}. El otro, conformado por los valores que sustentatn la hip\'otesis nula, se le denomina \textbf{regi\'on de aceptaci\'on}.\medskip

Cuando la regi\'on de rechazo est\'a en la cola izquierda de la distribuci\'on, la  prueba se denomina \textbf{prueba lateral izquierda}. Una prueba con regi\'on de rechazo en la cola derecha se le llama \textbf{prueba lateral derecha}.


Si el estad\'stico de prueba cae en la regi\'on de rechazo, entonces se rechaza $H_{0}$. Si el estad\'stico de prueba cae en la regi\'on de aceptaci\'on, entonces la hip\'otesis nula se acepta o la prueba se juzga como no concluyente.\medskip
%\end{frame}



%\begin{frame}

Dependiendo del nivel de confianza que se desea agregar a las conclusiones de la prueba, y el \textbf{nivel de significancia $\alpha$}, el riesgo que est\'a dispuesto a correr si se toma una decisi\'on incorrecta.

%\end{frame}


%\begin{frame}

\begin{Def}
Un \textbf{error de tipo I} para una prueba estad\'istica es el error que se tiene al rechazar la hip\'otesis nula cuando es verdadera. El \textbf{nivel de significancia} para una prueba estad\'istica de hip\'otesis es
\begin{eqnarray*}
\alpha&=&P\left\{\textrm{error tipo I}\right\}=P\left\{\textrm{rechazar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es verdadera}\right\}
\end{eqnarray*}

\end{Def}
Este valor $\alpha$ representa el valor m\'aximo de riesgo tolerable de rechazar incorrectamente $H_{0}$. Una vez establecido el nivel de significancia, la regi\'on de rechazo se define para poder determinar si se rechaza $H_{0}$ con un cierto nivel de confianza.

%\end{frame}

\section{Muestras grandes: una media poblacional}
\subsection{C\'alculo de valor $p$}



%\begin{frame}

\begin{Def}
El \textbf{valor de $p$} (\textbf{$p$-value}) o nivel de significancia observado de un estad\'istico de prueba es el valor m\'as peque\~ no de $\alpha$ para el cual $H_{0}$ se puede rechazar. El riesgo de cometer un error tipo $I$, si $H_{0}$ es rechazada con base en la informaci\'on que proporciona la muestra.
\end{Def}

\begin{Note}
Valores peque\~ nos de $p$ indican 	que el valor observado del estad\'stico de prueba se encuentra alejado del valor hipot\'etico de $\mu$, es decir se tiene evidencia de que $H_{0}$ es falsa y por tanto debe de rechazarse.
\end{Note}

\begin{Note}
Valores grandes de $p$ indican que el estad\'istico de prueba observado no est\'a alejado de la medi hipot\'etica y no apoya el rechazo de $H_{0}$.
\end{Note}


%\end{frame}


%\begin{frame}

\begin{Def}
Si el valor de $p$ es menor o igual que el nivel de significancia $\alpha$, determinado previamente, entonces $H_{0}$ es rechazada y se puede concluir que los resultados son estad\'isticamente significativos con un nivel de confianza del $100\left(1-\alpha\right)\%$.
\end{Def}
Es usual utilizar la siguiente clasificaci\'on de resultados


\begin{tabular}{|c||c|l|}\hline
$p$& $H_{0}$&Significativa\\\hline\hline
$p<0.01$&Rechazar &Altamente\\\hline
$0.01\leq p<0.05$ & Rechazar&Estad\'isticamente\\\hline
$0.05\leq p <0.1$ & No rechazar & Tendencia estad\'istica\\\hline
$0.01\leq p$ & No rechazar & No son estad\'isticamente\\\hline
\end{tabular}

%\end{frame}

%\begin{frame}

\begin{Note}
Para determinar el valor de $p$, encontrar el \'area en la cola despu\'es del estad\'istico de prueba. Si la prueba es de una cola, este es el valor de $p$. Si es de dos colas, \'este valor encontrado es la mitad del valor de $p$. Rechazar $H_{0}$ cuando el valor de $p<\alpha$.
\end{Note}

Hay dos tipos de errores al realizar una prueba de hip\'otesis
\begin{center}
\begin{tabular}{c|cc}
& $H_{0}$ es Verdadera & $H_{0}$ es Falsa\\\hline\hline
Rechazar $H_{0}$ & Error tipo I & $\surd$\\
Aceptar $H_{0}$ & $\surd$ & Error tipo II
\end{tabular}
\end{center}

%\end{frame}


%\begin{frame}

\begin{Def}
La probabilidad de cometer el error tipo II se define por $\beta$ donde
\begin{eqnarray*}
\beta&=&P\left\{\textrm{error tipo II}\right\}=P\left\{\textrm{Aceptar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{Aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}
\end{eqnarray*}
\end{Def}

\begin{Note}
Cuando $H_{0}$ es falsa y $H_{1}$ es verdadera, no siempre es posible especificar un valor exacto de $\mu$, sino m\'as bien un rango de posibles valores.\medskip
En lugar de arriesgarse a tomar una decisi\'on incorrecta, es mejor conlcuir que \textit{no hay evidencia suficiente para rechazar $H_{0}$}, es decir en lugar de aceptar $H_{0}$, \textit{no rechazar $H_{0}$}.

\end{Note}
%\end{frame}



%\begin{frame}

La bondad de una prueba estad\'istica se mide por el tama\~ no de $\alpha$ y $\beta$, ambas deben de ser peque\~ nas. Una manera muy efectiva de medir la potencia de la prueba es calculando el complemento del error tipo $II$:
\begin{eqnarray*}
1-\beta&= &P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{1}\textrm{ es verdadera}\right\}
\end{eqnarray*}
\begin{Def}
La \textbf{potencia de la prueba}, $1-\beta$, mide la capacidad de que la prueba funciona como se necesita.
\end{Def}


%\end{frame}


%\begin{frame}

\begin{Ejem}
La producci\'on diariade una planta qu\'imica local ha promediado 880 toneladas en los \'ultimos a\~nos. A la gerente de control de calidad le gustar\'ia saber si este promedio ha cambiado en meses recientes. Ella selecciona al azar 50 d\'ias de la base de datos computarizada y calcula el promedio y la desviaci\'on est\'andar de las $n=50$  producciones como $\overline{x}=871$ toneladas y $s=21$ toneladas, respectivamente. Pruebe la hip\'otesis  apropiada usando $\alpha=0.05$.

\end{Ejem}

%\end{frame}


%\begin{frame}

\begin{Sol}
La hip\'otesis nula apropiada es:

\begin{eqnarray*}
H_{0}&:& \mu=880\\
&&\textrm{ y la hip\'otesis alternativa }H_{1}\textrm{ es }\\
H_{1}&:& \mu\neq880
\end{eqnarray*}
el estimador puntual para $\mu$ es $\overline{x}$, entonces el estad\'istico de prueba es\medskip
\begin{eqnarray*}
z&=&\frac{\overline{x}-\mu_{0}}{s/\sqrt{n}}\\
&=&\frac{871-880}{21/\sqrt{50}}=-3.03
\end{eqnarray*}
\end{Sol}



\begin{Sol}
Para esta prueba de  dos colas, hay que determinar los dos valores de $z_{\alpha/2}$, es decir, $z_{\alpha/2}=\pm1.96$

\end{Sol}


%\end{frame}


%---------------------------------------------------------
\section{Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{Tipos de errores}



%\begin{frame}

\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}

%\end{frame}





%\begin{frame}


\begin{itemize}
\item La descisi\'on de aceptar o rechazar la hip\'otesis nula se basa en un estad\'istico calculado a partir de la muestra. Esto necesariamente implica la existencia de un error.


\end{itemize}

%\end{frame}

%---------------------------------------------------------
\section{Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{Tipos de errores}


%\begin{frame}

\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}


%\end{frame}


%\begin{frame}

Una prueba de hip\'otesis est\'a formada por cinco partes
\begin{itemize}
\item La hip\'otesis nula, denotada por $H_{0}$.
\item La hip\'otesis alterativa, denorada por $H_{1}$.
\item El estad\'sitico de prueba y su valor $p$.
\item La regi\'on de rechazo.
\item La conclusi\'on.

\end{itemize}

\begin{Def}
Las dos hip\'otesis en competencias son la \textbf{hip\'otesis alternativa $H_{1}$}, usualmente la que se desea apoyar, y la \textbf{hip\'otesis nula $H_{0}$}, opuesta a $H_{1}$.
\end{Def}


%\end{frame}



%\begin{frame}

En general, es m\'as f\'acil presentar evidencia de que $H_{1}$ es cierta, que demostrar 	que $H_{0}$ es falsa, es por eso que por lo regular se comienza suponiendo que $H_{0}$ es cierta, luego se utilizan los datos de la muestra para decidir si existe evidencia a favor de $H_{1}$, m\'as que a favor de $H_{0}$, as\'i se tienen dos conclusiones
\begin{itemize}
\item Rechazar $H_{0}$ y concluir que $H_{1}$ es verdadera.
\item Aceptar, no rechazar, $H_{0}$ como verdadera.

\end{itemize}

\begin{Ejem}
Se desea demostrar que el salario promedio  por hora en cierto lugar es distinto de $19$usd, que es el promedio nacional. Entonces $H_{1}:\mu\neq19$, y $H_{0}:\mu=19$.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de dos colas}.

%\end{frame}


%\begin{frame}

\begin{Ejem}
Un determinado proceso produce un promedio de $5\%$ de piezas defectuosas. Se est\'a interesado en demostrar que un simple ajuste en una m\'aquina reducir\'a $p$, la proporci\'on de piezas defectuosas producidas en este proceso. Entonces se tiene $H_{0}:p<0.3$ y $H_{1}:p=0.03$. Si se puede rechazar $H_{0}$, se concluye que el proceso ajustado produce menos del $5\%$ de piezas defectuosas.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de una cola}.


La decisi\'on de rechazar o aceptar la hip\'otesis nula est\'a basada en la informaci\'on contenida en una muestra proveniente de la poblaci\'on de inter\'es. Esta informaci\'on tiene estas formas

\begin{itemize}
\item \textbf{Estad\'sitico de prueba:} un s\'olo n\'umero calculado a partir de la muestra.

\item \textbf{$p$-value:} probabilidad calculada a partir del estad\'stico de prueba.
\begin{Def}
El $p$-value es la probabilidad de observar un estad\'istico de prueba tanto o m\'as alejado del valor obervado, si en realidad $H_{0}$ es verdadera.\medskip
Valores grandes del estad\'stica de prueba  y valores peque\~nos de $p$ significan que se ha observado un evento muy poco probable, si $H_{0}$ en realidad es verdadera.
\end{Def}

\end{itemize}

%\end{frame}




%\begin{frame}

Todo el conjunto de valores que puede tomar el estad\'istico de prueba se divide en dos regiones. Un conjunto, formado de valores que apoyan la hip\'otesis alternativa y llevan a rechazar $H_{0}$, se denomina \textbf{regi\'on de rechazo}. El otro, conformado por los valores que sustentatn la hip\'otesis nula, se le denomina \textbf{regi\'on de aceptaci\'on}.\medskip

Cuando la regi\'on de rechazo est\'a en la cola izquierda de la distribuci\'on, la  prueba se denomina \textbf{prueba lateral izquierda}. Una prueba con regi\'on de rechazo en la cola derecha se le llama \textbf{prueba lateral derecha}.



Si el estad\'stico de prueba cae en la regi\'on de rechazo, entonces se rechaza $H_{0}$. Si el estad\'stico de prueba cae en la regi\'on de aceptaci\'on, entonces la hip\'otesis nula se acepta o la prueba se juzga como no concluyente.\medskip

%\end{frame}




%\begin{frame}

Dependiendo del nivel de confianza que se desea agregar a las conclusiones de la prueba, y el \textbf{nivel de significancia $\alpha$}, el riesgo que est\'a dispuesto a correr si se toma una decisi\'on incorrecta.
%\end{frame}




%\begin{frame}


\begin{Def}
Un \textbf{error de tipo I} para una prueba estad\'istica es el error que se tiene al rechazar la hip\'otesis nula cuando es verdadera. El \textbf{nivel de significancia} para una prueba estad\'istica de hip\'otesis es
\begin{eqnarray*}
\alpha&=&P\left\{\textrm{error tipo I}\right\}=P\left\{\textrm{rechazar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es verdadera}\right\}
\end{eqnarray*}

\end{Def}
Este valor $\alpha$ representa el valor m\'aximo de riesgo tolerable de rechazar incorrectamente $H_{0}$. Una vez establecido el nivel de significancia, la regi\'on de rechazo se define para poder determinar si se rechaza $H_{0}$ con un cierto nivel de confianza.

%\end{frame}




\section{Muestras grandes: una media poblacional}
\subsection{C\'alculo de valor $p$}




%\begin{frame}

\begin{Def}
El \textbf{valor de $p$} (\textbf{$p$-value}) o nivel de significancia observado de un estad\'istico de prueba es el valor m\'as peque\~ no de $\alpha$ para el cual $H_{0}$ se puede rechazar. El riesgo de cometer un error tipo $I$, si $H_{0}$ es rechazada con base en la informaci\'on que proporciona la muestra.
\end{Def}

\begin{Note}
Valores peque\~ nos de $p$ indican 	que el valor observado del estad\'stico de prueba se encuentra alejado del valor hipot\'etico de $\mu$, es decir se tiene evidencia de que $H_{0}$ es falsa y por tanto debe de rechazarse.
\end{Note}

\begin{Note}
Valores grandes de $p$ indican que el estad\'istico de prueba observado no est\'a alejado de la medi hipot\'etica y no apoya el rechazo de $H_{0}$.
\end{Note}

%\end{frame}



%\begin{frame}


\begin{Def}
Si el valor de $p$ es menor o igual que el nivel de significancia $\alpha$, determinado previamente, entonces $H_{0}$ es rechazada y se puede concluir que los resultados son estad\'isticamente significativos con un nivel de confianza del $100\left(1-\alpha\right)\%$.
\end{Def}
Es usual utilizar la siguiente clasificaci\'on de resultados


\begin{tabular}{|c||c|l|}\hline
$p$& $H_{0}$&Significativa\\\hline\hline
$p<0.01$&Rechazar &Altamente\\\hline
$0.01\leq p<0.05$ & Rechazar&Estad\'isticamente\\\hline
$0.05\leq p <0.1$ & No rechazar & Tendencia estad\'istica\\\hline
$0.01\leq p$ & No rechazar & No son estad\'isticamente\\\hline
\end{tabular}

%\end{frame}


%\begin{frame}

\begin{Note}
Para determinar el valor de $p$, encontrar el \'area en la cola despu\'es del estad\'istico de prueba. Si la prueba es de una cola, este es el valor de $p$. Si es de dos colas, \'este valor encontrado es la mitad del valor de $p$. Rechazar $H_{0}$ cuando el valor de $p<\alpha$.
\end{Note}

Hay dos tipos de errores al realizar una prueba de hip\'otesis
\begin{center}
\begin{tabular}{c|cc}
& $H_{0}$ es Verdadera & $H_{0}$ es Falsa\\\hline\hline
Rechazar $H_{0}$ & Error tipo I & $\surd$\\
Aceptar $H_{0}$ & $\surd$ & Error tipo II
\end{tabular}
\end{center}
%\end{frame}

%\begin{frame}



\begin{Def}
La probabilidad de cometer el error tipo II se define por $\beta$ donde
\begin{eqnarray*}
\beta&=&P\left\{\textrm{error tipo II}\right\}=P\left\{\textrm{Aceptar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{Aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}
\end{eqnarray*}
\end{Def}

\begin{Note}
Cuando $H_{0}$ es falsa y $H_{1}$ es verdadera, no siempre es posible especificar un valor exacto de $\mu$, sino m\'as bien un rango de posibles valores.\medskip
En lugar de arriesgarse a tomar una decisi\'on incorrecta, es mejor conlcuir que \textit{no hay evidencia suficiente para rechazar $H_{0}$}, es decir en lugar de aceptar $H_{0}$, \textit{no rechazar $H_{0}$}.

\end{Note}
%\end{frame}


%\begin{frame}


La bondad de una prueba estad\'istica se mide por el tama\~ no de $\alpha$ y $\beta$, ambas deben de ser peque\~ nas. Una manera muy efectiva de medir la potencia de la prueba es calculando el complemento del error tipo $II$:
\begin{eqnarray*}
1-\beta&= &P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{1}\textrm{ es verdadera}\right\}
\end{eqnarray*}
\begin{Def}
La \textbf{potencia de la prueba}, $1-\beta$, mide la capacidad de que la prueba funciones como se necesita.
\end{Def}
%\end{frame}



%---------------------------------------------------------
\section{Estimaci\'on por intervalos}
%---------------------------------------------------------
\subsection*{Para la media}

%\begin{frame}



Recordemos que $S^{2}$ es un estimador insesgado de $\sigma^{2}$
\begin{Def}
Sean $\hat{\theta}_{1}$ y $\hat{\theta}_{2}$ dos estimadores insesgados de $\theta$, par\'ametro poblacional. Si $\sigma_{\hat{\theta}_{1}}^{2}<\sigma_{\hat{\theta}_{2}}^{2}$, decimos que $\hat{\theta}_{1}$ un estimador m\'as eficaz de $\theta$ que $\hat{\theta}_{2}$.
\end{Def}

Algunas observaciones que es preciso realizar

\begin{enumerate}
\item[a) ]Para poblaciones normales, $\overline{X}$ y $\tilde{X}$ son estimadores insesgados de $\mu$, pero con $\sigma_{\overline{X}}^{2}<\sigma_{\tilde{X}_{2}}^{2}$.
%\end{Note}

%\begin{Note}
\item[b) ]Para las estimaciones por intervalos de $\theta$, un intervalo de la forma $\hat{\theta}_{L}<\theta<\hat{\theta}_{U}$,  $\hat{\theta}_{L}$ y $\hat{\theta}_{U}$ dependen del valor de $\hat{\theta}$.
\item[c) ]Para $\sigma_{\overline{X}}^{2}=\frac{\sigma^{2}}{n}$, si $n\rightarrow\infty$, entonces $\hat{\theta}\rightarrow\mu$.
%\end{Note}
\end{enumerate}

%\end{frame}



%\begin{frame}



%\begin{Note}
%Para $\sigma_{\overline{X}}^{2}=\frac{\sigma^{2}}{n}$, si $n\rightarrow\infty$, %entonces $\hat{\theta}\rightarrow\mu$.
%\end{Note}

%\begin{Note}
\begin{enumerate}
\item[d) ]Para $\hat{\theta}$ se determinan $\hat{\theta}_{L}$ y $\hat{\theta}_{U}$ de modo tal que 
\begin{eqnarray}
P\left\{\hat{\theta}_{L}<\hat{\theta}<\hat{\theta}_{U}\right\}=1-\alpha,
\end{eqnarray}
con $\alpha\in\left(0,1\right)$. Es decir, $\theta\in\left(\hat{\theta}_{L},\hat{\theta}_{U}\right)$ es un intervalo de confianza del $100\left(1-\alpha\right)\%$.

\item[e) ] De acuerdo con el TLC se espera que la distribuci\'on muestral de $\overline{X}$ se distribuye aproximadamente normal con media $\mu_{X}=\mu$ y desviaci\'on est\'andar $\sigma_{\overline{X}}=\frac{\sigma}{\sqrt{n}}$.

\end{enumerate}
%\end{frame}


%\begin{frame}




Para $Z_{\alpha/2}$ se tiene $P\left\{-Z_{\alpha/2}<Z<Z_{\alpha/2}\right\}=1-\alpha$, donde $Z=\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}$. Entonces
$P\left\{-Z_{\alpha/2}<\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}<Z_{\alpha/2}\right\}=1-\alpha$ es equivalente a 
$P\left\{\overline{X}-Z_{\alpha/2}\frac{\sigma}{\sqrt{n}}<\mu<\overline{X}+Z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right\}=1-\alpha$ 

\begin{enumerate}
\item[f) ]Si $\overline{X}$ es la media muestral de una muestra de tama\~no $n$ de una poblaci\'on con varianza conocida $\sigma^{2}$, el intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\mu$ es $\mu\in\left(\overline{x}-z_{\alpha/2}\frac{\sigma}{\sqrt{n}},\overline{x}+z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right)$.

\item[g) ] Para muestras peque\~nas de poblaciones no normales, no se puede esperar que el grado de confianza sea preciso.
\item[h) ] Para $n\geq30$, con distribuci\'on de forma no muy sesgada, se pueden tener buenos resultados.
\end{enumerate}

%\end{frame}


%\begin{frame}



\begin{Teo}
Si $\overline{X}$ es un estimador de $\mu$, podemos tener $100\left(1-\alpha\right)\%$  de confianza en que el error no exceder\'a a $z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$, error entre $\overline{X}$ y $\mu$.
\end{Teo}

\begin{Teo}
Si $\overline{X}$ es un estimador de $\mu$, podemos tener $100\left(1-\alpha\right)\%$  de confianza en que el error no exceder\'a una cantidad $e$ cuando el tama\~no de la muestra es $$n=\left(\frac{z_{\alpha/2}\sigma}{e}\right)^{2}.$$
\end{Teo}
\begin{Note}
Para intervalos unilaterales
$$P\left\{\frac{\overline{X}-\mu}{\sigma/\sqrt{n}}<Z_{\alpha}\right\}=1-\alpha$$
\end{Note}

%\end{frame}


%\begin{frame}



equivalentemente
$$P\left\{\mu<\overline{X}+Z_{\alpha}\frac{\sigma}{\sqrt{n}}\right\}=1-\alpha.$$
Si $\overline{X}$ es la media de una muestra aleatoria de tama\~no $n$  a partir de una poblaci\'on con varianza $\sigma^{2}$, los l\'imites de confianza unilaterales del   $100\left(1-\alpha\right)\%$  de confianza para $\mu$ est\'an dados por
\begin{itemize}
\item L\'imite unilateral superior: $\overline{x}+z_{\alpha}\frac{\sigma}{\sqrt{n}}$
\item L\'imite unilateral inferior: $\overline{x}-z_{\alpha}\frac{\sigma}{\sqrt{n}}$
\end{itemize}


\begin{itemize}
\item Para $\sigma$ desconocida recordar que $T=\frac{\overline{x}-\mu}{s/\sqrt{n}}\sim t_{n-1}$, donde $s$ es la desviaci\'on est\'andar de la muestra. Entonces
\begin{eqnarray*}
P\left\{-t_{\alpha/2}<T<t_{\alpha/2}\right\}=1-\alpha,\textrm{equivalentemente}\\
P\left\{\overline{X}-t_{\alpha/2}\frac{s}{\sqrt{n}}<\mu<\overline{X}+t_{\alpha/2}\frac{s}{\sqrt{n}}\right\}=1-\alpha.
\end{eqnarray*}

\item Un intervalo de confianza del $100\left(1-\alpha\right)\%$  de confianza para $\mu$, $\sigma^{2}$ desconocida y poblaci\'on normal es $\mu\in\left(\overline{x}-t_{\alpha/2}\frac{s}{\sqrt{n}},\overline{x}+t_{\alpha/2}\frac{s}{\sqrt{n}}\right)$, donde $t_{\alpha/2}$ es una $t$-student con $\nu=n-1$ grados de libertad.
\item Los l\'imites unilaterales para $\mu$ con $\sigma$ desconocida son $\overline{X}-t_{\alpha/2}\frac{s}{\sqrt{n}}$ y $\overline{X}+t_{\alpha/2}\frac{s}{\sqrt{n}}$.
\end{itemize}

%\end{frame}




%\begin{frame}



\begin{itemize}
\item Cuando la poblaci\'on no es normal, $\sigma$ desconocida y $n\geq30$, $\sigma$ se puede reemplazar por $s$ para obtener el intervalo de confianza para muestras grandes:
$$\overline{X}\pm t_{\alpha/2}\frac{s}{\sqrt{n}}.$$

\item El estimador de $\overline{X}$ de $\mu$,  $\sigma$ desconocida, la varianza de $\sigma_{\overline{X}}^{2}=\frac{\sigma^{2}}{n}$, el error est\'andar de $\overline{X}$ es $\sigma/\sqrt{n}$.

\item Si $\sigma$ es desconocida y la poblaci\'on es normal, $s\rightarrow\sigma$ y se incluye el error est\'andar $s/\sqrt{n}$, entonces $$\overline{x}\pm t_{\alpha/2}\frac{s}{\sqrt{n}}.$$
\end{itemize}


%\end{frame}

%---------------------------------------------------------
\subsection*{Intervalos de confianza sobre la varianza}
%---------------------------------------------------------

%\begin{frame}



Supongamos que  $X$ se distribuye normal $\left(\mu,\sigma^{2}\right)$, desconocidas. Sea $X_{1},X_{2},\ldots,X_{n}$ muestra aleatoria de tama\~no $n$ , $s^{2}$ la varianza muestral.

Se sabe que $X^{2}=\frac{\left(n-1\right)s^{2}}{\sigma^{2}}$ se distribuye $\chi^{2}_{n-1}$ grados de libertad. Su intervalo de confianza es
\begin{eqnarray}
\begin{array}{l}
P\left\{\chi^{2}_{1-\frac{\alpha}{2},n-1}\leq\chi^{2}\leq\chi^{2}_{\frac{\alpha}{2},n-1}\right\}=1-\alpha\\
P\left\{\chi^{2}_{1-\frac{\alpha}{2},n-1}\leq\frac{\left(n-1\right)s^{2}}{\sigma^{2}}\leq\chi^{2}_{\frac{\alpha}{2},n-1}\right\}=1-\alpha\\
P\left\{\frac{\left(n-1\right)s^{2}}{\chi^{2}_{\frac{\alpha}{2},n-1}}\leq\sigma^{2}\leq\frac{\left(n-1\right)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2},n-1}}\right\}=1-\alpha
\end{array}
\end{eqnarray}
es decir
%\end{frame}


%\begin{frame}




\begin{eqnarray}
\sigma^{2}\in\left[\frac{\left(n-1\right)s^{2}}{\chi^{2}_{\frac{\alpha}{2},n-1}},\frac{\left(n-1\right)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2},n-1}}\right]
\end{eqnarray}
los intervalos unilaterales son
\begin{eqnarray}
\sigma^{2}\in\left[\frac{\left(n-1\right)s^{2}}{\chi^{2}_{\frac{\alpha}{2},n-1}},\infty\right]-
\end{eqnarray}
\begin{eqnarray}
\sigma^{2}\in\left[-\infty,\frac{\left(n-1\right)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2},n-1}}\right]
\end{eqnarray}
%\end{frame}



%---------------------------------------------------------
\subsection*{Intervalos de confianza para proporciones}
%---------------------------------------------------------
%\begin{frame}



Supongamos que se tienen una muestra de tama\~no $n$ de una poblaci\'on grande pero finita, y supongamos que $X$, $X\leq n$, pertenecen a la clase de inter\'es, entonces $$\hat{p}=\frac{\overline{X}}{n}$$ es el estimador puntual de la proporci\'on de la poblaci\'on que pertenece a dicha clase.

$n$ y $p$ son los par\'ametros de la distribuci\'on binomial, entonces $\hat{p}\sim N\left(p,\frac{p\left(1-p\right)}{n}\right)$ aproximadamente si $p$ es distinto de $0$ y $1$; o si $n$ es suficientemente grande. Entonces
\begin{eqnarray*}
Z=\frac{\hat{p}-p}{\sqrt{\frac{p\left(1-p\right)}{n}}}\sim N\left(0,1\right),\textrm{aproximadamente.}
\end{eqnarray*}
 
 
entonces
\begin{eqnarray*}
1-\alpha&=&P\left\{-z_{\alpha/2}\leq\frac{\hat{p}-p}{\sqrt{\frac{p\left(1-p\right)}{n}}}\leq z_{\alpha/2}\right\}\\
&=&P\left\{\hat{p}-z_{\alpha/2}\sqrt{\frac{p\left(1-p\right)}{n}}\leq p\leq \hat{p}+z_{\alpha/2}\sqrt{\frac{p\left(1-p\right)}{n}}\right\}
\end{eqnarray*}
con $\sqrt{\frac{p\left(1-p\right)}{n}}$ error est\'andar del estimador puntual $p$. Una soluci\'on para determinar el intervalo de confianza del par\'ametro $p$ (desconocido) es
%\end{frame}


%\begin{frame}



\begin{eqnarray*}
1-\alpha=P\left\{\hat{p}-z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\leq p\leq \hat{p}+z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\right\}
\end{eqnarray*}
entonces los intervalos de confianza, tanto unilaterales como de dos colas son: 
\begin{itemize}
\item $p\in \left(\hat{p}-z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}},\hat{p}+z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\right)$

\item $p\in \left(-\infty,\hat{p}+z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}}\right)$

\item $p\in \left(\hat{p}-z_{\alpha/2}\sqrt{\frac{\hat{p}\left(1-\hat{p}\right)}{n}},\infty\right)$

\end{itemize}
para minimizar el error est\'andar, se propone que el tama\~no de la muestra sea $n= \left(\frac{z_{\alpha/2}}{E}\right)^{2}p\left(1-p\right)$, donde $E=\mid p-\hat{p}\mid$.
%\end{frame}


%---------------------------------------------------------
\section{Intervalos de confianza para dos muestras}
%---------------------------------------------------------
\subsection*{Varianzas conocidas}
%---------------------------------------------------------
%\begin{frame}



Sean $X_{1}$ y $X_{2}$ variables aleatorias independientes. $X_{1}$ con media desconocida $\mu_{1}$ y varianza conocida $\sigma_{1}^{2}$; y $X_{2}$ con media desconocida $\mu_{2}$ y varianza conocida $\sigma_{2}^{2}$. Se busca encontrar un intervalo de confianza de $100\left(1-\alpha\right)\%$ de la diferencia entre medias $\mu_{1}$ y $\mu_{2}$.\medskip

Sean $X_{11},X_{12},\ldots,X_{1n_{1}}$ muestra aleatoria de $n_{1}$ observaciones de $X_{1}$, y sean $X_{21},X_{22},\ldots,X_{2n_{2}}$ muestra aleatoria de $n_{2}$ observaciones de $X_{2}$.\medskip

Sean $\overline{X}_{1}$ y $\overline{X}_{2}$, medias muestrales, entonces el estad\'sitico 
\begin{eqnarray}
Z=\frac{\left(\overline{X}_{1}-\overline{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}\sim N\left(0,1\right),\end{eqnarray}
si $X_{1}$ y $X_{2}$ son normales o aproximadamente normales si se aplican las condiciones del Teorema de L\'imite Central respectivamente. 
%\end{frame}


%\begin{frame}



Entonces se tiene
\begin{eqnarray*}
1-\alpha&=& P\left\{-Z_{\alpha/2}\leq Z\leq Z_{\alpha/2}\right\}\\
&=&P\left\{-Z_{\alpha/2}\leq \frac{\left(\overline{X}_{1}-\overline{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}\leq Z_{\alpha/2}\right\}\\
&=&P\left\{\left(\overline{X}_{1}-\overline{X}_{2}\right)-Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\leq \mu_{1}-\mu_{2}\leq\right.\\
&&\left. \left(\overline{X}_{1}-\overline{X}_{2}\right)+Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right\}
\end{eqnarray*}

Entonces los intervalos de confianza unilaterales y de dos colas al $\left(1-\alpha\right)\%$ de confianza son 
%\end{frame}


%\begin{frame}



\begin{itemize}
\item $\mu_{1}-\mu_{2}\in \left[\left(\overline{X}_{1}-\overline{X}_{2}\right)-Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}},\left(\overline{X}_{1}-\overline{X}_{2}\right)+Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right]$

\item $\mu_{1}-\mu_{2}\in \left[-\infty,\left(\overline{X}_{1}-\overline{X}_{2}\right)+Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right]$

\item $\mu_{1}-\mu_{2}\in \left[\left(\overline{X}_{1}-\overline{X}_{2}\right)-Z_{\alpha/2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}},\infty\right]$

\end{itemize}
%\end{frame}


%\begin{frame}




\begin{Note}
Si $\sigma_{1}$ y $\sigma_{2}$ son conocidas, o por lo menos se conoce una aproximaci\'on, y los tama\~nos de las muestras $n_{1}$ y $n_{2}$ son iguales, $n_{1}=n_{2}=n$, se puede determinar el tama\~no de la muestra para que el error al estimar $\mu_{1}-\mu_{2}$ usando $\overline{X}_{1}-\overline{X}_{2}$ sea menor que $E$ (valor del error deseado) al $\left(1-\alpha\right)\%$ de confianza. El tama\~no $n$ de la muestra requerido para cada muestra es
\begin{eqnarray*}
n=\left(\frac{Z_{\alpha/2}}{E}\right)^{2}\left(\sigma_{1}^{2}+\sigma_{2}^{2}\right).
\end{eqnarray*}

\end{Note}
%\end{frame}




\subsection*{Varianzas desconocidas}


%\begin{frame}



\begin{itemize}
\item Si $n_{1},n_{2}\geq30$ se pueden utilizar los intervalos de la distribuci\'on normal para varianza conocida


\item Si $n_{1},n_{2}$ son muestras peque\~nas, supongase que las poblaciones para $X_{1}$ y $X_{2}$ son normales con varianzas desconocidas y con base en el intervalo de confianza para distribuciones $t$-student
\end{itemize}

%\end{frame}


\subsubsection*{$\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma$}

%\begin{frame}
Supongamos que $X_{1}$ es una variable aleatoria con media $\mu_{1}$ y varianza $\sigma_{1}^{2}$, $X_{2}$ es una variable aleatoria con media $\mu_{2}$ y varianza $\sigma_{2}^{2}$. Todos los par\'ametros son desconocidos. Sin embargo sup\'ongase que es razonable considerar que $\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2}$.\medskip

Nuevamente sean $X_{1}$ y $X_{2}$ variables aleatorias independientes. $X_{1}$ con media desconocida $\mu_{1}$ y varianza muestral $S_{1}^{2}$; y $X_{2}$ con media desconocida $\mu_{2}$ y varianza muestral $S_{2}^{2}$. Dado que $S_{1}^{2}$ y $S_{2}^{2}$ son estimadores de $\sigma_{1}^{2}$, se propone el estimador $S$ de $\sigma^{2}$ como 

\begin{eqnarray*}
S_{p}^{2}=\frac{\left(n_{1}-1\right)S_{1}^{2}+\left(n_{2}-1\right)S_{2}^{2}}{n_{1}+n_{2}-2},
\end{eqnarray*}
entonces, el estad\'istico para $\mu_{1}-\mu_{2}$ es

\begin{eqnarray*}
t_{\nu}=\frac{\left(\overline{X}_{1}-\overline{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}
\end{eqnarray*}
donde $t_{\nu}$ es una $t$ de student con $\nu=n_{1}+n_{2}-2$ grados de libertad.\medskip

Por lo tanto
%\end{frame}


%\begin{frame}



\begin{eqnarray*}
1-\alpha=P\left\{-t_{\alpha/2,\nu}\leq t\leq t_{\alpha/2,\nu}\right\}\\
=P\left\{\left(\overline{X}_{1}-\overline{X}_{2}\right)-t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\leq \right.\\
\left.t\leq\left(\overline{X}_{1}-\overline{X}_{2}\right)+ t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right\}
\end{eqnarray*}

luego, los intervalos de confianza del $\left(1-\alpha\right)\%$ para $\mu_{1}-|mu_{2}$ son 
\begin{itemize}
\item $\mu_{1}-\mu_{2}\in\left[\left(\overline{X}_{1}-\overline{X}_{2}\right)- t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}},\left(\overline{X}_{1}-\overline{X}_{2}\right)+ t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right]$


\item $\mu_{1}-\mu_{2}\in\left[-\infty,\left(\overline{X}_{1}-\overline{X}_{2}\right)+ t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right]$

\item $\mu_{1}-\mu_{2}\in\left[\left(\overline{X}_{1}-\overline{X}_{2}\right)- t_{\alpha/2,\nu}S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}},\infty\right]$


\end{itemize}

%\end{frame}



\subsubsection*{$\sigma_{1}^{2}\neq\sigma_{2}^{2}$}
%\begin{frame}




Si no se tiene certeza de que $\sigma_{1}^{2}=\sigma_{2}^{2}$, se propone el estad\'istico
\begin{eqnarray}
t^{*}=\frac{\left(\overline{X}_{1}-\overline{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}}}
\end{eqnarray}
que se distribuye $t$-student con $\nu$ grados de libertad, donde

\begin{eqnarray*}
\nu=\frac{\left(\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}\right)^{2}}{\frac{S_{1}^{2}/n_{1}}{n_{1}+1}+\frac{S_{2}^{2}/n_{2}}{n_{2}+1}}-2
\end{eqnarray*}


Entonces el intervalo de confianza de aproximadamente el $100\left(1-\alpha\right)\%$ para $\mu_{1}-\mu_{2}$ con $\sigma_{1}^{2}\neq\sigma_{2}^{2}$ es
\begin{eqnarray*}
\mu_{1}-\mu_{2}\in\left[\left(\overline{X}_{1}-\overline{X}_{2}\right)-t_{\alpha/2,\nu}\sqrt{\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}},\right.\\
\left.\left(\overline{X}_{1}-\overline{X}_{2}\right)+t_{\alpha/2,\nu}\sqrt{\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}}\right]
\end{eqnarray*}

%\end{frame}




\section{Intervalos de confianza para raz\'on de Varianzas}

%\begin{frame}



Supongamos que se toman dos muestras aleatorias independientes de las dos poblaciones de inter\'es.\medskip

Sean $X_{1}$ y $X_{2}$ variables normales independientes con medias desconocidas $\mu_{1}$ y $\mu_{2}$ y varianzas desconocidas $\sigma_{1}^{2}$ y $\sigma_{2}^{2}$ respectivamente. Se busca un intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\sigma_{1}^{2}/\sigma_{2}^{2}$.\medskip
Supongamos $n_{1}$ y $n_{2}$ muestras aleatorias de $X_{1}$ y $X_{2}$ y sean $S_{1}^{2}$ y $S_{2}^{2}$ varianzas muestralres. Se sabe que 
$$F=\frac{S_{2}^{2}/\sigma_{2}^{2}}{S_{1}^{2}/\sigma_{1}^{2}}$$
se distribuye $F$ con $n_{2}-1$ y $n_{1}-1$ grados de libertad.


Por lo tanto
\begin{eqnarray*}
P\left\{F_{1-\frac{\alpha}{2},n_{2}-1,n_{1}-1}\leq F\leq F_{\frac{\alpha}{2},n_{2}-1,n_{1}-1}\right\}=1-\alpha\\
P\left\{F_{1-\frac{\alpha}{2},n_{2}-1,n_{1}-1}\leq \frac{S_{2}^{2}/\sigma_{2}^{2}}{S_{1}^{2}/\sigma_{1}^{2}}\leq F_{\frac{\alpha}{2},n_{2}-1,n_{1}-1}\right\}=1-\alpha
\end{eqnarray*}
por lo tanto
\begin{eqnarray*}
P\left\{\frac{S_{1}^{2}}{S_{2}^{2}}F_{1-\frac{\alpha}{2},n_{2}-1,n_{1}-1}\leq \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\leq \frac{S_{1}^{2}}{S_{2}^{2}}F_{\frac{\alpha}{2},n_{2}-1,n_{1}-1}\right\}=1-\alpha\\
\end{eqnarray*}
entonces

%\end{frame}


%\begin{frame}



\begin{eqnarray*}
\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\in \left[\frac{S_{1}^{2}}{S_{2}^{2}}F_{1-\frac{\alpha}{2},n_{2}-1,n_{1}-1}, \frac{S_{1}^{2}}{S_{2}^{2}}F_{\frac{\alpha}{2},n_{2}-1,n_{1}-1}\right]
\end{eqnarray*}
donde
\begin{eqnarray*}
F_{1-\frac{\alpha}{2},n_{2}-1,n_{1}-1}=\frac{1}{F_{\frac{\alpha}{2},n_{2}-1,n_{1}-1}}
\end{eqnarray*}

%\end{frame}



\section{Intervalos de confianza para diferencia de proporciones}

%\begin{frame}



Sean dos proporciones de inter\'es $p_{1}$ y $p_{2}$. Se busca un intervalo para $p_{1}-p_{2}$ al $100\left(1-\alpha\right)\%$.\medskip

Sean dos muestras independientes de tama\~no $n_{1}$ y $n_{2}$ de poblaciones infinitas de modo que $X_{1}$ y $X_{2}$ variables aleatorias binomiales independientes con par\'ametros $\left(n_{1},p_{1}\right)$ y $\left(n_{2},p_{2}\right)$.\medskip

$X_{1}$ y $X_{2}$ son  el n\'umero de observaciones que pertenecen a la clase de inter\'es correspondientes. Entonces $\hat{p}_{1}=\frac{X_{1}}{n_{1}}$ y $\hat{p}_{2}=\frac{X_{2}}{n_{2}}$ son estimadores de $p_{1}$ y $p_{2}$ respectivamente. Supongamos que se cumple la aproximaci\'on  normal a la binomial, entonces




\begin{eqnarray*}
Z=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)-\left(p_{1}-p_{2}\right)}{\sqrt{\frac{p_{1}\left(1-p_{1}\right)}{n_{1}}-\frac{p_{2}\left(1-p_{2}\right)}{n_{2}}}}\sim N\left(0,1\right)\textrm{aproximadamente}
\end{eqnarray*}
entonces

\begin{eqnarray*}
\left(\hat{p}_{1}-\hat{p}_{2}\right)-Z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}_{1}\left(1-\hat{p}_{1}\right)}{n_{1}}+\frac{\hat{p}_{2}\left(1-\hat{p}_{2}\right)}{n_{2}}}\leq p_{1}-p_{2}\\
\leq\left(\hat{p}_{1}-\hat{p}_{2}\right)+Z_{\frac{\alpha}{2}}\sqrt{\frac{\hat{p}_{1}\left(1-\hat{p}_{1}\right)}{n_{1}}-\frac{\hat{p}_{2}\left(1-\hat{p}_{2}\right)}{n_{2}}}
\end{eqnarray*}
%\end{frame}


%\begin{frame}
\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}
%\end{frame}


%---------------------------------------------------------
\section{2. Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{2.1 Tipos de errores}

%\begin{frame}
Una prueba de hip\'otesis est\'a formada por cinco partes
\begin{itemize}
\item La hip\'otesis nula, denotada por $H_{0}$.
\item La hip\'otesis alterativa, denorada por $H_{1}$.
\item El estad\'sitico de prueba y su valor $p$.
\item La regi\'on de rechazo.
\item La conclusi\'on.

\end{itemize}

\begin{Def}
Las dos hip\'otesis en competencias son la \textbf{hip\'otesis alternativa $H_{1}$}, usualmente la que se desea apoyar, y la \textbf{hip\'otesis nula $H_{0}$}, opuesta a $H_{1}$.
\end{Def}
%\end{frame}



%\begin{frame}
En general, es m\'as f\'acil presentar evidencia de que $H_{1}$ es cierta, que demostrar 	que $H_{0}$ es falsa, es por eso que por lo regular se comienza suponiendo que $H_{0}$ es cierta, luego se utilizan los datos de la muestra para decidir si existe evidencia a favor de $H_{1}$, m\'as que a favor de $H_{0}$, as\'i se tienen dos conclusiones:
\begin{itemize}
\item Rechazar $H_{0}$ y concluir que $H_{1}$ es verdadera.
\item Aceptar, no rechazar, $H_{0}$ como verdadera.

\end{itemize}
%\end{frame}



%\begin{frame}
\begin{Ejem}
Se desea demostrar que el salario promedio  por hora en cierto lugar es distinto de $19$usd, que es el promedio nacional. Entonces $H_{1}:\mu\neq19$, y $H_{0}:\mu=19$.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de dos colas}.


\begin{Ejem}
Un determinado proceso produce un promedio de $5\%$ de piezas defectuosas. Se est\'a interesado en demostrar que un simple ajuste en una m\'aquina reducir\'a $p$, la proporci\'on de piezas defectuosas producidas en este proceso. Entonces se tiene $H_{0}:p<0.3$ y $H_{1}:p=0.03$. Si se puede rechazar $H_{0}$, se concluye que el proceso ajustado produce menos del $5\%$ de piezas defectuosas.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de una cola}.

La decisi\'on de rechazar o aceptar la hip\'otesis nula est\'a basada en la informaci\'on contenida en una muestra proveniente de la poblaci\'on de inter\'es. Esta informaci\'on tiene estas formas
%\end{frame}



%\begin{frame}
\begin{itemize}
\item \textbf{Estad\'sitico de prueba:} un s\'olo n\'umero calculado a partir de la muestra.

\item \textbf{$p$-value:} probabilidad calculada a partir del estad\'stico de prueba.

\end{itemize}

\begin{Def}
El $p$-value es la probabilidad de observar un estad\'istico de prueba tanto o m\'as alejado del valor obervado, si en realidad $H_{0}$ es verdadera.\medskip
Valores grandes del estad\'stica de prueba  y valores peque\~nos de $p$ significan que se ha observado un evento muy poco probable, si $H_{0}$ en realidad es verdadera.
\end{Def}
%\end{frame}



%\begin{frame}
Todo el conjunto de valores que puede tomar el estad\'istico de prueba se divide en dos regiones. Un conjunto, formado de valores que apoyan la hip\'otesis alternativa y llevan a rechazar $H_{0}$, se denomina \textbf{regi\'on de rechazo}. El otro, conformado por los valores que sustentatn la hip\'otesis nula, se le denomina \textbf{regi\'on de aceptaci\'on}.\medskip


Cuando la regi\'on de rechazo est\'a en la cola izquierda de la distribuci\'on, la  prueba se denomina \textbf{prueba lateral izquierda}. Una prueba con regi\'on de rechazo en la cola derecha se le llama \textbf{prueba lateral derecha}.\medskip

Si el estad\'stico de prueba cae en la regi\'on de rechazo, entonces se rechaza $H_{0}$. Si el estad\'stico de prueba cae en la regi\'on de aceptaci\'on, entonces la hip\'otesis nula se acepta o la prueba se juzga como no concluyente.\medskip
%\end{frame}



%\begin{frame}
Dependiendo del nivel de confianza que se desea agregar a las conclusiones de la prueba, y el \textbf{nivel de significancia $\alpha$}, el riesgo que est\'a dispuesto a correr si se toma una decisi\'on incorrecta.

\begin{Def}
Un \textbf{error de tipo I} para una prueba estad\'istica es el error que se tiene al rechazar la hip\'otesis nula cuando es verdadera. El \textbf{nivel de significancia} para una prueba estad\'istica de hip\'otesis es
\begin{eqnarray*}
\alpha&=&P\left\{\textrm{error tipo I}\right\}=P\left\{\textrm{rechazar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es verdadera}\right\}
\end{eqnarray*}

\end{Def}
%\end{frame}



%\begin{frame}
Este valor $\alpha$ representa el valor m\'aximo de riesgo tolerable de rechazar incorrectamente $H_{0}$. Una vez establecido el nivel de significancia, la regi\'on de rechazo se define para poder determinar si se rechaza $H_{0}$ con un cierto nivel de confianza.

%\end{frame}



\section{2.2 Muestras grandes: una media poblacional}
\subsection{2.2.1 C\'alculo de valor $p$}
%\begin{frame}

\begin{Def}
El \textbf{valor de $p$} (\textbf{$p$-value}) o nivel de significancia observado de un estad\'istico de prueba es el valor m\'as peque\~ no de $\alpha$ para el cual $H_{0}$ se puede rechazar. El riesgo de cometer un error tipo $I$, si $H_{0}$ es rechazada con base en la informaci\'on que proporciona la muestra.
\end{Def}

\begin{Note}
Valores peque\~ nos de $p$ indican 	que el valor observado del estad\'stico de prueba se encuentra alejado del valor hipot\'etico de $\mu$, es decir se tiene evidencia de que $H_{0}$ es falsa y por tanto debe de rechazarse.
\end{Note}
%\end{frame}


%\begin{frame}
\begin{Note}
Valores grandes de $p$ indican que el estad\'istico de prueba observado no est\'a alejado de la medi hipot\'etica y no apoya el rechazo de $H_{0}$.
\end{Note}

\begin{Def}
Si el valor de $p$ es menor o igual que el nivel de significancia $\alpha$, determinado previamente, entonces $H_{0}$ es rechazada y se puede concluir que los resultados son estad\'isticamente significativos con un nivel de confianza del $100\left(1-\alpha\right)\%$.
\end{Def}
Es usual utilizar la siguiente clasificaci\'on de resultados
%\end{frame}


%\begin{frame}
\begin{tabular}{|c||c|l|}\hline
$p$& $H_{0}$&Significativa\\\hline\hline
$p<0.01$&Rechazar &Altamente\\\hline
$0.01\leq p<0.05$ & Rechazar&Estad\'isticamente\\\hline
$0.05\leq p <0.1$ & No rechazar & Tendencia estad\'istica\\\hline
$0.01\leq p$ & No rechazar & No son estad\'isticamente\\\hline
\end{tabular}

\begin{Note}
Para determinar el valor de $p$, encontrar el \'area en la cola despu\'es del estad\'istico de prueba. Si la prueba es de una cola, este es el valor de $p$. Si es de dos colas, \'este valor encontrado es la mitad del valor de $p$. Rechazar $H_{0}$ cuando el valor de $p<\alpha$.
\end{Note}
%\end{frame}


%\begin{frame}
Hay dos tipos de errores al realizar una prueba de hip\'otesis
\begin{center}
\begin{tabular}{c|cc}
& $H_{0}$ es Verdadera & $H_{0}$ es Falsa\\\hline\hline
Rechazar $H_{0}$ & Error tipo I & $\surd$\\
Aceptar $H_{0}$ & $\surd$ & Error tipo II
\end{tabular}
\end{center}
\begin{Def}
La probabilidad de cometer el error tipo II se define por $\beta$ donde
\begin{eqnarray*}
\beta&=&P\left\{\textrm{error tipo II}\right\}=P\left\{\textrm{Aceptar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{Aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}
\end{eqnarray*}
\end{Def}
%\end{frame}


%\begin{frame}

\begin{Note}
Cuando $H_{0}$ es falsa y $H_{1}$ es verdadera, no siempre es posible especificar un valor exacto de $\mu$, sino m\'as bien un rango de posibles valores.\medskip
En lugar de arriesgarse a tomar una decisi\'on incorrecta, es mejor conlcuir que \textit{no hay evidencia suficiente para rechazar $H_{0}$}, es decir en lugar de aceptar $H_{0}$, \textit{no rechazar $H_{0}$}.

\end{Note}
La bondad de una prueba estad\'istica se mide por el tama\~ no de $\alpha$ y $\beta$, ambas deben de ser peque\~ nas. Una manera muy efectiva de medir la potencia de la prueba es calculando el complemento del error tipo $II$:
\begin{eqnarray*}
1-\beta&= &P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{1}\textrm{ es verdadera}\right\}
\end{eqnarray*}
\begin{Def}
La \textbf{potencia de la prueba}, $1-\beta$, mide la capacidad de que la prueba funciona como se necesita.
\end{Def}
%\end{frame}


%\begin{frame}

\begin{Ejem}
La producci\'on diariade una planta qu\'imica local ha promediado 880 toneladas en los \'ultimos a\~nos. A la gerente de control de calidad le gustar\'ia saber si este promedio ha cambiado en meses recientes. Ella selecciona al azar 50 d\'ias de la base de datos computarizada y calcula el promedio y la desviaci\'on est\'andar de las $n=50$  producciones como $\overline{x}=871$ toneladas y $s=21$ toneladas, respectivamente. Pruebe la hip\'otesis  apropiada usando $\alpha=0.05$.

\end{Ejem}

\begin{Sol}
La hip\'otesis nula apropiada es:
\begin{eqnarray*}
H_{0}&:& \mu=880\\
&&\textrm{ y la hip\'otesis alternativa }H_{1}\textrm{ es }\\
H_{1}&:& \mu\neq880
\end{eqnarray*}
el estimador puntual para $\mu$ es $\overline{x}$, entonces el estad\'istico de prueba es\medskip
\begin{eqnarray*}
z&=&\frac{\overline{x}-\mu_{0}}{s/\sqrt{n}}\\
&=&\frac{871-880}{21/\sqrt{50}}=-3.03
\end{eqnarray*}
\end{Sol}
%\end{frame}


%\begin{frame}
\begin{Sol}
Para esta prueba de  dos colas, hay que determinar los dos valores de $z_{\alpha/2}$, es decir,  $z_{\alpha/2}=\pm1.96$, como $z>z_{\alpha/2}$, $z$ cae en la zona de rechazo, por lo tanto  la gerente puede rechazar la hip\'otesis nula y concluir que el promedio efectivamente ha cambiado.\medskip
La probabilidad de rechazar $H_{0}$ cuando esta es verdadera es de  $0.05$.


Recordemos que el valor observado del estad\'istico de prueba es $z=-3.03$, la regi\'on de rechazo m\'as peque\~na que puede usarse y todav\'ia seguir rechazando $H_{0}$ es $|z|>3.03$, \\
entonces $p=2(0.012)=0.0024$, que a su vez es menor que el nivel de significancia $\alpha$ asignado inicialmente, y adem\'as los resultados son  \textbf{altamente significativos}.


\end{Sol}
%\end{frame}


%\begin{frame}

Finalmente determinemos la potencia de la prueba cuando $\mu$ en realidad es igual a $870$ toneladas.

Recordar que la regi\'on de aceptaci\'on est\'a entre $-1.96$ y $1.96$, para $\mu=880$, equivalentemente $$874.18<\overline{x}<885.82$$
$\beta$ es la probabilidad de aceptar $H_{0}$ cuando $\mu=870$, calculemos los valores de $z$ correspondientes a $874.18$ y $885.82$ \medskip
Entonces
\begin{eqnarray*}
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{874.18-870}{21/\sqrt{50}}=1.41\\
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{885.82-870}{21/\sqrt{50}}=5.33
\end{eqnarray*}
por lo tanto
\begin{eqnarray*}
\beta&=&P\left\{\textrm{aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{874.18<\mu<885.82\textrm{ cuando }\mu=870\right\}\\
&=&P\left\{1.41<z<5.33\right\}=P\left\{1.41<z\right\}\\
&=&1-0.9207=0.0793
\end{eqnarray*}
entonces, la potencia de la prueba es
$$1-\beta=1-0.0793=0.9207$$ que es la probabilidad de rechazar correctamente $H_{0}$ cuando $H_{0}$ es falsa.
%\end{frame}


%\begin{frame}
Determinar la potencia de la prueba para distintos valores de $H_{1}$ y graficarlos, \textit{curva de potencia}
\begin{center}
\begin{tabular}{c||c}
$H_{1}$ & $\left(1-\beta\right)$ \\\hline 
\hline 
865 &  \\ \hline 
870 &  \\ \hline 
872 &  \\ \hline 
875 &  \\ \hline 
877 &  \\ \hline 
880 &  \\ \hline 
883 &  \\ \hline 
885 &  \\ \hline 
888 &  \\ \hline 
890 &  \\ \hline 
895 &  \\ \hline 
\end{tabular} 

\end{center}
%\end{frame}


%\begin{frame}
\begin{enumerate}
\item Encontrar las regiones de rechazo para el estad\'istico $z$, para una prueba de
\begin{itemize}
\item[a) ]  dos colas para $\alpha=0.01,0.05,0.1$
\item[b) ]  una cola superior para $\alpha=0.01,0.05,0.1$
\item[c) ] una cola inferior para $\alpha=0.01,0.05,0.1$

\end{itemize}


\item Suponga que el valor del estad\'istico de prueba es 
\begin{itemize}
\item[a) ]$z=-2.41$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[b) ] $z=2.16$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[c) ] $z=1.15$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[d) ] $z=-2.78$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[e) ] $z=-1.81$, sacar las conclusiones correspondientes para los incisos anteriores.

\end{itemize}
\end{enumerate}
%\end{frame}



%\begin{frame}
\begin{itemize}
\item[3. ] Encuentre el valor de $p$ para las pruebas de hip\'otesis correspondientes a los valores de $z$ del ejercicio anterior.

\item[4. ] Para las pruebas dadas en el ejercicio 2, utilice el valor de $p$, determinado en el ejercicio 3,  para determinar la significancia de los resultados.


\end{itemize}


\begin{itemize}
\item[5. ] Una muestra aleatoria de $n=45$ observaciones de una poblaci\'on con media $\overline{x}=2.4$, y desviaci\'on est\'andar $s=0.29$. Suponga que el objetivo es demostrar que la media poblacional $\mu$ excede $2.3$.
\begin{itemize}
\item[a) ] Defina la hip\'otesis nula y alternativa para la prueba.
\item[b) ] Determine la regi\'on de rechazo para un nivel de significancia de: $\alpha=0.1,0.05,0.01$.
\item[c) ] Determine el error est\'andar de la media muestral.
\item[d) ] Calcule el valor de $p$ para los estad\'isticos de prueba definidos en los incisos anteriores.
\item[e) ] Utilice el valor de $p$ pra sacar una conclusi\'on al nivel de significancia $\alpha$.
\item[f) ] Determine el valor de $\beta$ cuando $\mu=2.5$
\item[g) ] Graficar la curva de potencia para la prueba.

\end{itemize}
\end{itemize}
%\end{frame}

\subsection{2.2.2 Prueba de hip\'otesis para la diferencia entre dos medias poblacionales}

%\begin{frame}

El estad\'istico que resume la informaci\'on muestral respecto a la diferencia en medias poblacionales $\left(\mu_{1}-\mu_{2}\right)$ es la diferencia de las medias muestrales $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, por tanto al probar la difencia entre las medias muestrales se verifica que la diferencia real entre las medias poblacionales difiere de un valor especificado, $\left(\mu_{1}-\mu_{2}\right)=D_{0}$, se puede usar el error est\'andar de $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, es decir
$$\sqrt{\frac{\sigma^{2}_{1}}{n_{1}}+\frac{\sigma^{2}_{2}}{n_{2}}}$$
cuyo estimador est\'a dado por
$$SE=\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}$$
El procedimiento para muestras grandes es:
%\end{frame}

%\begin{frame}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}

%\end{frame}

%\begin{frame}
\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$z=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}

%\end{frame}

%\begin{frame}

\begin{Ejem}
Para determinar si ser propietario de un autom\'ovil afecta el rendimiento acad\'emico de un estudiante, se tomaron dos muestras aleatorias de 100 estudiantes varones. El promedio de calificaciones para los $n_{1}=100$ no propietarios de un auto tuvieron un promedio y varianza de $\overline{x}_{1}=2.7$ y $s_{1}^{2}=0.36$, respectivamente, mientras que para para la segunda muestra con $n_{2}=100$ propietarios de un auto, se tiene $\overline{x}_{2}=2.54$ y $s_{2}^{2}=0.4$. Los datos presentan suficiente evidencia para indicar una diferencia en la media en el rendimiento acad\'emico entre propietarios y no propietarios de un autom\'ovil? Hacer pruebas para $\alpha=0.01,0.05$ y $\alpha=0.1$.
\end{Ejem}

\begin{Sol}
\begin{itemize}
\item Soluci\'on utilizando la t\'ecnica de regiones de rechazo:\medskip
realizando las operaciones
$z=1.84$, determinar si excede los valores de $z_{\alpha/2}$.
\item Soluci\'on utilizando el $p$-value:\medskip
Calcular el valor de $p$, la probabilidad de que $z$ sea mayor que $z=1.84$ o menor que $z=-1.84$, se tiene que $p=0.0658$. Concluir.
\end{itemize}
\end{Sol}
%\end{frame}

%\begin{frame}
\begin{itemize}
\item Si el intervalo de confianza que se construye contiene el valor del par\'ametro especificado por $H_{0}$, entonces ese valor es uno de los posibles valores del par\'ametro y $H_{0}$ no debe ser rechazada.

\item Si el valor hipot\'etico se encuentra fuera de los l\'imites de confianza, la hip\'otesis nula es rechazada al nivel de significancia $\alpha$.
\end{itemize}

\begin{enumerate}
\item Del libro Mendenhall resolver los ejercicios 9.18, 9.19 y 9.20(\href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall}).

\item Del libro \href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall} resolver los ejercicios: 9.23, 9.26 y 9.28.
\end{enumerate}

%\end{frame}

\subsection{2.2.3 Prueba de Hip\'otesis para una Proporci\'on Binomial}

%\begin{frame}
Para una muestra aleatoria de $n$ intentos id\'enticos, de una poblaci\'on binomial, la proporci\'on muesrtal $\hat{p}$ tiene una distribuci\'on aproximadamente normal cuando $n$ es grande, con media $p$ y error est\'andar
$$SE=\sqrt{\frac{pq}{n}}.$$
La prueba de hip\'otesis de la forma
\begin{eqnarray*}
H_{0}&:&p=p_{0}\\
H_{1}&:&p>p_{0}\textrm{, o }p<p_{0}\textrm{ o }p\neq p_{0}
\end{eqnarray*}
El estad\'istico de prueba se construye con el mejor estimador de la proporci\'on verdadera, $\hat{p}$, con el estad\'istico de prueba $z$, que se distribuye normal est\'andar.
%\end{frame}

%\begin{frame}
El procedimiento es
\begin{itemize}
\item[1) ] Hip\'otesis nula: $H_{0}:p=p_{0}$
\item[2) ] Hip\'otesis alternativa
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:p>p_{0}$ & $p\neq p_{0}$\\
$H_{1}:p<p_{0}$ & \\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\hat{p}-p_{0}}{\sqrt{\frac{pq}{n}}},\hat{p}=\frac{x}{n}
\end{eqnarray*}
donde $x$ es el n\'umero de \'exitos en $n$ intentos binomiales.

\end{itemize}
%\end{frame}

%\begin{frame}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}
%\end{frame}

%\begin{frame}
\begin{Ejem}
A cualquier edad, alrededor del $20\%$ de los adultos de cierto pa\'is realiza actividades de acondicionamiento f\'isico al menos dos veces por semana. En una encuesta local de $n=100$ adultos de m\'as de $40$ a\ ~nos, un total de 15 personas indicaron que realizaron actividad f\'isica al menos dos veces por semana. Estos datos indican que el porcentaje de participaci\'on para adultos de m\'as de 40 a\ ~nos de edad es  considerablemente menor a la cifra del $20\%$? Calcule el valor de $p$ y \'uselo para sacar las conclusiones apropiadas.
\end{Ejem}

\begin{enumerate}
\item Resolver los ejercicios: 9.30, 9.32, 9.33, 9.35 y 9.39.
\end{enumerate}
%\end{frame}


\subsection{2.2.4 Prueba de Hip\'otesis diferencia entre dos Proporciones Binomiales}


%\begin{frame}

\begin{Note}
Cuando se tienen dos muestras aleatorias independientes de dos poblaciones binomiales, el objetivo del experimento puede ser la diferencia $\left(p_{1}-p_{2}\right)$ en las proporciones de individuos u objetos que poseen una caracter\'istica especifica en las dos poblaciones. En este caso se pueden utilizar los estimadores de las dos proporciones $\left(\hat{p}_{1}-\hat{p}_{2}\right)$ con error est\'andar dado por
$$SE=\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}$$
considerando el estad\'istico $z$ con un nivel de significancia $\left(1-\alpha\right)100\%$

\end{Note}


\begin{Note}
La hip\'otesis nula a probarse es de la forma
\begin{itemize}
\item[$H_{0}$: ] $p_{1}=p_{2}$ o equivalentemente $\left(p_{1}-p_{2}\right)=0$, contra una hip\'otesis alternativa $H_{1}$ de una o dos colas.
\end{itemize}
\end{Note}
%\end{frame}


%\begin{frame}

\begin{Note}
Para estimar el error est\'andar del estad\'istico $z$, se debe de utilizar el hecho de que suponiendo que $H_{0}$ es verdadera, las dos proporciones son iguales a alg\'un valor com\'un, $p$. Para obtener el mejor estimador de $p$ es
$$p=\frac{\textrm{n\'umero total de \'exitos}}{\textrm{N\'umero total de pruebas}}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$$
\end{Note}



\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\left(p_{1}-p_{2}\right)=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(p_{1}-p_{2}\right)>0$ & $H_{1}:\left(p_{1}-p_{2}\right)\neq 0$\\ 
$H_{1}:\left(p_{1}-p_{2}\right)<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}}=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{pq}{n_{1}}+\frac{pq}{n_{2}}}}
\end{eqnarray*}
donde $\hat{p_{1}}=x_{1}/n_{1}$ y $\hat{p_{2}}=x_{2}/n_{2}$ , dado que el valor com\'un para $p_{1}$ y $p_{2}$ es $p$, entonces $\hat{p}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$ y por tanto el estad\'istico de prueba es
\end{itemize}
%\end{frame}


%\begin{frame}


\begin{eqnarray*}
z=\frac{\hat{p}_{1}-\hat{p}_{2}}{\sqrt{\hat{p}\hat{q}}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}
\end{eqnarray*}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{\alpha}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

\end{itemize}
%\end{frame}


%\begin{frame}

\begin{Ejem}
Los registros de un hospital, indican que 52 hombres de una muestra de 1000 contra 23 mujeres de una muestra de 1000 fueron ingresados por enfermedad del coraz\'on. Estos datos presentan suficiente evidencia para indicar un porcentaje m\'as alto de enfermedades del coraz\'on entre hombres ingresados al hospital?, utilizar distintos niveles de confianza de $\alpha$.

\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios 9.42

\item Resolver los ejercicios: 9.45, 9.48, 9.50
\end{enumerate}

%\end{frame}



\section{2.3 Muestras Peque\~nas}

\subsection{2.3.1 Una media poblacional}


%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu=\mu_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu>\mu_{0}$ & $H_{1}:\mu\neq \mu_{0}$\\ 
$H_{1}:\mu<\mu0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{x}-\mu_{0}}{\sqrt{\frac{s^{2}}{n}}}
\end{eqnarray*}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}
%\end{frame}


%\begin{frame}

\begin{Ejem}
Las etiquetas en latas de un gal'on de pintura por lo general indican el tiempo de secado y el \'area puede cubrir una capa. Casi todas las marcas de pintura indican que, en una capa, un gal\'on cubrir\'a entre 250 y 500 pies cuadrados, dependiento de la textura de la superficie a pintarse, un fabricante, sin embargo afirma que un gal\'on de su pintura cubrir\'a 400 pies cuadrados de \'area superficial. Para probar su afirmaci\'on, una muestra aleatoria de 10 latas de un gal\'on de pintura blanca se emple\'o para pintar 10 \'areas id\'enticas usando la misma clase de equipo. Las \'areas reales en pies cuadrados cubiertas por estos 10 galones de pintura se dan a continuac\'on:
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline 
310 & 311 & 412 & 368 & 447 \\ 
\hline 
376 & 303 &410 &365 & 350 \\ 
\hline 
\end{tabular} 
\end{center}
\end{Ejem}
%\end{frame}


%\begin{frame}

\begin{Ejem}
Los datos presentan suficiente evidencia para indicar que el promedio de la cobertura difiere de 400 pies cuadrados? encuentre el valor de $p$ para la prueba y \'uselo para evaluar la significancia de los resultados.
\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios: 10.2, 10.3,10.5, 10.7, 10.9, 10.13 y 10.16
\end{enumerate}

%\end{frame}


\subsection{2.3.2 Diferencia entre dos medias poblacionales: M.A.I.}


%\begin{frame}

\begin{Note}
Cuando los tama\ ~nos de muestra son peque\ ~nos, no se puede asegurar que las medias muestrales sean normales, pero si las poblaciones originales son normales, entonces la distribuci\'on muestral de la diferencia de las medias muestales, $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, ser\'a normal con media $\left(\mu_{1}-\mu_{2}\right)$ y error est\'andar $$ES=\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}$$

\end{Note}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\item[3) ] Estad\'istico de prueba:
$$t=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\end{itemize}
%\end{frame}


%\begin{frame}


donde $$s^{2}=\frac{\left(n_{1}-1\right)s_{1}^{2}+\left(n_{2}-1\right)s_{2}^{2}}{n_{1}+n_{2}-2}$$
\begin{itemize}

\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.


\end{itemize}

%\end{frame}


\subsection{2.3.3 Diferencia entre dos medias poblacionales: Diferencias Pareadas}



%\begin{frame}


\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu_{d}=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:\mu_{d}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu_{d}>0$ & $H_{1}:\mu_{d}\neq 0$\\ 
$H_{1}:\mu_{d}<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{d}}{\sqrt{\frac{s_{d}^{2}}{n}}}
\end{eqnarray*}
donde $n$ es el n\'umero de diferencias pareadas, $\overline{d}$ es la media de las diferencias muestrales, y $s_{d}$ es la desviaci\'on est\'andar de las diferencias muestrales.

\end{itemize}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.

\end{itemize}


%\end{frame}



\subsection{2.3.4 Inferencias con respecto a la Varianza Poblacional}


%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\sigma^{2}=\sigma^{2}_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\sigma^{2}>\sigma^{2}_{0}$ & $H_{1}:\sigma^{2}\neq \sigma^{2}_{0}$\\ 
$H_{1}:\sigma^{2}<\sigma^{2}_{0}$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
\chi^{2}=\frac{\left(n-1\right)s^{2}}{\sigma^{2}_{0}}
\end{eqnarray*}

\end{itemize}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$\chi^{2}>\chi^{2}_{\alpha}$ & \\
$\chi^{2}<\chi^{2}_{\left(1-\alpha\right)}$ cuando $H_{1}:\chi^{2}<\chi^{2}_{0}$&$\chi^{2}>\chi^{2}_{\alpha/2}$ o $\chi^{2}<\chi^{2}_{\left(1-\alpha/2\right)}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $\chi^{2}$,est\'an basados en $\left(n_{1}+\right)$ grados de libertad.

\end{itemize}


%\end{frame}


\subsection{2.3.5 Comparaci\'on de dos varianzas poblacionales}



%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)>D_{0}$ & $H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}

%\end{frame}


%\begin{frame}


\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$F=\frac{s_{1}^{2}}{s_{2}^{2}}$$
donde $s_{1}^{2}$ es la varianza muestral m\'as grande.
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$F>F_{\alpha}$ & $F>F_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}

%\end{frame}


%---------------------------------------------------------
\section{2. Pruebas de Hip\'otesis}
%---------------------------------------------------------
\subsection{2.1 Tipos de errores}


%\begin{frame}


\begin{itemize}
\item Una hip\'otesis estad\'istica es una afirmaci\'on  acerca de la distribuci\'on de probabilidad de una variable aleatoria, a menudo involucran uno o m\'as par\'ametros de la distribuci\'on.

\item Las hip\'otesis son afirmaciones respecto a la poblaci\'on o distribuci\'on bajo estudio, no en torno a la muestra.

\item La mayor\'ia de las veces, la prueba de hip\'otesis consiste en determinar si la situaci \'on experimental ha cambiado

\item el inter\'es principal es decidir sobre la veracidad o falsedad de una hip\'otesis, a este procedimiento se le llama \textit{prueba de hip\'otesis}.

\item Si la informaci\'on es consistente con la hip\'otesis, se concluye que esta es verdadera, de lo contrario que con base en la informaci\'on, es falsa.

\end{itemize}


%\end{frame}


%\begin{frame}

Una prueba de hip\'otesis est\'a formada por cinco partes
\begin{itemize}
\item La hip\'otesis nula, denotada por $H_{0}$.
\item La hip\'otesis alterativa, denorada por $H_{1}$.
\item El estad\'sitico de prueba y su valor $p$.
\item La regi\'on de rechazo.
\item La conclusi\'on.

\end{itemize}


\begin{Def}
Las dos hip\'otesis en competencias son la \textbf{hip\'otesis alternativa $H_{1}$}, usualmente la que se desea apoyar, y la \textbf{hip\'otesis nula $H_{0}$}, opuesta a $H_{1}$.
\end{Def}


%\end{frame}


%\begin{frame}

En general, es m\'as f\'acil presentar evidencia de que $H_{1}$ es cierta, que demostrar 	que $H_{0}$ es falsa, es por eso que por lo regular se comienza suponiendo que $H_{0}$ es cierta, luego se utilizan los datos de la muestra para decidir si existe evidencia a favor de $H_{1}$, m\'as que a favor de $H_{0}$, as\'i se tienen dos conclusiones:
\begin{itemize}
\item Rechazar $H_{0}$ y concluir que $H_{1}$ es verdadera.
\item Aceptar, no rechazar, $H_{0}$ como verdadera.

\end{itemize}


%\end{frame}


%\begin{frame}

\begin{Ejem}
Se desea demostrar que el salario promedio  por hora en cierto lugar es distinto de $19$usd, que es el promedio nacional. Entonces $H_{1}:\mu\neq19$, y $H_{0}:\mu=19$.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de dos colas}.


\begin{Ejem}
Un determinado proceso produce un promedio de $5\%$ de piezas defectuosas. Se est\'a interesado en demostrar que un simple ajuste en una m\'aquina reducir\'a $p$, la proporci\'on de piezas defectuosas producidas en este proceso. Entonces se tiene $H_{0}:p<0.3$ y $H_{1}:p=0.03$. Si se puede rechazar $H_{0}$, se concluye que el proceso ajustado produce menos del $5\%$ de piezas defectuosas.
\end{Ejem}
A esta se le denomina \textbf{Prueba de hip\'otesis de una cola}.

%\end{frame}


%\begin{frame}

La decisi\'on de rechazar o aceptar la hip\'otesis nula est\'a basada en la informaci\'on contenida en una muestra proveniente de la poblaci\'on de inter\'es. Esta informaci\'on tiene estas formas

\begin{itemize}
\item \textbf{Estad\'sitico de prueba:} un s\'olo n\'umero calculado a partir de la muestra.

\item \textbf{$p$-value:} probabilidad calculada a partir del estad\'stico de prueba.

\end{itemize}

%\end{frame}


%\begin{frame}

\begin{Def}
El $p$-value es la probabilidad de observar un estad\'istico de prueba tanto o m\'as alejado del valor obervado, si en realidad $H_{0}$ es verdadera.\medskip
Valores grandes del estad\'stica de prueba  y valores peque\~nos de $p$ significan que se ha observado un evento muy poco probable, si $H_{0}$ en realidad es verdadera.
\end{Def}

Todo el conjunto de valores que puede tomar el estad\'istico de prueba se divide en dos regiones. Un conjunto, formado de valores que apoyan la hip\'otesis alternativa y llevan a rechazar $H_{0}$, se denomina \textbf{regi\'on de rechazo}. El otro, conformado por los valores que sustentatn la hip\'otesis nula, se le denomina \textbf{regi\'on de aceptaci\'on}.\medskip


%\end{frame}


%\begin{frame}

Cuando la regi\'on de rechazo est\'a en la cola izquierda de la distribuci\'on, la  prueba se denomina \textbf{prueba lateral izquierda}. Una prueba con regi\'on de rechazo en la cola derecha se le llama \textbf{prueba lateral derecha}.\medskip

Si el estad\'stico de prueba cae en la regi\'on de rechazo, entonces se rechaza $H_{0}$. Si el estad\'stico de prueba cae en la regi\'on de aceptaci\'on, entonces la hip\'otesis nula se acepta o la prueba se juzga como no concluyente.\medskip

Dependiendo del nivel de confianza que se desea agregar a las conclusiones de la prueba, y el \textbf{nivel de significancia $\alpha$}, el riesgo que est\'a dispuesto a correr si se toma una decisi\'on incorrecta.

%\end{frame}


%\begin{frame}

\begin{Def}
Un \textbf{error de tipo I} para una prueba estad\'istica es el error que se tiene al rechazar la hip\'otesis nula cuando es verdadera. El \textbf{nivel de significancia} para una prueba estad\'istica de hip\'otesis es
\begin{eqnarray*}
\alpha&=&P\left\{\textrm{error tipo I}\right\}=P\left\{\textrm{rechazar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es verdadera}\right\}
\end{eqnarray*}

\end{Def}
Este valor $\alpha$ representa el valor m\'aximo de riesgo tolerable de rechazar incorrectamente $H_{0}$. Una vez establecido el nivel de significancia, la regi\'on de rechazo se define para poder determinar si se rechaza $H_{0}$ con un cierto nivel de confianza.


%\end{frame}

\section{2.2 Muestras grandes: una media poblacional}
\subsection{2.2.1 C\'alculo de valor $p$}



%\begin{frame}

\begin{Def}
El \textbf{valor de $p$} (\textbf{$p$-value}) o nivel de significancia observado de un estad\'istico de prueba es el valor m\'as peque\~ no de $\alpha$ para el cual $H_{0}$ se puede rechazar. El riesgo de cometer un error tipo $I$, si $H_{0}$ es rechazada con base en la informaci\'on que proporciona la muestra.
\end{Def}

\begin{Note}
Valores peque\~ nos de $p$ indican 	que el valor observado del estad\'stico de prueba se encuentra alejado del valor hipot\'etico de $\mu$, es decir se tiene evidencia de que $H_{0}$ es falsa y por tanto debe de rechazarse.
\end{Note}


%\end{frame}


%\begin{frame}



\begin{Note}
Valores grandes de $p$ indican que el estad\'istico de prueba observado no est\'a alejado de la medi hipot\'etica y no apoya el rechazo de $H_{0}$.
\end{Note}

\begin{Def}
Si el valor de $p$ es menor o igual que el nivel de significancia $\alpha$, determinado previamente, entonces $H_{0}$ es rechazada y se puede concluir que los resultados son estad\'isticamente significativos con un nivel de confianza del $100\left(1-\alpha\right)\%$.
\end{Def}
Es usual utilizar la siguiente clasificaci\'on de resultados



%\end{frame}


%\begin{frame}


\begin{tabular}{|c||c|l|}\hline
$p$& $H_{0}$&Significativa\\\hline\hline
$p<0.01$&Rechazar &Altamente\\\hline
$0.01\leq p<0.05$ & Rechazar&Estad\'isticamente\\\hline
$0.05\leq p <0.1$ & No rechazar & Tendencia estad\'istica\\\hline
$0.01\leq p$ & No rechazar & No son estad\'isticamente\\\hline
\end{tabular}

\begin{Note}
Para determinar el valor de $p$, encontrar el \'area en la cola despu\'es del estad\'istico de prueba. Si la prueba es de una cola, este es el valor de $p$. Si es de dos colas, \'este valor encontrado es la mitad del valor de $p$. Rechazar $H_{0}$ cuando el valor de $p<\alpha$.
\end{Note}


%\end{frame}


%\begin{frame}


Hay dos tipos de errores al realizar una prueba de hip\'otesis
\begin{center}
\begin{tabular}{c|cc}
& $H_{0}$ es Verdadera & $H_{0}$ es Falsa\\\hline\hline
Rechazar $H_{0}$ & Error tipo I & $\surd$\\
Aceptar $H_{0}$ & $\surd$ & Error tipo II
\end{tabular}
\end{center}
\begin{Def}
La probabilidad de cometer el error tipo II se define por $\beta$ donde
\begin{eqnarray*}
\beta&=&P\left\{\textrm{error tipo II}\right\}=P\left\{\textrm{Aceptar equivocadamente }H_{0}\right\}\\
&=&P\left\{\textrm{Aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}
\end{eqnarray*}
\end{Def}

%\end{frame}


%\begin{frame}


\begin{Note}
Cuando $H_{0}$ es falsa y $H_{1}$ es verdadera, no siempre es posible especificar un valor exacto de $\mu$, sino m\'as bien un rango de posibles valores.\medskip
En lugar de arriesgarse a tomar una decisi\'on incorrecta, es mejor conlcuir que \textit{no hay evidencia suficiente para rechazar $H_{0}$}, es decir en lugar de aceptar $H_{0}$, \textit{no rechazar $H_{0}$}.

\end{Note}

%\end{frame}


%\begin{frame}

La bondad de una prueba estad\'istica se mide por el tama\~ no de $\alpha$ y $\beta$, ambas deben de ser peque\~ nas. Una manera muy efectiva de medir la potencia de la prueba es calculando el complemento del error tipo $II$:
\begin{eqnarray*}
1-\beta&= &P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{\textrm{Rechazar }H_{0}\textrm{ cuando }H_{1}\textrm{ es verdadera}\right\}
\end{eqnarray*}
\begin{Def}
La \textbf{potencia de la prueba}, $1-\beta$, mide la capacidad de que la prueba funciona como se necesita.
\end{Def}

%\end{frame}


%\begin{frame}


\begin{Ejem}
La producci\'on diariade una planta qu\'imica local ha promediado 880 toneladas en los \'ultimos a\~nos. A la gerente de control de calidad le gustar\'ia saber si este promedio ha cambiado en meses recientes. Ella selecciona al azar 50 d\'ias de la base de datos computarizada y calcula el promedio y la desviaci\'on est\'andar de las $n=50$  producciones como $\overline{x}=871$ toneladas y $s=21$ toneladas, respectivamente. Pruebe la hip\'otesis  apropiada usando $\alpha=0.05$.

\end{Ejem}

\begin{Sol}
La hip\'otesis nula apropiada es:
\begin{eqnarray*}
H_{0}&:& \mu=880\\
&&\textrm{ y la hip\'otesis alternativa }H_{1}\textrm{ es }\\
H_{1}&:& \mu\neq880
\end{eqnarray*}
el estimador puntual para $\mu$ es $\overline{x}$, entonces el estad\'istico de prueba es\medskip
\begin{eqnarray*}
z&=&\frac{\overline{x}-\mu_{0}}{s/\sqrt{n}}\\
&=&\frac{871-880}{21/\sqrt{50}}=-3.03
\end{eqnarray*}
\end{Sol}


%\end{frame}


%\begin{frame}

\begin{Sol}
Para esta prueba de  dos colas, hay que determinar los dos valores de $z_{\alpha/2}$, es decir,  $z_{\alpha/2}=\pm1.96$, como $z>z_{\alpha/2}$, $z$  cae en la zona de rechazo, por lo tanto  la gerente puede rechazar la hip\'otesis nula y concluir que el promedio efectivamente ha cambiado.\medskip
La probabilidad de rechazar $H_{0}$ cuando esta es verdadera es de $0.05$.


Recordemos que el valor observado del estad\'istico de prueba es $z=-3.03$, la regi\'on de rechazo m\'as peque\~na que puede usarse y todav\'ia seguir rechazando $H_{0}$ es $|z|>3.03$, \\
entonces $p=2(0.012)=0.0024$, que a su vez es menor que el nivel de significancia $\alpha$ asignado inicialmente, y adem\'as los resultados son  \textbf{altamente significativos}.


\end{Sol}

%\end{frame}


%\begin{frame}

Finalmente determinemos la potencia de la prueba cuando $\mu$ en realidad es igual a $870$ toneladas.

Recordar que la regi\'on de aceptaci\'on est\'a entre $-1.96$ y $1.96$, para $\mu=880$, equivalentemente $$874.18<\overline{x}<885.82$$
$\beta$ es la probabilidad de aceptar $H_{0}$ cuando $\mu=870$, calculemos los valores de $z$ correspondientes a $874.18$ y $885.82$ \medskip
Entonces
\begin{eqnarray*}
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{874.18-870}{21/\sqrt{50}}=1.41\\
z_{1}&=&\frac{\overline{x}-\mu}{s/\sqrt{n}}=\frac{885.82-870}{21/\sqrt{50}}=5.33
\end{eqnarray*}


por lo tanto
\begin{eqnarray*}
\beta&=&P\left\{\textrm{aceptar }H_{0}\textrm{ cuando }H_{0}\textrm{ es falsa}\right\}\\
&=&P\left\{874.18<\mu<885.82\textrm{ cuando }\mu=870\right\}\\
&=&P\left\{1.41<z<5.33\right\}=P\left\{1.41<z\right\}\\
&=&1-0.9207=0.0793
\end{eqnarray*}
entonces, la potencia de la prueba es
$$1-\beta=1-0.0793=0.9207$$ que es la probabilidad de rechazar correctamente $H_{0}$ cuando $H_{0}$ es falsa.

%\end{frame}


%\begin{frame}

Determinar la potencia de la prueba para distintos valores de $H_{1}$ y graficarlos, \textit{curva de potencia}
\begin{center}
\begin{tabular}{c||c}
$H_{1}$ & $\left(1-\beta\right)$ \\\hline 
\hline 
865 &  \\ \hline 
870 &  \\ \hline 
872 &  \\ \hline 
875 &  \\ \hline 
877 &  \\ \hline 
880 &  \\ \hline 
883 &  \\ \hline 
885 &  \\ \hline 
888 &  \\ \hline 
890 &  \\ \hline 
895 &  \\ \hline 
\end{tabular} 

\end{center}

%\end{frame}


%\begin{frame}

\begin{enumerate}
\item Encontrar las regiones de rechazo para el estad\'istico $z$, para una prueba de
\begin{itemize}
\item[a) ]  dos colas para $\alpha=0.01,0.05,0.1$
\item[b) ]  una cola superior para $\alpha=0.01,0.05,0.1$
\item[c) ] una cola inferior para $\alpha=0.01,0.05,0.1$

\end{itemize}


\item Suponga que el valor del estad\'istico de prueba es 
\begin{itemize}
\item[a) ]$z=-2.41$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[b) ] $z=2.16$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[c) ] $z=1.15$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[d) ] $z=-2.78$, sacar las conclusiones correspondientes para los incisos anteriores.
\item[e) ] $z=-1.81$, sacar las conclusiones correspondientes para los incisos anteriores.

\end{itemize}
\end{enumerate}
%\end{frame}


%\begin{frame}

\begin{itemize}
\item[3. ] Encuentre el valor de $p$ para las pruebas de hip\'otesis correspondientes a los valores de $z$ del ejercicio anterior.

\item[4. ] Para las pruebas dadas en el ejercicio 2, utilice el valor de $p$, determinado en el ejercicio 3,  para determinar la significancia de los resultados.


\end{itemize}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item[5. ] Una muestra aleatoria de $n=45$ observaciones de una poblaci\'on con media $\overline{x}=2.4$, y desviaci\'on est\'andar $s=0.29$. Suponga que el objetivo es demostrar que la media poblacional $\mu$ excede $2.3$.
\begin{itemize}
\item[a) ] Defina la hip\'otesis nula y alternativa para la prueba.
\item[b) ] Determine la regi\'on de rechazo para un nivel de significancia de: $\alpha=0.1,0.05,0.01$.
\item[c) ] Determine el error est\'andar de la media muestral.
\item[d) ] Calcule el valor de $p$ para los estad\'isticos de prueba definidos en los incisos anteriores.
\item[e) ] Utilice el valor de $p$ pra sacar una conclusi\'on al nivel de significancia $\alpha$.
\item[f) ] Determine el valor de $\beta$ cuando $\mu=2.5$
\item[g) ] Graficar la curva de potencia para la prueba.

\end{itemize}
\end{itemize}
%\end{frame}




\subsection{2.2.2 Prueba de hip\'otesis para la diferencia entre dos medias poblacionales}

%\begin{frame}



El estad\'istico que resume la informaci\'on muestral respecto a la diferencia en medias poblacionales $\left(\mu_{1}-\mu_{2}\right)$ es la diferencia de las medias muestrales $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, por tanto al probar la difencia entre las medias muestrales se verifica que la diferencia real entre las medias poblacionales difiere de un valor especificado, $\left(\mu_{1}-\mu_{2}\right)=D_{0}$, se puede usar el error est\'andar de $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, es decir
$$\sqrt{\frac{\sigma^{2}_{1}}{n_{1}}+\frac{\sigma^{2}_{2}}{n_{2}}}$$
cuyo estimador est\'a dado por
$$SE=\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}$$

El procedimiento para muestras grandes es:
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}

%\end{frame}


%\begin{frame}



\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$z=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}


%\end{frame}


%\begin{frame}



\begin{Ejem}
Para determinar si ser propietario de un autom\'ovil afecta el rendimiento acad\'emico de un estudiante, se tomaron dos muestras aleatorias de 100 estudiantes varones. El promedio de calificaciones para los $n_{1}=100$ no propietarios de un auto tuvieron un promedio y varianza de $\overline{x}_{1}=2.7$ y $s_{1}^{2}=0.36$, respectivamente, mientras que para para la segunda muestra con $n_{2}=100$ propietarios de un auto, se tiene $\overline{x}_{2}=2.54$ y $s_{2}^{2}=0.4$. Los datos presentan suficiente evidencia para indicar una diferencia en la media en el rendimiento acad\'emico entre propietarios y no propietarios de un autom\'ovil? Hacer pruebas para $\alpha=0.01,0.05$ y $\alpha=0.1$.
\end{Ejem}

%\end{frame}


%\begin{frame}


\begin{Sol}
\begin{itemize}
\item Soluci\'on utilizando la t\'ecnica de regiones de rechazo:\medskip
realizando las operaciones
$z=1.84$, determinar si excede los valores de $z_{\alpha/2}$.
\item Soluci\'on utilizando el $p$-value:\medskip
Calcular el valor de $p$, la probabilidad de que $z$ sea mayor que $z=1.84$ o menor que $z=-1.84$, se tiene que $p=0.0658$. Concluir.
\end{itemize}
\end{Sol}

%\end{frame}


%\begin{frame}


\begin{itemize}
\item Si el intervalo de confianza que se construye contiene el valor del par\'ametro especificado por $H_{0}$, entonces ese valor es uno de los posibles valores del par\'ametro y $H_{0}$ no debe ser rechazada.

\item Si el valor hipot\'etico se encuentra fuera de los l\'imites de confianza, la hip\'otesis nula es rechazada al nivel de significancia $\alpha$.
\end{itemize}

\begin{enumerate}
\item Del libro Mendenhall resolver los ejercicios 9.18, 9.19 y 9.20(\href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall}).

\item Del libro \href{https://cu.uacm.edu.mx/nextcloud/index.php/f/202873}{Mendenhall} resolver los ejercicios: 9.23, 9.26 y 9.28.
\end{enumerate}



%\end{frame}



\subsection{2.2.3 Prueba de Hip\'otesis para una Proporci\'on Binomial}

%\begin{frame}


Para una muestra aleatoria de $n$ intentos id\'enticos, de una poblaci\'on binomial, la proporci\'on muesrtal $\hat{p}$ tiene una distribuci\'on aproximadamente normal cuando $n$ es grande, con media $p$ y error est\'andar
$$SE=\sqrt{\frac{pq}{n}}.$$
La prueba de hip\'otesis de la forma
\begin{eqnarray*}
H_{0}&:&p=p_{0}\\
H_{1}&:&p>p_{0}\textrm{, o }p<p_{0}\textrm{ o }p\neq p_{0}
\end{eqnarray*}
El estad\'istico de prueba se construye con el mejor estimador de la proporci\'on verdadera, $\hat{p}$, con el estad\'istico de prueba $z$, que se distribuye normal est\'andar.

El procedimiento es
\begin{itemize}
\item[1) ] Hip\'otesis nula: $H_{0}:p=p_{0}$
\item[2) ] Hip\'otesis alternativa
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:p>p_{0}$ & $p\neq p_{0}$\\
$H_{1}:p<p_{0}$ & \\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\hat{p}-p_{0}}{\sqrt{\frac{pq}{n}}},\hat{p}=\frac{x}{n}
\end{eqnarray*}
donde $x$ es el n\'umero de \'exitos en $n$ intentos binomiales.

\end{itemize}

%\end{frame}


%\begin{frame}


\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}

%\end{frame}


%\begin{frame}


\begin{Ejem}
A cualquier edad, alrededor del $20\%$ de los adultos de cierto pa\'is realiza actividades de acondicionamiento f\'isico al menos dos veces por semana. En una encuesta local de $n=100$ adultos de m\'as de $40$ a\ ~nos, un total de 15 personas indicaron que realizaron actividad f\'isica al menos dos veces por semana. Estos datos indican que el porcentaje de participaci\'on para adultos de m\'as de 40 a\ ~nos de edad es  considerablemente menor a la cifra del $20\%$? Calcule el valor de $p$ y \'uselo para sacar las conclusiones apropiadas.
\end{Ejem}

\begin{enumerate}
\item Resolver los ejercicios: 9.30, 9.32, 9.33, 9.35 y 9.39.
\end{enumerate}



%\end{frame}


\subsection{2.2.4 Prueba de Hip\'otesis diferencia entre dos Proporciones Binomiales}



%\begin{frame}


\begin{Note}
Cuando se tienen dos muestras aleatorias independientes de dos poblaciones binomiales, el objetivo del experimento puede ser la diferencia $\left(p_{1}-p_{2}\right)$ en las proporciones de individuos u objetos que poseen una caracter\'istica especifica en las dos poblaciones. En este caso se pueden utilizar los estimadores de las dos proporciones $\left(\hat{p}_{1}-\hat{p}_{2}\right)$ con error est\'andar dado por
$$SE=\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}$$
considerando el estad\'istico $z$ con un nivel de significancia $\left(1-\alpha\right)100\%$

\end{Note}


\begin{Note}
La hip\'otesis nula a probarse es de la forma
\begin{itemize}
\item[$H_{0}$: ] $p_{1}=p_{2}$ o equivalentemente $\left(p_{1}-p_{2}\right)=0$, contra una hip\'otesis alternativa $H_{1}$ de una o dos colas.
\end{itemize}
\end{Note}

%\end{frame}


%\begin{frame}


\begin{Note}
Para estimar el error est\'andar del estad\'istico $z$, se debe de utilizar el hecho de que suponiendo que $H_{0}$ es verdadera, las dos proporciones son iguales a alg\'un valor com\'un, $p$. Para obtener el mejor estimador de $p$ es
$$p=\frac{\textrm{n\'umero total de \'exitos}}{\textrm{N\'umero total de pruebas}}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$$
\end{Note}



\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\left(p_{1}-p_{2}\right)=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(p_{1}-p_{2}\right)>0$ & $H_{1}:\left(p_{1}-p_{2}\right)\neq 0$\\ 
$H_{1}:\left(p_{1}-p_{2}\right)<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
z=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{p_{1}q_{1}}{n_{1}}+\frac{p_{2}q_{2}}{n_{2}}}}=\frac{\left(\hat{p}_{1}-\hat{p}_{2}\right)}{\sqrt{\frac{pq}{n_{1}}+\frac{pq}{n_{2}}}}
\end{eqnarray*}
donde $\hat{p_{1}}=x_{1}/n_{1}$ y $\hat{p_{2}}=x_{2}/n_{2}$ , dado que el valor com\'un para $p_{1}$ y $p_{2}$ es $p$, entonces $\hat{p}=\frac{x_{1}+x_{2}}{n_{1}+n_{2}}$ y por tanto el estad\'istico de prueba es
\end{itemize}

%\end{frame}


%\begin{frame}



\begin{eqnarray*}
z=\frac{\hat{p}_{1}-\hat{p}_{2}}{\sqrt{\hat{p}\hat{q}}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}
\end{eqnarray*}
\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{\alpha}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:p<p_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

\end{itemize}

%\end{frame}


%\begin{frame}



\begin{Ejem}
Los registros de un hospital, indican que 52 hombres de una muestra de 1000 contra 23 mujeres de una muestra de 1000 fueron ingresados por enfermedad del coraz\'on. Estos datos presentan suficiente evidencia para indicar un porcentaje m\'as alto de enfermedades del coraz\'on entre hombres ingresados al hospital?, utilizar distintos niveles de confianza de $\alpha$.

\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios 9.42

\item Resolver los ejercicios: 9.45, 9.48, 9.50
\end{enumerate}



%\end{frame}



\section{2.3 Muestras Peque\~nas}

\subsection{2.3.1 Una media poblacional}


%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu=\mu_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu>\mu_{0}$ & $H_{1}:\mu\neq \mu_{0}$\\ 
$H_{1}:\mu<\mu0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{x}-\mu_{0}}{\sqrt{\frac{s^{2}}{n}}}
\end{eqnarray*}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
\end{itemize}

%\end{frame}


%\begin{frame}

\begin{Ejem}
Las etiquetas en latas de un gal'on de pintura por lo general indican el tiempo de secado y el \'area puede cubrir una capa. Casi todas las marcas de pintura indican que, en una capa, un gal\'on cubrir\'a entre 250 y 500 pies cuadrados, dependiento de la textura de la superficie a pintarse, un fabricante, sin embargo afirma que un gal\'on de su pintura cubrir\'a 400 pies cuadrados de \'area superficial. Para probar su afirmaci\'on, una muestra aleatoria de 10 latas de un gal\'on de pintura blanca se emple\'o para pintar 10 \'areas id\'enticas usando la misma clase de equipo. Las \'areas reales en pies cuadrados cubiertas por estos 10 galones de pintura se dan a continuac\'on:
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline 
310 & 311 & 412 & 368 & 447 \\ 
\hline 
376 & 303 &410 &365 & 350 \\ 
\hline 
\end{tabular} 
\end{center}
\end{Ejem}

%\end{frame}


%\begin{frame}

\begin{Ejem}
Los datos presentan suficiente evidencia para indicar que el promedio de la cobertura difiere de 400 pies cuadrados? encuentre el valor de $p$ para la prueba y \'uselo para evaluar la significancia de los resultados.
\end{Ejem}
\begin{enumerate}
\item Resolver los ejercicios: 10.2, 10.3,10.5, 10.7, 10.9, 10.13 y 10.16
\end{enumerate}


%\end{frame}


\subsection{2.3.2 Diferencia entre dos medias poblacionales: M.A.I.}

%\begin{frame}

\begin{Note}
Cuando los tama\ ~nos de muestra son peque\ ~nos, no se puede asegurar que las medias muestrales sean normales, pero si las poblaciones originales son normales, entonces la distribuci\'on muestral de la diferencia de las medias muestales, $\left(\overline{x}_{1}-\overline{x}_{2}\right)$, ser\'a normal con media $\left(\mu_{1}-\mu_{2}\right)$ y error est\'andar $$ES=\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}$$

\end{Note}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\mu_{1}-\mu_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\mu_{1}-\mu_{2}\right)>D_{0}$ & $H_{1}:\left(\mu_{1}-\mu_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&\\
\end{tabular}

\item[3) ] Estad\'istico de prueba:
$$t=\frac{\left(\overline{x}_{1}-\overline{x}_{2}\right)-D_{0}}{\sqrt{\frac{s^{2}_{1}}{n_{1}}+\frac{s^{2}_{2}}{n_{2}}}}$$
\end{itemize}

%\end{frame}


%\begin{frame}


donde $$s^{2}=\frac{\left(n_{1}-1\right)s_{1}^{2}+\left(n_{2}-1\right)s_{2}^{2}}{n_{1}+n_{2}-2}$$
\begin{itemize}

\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$z>z_{0}$ & \\
$z<-z_{\alpha}$ cuando $H_{1}:\left(\mu_{1}-\mu_{2}\right)<D_{0}$&$z>z_{\alpha/2}$ o $z<-z_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}
Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.


\end{itemize}


%\end{frame}



\subsection{2.3.3 Diferencia entre dos medias poblacionales: Diferencias Pareadas}


%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\mu_{d}=0$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}:\mu_{d}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\mu_{d}>0$ & $H_{1}:\mu_{d}\neq 0$\\ 
$H_{1}:\mu_{d}<0$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
t=\frac{\overline{d}}{\sqrt{\frac{s_{d}^{2}}{n}}}
\end{eqnarray*}
donde $n$ es el n\'umero de diferencias pareadas, $\overline{d}$ es la media de las diferencias muestrales, y $s_{d}$ es la desviaci\'on est\'andar de las diferencias muestrales.



\end{itemize}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$t>t_{\alpha}$ & \\
$t<-t_{\alpha}$ cuando $H_{1}:\mu<mu_{0}$&$t>t_{\alpha/2}$ o $t<-t_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $t$, $t_{-\alpha}$ y $t_{\alpha/2}$ est\'an basados en $\left(n_{1}+n_{2}-2\right)$ grados de libertad.

\end{itemize}

%\end{frame}



\subsection{2.3.4 Inferencias con respecto a la Varianza Poblacional}


%\begin{frame}

\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula:} $H_{0}:\sigma^{2}=\sigma^{2}_{0}$
\item[2) ] \textbf{Hip\'otesis Alternativa: } $H_{1}$
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\sigma^{2}>\sigma^{2}_{0}$ & $H_{1}:\sigma^{2}\neq \sigma^{2}_{0}$\\ 
$H_{1}:\sigma^{2}<\sigma^{2}_{0}$&\\
\end{tabular}
\item[3) ] Estad\'istico de prueba:
\begin{eqnarray*}
\chi^{2}=\frac{\left(n-1\right)s^{2}}{\sigma^{2}_{0}}
\end{eqnarray*}

\end{itemize}


%\end{frame}


%\begin{frame}

\begin{itemize}
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$\chi^{2}>\chi^{2}_{\alpha}$ & \\
$\chi^{2}<\chi^{2}_{\left(1-\alpha\right)}$ cuando $H_{1}:\chi^{2}<\chi^{2}_{0}$&$\chi^{2}>\chi^{2}_{\alpha/2}$ o $\chi^{2}<\chi^{2}_{\left(1-\alpha/2\right)}$\\
 cuando $p<\alpha$&\\
\end{tabular}

Los valores cr\'iticos de $\chi^{2}$,est\'an basados en $\left(n_{1}+\right)$ grados de libertad.

\end{itemize}

%\end{frame}


\subsection{2.3.5 Comparaci\'on de dos varianzas poblacionales}



%\begin{frame}
\begin{itemize}
\item[1) ] \textbf{Hip\'otesis Nula} $H_{0}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)=D_{0}$,\medskip

donde $D_{0}$ es el valor, la diferencia, espec\'ifico que se desea probar. En algunos casos se querr\'a demostrar que no hay diferencia alguna, es decir $D_{0}=0$.

\item[2) ] \textbf{Hip\'otesis Alternativa}
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)>D_{0}$ & $H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)\neq D_{0}$\\ 
$H_{1}:\left(\sigma^{2}_{1}-\sigma^{2}_{2}\right)<D_{0}$&\\
\end{tabular}

\end{itemize}


\begin{itemize}
\item[3) ] Estad\'istico de prueba:
$$F=\frac{s_{1}^{2}}{s_{2}^{2}}$$
donde $s_{1}^{2}$ es la varianza muestral m\'as grande.
\item[4) ] Regi\'on de rechazo: rechazar $H_{0}$ cuando
\begin{tabular}{cc}\hline
\textbf{Prueba de una Cola} & \textbf{Prueba de dos colas}\\\hline
$F>F_{\alpha}$ & $F>F_{\alpha/2}$\\
 cuando $p<\alpha$&\\
\end{tabular}


\end{itemize}

%\end{frame}


\section{Ejercicios}

%\begin{frame}
\begin{itemize}
\item[1) ] Del libro Probabililidad y Estad\'sitica para Ingenier\'ia de Hines, Montgomery, Goldsman y Borror resolver los siguientes ejercicios: 10-9, 10-10,10-13,10-16 y 10-20.

\item[2) ] Realizar un programa en R para cada una de las secciones y subsecciones revisadas en clase, para determinar intervalos de confianza.

\item[3) ] Aplicar los programas elaborados en el ejercicio anterior a la siguiente lista:  10-39, 10-41, 10-45, 10-47, 10-48, 10-50, 10-52, 10-54, 10-56,10-57, 10-58, 10-65, 10-68, 10-72 y 10-73.

\item[4) ]  Elaborar una rutina en R que grafique las siguientes distribuciones, permitiendo variar los par\'ametros de las distribuciones: Binomial, Uniforme continua, Gamma, Beta, Exponencial, Normal y $t$-Student.

\item[5)] Presentar el primer cap\'itulo del libro del curso en formato \textit{Rnw} con su respectivo archivo \textit{pdf} generado
\end{itemize}


%\end{frame}


%---------------------------------------------------------
\section{An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------


%\begin{frame}
\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

\end{Note}

%\end{frame}

%---------------------------------------------------------
\section{An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------

%\begin{frame}
\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

\end{Note}


%\end{frame}


\subsection{Regresi\'on Lineal Simple (RLS)}


%\begin{frame}

Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y  $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 

Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}

donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


%\end{frame}


%\begin{frame}
Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$,  estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.

Entonces la ecuaci\'on (\ref{Modelo.Regresion}) se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on 
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}

%\end{frame}


%\begin{frame}
Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$,  $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$,  igualar a cero y  resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene 

\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}

%\end{frame}


%\begin{frame}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}

Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto

%\end{frame}


%\begin{frame}
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}

%\end{frame}


\subsection{Regresi\'on Lineal Simple (RLS)}




%\begin{frame}
Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y  $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 

Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}

%\end{frame}


%\begin{frame}
donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$,  estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.


Entonces la ecuaci\'on (\ref{Modelo.Regresion}) se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on 
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}

%\end{frame}


%\begin{frame}
Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$, $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$,  igualar a cero y  resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene

\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}

%\end{frame}


%\begin{frame}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}

Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}

%\end{frame}


%---------------------------------------------------------
\section{3. An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------

%\begin{frame}


\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\end{itemize}

\end{Note}

%\end{frame}


\subsection{3.1 Regresi\'on Lineal Simple (RLS)}



%\begin{frame}

\begin{itemize}

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 



%\end{frame}

\subsection{3.2 M\'etodo de M\'inimos Cuadrados}


%\begin{frame}

Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}
donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$, estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.


%\end{frame}


%\begin{frame}

Entonces la ecuaci\'on \ref{Modelo.Regresion} se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}

%\end{frame}


%\begin{frame}

Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$, $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$, igualar a cero y resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene

\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}\label{Ecs.Estimadores.Regresion}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}

%\end{frame}


%\begin{frame}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}
Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}

%\end{frame}


\subsection{3.3 Propiedades de los Estimadores $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$}

%\begin{frame}
\begin{Note}
\begin{itemize}
\item Las propiedades estad\'isticas de los estimadores de m\'inimos cuadrados son \'utiles para evaluar la suficiencia del modelo.

\item Dado que $\hat{\beta}_{0}$ y  $\hat{\beta}_{1}$ son combinaciones lineales de las variables aleatorias $y_{i}$, tambi\'en resultan ser variables aleatorias.
\end{itemize}
\end{Note}
A saber
\begin{eqnarray*}
E\left(\hat{\beta}_{1}\right)&=&E\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)\right)
\end{eqnarray*}
\begin{eqnarray*}
&=&\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\right)\left(x_{i}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}}\left[\beta_{0}E\left(\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)\right)+E\left(\beta_{1}\sum_{k=1}^{n}x_{k}\left(x_{k}-\overline{x}\right)\right)\right.\\
&+&\left.E\left(\sum_{k=1}^{n}\epsilon_{k}\left(x_{k}-\overline{x}\right)\right)\right]=\frac{1}{S_{xx}}\beta_{1}S_{xx}=\beta_{1}
\end{eqnarray*}

%\end{frame}


%\begin{frame}

por lo tanto 
\begin{equation}\label{Esperanza.Beta.1}
E\left(\hat{\beta}_{1}\right)=\beta_{1}
\end{equation}
\begin{Note}
Es decir, $\hat{\beta_{1}}$ es un estimador insesgado.
\end{Note}
Ahora calculemos la varianza:
\begin{eqnarray*}
V\left(\hat{\beta}_{1}\right)&=&V\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}^{2}}V\left(\sum_{k=1}^{n}y_{k}\left(x_{k}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}V\left(y_{k}\left(x_{k}-\overline{x}\right)\right)=\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}\sigma^{2}\left(x_{k}-\overline{x}\right)^{2}\\
&=&\frac{\sigma^{2}}{S_{xx}^{2}}\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)^{2}=\frac{\sigma^{2}}{S_{xx}}
\end{eqnarray*}

%\end{frame}


%\begin{frame}

por lo tanto
\begin{equation}\label{Varianza.Beta.1}
V\left(\hat{\beta}_{1}\right)=\frac{\sigma^{2}}{S_{xx}}
\end{equation}
\begin{Prop}
\begin{eqnarray*}
E\left(\hat{\beta}_{0}\right)&=&\beta_{0},\\
V\left(\hat{\beta}_{0}\right)&=&\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right),\\
Cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right)&=&-\frac{\sigma^{2}\overline{x}}{S_{xx}}.
\end{eqnarray*}
\end{Prop}
Para estimar $\sigma^{2}$ es preciso definir la diferencia entre la observaci\'on $y_{k}$, y el valor predecido $\hat{y}_{k}$, es decir
\begin{eqnarray*}
e_{k}=y_{k}-\hat{y}_{k},\textrm{ se le denomina \textbf{residuo}.}
\end{eqnarray*}
La suma de los cuadrados de los errores de los reisduos, \textit{suma de cuadrados del error}
\begin{eqnarray}
SC_{E}=\sum_{k=1}^{n}e_{k}^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray}

%\end{frame}


%\begin{frame}

sustituyendo $\hat{y}_{k}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}$ se obtiene
\begin{eqnarray*}
SC_{E}&=&\sum_{k=1}^{n}y_{k}^{2}-n\overline{y}^{2}-\hat{\beta}_{1}S_{xy}=S_{yy}-\hat{\beta}_{1}S_{xy},\\
E\left(SC_{E}\right)&=&\left(n-2\right)\sigma^{2},\textrm{ por lo tanto}\\
\hat{\sigma}^{2}&=&\frac{SC_{E}}{n-2}=MC_{E}\textrm{ es un estimador insesgado de }\sigma^{2}.
\end{eqnarray*}

%\end{frame}

\subsection{3.4 Prueba de Hip\'otesis en RLS}


%\begin{frame}

\begin{itemize}
\item Para evaluar la suficiencia del modelo de regresi\'on lineal simple, es necesario lleva a cabo una prueba de hip\'otesis respecto de los par\'ametros del modelo as\'i como de la construcci\'on de intervalos de confianza.

\item Para poder realizar la prueba de hip\'otesis sobre la pendiente y la ordenada al or\'igen de la recta de regresi\'on es necesario hacer el supuesto de que el error $\epsilon_{i}$ se distribuye normalmente, es decir $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$.

\end{itemize}

%\end{frame}


%\begin{frame}

Suponga que se desea probar la hip\'otesis de que la pendiente es igual a una constante, $\beta_{0,1}$ las hip\'otesis Nula y Alternativa son:
\begin{centering}
\begin{itemize}
\item[$H_{0}$: ] $\beta_{1}=\beta_{1,0}$,

\item[$H_{1}$: ]$\beta_{1}\neq\beta_{1,0}$.

\end{itemize}
donde dado que las $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$, se tiene que $y_{i}$ son variables aleatorias normales $N\left(\beta_{0}+\beta_{1}x_{1},\sigma^{2}\right)$. 
\end{centering}

%\end{frame}


%\begin{frame}
De las ecuaciones (\ref{Ecs.Estimadores.Regresion}) se desprende que $\hat{\beta}_{1}$ es combinaci\'on lineal de variables aleatorias normales independientes, es decir, $\hat{\beta}_{1}\sim N\left(\beta_{1},\sigma^{2}/S_{xx}\right)$, recordar las ecuaciones (\ref{Esperanza.Beta.1}) y (\ref{Varianza.Beta.1}).
Entonces se tiene que el estad\'istico de prueba apropiado es
\begin{equation}\label{Estadistico.Beta.1}
t_{0}=\frac{\hat{\beta}_{1}-\hat{\beta}_{1,0}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
que se distribuye $t$ con $n-2$ grados de libertad bajo $H_{0}:\beta_{1}=\beta_{1,0}$. Se rechaza $H_{0}$ si 
\begin{equation}\label{Zona.Rechazo.Beta.1}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}


%\end{frame}


%\begin{frame}

Para $\beta_{0}$ se puede proceder de manera an\'aloga para
\begin{itemize}
\item[$H_{0}:$] $\beta_{0}=\beta_{0,0}$,
\item[$H_{1}:$] $\beta_{0}\neq\beta_{0,0}$,
\end{itemize}
con $\hat{\beta}_{0}\sim N\left(\beta_{0},\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)\right)$, por lo tanto
\begin{equation}\label{Estadistico.Beta.0}
t_{0}=\frac{\hat{\beta}_{0}-\beta_{0,0}}{MC_{E}\left[\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right]},
\end{equation}
con el que rechazamos la hip\'otesis nula si
\begin{equation}\label{Zona.Rechazo.Beta.0}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}

%\end{frame}


%\begin{frame}

\begin{itemize}
\item No rechazar $H_{0}:\beta_{1}=0$ es equivalente a decir que no hay relaci\'on lineal entre $x$ y $y$.
\item Alternativamente, si $H_{0}:\beta_{1}=0$ se rechaza, esto implica que $x$ explica la variabilidad de $y$, es decir, podr\'ia significar que la l\'inea recta esel modelo adecuado.
\end{itemize}
El procedimiento de prueba para $H_{0}:\beta_{1}=0$ puede realizarse de la siguiente manera:
\begin{eqnarray*}
S_{yy}=\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}

\begin{eqnarray*}
S_{yy}&=&\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}+\hat{y}_{k}-\overline{y}\right)^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)+\left(y_{k}-\hat{y}_{k}\right)\right]^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\left(y_{k}-\hat{y}_{k}\right)^{2}\right]\\
&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}

%\end{frame}


%\begin{frame}

\begin{eqnarray*}
&&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)=\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\sum_{k=1}^{n}\overline{y}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}\right)\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)
\end{eqnarray*}

\begin{eqnarray*}
&=&\sum_{k=1}^{n}\hat{\beta}_{0}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\sum_{k=1}^{n}\hat{\beta}_{1}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&=&\hat{\beta}_{0}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\hat{\beta}_{1}\sum_{k=1}^{n}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)=0+0+0=0.
\end{eqnarray*}

%\end{frame}


%\begin{frame}

Por lo tanto, efectivamente se tiene
\begin{equation}\label{Suma.Total.Cuadrados}
S_{yy}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2},
\end{equation}
donde se hacen las definiciones
\begin{eqnarray}
SC_{E}&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}\cdots\textrm{Suma de Cuadrados del Error}\\
SC_{R}&=&\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}\cdots\textrm{ Suma de Regresi\'on de Cuadrados}
\end{eqnarray}
Por lo tanto la ecuaci\'on (\ref{Suma.Total.Cuadrados}) se puede reescribir como 
\begin{equation}\label{Suma.Total.Cuadrados.Dos}
S_{yy}=SC_{R}+SC_{E}
\end{equation}
recordemos que $SC_{E}=S_{yy}-\hat{\beta}_{1}S_{xy}$
\begin{eqnarray*}
S_{yy}&=&SC_{R}+\left( S_{yy}-\hat{\beta}_{1}S_{xy}\right)\\
S_{xy}&=&\frac{1}{\hat{\beta}_{1}}SC_{R}
\end{eqnarray*}
$S_{xy}$ tiene $n-1$ grados de libertad y $SC_{R}$ y $SC_{E}$ tienen 1 y $n-2$ grados de libertad respectivamente.

%\end{frame}


%\begin{frame}

\begin{Prop}
\begin{equation}
E\left(SC_{R}\right)=\sigma^{2}+\beta_{1}S_{xx}
\end{equation}
adem\'as, $SC_{E}$ y $SC_{R}$ son independientes.
\end{Prop}
Recordemos que $\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}$. Para $H_{0}:\beta_{1}=0$ verdadera,
\begin{eqnarray*}
F_{0}=\frac{SC_{R}/1}{SC_{E}/(n-2)}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
se distribuye $F_{1,n-2}$, y se rechazar\'ia $H_{0}$ si $F_{0}>F_{\alpha,1,n-2}$.

El procedimiento de prueba de hip\'otesis puede presentarse como la tabla de an\'alisis de varianza siguiente\medskip

%\end{frame}


%\begin{frame}

\begin{tabular}{lcccc}\hline
Fuente de & Suma de  &  Grados de  & Media  & $F_{0}$ \\ 
 variaci\'on & Cuadrados & Libertad & Cuadr\'atica & \\\hline
 Regresi\'on & $SC_{R}$ & 1 & $MC_{R}$  & $MC_{R}/MC_{E}$\\
 Error Residual & $SC_{E}$ & $n-2$ & $MC_{E}$ & \\\hline
 Total & $S_{yy}$ & $n-1$ & & \\\hline
\end{tabular} 

La prueba para la significaci\'on de la regresi\'on puede desarrollarse bas\'andose en la expresi\'on (\ref{Estadistico.Beta.1}), con $\hat{\beta}_{1,0}=0$, es decir
\begin{equation}\label{Estadistico.Beta.1.Cero}
t_{0}=\frac{\hat{\beta}_{1}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}

%\end{frame}


%\begin{frame}
Elevando al cuadrado ambos t\'erminos:
\begin{eqnarray*}
t_{0}^{2}=\frac{\hat{\beta}_{1}^{2}S_{xx}}{MC_{E}}=\frac{\hat{\beta}_{1}S_{xy}}{MC_{E}}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
Observar que $t_{0}^{2}=F_{0}$, por tanto la prueba que se utiliza para $t_{0}$ es la misma que para $F_{0}$.

%\end{frame}


\subsection{Estimaci\'on de Intervalos en RLS}


%\begin{frame}

\begin{itemize}
\item Adem\'as de la estimaci\'on puntual para los par\'ametros $\beta_{1}$ y $\beta_{0}$, es posible obtener estimaciones del intervalo de confianza de estos par\'ametros.

\item El ancho de estos intervalos de confianza es una medida de la calidad total de la recta de regresi\'on.

\end{itemize}

%\end{frame}


%\begin{frame}

Si los $\epsilon_{k}$ se distribuyen normal e independientemente, entonces
\begin{eqnarray*}
\begin{array}{ccc}
\frac{\left(\hat{\beta}_{1}-\beta_{1}\right)}{\sqrt{\frac{MC_{E}}{S_{xx}}}}&y &\frac{\left(\hat{\beta}_{0}-\beta_{0}\right)}{\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}}
\end{array}
\end{eqnarray*}
se distribuyen $t$ con $n-2$ grados de libertad. Por tanto un intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\beta_{1}$ est\'a dado por
\begin{eqnarray}
\hat{\beta}_{1}-t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}\leq \beta_{1}\leq\hat{\beta}_{1}+t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}.
\end{eqnarray}
De igual manera, para $\beta_{0}$ un intervalo de confianza al $100\left(1-\alpha\right)\%$ es
\small{
\begin{eqnarray}
\begin{array}{l}
\hat{\beta}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}\leq\beta_{0}\leq\hat{\beta}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}
\end{array}
\end{eqnarray}}

%\end{frame}

%---------------------------------------------------------
\section{3. An\'alisis de Regresion Lineal (RL)}
%---------------------------------------------------------

%\begin{frame}

\begin{Note}
\begin{itemize}
\item En muchos problemas hay dos o m\'as variables relacionadas, para medir el grado de relaci\'on se utiliza el \textbf{an\'alisis de regresi\'on}. 
\item Supongamos que se tiene una \'unica variable dependiente, $y$, y varias  variables independientes, $x_{1},x_{2},\ldots,x_{n}$.

\item  La variable $y$ es una varaible aleatoria, y las variables independientes pueden ser distribuidas independiente o conjuntamente. 

\end{itemize}

\end{Note}

%\end{frame}



\subsection{3.1 Regresi\'on Lineal Simple (RLS)}



%\begin{frame}

\begin{itemize}

\item A la relaci\'on entre estas variables se le denomina modelo regresi\'on de $y$ en $x_{1},x_{2},\ldots,x_{n}$, por ejemplo $y=\phi\left(x_{1},x_{2},\ldots,x_{n}\right)$, lo que se busca es una funci\'on que mejor aproxime a $\phi\left(\cdot\right)$.

\end{itemize}

Supongamos que de momento solamente se tienen una variable independiente $x$, para la variable de respuesta $y$. Y supongamos que la relaci\'on que hay entre $x$ y $y$ es una l\'inea recta, y que para cada observaci\'on de $x$, $y$ es una variable aleatoria.

El valor esperado de $y$ para cada valor de $x$ es
\begin{eqnarray}
E\left(y|x\right)=\beta_{0}+\beta_{1}x
\end{eqnarray}
$\beta_{0}$ es la ordenada al or\'igen y $\beta_{1}$ la pendiente de la recta en cuesti\'on, ambas constantes desconocidas. 


%\end{frame}

\subsection{3.2 M\'etodo de M\'inimos Cuadrados}


%\begin{frame}

Supongamos que cada observaci\'on $y$ se puede describir por el modelo
\begin{eqnarray}\label{Modelo.Regresion}
y=\beta_{0}+\beta_{1}x+\epsilon
\end{eqnarray}
donde $\epsilon$ es un error aleatorio con media cero y varianza $\sigma^{2}$. Para cada valor $y_{i}$ se tiene $\epsilon_{i}$ variables aleatorias no correlacionadas, cuando se incluyen en el modelo \ref{Modelo.Regresion}, este se le llama \textit{modelo de regresi\'on lineal simple}.


Suponga que se tienen $n$ pares de observaciones $\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right),\ldots,\left(x_{n},y_{n}\right)$, estos datos pueden utilizarse para estimar los valores de $\beta_{0}$ y $\beta_{1}$. Esta estimaci\'on es por el \textbf{m\'etodos de m\'inimos cuadrados}.



%\end{frame}


%\begin{frame}


Entonces la ecuaci\'on \ref{Modelo.Regresion} se puede reescribir como
\begin{eqnarray}\label{Modelo.Regresion.dos}
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\textrm{ para }i=1,2,\ldots,n.
\end{eqnarray}
Si consideramos la suma de los cuadrados de los errores aleatorios, es decir, el cuadrado de la diferencia entre las observaciones con la recta de regresi\'on
\begin{eqnarray}
L=\sum_{i=1}^{n}\epsilon^{2}=\sum_{i=1}^{n}\left(y_{i}-\beta_{0}-\beta_{1}x_{i}\right)^{2}
\end{eqnarray}
Para obtener los estimadores por m\'inimos cuadrados de $\beta_{0}$ y $\beta_{1}$, $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, es preciso calcular las derivadas parciales con respecto a $\beta_{0}$ y $\beta_{1}$, igualar a cero y resolver el sistema de ecuaciones lineales resultante:
\begin{eqnarray*}
\frac{\partial L}{\partial \beta_{0}}=0\\
\frac{\partial L}{\partial \beta_{1}}=0\\
\end{eqnarray*}

%\end{frame}


%\begin{frame}
evaluando en $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$, se tiene
\begin{eqnarray*}
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)&=&0\\
-2\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{i}\right)x_{i}&=&0
\end{eqnarray*}
simplificando
\begin{eqnarray*}
n\hat{\beta}_{0}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}&=&\sum_{i=1}^{n}y_{i}\\
\hat{\beta}_{0}\sum_{i=1}^{n}x_{i}+\hat{\beta}_{1}\sum_{i=1}^{n}x_{i}^{2}&=&\sum_{i=1}^{n}x_{i}y_{i}
\end{eqnarray*}
Las ecuaciones anteriores se les denominan \textit{ecuaciones normales de m\'inimos cuadrados} con soluci\'on
\begin{eqnarray}\label{Ecs.Estimadores.Regresion}
\hat{\beta}_{0}&=&\overline{y}-\hat{\beta}_{1}\overline{x}\\
\hat{\beta}_{1}&=&\frac{\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}y_{i}\right)\left(\sum_{i=1}^{n}x_{i}\right)}{\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}}
\end{eqnarray}

%\end{frame}


%\begin{frame}
entonces el modelo de regresi\'on lineal simple ajustado es
\begin{eqnarray}
\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1}x
\end{eqnarray}
Se intrduce la siguiente notaci\'on
\begin{eqnarray}
S_{xx}&=&\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\sum_{i=1}^{n}x_{i}^{2}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)^{2}\\
S_{xy}&=&\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)=\sum_{i=1}^{n}x_{i}y_{i}-\frac{1}{n}\left(\sum_{i=1}^{n}x_{i}\right)\left(\sum_{i=1}^{n}y_{i}\right)
\end{eqnarray}
y por tanto
\begin{eqnarray}
\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}
\end{eqnarray}

%\end{frame}



\subsection{3.3 Propiedades de los Estimadores $\hat{\beta}_{0}$ y $\hat{\beta}_{1}$}



%\begin{frame}

\begin{Note}
\begin{itemize}
\item Las propiedades estad\'isticas de los estimadores de m\'inimos cuadrados son \'utiles para evaluar la suficiencia del modelo.

\item Dado que $\hat{\beta}_{0}$ y  $\hat{\beta}_{1}$ son combinaciones lineales de las variables aleatorias $y_{i}$, tambi\'en resultan ser variables aleatorias.
\end{itemize}
\end{Note}
A saber
\begin{eqnarray*}
E\left(\hat{\beta}_{1}\right)&=&E\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}y_{i}\left(x_{i}-\overline{x}\right)\right)
\end{eqnarray*}

%\end{frame}


%\begin{frame}

\begin{eqnarray*}
&=&\frac{1}{S_{xx}}E\left(\sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\right)\left(x_{i}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}}\left[\beta_{0}E\left(\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)\right)+E\left(\beta_{1}\sum_{k=1}^{n}x_{k}\left(x_{k}-\overline{x}\right)\right)\right.\\
&+&\left.E\left(\sum_{k=1}^{n}\epsilon_{k}\left(x_{k}-\overline{x}\right)\right)\right]=\frac{1}{S_{xx}}\beta_{1}S_{xx}=\beta_{1}
\end{eqnarray*}
por lo tanto 
\begin{equation}\label{Esperanza.Beta.1}
E\left(\hat{\beta}_{1}\right)=\beta_{1}
\end{equation}

%\end{frame}


%\begin{frame}

\begin{Note}
Es decir, $\hat{\beta_{1}}$ es un estimador insesgado.
\end{Note}
Ahora calculemos la varianza:
\begin{eqnarray*}
V\left(\hat{\beta}_{1}\right)&=&V\left(\frac{S_{xy}}{S_{xx}}\right)=\frac{1}{S_{xx}^{2}}V\left(\sum_{k=1}^{n}y_{k}\left(x_{k}-\overline{x}\right)\right)\\
&=&\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}V\left(y_{k}\left(x_{k}-\overline{x}\right)\right)=\frac{1}{S_{xx}^{2}}\sum_{k=1}^{n}\sigma^{2}\left(x_{k}-\overline{x}\right)^{2}\\
&=&\frac{\sigma^{2}}{S_{xx}^{2}}\sum_{k=1}^{n}\left(x_{k}-\overline{x}\right)^{2}=\frac{\sigma^{2}}{S_{xx}}
\end{eqnarray*}

%\end{frame}


%\begin{frame}


por lo tanto
\begin{equation}\label{Varianza.Beta.1}
V\left(\hat{\beta}_{1}\right)=\frac{\sigma^{2}}{S_{xx}}
\end{equation}
\begin{Prop}
\begin{eqnarray*}
E\left(\hat{\beta}_{0}\right)&=&\beta_{0},\\
V\left(\hat{\beta}_{0}\right)&=&\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right),\\
Cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right)&=&-\frac{\sigma^{2}\overline{x}}{S_{xx}}.
\end{eqnarray*}
\end{Prop}

Para estimar $\sigma^{2}$ es preciso definir la diferencia entre la observaci\'on $y_{k}$, y el valor predecido $\hat{y}_{k}$, es decir
\begin{eqnarray*}
e_{k}=y_{k}-\hat{y}_{k},\textrm{ se le denomina \textbf{residuo}.}
\end{eqnarray*}
La suma de los cuadrados de los errores de los reisduos, \textit{suma de cuadrados del error}
\begin{eqnarray}
SC_{E}=\sum_{k=1}^{n}e_{k}^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray}

%\end{frame}


%\begin{frame}

sustituyendo $\hat{y}_{k}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}$ se obtiene
\begin{eqnarray*}
SC_{E}&=&\sum_{k=1}^{n}y_{k}^{2}-n\overline{y}^{2}-\hat{\beta}_{1}S_{xy}=S_{yy}-\hat{\beta}_{1}S_{xy},\\
E\left(SC_{E}\right)&=&\left(n-2\right)\sigma^{2},\textrm{ por lo tanto}\\
\hat{\sigma}^{2}&=&\frac{SC_{E}}{n-2}=MC_{E}\textrm{ es un estimador insesgado de }\sigma^{2}.
\end{eqnarray*}


%\end{frame}



%\end{document}
\subsection{3.4 Prueba de Hip\'otesis en RLS}


%\begin{frame}

\begin{itemize}
\item Para evaluar la suficiencia del modelo de regresi\'on lineal simple, es necesario lleva a cabo una prueba de hip\'otesis respecto de los par\'ametros del modelo as\'i como de la construcci\'on de intervalos de confianza.

\item Para poder realizar la prueba de hip\'otesis sobre la pendiente y la ordenada al or\'igen de la recta de regresi\'on es necesario hacer el supuesto de que el error $\epsilon_{i}$ se distribuye normalmente, es decir $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$.

\end{itemize}


Suponga que se desea probar la hip\'otesis de que la pendiente es igual a una constante, $\beta_{0,1}$ las hip\'otesis Nula y Alternativa son:
\begin{centering}
\begin{itemize}
\item[$H_{0}$: ] $\beta_{1}=\beta_{1,0}$,

\item[$H_{1}$: ]$\beta_{1}\neq\beta_{1,0}$.

\end{itemize}

donde dado que las $\epsilon_{i} \sim N\left(0,\sigma^{2}\right)$, se tiene que $y_{i}$ son variables aleatorias normales $N\left(\beta_{0}+\beta_{1}x_{1},\sigma^{2}\right)$. 
\end{centering}

%\end{frame}

%\begin{frame}
De las ecuaciones (\ref{Ecs.Estimadores.Regresion}) se desprende que $\hat{\beta}_{1}$ es combinaci\'on lineal de variables aleatorias normales independientes, es decir, $\hat{\beta}_{1}\sim N\left(\beta_{1},\sigma^{2}/S_{xx}\right)$, recordar las ecuaciones (\ref{Esperanza.Beta.1}) y (\ref{Varianza.Beta.1}).

Entonces se tiene que el estad\'istico de prueba apropiado es
\begin{equation}\label{Estadistico.Beta.1}
t_{0}=\frac{\hat{\beta}_{1}-\hat{\beta}_{1,0}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
que se distribuye $t$ con $n-2$ grados de libertad bajo $H_{0}:\beta_{1}=\beta_{1,0}$. Se rechaza $H_{0}$ si 
\begin{equation}\label{Zona.Rechazo.Beta.1}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}


%\end{frame}

%\begin{frame}


Para $\beta_{0}$ se puede proceder de manera an\'aloga para
\begin{itemize}
\item[$H_{0}:$] $\beta_{0}=\beta_{0,0}$,
\item[$H_{1}:$] $\beta_{0}\neq\beta_{0,0}$,
\end{itemize}
con $\hat{\beta}_{0}\sim N\left(\beta_{0},\sigma^{2}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)\right)$, por lo tanto
\begin{equation}\label{Estadistico.Beta.0}
t_{0}=\frac{\hat{\beta}_{0}-\beta_{0,0}}{MC_{E}\left[\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right]},
\end{equation}
con el que rechazamos la hip\'otesis nula si
\begin{equation}\label{Zona.Rechazo.Beta.0}
t_{0}|>t_{\alpha/2,n-2}.
\end{equation}


%\end{frame}

%\begin{frame}



\begin{itemize}
\item No rechazar $H_{0}:\beta_{1}=0$ es equivalente a decir que no hay relaci\'on lineal entre $x$ y $y$.
\item Alternativamente, si $H_{0}:\beta_{1}=0$ se rechaza, esto implica que $x$ explica la variabilidad de $y$, es decir, podr\'ia significar que la l\'inea recta esel modelo adecuado.
\end{itemize}
El procedimiento de prueba para $H_{0}:\beta_{1}=0$ puede realizarse de la siguiente manera:
\begin{eqnarray*}
S_{yy}=\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}


%\end{frame}

%\begin{frame}

\begin{eqnarray*}
S_{yy}&=&\sum_{k=1}^{n}\left(y_{k}-\overline{y}\right)^{2}=\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}+\hat{y}_{k}-\overline{y}\right)^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)+\left(y_{k}-\hat{y}_{k}\right)\right]^{2}\\
&=&\sum_{k=1}^{n}\left[\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\left(y_{k}-\hat{y}_{k}\right)^{2}\right]\\
&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+2\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}
\end{eqnarray*}

\begin{eqnarray*}
&&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)\left(y_{k}-\hat{y}_{k}\right)=\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\sum_{k=1}^{n}\overline{y}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\hat{y}_{k}\left(y_{k}-\hat{y}_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)\\
&=&\sum_{k=1}^{n}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{k}\right)\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)-\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)
\end{eqnarray*}

%\end{frame}

%\begin{frame}

\begin{eqnarray*}
&=&\sum_{k=1}^{n}\hat{\beta}_{0}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\sum_{k=1}^{n}\hat{\beta}_{1}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&=&\hat{\beta}_{0}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)+\hat{\beta}_{1}\sum_{k=1}^{n}x_{k}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)\\
&-&\overline{y}\sum_{k=1}^{n}\left(y_{k}-\hat{\beta}_{0}-\hat{\beta}_{1}x_{k}\right)=0+0+0=0.
\end{eqnarray*}

Por lo tanto, efectivamente se tiene
\begin{equation}\label{Suma.Total.Cuadrados}
S_{yy}=\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}+\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2},
\end{equation}
donde se hacen las definiciones
\begin{eqnarray}
SC_{E}&=&\sum_{k=1}^{n}\left(\hat{y}_{k}-\overline{y}\right)^{2}\cdots\textrm{Suma de Cuadrados del Error}\\
SC_{R}&=&\sum_{k=1}^{n}\left(y_{k}-\hat{y}_{k}\right)^{2}\cdots\textrm{ Suma de Regresi\'on de Cuadrados}
\end{eqnarray}

%\end{frame}

%\begin{frame}

Por lo tanto la ecuaci\'on (\ref{Suma.Total.Cuadrados}) se puede reescribir como 
\begin{equation}\label{Suma.Total.Cuadrados.Dos}
S_{yy}=SC_{R}+SC_{E}
\end{equation}
recordemos que $SC_{E}=S_{yy}-\hat{\beta}_{1}S_{xy}$
\begin{eqnarray*}
S_{yy}&=&SC_{R}+\left( S_{yy}-\hat{\beta}_{1}S_{xy}\right)\\
S_{xy}&=&\frac{1}{\hat{\beta}_{1}}SC_{R}
\end{eqnarray*}
$S_{xy}$ tiene $n-1$ grados de libertad y $SC_{R}$ y $SC_{E}$ tienen 1 y $n-2$ grados de libertad respectivamente.

\begin{Prop}
\begin{equation}
E\left(SC_{R}\right)=\sigma^{2}+\beta_{1}S_{xx}
\end{equation}
adem\'as, $SC_{E}$ y $SC_{R}$ son independientes.
\end{Prop}

%\end{frame}

%\begin{frame}
Recordemos que $\hat{\beta}_{1}=\frac{S_{xy}}{S_{xx}}$. Para $H_{0}:\beta_{1}=0$ verdadera,
\begin{eqnarray*}
F_{0}=\frac{SC_{R}/1}{SC_{E}/(n-2)}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
se distribuye $F_{1,n-2}$, y se rechazar\'ia $H_{0}$ si $F_{0}>F_{\alpha,1,n-2}$.
									
El procedimiento de prueba de hip\'otesis puede presentarse como la tabla de an\'alisis de varianza siguiente\medskip

\begin{tabular}{lcccc}\hline
Fuente de & Suma de  &  Grados de  & Media  & $F_{0}$ \\ 
 variaci\'on & Cuadrados & Libertad & Cuadr\'atica & \\\hline
 Regresi\'on & $SC_{R}$ & 1 & $MC_{R}$  & $MC_{R}/MC_{E}$\\
 Error Residual & $SC_{E}$ & $n-2$ & $MC_{E}$ & \\\hline
 Total & $S_{yy}$ & $n-1$ & & \\\hline
\end{tabular} 

%\end{frame}

%\begin{frame}

La prueba para la significaci\'on de la regresi\'on puede desarrollarse bas\'andose en la expresi\'on (\ref{Estadistico.Beta.1}), con $\hat{\beta}_{1,0}=0$, es decir
\begin{equation}\label{Estadistico.Beta.1.Cero}
t_{0}=\frac{\hat{\beta}_{1}}{\sqrt{MC_{E}/S_{xx}}}
\end{equation}
Elevando al cuadrado ambos t\'erminos:
\begin{eqnarray*}
t_{0}^{2}=\frac{\hat{\beta}_{1}^{2}S_{xx}}{MC_{E}}=\frac{\hat{\beta}_{1}S_{xy}}{MC_{E}}=\frac{MC_{R}}{MC_{E}}
\end{eqnarray*}
Observar que $t_{0}^{2}=F_{0}$, por tanto la prueba que se utiliza para $t_{0}$ es la misma que para $F_{0}$.


%\end{frame}


\subsection{Estimaci\'on de Intervalos en RLS}

%\begin{frame}

\begin{itemize}
\item Adem\'as de la estimaci\'on puntual para los par\'ametros $\beta_{1}$ y $\beta_{0}$, es posible obtener estimaciones del intervalo de confianza de estos par\'ametros.

\item El ancho de estos intervalos de confianza es una medida de la calidad total de la recta de regresi\'on.

\end{itemize}

Si los $\epsilon_{k}$ se distribuyen normal e independientemente, entonces
\begin{eqnarray*}
\begin{array}{ccc}
\frac{\left(\hat{\beta}_{1}-\beta_{1}\right)}{\sqrt{\frac{MC_{E}}{S_{xx}}}}&y &\frac{\left(\hat{\beta}_{0}-\beta_{0}\right)}{\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}}
\end{array}
\end{eqnarray*}
se distribuyen $t$ con $n-2$ grados de libertad. Por tanto un intervalo de confianza de $100\left(1-\alpha\right)\%$ para $\beta_{1}$ est\'a dado por

%\end{frame}

%\begin{frame}
\begin{eqnarray}
\hat{\beta}_{1}-t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}\leq \beta_{1}\leq\hat{\beta}_{1}+t_{\alpha/2,n-2}\sqrt{\frac{MC_{E}}{S_{xx}}}.
\end{eqnarray}
De igual manera, para $\beta_{0}$ un intervalo de confianza al $100\left(1-\alpha\right)\%$ es
\small{
\begin{eqnarray}
\begin{array}{l}
\hat{\beta}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}\leq\beta_{0}\leq\hat{\beta}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left(\frac{1}{n}+\frac{\overline{x}^{2}}{S_{xx}}\right)}
\end{array}
\end{eqnarray}}

%\end{frame}
%\end{document}
\subsection{Predicci\'on}
%\begin{frame}

Supongamos que se tiene un valor $x_{0}$ de inter\'es, entonces la estimaci\'on puntual de este nuevo valor
\begin{equation}
\hat{y}_{0}=\hat{\beta}_{0}+\hat{\beta}_{1}x_{0}
\end{equation}
\begin{Note}
Esta nueva observaci\'on es independiente de las utilizadas para obtener el modelo de regresi\'on, por tanto, el intervalo en torno a la recta de regresi\'on es inapropiado, puesto que se basa \'unicamente en los datos empleados para ajustar el modelo de regresi\'on.\\

El intervalo de confianza en torno a la recta de regresi\'on se refiere a la respuesta media verdadera $x=x_{0}$, no a observaciones futuras.
\end{Note}

%\end{frame}

%\begin{frame}


Sea $y_{0}$ la observaci\'on futura en $x=x_{0}$, y sea $\hat{y}_{0}$ dada en la ecuaci\'on anterior, el estimador de $y_{0}$. Si se define la variable aleatoria $$w=y_{0}-\hat{y}_{0},$$ esta se distribuye normalmente con media cero y varianza $$V\left(w\right)=\sigma^{2}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]$$
dado que $y_{0}$ es independiente de $\hat{y}_{0}$, por lo tanto el intervalo de predicci\'on al nivel $\alpha$ para futuras observaciones $x_{0}$ es


\begin{eqnarray*}
\hat{y}_{0}-t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}\leq y_{0}\\
\leq \hat{y}_{0}+t_{\alpha/2,n-2}\sqrt{MC_{E}\left[1+\frac{1}{n}+\frac{\left(x-x_{0}\right)^2}{S_{xx}}\right]}.
\end{eqnarray*}


%\end{frame}


\subsection{Prueba de falta de ajuste}
%\begin{frame}\frametitle{Falta de ajuste}
Es com\'un encontrar que el modelo ajustado no satisface totalmente el modelo necesario para los datos, en este caso es preciso saber qu\'e tan bueno es el modelo propuesto. Para esto se propone la siguiente prueba de hip\'otesis:
\begin{itemize}
\item[$H_{0}:$ ]El modelo propuesto se ajusta adecuademente a los datos.
\item[$H_{1}:$ ]El modelo NO se ajusta a los datos.
\end{itemize}
La prueba implica dividir la suma de cuadrados del eror o del residuo en las siguientes dos componentes:
\begin{eqnarray*}
SC_{E}=SC_{EP}+SC_{FDA}
\end{eqnarray*}

%\end{frame}

%\begin{frame}\frametitle{Falta de ajuste}
donde $SC_{EP}$ es la suma de cuadrados atribuibles al error puro, y $SC_{FDA}$ es la suma de cuadrados atribuible a la falta de ajuste del modelo.
%\end{frame}

%%\begin{frame}\frametitle{Falta de ajuste}
%%\end{frame}


\subsection{Coeficiente de Determinaci\'on}

%\begin{frame}

La cantidad
\begin{equation}
R^{2}=\frac{SC_{R}}{S_{yy}}=1-\frac{SC_{E}}{S_{yy}}
\end{equation}
se denomina coeficiente de determinaci\'on y se utiliza para saber si el modelo de regresi\'on es suficiente o no. Se puede demostrar que $0\leq R^{2}\leq1$, una manera de interpretar este valor es que si $R^{2}=k$, entonces el modelo de regresi\'on explica el $k*100\%$ de la variabilidad en los datos.
$R^{2}$ 
\begin{itemize}
\item No mide la magnitud de la pendiente de la recta de regresi\'on
\item Un valor grande de $R^{2}$ no implica una pendiente empinada.
\item No mide la suficiencia del modelo.
\item Valores grandes de $R^{2}$ no implican necesariamente que el modelo de regresi\'on proporcionar\'a predicciones precisas para futuras observaciones.
\end{itemize}


%\end{frame}


