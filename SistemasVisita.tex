\section{Sistemas de Visitas}
%_________________________________________________________________________
%\subsection{Historia}
%_________________________________________________________________________
Los {\emph{Sistemas de Visitas}} fueron introducidos a principios de los a\~nos 50, ver \cite{Boxma,BoonMeiWinands,LevySidi,TesisRoubos,Takagi,Semenova}, con un problema relacionado con las personas encargadas de la revisi\'on y reparaci\'on de m\'aquinas; m\'as adelante fueron utilizados para estudiar problemas de control de se\~nales de tr\'afico. A partir de ese momento el campo de aplicaci\'on ha crecido considerablemente, por ejemplo en: comunicaci\'on en redes de computadoras, rob\'otica, tr\'afico y transporte, manufactura, producci\'on, distribuci\'on de correo, sistema de saludp\'ublica, etc.
%_________________________________________________________________________
%\section{Descripci\'on}
%_________________________________________________________________________

Un modelo de colas es un modelo matem\'atico que describe la situaci\'on en la que uno o varios usuarios solicitan de un servicio a una instancia, computadora o persona. Aquellos usuarios que no son atendidos inmediatamente toman un lugar en una cola en espera de servicio. Un sistema de visitas consiste en modelos de colas conformadas por varias colas y un solo servidor que las visita en alg\'un orden para atender a los usuarios que se encuentran esperando por servicio.

%_________________________________________________________________________
%\section{Objetivos}
%_________________________________________________________________________

Uno de los principales objetivos de este tipo de sistemas es tratar de mejorar el desempe\~no del sistema de visitas. Una de medida de desempe\~no importante es el tiempo de respuesta del sistema, as\'i como los tiempos promedios de espera en una fila y el tiempo promedio total que tarda en ser realizada una operaci\'on completa a lo largo de todo el sistema.\\

Algunas medidas de desempe\~no para los usuarios son los valores promedio de espera para ser atendidos, de servicio, de permanencia total en el sistema; mientras que para el servidor son los valores promedio de permanencia en una cola atendiendo, de traslado entre las colas, de duraci\'on del ciclo entre dos visitas consecutivas a la misma cola, entre otras medidas de desempe\~no estudiadas en la literatura.

%_________________________________________________________________________
%\section{Caracter\'isticas}
%_________________________________________________________________________

En la mayor\'ia de los modelos de colas c\'iclicas, la capacidad de almacenamiento es infinita, es decir la cola puede acomodar a una cantidad infinita de usuarios a la vez.

%_________________________________________________________________________
%\subsection{Clasificaci\'on}
%_________________________________________________________________________
Los sistemas de visitas pueden dividirse en dos clases:
\begin{itemize}
\item[i)] hay varios servidores y los usuarios que llegan al sistema eligen un servidor de entre los que est\'an presentes.

\item[ii)] hay uno o varios servidores que son comunes a todas las colas, estos visitan a cada una de las colas y atienden a los usuarios que est\'an presentes al momento de la visita del
servidor.
\end{itemize}
%_________________________________________________________________________
%\subsection{Tiempos de arribo a las colas}
%_________________________________________________________________________

La manera en que los usuarios llegan a las colas. Los usuarios llegan a las colas de manera tal que los tiempos entre arribos son independientes e id\'enticamente distribuidos. En la mayor\'ia de los modelos de visitas c\'iclicas, la capacidad de almacenamiento es infinita, es decir la cola puede acomodar a una cantidad infinita de usuarios a la vez.

%________________________________________________________
%\subsection{Tiempos de servicio}
%________________________________________________________
Los tiempos de servicio en una cola son usualmente considerados como muestra de una distribuci\'on de probabilidad que caracteriza a la cola, adem\'as se acostumbra considerarlos mutuamente independientes e independientes del estado actual del sistema. 

%________________________________________________________
%\subsection{Traslados del Servidor}
%________________________________________________________

La ruta de atenci\'on del servidor, es el orden en el cual el servidor visita las colas determinado por un mecanismo que puede depender del estado actual del sistema (din\'amico) o puede ser independiente del estado del sistema (est\'atico). 

El mecanismo m\'as utilizado es el c\'iclico. Para modelar sistemas en los cuales ciertas colas son visitadas con mayor frecuencia que otras, las colas c\'iclicas se han extendido a colas peri\'odicas, en las cuales el servidor visita la cola conforme a una orden de servicio de longitud finita. 

El {\em orden de visita} se entiende como la regla utilizada por el servidor para elegir la pr\'oxima cola. Este servicio puede ser din\'amico o est\'atico:

\begin{itemize}
\item[i)] Para el caso {\em est\'atico} la regla permanece invariante a lo largo del curso de la operaci\'on del sistema.

\item[ii)] Para el caso {\em din\'amico} la cola que se elige para servicio en el momento depende de un conocimiento total o parcial del estado del sistema.
\end{itemize}

Dentro de los ordenes de tipo est\'atico hay varios, los m\'as comunes son:

\begin{itemize}
\item[i)] {\em c\'iclico}: Si denotamos por $\left\{Q_{i}\right\}_{i=1}^{N}$ al conjunto de colas a las cuales el servidor visita en el orden \[Q_{1},Q_{2},\ldots,Q_{N},Q_{1},Q_{2},\ldots,Q_{N}.\]

\item[ii)] {\em peri\'odico}: el servidor visita las colas en el orden:
\[Q_{T\left(1\right)},Q_{T\left(2\right)},\ldots,Q_{T\left(M\right)},Q_{T\left(1\right)},\ldots,Q_{T\left(M\right)}\]
caracterizada por una tabla de visitas
\[\left(T\left(1\right),T\left(2\right),\ldots,T\left(M\right)\right),\]
con $M\geq N$, $T\left(i\right)\in\left\{1,2,\ldots,N\right\}$ e $i=\overline{1,M}$. Hay un caso especial, {\em colas tipo elevador} donde las colas son atendidas en el orden \[Q_{1},Q_{2},\ldots,Q_{N},Q_{1},Q_{2},\ldots,Q_{N-1},Q_{N},Q_{N-1},\ldots,Q_{1}\].

\item[iii)] {\em aleatorio}: la cola $Q_{i}$ es elegida para serbatendida con probabilidad $p_{i}$, $i=\overline{1,N}$, $\sum_{i=1}^{N}p_{i}=1$. Una posible variaci\'on es que despu\'es de atender $Q_{i}$ el servidor se desplaza a $Q_{j}$ con probabilidad $p_{ij}$, con $i,j=\overline{1,N}$, $\sum_{j=1}^{N}p_{ij}=1$, para $i=\overline{1,N}$.
\end{itemize}

El servidor usualmente incurrir\'a en tiempos de traslado para ir de una cola a otra. Un sistema de visitas puede expresarse en un par de par\'ametros: el n\'umero de colas, que usualmente se denotar\'a por $N$, y el tr\'afico caracter\'istico de las colas, que consiste de los procesos de arribo y los procesos de servicio, la figura (\ref{Sistema.de.Visitas}) caracteriza a estos sistemas.\\

%________________________________________________________
%\subsection{Disciplina de servicio}
%________________________________________________________

La disciplina de servicio especifica el n\'umero de usuarios que son atendidos durante la visita del servidor a la cola; estas pueden ser clasificadas en l\'imite de usuarios atendidos y en usuarios atendidos en un tiempo l\'imite, poniendo restricciones en la cantidad de tiempo utilizado por el servidor en una visita a la cola. Alternativamente pueden ser clasificadas en pol\'iticas exhaustivas y pol\'iticas cerradas, dependiendo en si los usuarios que llegaron a la cola mientras el servidor estaba dando servicio son candidatos para ser atendidos por el servidor que se encuentra en la cola dando servicio. En la pol\'itica exhaustiva estos usuarios son candidatos para ser atendidos mientras que en la cerrada no lo son. De estas dos pol\'iticas se han creado h\'ibridos los cuales pueden revisarse en \cite{BoonMeiWinands}.

La disciplina de la cola especifica el orden en el cual los usuarios presentes en la cola son atendidos. La m\'as com\'un es la {\em First-In-First-Served}.

%________________________________________________________
%\subsection{Pol\'itica de Servicio}
%________________________________________________________

Las pol\'iticas m\'as comunes son las de tipo exhaustivo que consiste en que el servidor continuar\'a trabajando hasta que la cola quede vac\'ia; y la pol\'itica cerrada, bajo la cual ser\'an atendidos exactamente aquellos que estaban presentes al momento en que lleg\'o el servidor a la cola. 

Las pol\'iticas de servicio deben de satisfacer las siguientes propiedades:
\begin{itemize}
\item[i)] No dependen de los procesos de servicio anteriores.
\item[ii)] La selecci\'on de los usuarios para ser atendidos es independiente del tiempo de servicio requerido  y de los posibles arribos futuros.
\item[iii)] las pol{\'\i}ticas de servicio que son aplicadas, es decir, el n\'umero de usuarios en la cola que ser{\'a}n atendidos durante la visita del servidor a la misma; \'estas pueden ser clasificadas por la cantidad de usuarios atendidos y por el n\'umero de usuarios atendidos en un intervalo de tiempo determinado. Las principales pol\'iticas de servicio para las cuales se han desarrollado aplicaciones son: la exhaustiva, la cerrada y la $k$-l\'imite, ver \cite{LevySidi, Takagi, Semenova}. De estas pol\'iticas se han creado h\'ibridos los cuales pueden revisarse en Boon and Van der Mei \cite{BoonMeiWinands}.

\item[iv)] Una pol{\'\i}tica de servicio es asignada a cada etapa independiente de la cola que se est{\'a} atendiendo, no necesariamente es la misma para todas las etapas.
\item[v)] El servidor da servicio de manera constante.

\item[vi)] La pol\'itica de servicio se asume mon\'otona (ver
\cite{Stability}).

\end{itemize}

Las principales pol\'iticas deterministas de servicio son:
\begin{itemize}

\item[i)] {\em Cerrada} donde solamente los usuarios presentes al comienzo de la etapa son considerados para ser atendidos.

\item[ii)] {\em Exhaustiva} en la que tanto los usuarios presentes al comienzo de la etapa como los que arriban   mientras se est\'a dando servicio son considerados para ser atendidos.

\item[iii)] $k_{i}$-limited: el n\'umero de usuarios por atender en la cola $i$ est\' acotado por $k_{i}$.

\item[iv)] {\em tiempo limitado} la cola es atendida solo por un periodo de tiempo fijo.
\end{itemize}

%________________________________________________________
%\subsection*{Extras}
%________________________________________________________
\begin{itemize}
\item Una etapa es el periodo de tiempo durante el cual el
servidor atiende de manera continua en una sola cola.

\item Un ciclo  es el periodo necesario para terminar $l$ etapas.

\end{itemize}


Boxma y Groenendijk \cite{Boxma2} enuncian la Ley de
Pseudo-Conservaci\'on para la pol\'itica exhaustiva como

\begin{equation}\label{LPCPE}
\sum_{i=1}^{N}\rho_{i}\esp
W_{i}=\rho\frac{\sum_{i=1}^{N}\lambda_{i}\esp\left[\delta_{i}^{(2)}\left(1\right)\right]}{2\left(1-\rho\right)}+\rho\frac{\delta^{(2)}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\left[\rho^{2}-\sum_{i=1}^{N}\rho_{i}^{2}\right],
\end{equation}

donde $\delta=\sum_{i=1}^{N}\delta_{i}\left(1\right)$ y
$\delta_{i}^{(2)}$ denota el segundo momento de los tiempos de traslado entre colas del servidor, $\delta^{(2)}$ es el segundo momento de los tiempos de traslado entre las colas de todo el sistema, finalmente sea $\rho=\sum_{i=1}^{N}\rho_{i}$. Por otro lado, se tiene que

\begin{equation}\label{Eq.Tiempo.Espera}
\esp W_{i}=\frac{\esp I_{i}^{2}}{2\esp
I_{i}}+\frac{\lambda_{i}\esp\left[\eta_{i}^{(2)}\left(1\right)\right]}{2\left(1-\rho_{i}\right)},
\end{equation}

con $I_{i}$ definido como el peri\'odo de intervisita, es decir el tiempo entre una salida y el pr\'oximo arribo del servidor a la cola $Q_{i}$, dado por $I_{i}=C_{i}-V_{i}$, donde $C_{i}$ es la longitud del ciclo, definido como el tiempo entre dos instantes de
visita consecutivos a la cola $Q_{i}$ y $V_{i}$ es el periodo de visita, definido como el tiempo que el servidor utiliza en atender a los usuarios de la cola $Q_{i}$.
\begin{equation}\label{Eq.Periodo.Intervisita}
\esp
I_{i}=\frac{\left(1-\rho_{i}\right)}{1-\rho}\sum_{i=1}^{N}\esp\left[\delta_{i}\left(1\right)\right],
\end{equation}

con

\begin{equation}\label{Eq.Periodo.Intervisita}
\esp
I_{i}^{2}=\esp\left[\delta_{i-1}^{(2)}\left(1\right)\right]-\left(\esp\left[\delta_{i-1}\left(1\right)\right]\right)^{2}+
\frac{1-\rho_{i}}{\rho_{i}}\sum_{j=1,j\neq i}^{N}r_{ij}+\left(\esp
I_{i}\right)^{2},
\end{equation}

donde el conjunto de valores $\left\{r_{ij}:i,j=1,2,\ldots,N\right\}$ representan la covarianza del tiempo para las colas $i$ y $j$; para sistemas con servicio
exhaustivo, el tiempo de estaci\'on para la cola $i$ se define como el intervalo de tiempo entre instantes sucesivos cuando el servidor abandona la cola $i-1$ y la cola $i$. Hideaki Takagi \cite{Takagi} proporciona expresiones cerradas para calcular $r_{ij}$, \'estas implican resolver un sistema de $N^{2}$
Ecuaciones lineales;

%{\footnotesize{
\begin{eqnarray}\label{Eq.Cov.TT}
r_{ij}&=&\frac{\rho_{i}}{1-\rho_{i}}\left(\sum_{m=i+1}^{N}r_{jm}+\sum_{m=1}^{j-1}r_{jm}+\sum_{m=j}^{i-1}r_{jm}\right),\textrm{
}j<i,\\
r_{ij}&=&\frac{\rho_{i}}{1-\rho_{i}}\left(\sum_{m=i+1}^{j-1}r_{jm}+\sum_{m=j}^{N}r_{jm}+\sum_{m=1}^{i-1}r_{jm}\right),\textrm{
}j>i,\\
r_{ij}&=&\frac{\esp\left[\delta_{i-1}^{(2)}\left(1\right)\right]-\left(\esp\left[\delta_{i-1}\left(1\right)\right]\right)^{2}}
{\left(1-\rho_{i}\right)^{2}}+\frac{\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]}{\left(1-\rho_{i}\right)^{3}}+\frac{\rho_{i}}{1-\rho_{i}}\sum_{j=i,j=1}^{N}r_{ij}.
\end{eqnarray}%}}

Para el caso de la Pol\'itica Cerrada la Ley de Pseudo-Conservaci\'on se expresa en los siguientes t\'erminos.
\begin{equation}\label{LPCPG}
\sum_{i=1}^{N}\rho_{i}\esp
W_{i}=\rho\frac{\sum_{i=1}^{N}\lambda_{i}\esp\left[\delta_{i}\left(1\right)^{(2)}\right]}{2\left(1-\rho\right)}+\rho\frac{\delta^{(2)}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\left[\rho^{2}+\sum_{i=1}^{N}\rho_{i}^{2}\right],
\end{equation}
el tiempo de espera promedio para los usuarios en la cola $Q_{1}$ se puede determinar por medio de
\begin{equation}\label{Eq.Tiempo.Espera.Gated}
\esp W_{i}=\frac{\left(1+\rho_{i}\right)\esp C_{i}^{2}}{2\esp
C_{i}},
\end{equation}
donde $C_{i}$ denota la longitud del ciclo para la cola $Q_{i}$, definida como el tiempo entre dos instantes consecutivos de visita en $Q_{i}$, cuyo segundo momento est\'a dado por

\begin{equation}\label{Eq.Periodo.Intervisita.Gated}
\esp C_{i}^{2}=\frac{1}{\rho_{i}}\sum_{j=1,j\neq
i}^{N}r_{ij}+\sum_{j=1}^{N}r_{ij}+\left(\esp C\right)^{2},
\end{equation}
con
\begin{eqnarray*}
\esp C=\frac{\delta}{1-\rho},
\end{eqnarray*}

donde $r_{ij}$ representa la covarianza del tiempo de estaci\'on para las colas $i$ y $j$, pero el tiempo de estaci\'on para la cola $i$ para la pol\'itica cerrada se define como el intervalo de tiempo entre instantes sucesivos cuando el servidor visita la cola $i$ y la cola $i+1$. El conjunto $\left\{r_{ij}:i,j=1,2,\ldots,N\right\}$ se calcula resolviendo un
sistema de $N^{2}$ ecuaciones lineales

\begin{eqnarray}\label{Eq.Cov.TT.Gated}
r_{ij}&=&\rho_{i}\left(\sum_{m=i}^{N}r_{jm}+\sum_{m=1}^{j-1}r_{jm}+\sum_{m=j}^{i-1}r_{mj}\right),\textrm{
}j<i,\\
r_{ij}&=&\rho_{i}\left(\sum_{m=i}^{j-1}r_{jm}+\sum_{m=j}^{N}r_{jm}+\sum_{m=1}^{i-1}r_{mj}\right),\textrm{
}j>i,\\
r_{ij}&=&r_{i-1}^{(2)}-\left(r_{i-1}^{(1)}\right)^{2}+\lambda_{i}b_{i}^{(2)}\esp
C_{i}+\rho_{i}\sum_{j=1,j\neq
i}^{N}r_{ij}+\rho_{i}^{2}\sum_{i=j,j=1}^{N}r_{ij}.
\end{eqnarray}

Finalmente, Takagi \cite{Takagi} proponen una aproximaci\'on para los tiempos de espera de los usuarios en cada una de las colas:
\begin{eqnarray*}
\sum_{i=1}^{N}\frac{\rho_{i}}{\rho}\left(1-\frac{\lambda_{i}\delta}{1-\rho}\right)\esp\left[W_{i}\right]&=&\sum_{i=1}^{N}\frac{\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]}{2\left(1-\rho\right)}\\
+\frac{\sum_{i=1}^{N}\esp\left[\delta_{i}^{2}\right]-\left(\esp\left[\delta_{i}\left(1\right)\right]\right)^{2}}{2\delta}&+&\frac{\delta\left(\rho-\sum_{i=1}^{N}\rho_{i}^{2}\right)}{2\rho\left(1-\rho\right)}+\frac{\delta\sum_{i=1}^{N}\rho_{i}^{2}}{\rho\left(1-\rho\right)},
\end{eqnarray*}
entonces
\begin{eqnarray*}\label{LPCPKL}
\esp
W_{i}&\cong&\frac{1-\rho+\rho_{i}}{1-\rho-\lambda_{i}\delta}\times\frac{1-\rho}{\rho\left(1-\rho\right)+\sum_{i=1}^{N}\rho_{i}^{2}}\\
&\times&\left[\frac{\rho}{2\left(1-\rho\right)}\sum_{i=1}^{N}\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]+\frac{\rho\Delta^{2}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\sum_{i=1}^{N}\rho_{i}\left(1+\rho_{i}\right).\right]
\end{eqnarray*}
donde $\Delta^{2}=\sum_{i=1}^{N}\delta_{i}^{2}$. 

El modelo est\'a compuesto por $c$ colas de capacidad infinita, etiquetadas de $1$ a $c$ las cuales son atendidas por $s$
servidores. Los servidores atienden de acuerdo a una cadena de Markov independiente $\left(X^{i}_{n}\right)_{n}$ con $1\leq i\leq s$ y $n\in\left\{1,2,\ldots,c\right\}$ con la misma matriz de transici\'on $r_{k,l}$ y \'unica medida invariante $\left(p_{k}\right)$. Cada servidor permanece atendiendo en la cola un periodo llamado de visita y determinada por la pol\'itica de
servicio asignada a la cola.

Los usuarios llegan a la cola $k$ con una tasa $\lambda_{k}$ y son atendidos a una raz\'on $\mu_{k}$. Las sucesiones de tiempos de interarribo $\left(\tau_{k}\left(n\right)\right)_{n}$, la de
tiempos de servicio $\left(\sigma_{k}^{i}\left(n\right)\right)_{n}$ y la de tiempos de cambio $\left(\sigma_{k,l}^{0,i}\left(n\right)\right)_{n}$ requeridas en la cola $k$ para el servidor $i$ son sucesiones independientes e id\'enticamente distribuidas con distribuci\'on general independiente de $i$, con media $\sigma_{k}=\frac{1}{\mu_{k}}$, respectivamente $\sigma_{k,l}^{0}=\frac{1}{\mu_{k,l}^{0}}$, e independiente de las cadenas de Markov $\left(X^{i}_{n}\right)_{n}$. Adem\'as se supone que los tiempos de interarribo se asume son acotados, para cada $\rho_{k}=\lambda_{k}\sigma_{k}<s$ para asegurar la estabilidad de la cola $k$ cuando opera como una cola $M/GM/1$.

Una pol\'itica de servicio determina el n\'umero de usuarios que ser\'an atendidos sin interrupci\'on en periodo de servicio por los servidores que atienden a la cola. Para un solo servidor esta se define a trav\'es de una funci\'on $f$ donde $f\left(x,a\right)$ es el n\'umero de usuarios que son atendidos sin interrupci\'on cuando el servidor llega a la cola y encuentra $x$ usuarios esperando dado el tiempo transcurrido de interarribo $a$. Sea $v\left(x,a\right)$ la du raci\'on del periodo de servicio para una sola condici\'on inicial $\left(x,a\right)$.

Las pol\'iticas de servicio consideradas satisfacen las siguientes
propiedades:

\begin{itemize}
\item[i)] Hay conservaci\'on del trabajo, es decir
\[v\left(x,a\right)=\sum_{l=1}^{f\left(x,a\right)}\sigma\left(l\right)\]
con $f\left(0,a\right)=v\left(0,a\right)=0$, donde
$\left(\sigma\left(l\right)\right)_{l}$ es una sucesi\'on independiente e id\'enticamente distribuida de los tiempos de servicio solicitados. 
\item[ii)] La selecci\'on de usuarios para se atendidos es independiente de sus correspondientes tiempos de servicio y del pasado hasta el inicio del periodo de servicio. As\'i las distribuci\'on $\left(f,v\right)$ no depende del orden en el cu\'al son atendidos los usuarios. \item[iii)] La pol\'itica de servicio es mon\'otona en el sentido de que para cada $a\geq0$ los n\'umeros $f\left(x,a\right)$ son mon\'otonos en distribuci\'on en $x$ y su l\'imite en distribuci\'on cuando $x\rightarrow\infty$ es una variable aleatoria $F^{*0}$ que no depende de $a$. \item[iv)] El n\'umero de usuarios atendidos por cada servidor es acotado por
$f^{min}\left(x\right)$ de la longitud de la cola $x$ que adem\'as converge mon\'otonamente en distribuci\'on a $F^{*}$ cuando $x\rightarrow\infty$
\end{itemize}



Un sistema de visitas o sistema de colas consiste en un cierto n\'umero de filas o colas atendidas por un solo servidor en un orden determinado, estos se puede aplicar en situaciones en las cuales varios tipos de usuarios intentan tener acceso a una fuente en com\'un que est\'a disponible para un solo tipo de usuario a la vez. 

Un sistema de visitas consiste en varias colas a las cuales los usuarios llegan conforme a un proceso poisson con tasa $\lambda_{i}$; la capacidad de las mismas, es decir, el n\'umero de lugares disponibles; el n\'umero de servidores que llegan a la cola correspondiente para dar servicio a los usuarios; la manera en que los servidores dan servicio; el tiempo que tarda el servidor en ir de una a otra cola, as\'i como el orden y la disciplina de servicio de la cola; la pol\'itica de servicio determina cuales y cuantos usuarios ser\'an atendidos durante la visita del servidor a la cola.\\

Las pol\'iticas m\'as comunes son las de tipo exhaustivo que consiste en que el servidor continuar\'a trabajando hasta que la cola quede vac\'ia; y la pol\'itica cerrada, bajo la cual ser\'an atendidos exactamente aquellos que estaban presentes al momento en que lleg\'o el servidor a la cola. El esquema de ruta determina en que orden el servidor visitara a las colas. La decisi\'on del servidor sobre la pr\'oxima cola que visitar\'a puede depender de la informaci\'on disponible para el servidor, por ejemplo las longitudes de las
colas.\\

El servidor usualmente incurrir\'a en tiempos de traslado para ir de una cola a otra. Un sistema de visitas puede expresarse en un par de par\'ametros: el n\'umero de colas, que usualmente se denotar\'a por $N$, y el tr\'afico caracter\'istico de las colas, que consiste de los procesos de arribo y los procesos de servicio, la figura (\ref{GRafSistColasCiclicas}) caracteriza a estos sistemas.\\

Algunas medidas de desempe\~no para los usuarios son los valores promedio de espera para ser atendidos, de servicio, de permanencia total en el sistema; mientras que para el servidor son los valores promedio de permanencia en una cola atendiendo, de traslado entre las colas, de duraci\'on del ciclo entre dos visitas consecutivas a la misma cola, entre otras medidas de desempe\~no estudiaddas en la literatura.


%___________________________________________________________________________________________
%
 \section{Funci\'on Generadora de Probabilidades}
%___________________________________________________________________________________________

\begin{Teo}[Teorema de Continuidad]
Sup\'ongase que $\left\{X_{n},n=1,2,3,\ldots\right\}$ son variables aleatorias finitas, no negativas con valores enteros tales que $P\left(X_{n}=k\right)=p_{k}^{(n)}$, para $n=1,2,3,\ldots$, $k=0,1,2,\ldots$, con $\sum_{k=0}^{\infty}p_{k}^{(n)}=1$, para $n=1,2,3,\ldots$. Sea $g_{n}$ la PGF para la variable aleatoria $X_{n}$. Entonces existe una sucesi\'on $\left\{p_{k}\right\}$ tal que \begin{eqnarray*}
lim_{n\rightarrow\infty}p_{k}^{(n)}=p_{k}\textrm{ para }0<s<1.
\end{eqnarray*}

En este caso, $g\left(s\right)=\sum_{k=0}^{\infty}s^{k}p_{k}$. Adem\'as
\begin{eqnarray*}
\sum_{k=0}^{\infty}p_{k}=1\textrm{ si y s\'olo si
}lim_{s\uparrow1}g\left(s\right)=1
\end{eqnarray*}
\end{Teo}

\begin{Teo}
Sea $N$ una variable aleatoria con valores enteros no negativos finita tal que $P\left(N=k\right)=p_{k}$, para $k=0,1,2,\ldots$, y $\sum_{k=0}^{\infty}p_{k}=P\left(N<\infty\right)=1$. Sea $\Phi$ la PGF de $N$ tal que
$g\left(s\right)=\esp\left[s^{N}\right]=\sum_{k=0}^{\infty}s^{k}p_{k}$ con $g\left(1\right)=1$. Si $0\leq p_{1}\leq1$ y $\esp\left[N\right]=g^{'}\left(1\right)\leq1$, entonces no existe soluci\'on  de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$. Si $\esp\left[N\right]=g^{'}\left(1\right)>1$, lo cual implica que $0\leq p_{1}<1$, entonces existe una \'unica soluci\'on de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$.
\end{Teo}


\begin{Teo}
Si $X$ y $Y$ tienen PGF $G_{X}$ y $G_{Y}$ respectivamente, entonces,\[G_{X}\left(s\right)=G_{Y}\left(s\right)\] para tod $s$, si y s\'olo si \[P\left(X=k\right))=P\left(Y=k\right)\] para toda $k=0,1,\ldots,$., es decir, si y s\'olo si $X$ y $Y$ tienen la misma distribuci\'on de probabilidad.
\end{Teo}


\begin{Teo}
Para cada $n$ fijo, sea la sucesi\'oin de probabilidades $\left\{a_{0,n},a_{1,n},\ldots,\right\}$, tales que $a_{k,n}\geq0$ para toda $k=0,1,2,\ldots,$ y $\sum_{k\geq0}a_{k,n}=1$, y sea $G_{n}\left(s\right)$ la correspondiente funci\'on generadora, $G_{n}\left(s\right)=\sum_{k\geq0}a_{k,n}s^{k}$. De modo que para cada valor fijo de $k$
\begin{eqnarray*}
lim_{n\rightarrow\infty}a_{k,n}=a_{k},
\end{eqnarray*}
es decir converge en distribuci\'on, es necesario y suficiente que para cada valor fijo $s\in\left[0,\right)$,

\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{n}\left(s\right)=G\left(s\right),
\end{eqnarray*}
donde $G\left(s\right)=\sum_{k\geq0}p_{k}s^{k}$, para cualquier la funci\'on generadora del l\'imite de la sucesi\'on.
\end{Teo}

\begin{Teo}[Teorema de Abel]
Sea $G\left(s\right)=\sum_{k\geq0}a_{k}s^{k}$ para cualquier $\left\{p_{0},p_{1},\ldots,\right\}$, tales que $p_{k}\geq0$ para toda $k=0,1,2,\ldots,$. Entonces $G\left(s\right)$ es continua por la derecha en $s=1$, es decir
\begin{eqnarray*}
lim_{s\uparrow1}G\left(s\right)=\sum_{k\geq0}p_{k}=G\left(\right),
\end{eqnarray*}
sin importar si la suma es finita o no.
\end{Teo}

\begin{Note}
El radio de Convergencia para cualquier PGF es $R\geq1$, entonces, el Teorema de Abel nos dice que a\'un en el peor escenario, cuando $R=1$, a\'un se puede confiar en que la PGF ser\'a continua en $s=1$, en contraste, no se puede asegurar que la PGF ser\'a continua en el l\'imite inferior $-R$, puesto que la PGF es sim\'etrica alrededor del cero: la PGF converge para todo $s\in\left(-R,R\right)$, y no lo hace para $s<-R$ o $s>R$. Adem\'as nos dice que podemos escribir $G_{X}\left(1\right)$ como una abreviaci\'on de $lim_{s\uparrow1}G_{X}\left(s\right)$.
\end{Note}

Entonces si suponemos que la diferenciaci\'on t\'ermino a t\'ermino est\'a permitida, entonces

\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x}
\end{eqnarray*}

el Teorema de Abel nos dice que
\begin{eqnarray*}
\esp\left(X\right]&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right):\\
\esp\left[X\right]&=&=\sum_{x=1}^{\infty}xp_{x}=G_{X}^{'}\left(1\right)\\
&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right),
\end{eqnarray*}
dado que el Teorema de Abel se aplica a
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x},
\end{eqnarray*}
estableciendo as\'i que $G_{X}^{'}\left(s\right)$ es continua en $s=1$. Sin el Teorema de Abel no se podr\'ia asegurar que el l\'imite de $G_{X}^{'}\left(s\right)$ conforme $s\uparrow1$ sea la respuesta correcta para $\esp\left[X\right]$.

\begin{Note}
La PGF converge para todo $|s|<R$, para alg\'un $R$. De hecho la PGF converge absolutamente si $|s|<R$. La PGF adem\'as converge uniformemente en conjuntos de la forma $\left\{s:|s|<R^{'}\right\}$, donde $R^{'}<R$, es decir, $\forall\epsilon>0, \exists n_{0}\in\ent$ tal que $\forall s$, con $|s|<R^{'}$, y $\forall n\geq n_{0}$,
\begin{eqnarray*}
|\sum_{x=0}^{n}s^{x}\prob\left(X=x\right)-G_{X}\left(s\right)|<\epsilon.
\end{eqnarray*}
De hecho, la convergencia uniforme es la que nos permite diferenciar t\'ermino a t\'ermino:
\begin{eqnarray*}
G_{X}\left(s\right)=\esp\left[s^{X}\right]=\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right),
\end{eqnarray*}
y sea $s<R$.
\begin{enumerate}
\item
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\frac{d}{ds}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)=\sum_{x=0}^{\infty}\frac{d}{ds}\left(s^{x}\prob\left(X=x\right)\right)\\
&=&\sum_{x=0}^{n}xs^{x-1}\prob\left(X=x\right).
\end{eqnarray*}

\item\begin{eqnarray*}
\int_{a}^{b}G_{X}\left(s\right)ds&=&\int_{a}^{b}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)ds=\sum_{x=0}^{\infty}\left(\int_{a}^{b}s^{x}\prob\left(X=x\right)ds\right)\\
&=&\sum_{x=0}^{\infty}\frac{s^{x+1}}{x+1}\prob\left(X=x\right),
\end{eqnarray*}
para $-R<a<b<R$.
\end{enumerate}
\end{Note}

\begin{Teo}[Teorema de Convergencia Mon\'otona para PGF] Sean $X$ y $X_{n}$ variables aleatorias no negativas, con valores en los enteros, finitas, tales que
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{X_{n}}\left(s\right)&=&G_{X}\left(s\right)
\end{eqnarray*}
para $0\leq s\leq1$, entonces
\begin{eqnarray*}
lim_{n\rightarrow\infty}P\left(X_{n}=k\right)=P\left(X=k\right),
\end{eqnarray*}
para $k=0,1,2,\ldots.$
\end{Teo}

El teorema anterior requiere del siguiente lema

\begin{Lemma}
Sean $a_{n,k}\in\ent^{+}$, $n\in\nat$ constantes no negativas con
$\sum_{k\geq0}a_{k,n}\leq1$. Sup\'ongase que para $0\leq s\leq1$,
se tiene
\begin{eqnarray*}
a_{n}\left(s\right)&=&\sum_{k=0}^{\infty}a_{k,n}s^{k}\rightarrow
a\left(s\right)=\sum_{k=0}^{\infty}a_{k}s^{k}.
\end{eqnarray*}
Entonces
\begin{eqnarray*}
a_{0,n}\rightarrow a_{0}.
\end{eqnarray*}
\end{Lemma}

Consideremos un sistema que consta de \'unicamente un servidor y una sola cola, a la cual los usuarios arriban conforme a un proceso poisson cuya tasa promedio de llegada es $1/\lambda$; la tasa promedio con la cual el servidor da servicio es $1/\mu$, adem\'as los tiempos entre arribos y los tiempos de servicio son independientes entre s\'i.

Se define la carga de tr\'afico $\rho:=\frac{\lambda}{\mu}$, para este modelo existe un teorema que nos dice la relaci\'on que hay entre el valor de $\rho$ y la estabilidad de la cola:

\begin{Prop}
La cola $M/M/1$ con carga de tr\'afico $\rho$, es estable si y s\'olo si $\rho<1$.
\end{Prop}

Este teorema nos permite determinar las principales medidas de desempe\~no: Tiempo de espera en el sistema, $W$, el n\'umero esperado de clientes en el sistema, $L$, adem\'as de los tiempos promedio e espera tanto en la cola como de servicio, $s$ representa el tiempo de servicio para un cliente:

\begin{eqnarray}
 L&=&\frac{\rho}{1-\rho},\\
W&=&\frac{1}{\mu-\lambda},\\
W_{q}&=&\esp\left[s\right]\frac{\rho}{1-\rho}\textrm{,  y }\\
L_{q}&=&\frac{\rho^{2}}{1-\rho}.
\end{eqnarray}

Esta es la idea general, poder determinar la principales medidas de desempe\~no para un sistema de colas o sistema de visitas, para este fin es necesario realizar los siguientes supuestos. En teor\'ia de colas hay casos particulares, para los cuales es posible determinar espec\'ificamente medidas de desempe\~no del sistema bajo condiciones de estabilidad, tales como los tiempos promedio de espera y de servicio, tanto en el sistema como en cada
una de las colas.


En teor\'ia de colas hay casos particulares, para los cuales es posible determinar espec\'ificamente medidas de desempe\~no del sistema bajo condiciones de estabilidad, tales como los tiempos promedio de espera y de servicio, tanto en el sistema como en cada
una de las colas. Se considerar\'an intervalos de tiempo de la forma $\left[t,t+1\right]$. Los usuarios arriban por paquetes de manera independiente del resto de las colas. Se define el grupo de usuarios que llegan a cada una de las colas del sistema 1, caracterizadas por $Q_{1}$ y $Q_{2}$ respectivamente, en el intervalo de tiempo $\left[t,t+1\right]$ por $X_{1}\left(t\right),X_{2}\left(t\right)$.

Para cada uno de los procesos anteriores se define su Funci\'on Generadora de Probabilidades (PGF):

\begin{eqnarray*}
\begin{array}{cc}
P_{1}\left(z_{1}\right)=\esp\left[z_{1}^{X_{1}\left(t\right)}\right], & P_{2}\left(z_{2}\right)=\esp\left[z_{2}^{X_{2}\left(t\right)}\right].\\
\end{array}
\end{eqnarray*}

Con primer momento definidos por

\begin{eqnarray*}
\mu_{1}&=&\esp\left[X_{1}\left(t\right)\right]=P_{1}^{(1)}\left(1\right),\\
\mu_{2}&=&\esp\left[X_{2}\left(t\right)\right]=P_{2}^{(1)}\left(1\right).
\end{eqnarray*}


En lo que respecta al servidor, en t\'erminos de los tiempos de visita a cada una de las colas, se denotar\'an por $\tau_{1},\tau_{2}$ para $Q_{1},Q_{2}$ respectivamente; y a los
tiempos en que el servidor termina de atender en las colas $Q_{1},Q_{2}$, se les denotar\'a por $\overline{\tau}_{1},\overline{\tau}_{2}$ respectivamente. Entonces, los tiempos de servicio est\'an dados por las diferencias $\overline{\tau}_{1}-\tau_{1},\overline{\tau}_{2}-\tau_{2}$ para $Q_{1},Q_{2}$. An\'alogamente los tiempos de traslado del servidor desde el momento en que termina de atender a una cola y llega a la siguiente para comenzar a dar servicio est\'an dados por $\tau_{2}-\overline{\tau}_{1},\tau_{1}-\overline{\tau}_{2}$.


La FGP para estos tiempos de traslado est\'an dados por

\begin{eqnarray*}
\begin{array}{cc}
R_{1}\left(z_{1}\right)=\esp\left[z_{1}^{\tau_{2}-\overline{\tau}_{1}}\right],
&
R_{2}\left(z_{2}\right)=\esp\left[z_{2}^{\tau_{1}-\overline{\tau}_{2}}\right],
\end{array}
\end{eqnarray*}

y al igual que como se hizo con anterioridad

\begin{eqnarray*}
\begin{array}{cc}
r_{1}=R_{1}^{(1)}\left(1\right)=\esp\left[\tau_{2}-\overline{\tau}_{1}\right],
&
r_{2}=R_{2}^{(1)}\left(1\right)=\esp\left[\tau_{1}-\overline{\tau}_{2}\right],\\
\end{array}
\end{eqnarray*}
Sean $\alpha_{1},\alpha_{2}$ el n\'umero de usuarios que arriban
en grupo a la cola $Q_{1}$ y $Q_{2}$ respectivamente. Sus PGF's
est\'an definidas como

\begin{eqnarray*}
\begin{array}{cc}
A_{1}\left(z\right)=\esp\left[z^{\alpha_{1}\left(t\right)}\right],&
A_{2}\left(z\right)=\esp\left[z^{\alpha_{2}\left(t\right)}\right].\\
\end{array}
\end{eqnarray*}

Su primer momento est\'a dado por

\begin{eqnarray*}
\begin{array}{cc}
\lambda_{1}=\esp\left[\alpha_{1}\left(t\right)\right]=A_{1}^{(1)}\left(1\right),&
\lambda_{2}=\esp\left[\alpha_{2}\left(t\right)\right]=A_{2}^{(1)}\left(1\right).\\
\end{array}
\end{eqnarray*}

Sean $\beta_{1},\beta_{2}$ el n\'umero de usuarios que arriban en el grupo $\alpha_{1},\alpha_{2}$ a la cola $Q_{1}$ y $Q_{2}$, respectivamente, de igual manera se definen sus PGF's

\begin{eqnarray*}
\begin{array}{cc}
B_{1}\left(z\right)=\esp\left[z^{\beta_{1}\left(t\right)}\right],&
B_{2}\left(z\right)=\esp\left[z^{\beta_{2}\left(t\right)}\right],\\
\end{array}
\end{eqnarray*}

con

\begin{eqnarray*}
\begin{array}{cc}
b_{1}=\esp\left[\beta_{1}\left(t\right)\right]=B_{1}^{(1)}\left(1\right),&
b_{2}=\esp\left[\beta_{2}\left(t\right)\right]=B_{2}^{(1)}\left(1\right).\\
\end{array}
\end{eqnarray*}

La distribuci\'on para el n\'umero de grupos que arriban al sistema en cada una de las colas se definen por:

\begin{eqnarray*}
\begin{array}{cc}
P_{1}\left(z_{1}\right)=A_{1}\left[B_{1}\left(z_{1}\right)\right]=\esp\left[B_{1}\left(z_{1}\right)^{\alpha_{1}\left(t\right)}\right],& P_{2}\left(z_{1}\right)=A_{1}\left[B_{1}\left(z_{1}\right)\right]=\esp\left[B_{1}\left(z_{1}\right)^{\alpha_{1}\left(t\right)}\right],\\
\end{array}
\end{eqnarray*}

entonces

\begin{eqnarray*}
P_{1}^{(1)}\left(1\right)&=&\esp\left[\alpha_{1}\left(t\right)B_{1}^{(1)}\left(1\right)\right]=B_{1}^{(1)}\left(1\right)\esp\left[\alpha_{1}\left(t\right)\right]=\lambda_{1}b_{1}\\
P_{2}^{(1)}\left(1\right)&=&\esp\left[\alpha_{2}\left(t\right)B_{2}^{(1)}\left(1\right)\right]=B_{2}^{(1)}\left(1\right)\esp\left[\alpha_{2}\left(t\right)\right]=\lambda_{2}b_{2}.\\
\end{eqnarray*}

De lo desarrollado hasta ahora se tiene lo siguiente

\begin{eqnarray*}
&&\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=\esp\left[z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)+X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right]\\
&=&\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{z_{2}^{X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right\}\right]=\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{P_{2}\left(z_{2}\right)\right\}^{\overline{\tau}_{1}-\tau_{1}}\right]\\
&=&\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{\theta_{1}\left(P_{2}\left(z_{2}\right)\right)\right\}^{L_{1}\left(\tau_{1}\right)}\right]=F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)
\end{eqnarray*}

es decir 
\begin{equation}\label{Eq.base.F1}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right).
\end{equation}

Procediendo de manera an\'aloga para $\overline{\tau}_{2}$:

\begin{eqnarray*}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{2}\right)}\right]&=&\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}\right]=\esp\left[z_{1}^{L_{1}\left(\tau_{2}\right)+X_{1}\left(\overline{\tau}_{2}-\tau_{2}\right)}\right]=\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{z_{1}^{X_{1}\left(\overline{\tau}_{2}-\tau_{2}\right)}\right\}\right]\\
&=&\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{P_{1}\left(z_{1}\right)\right\}^{\overline{\tau}_{2}-\tau_{2}}\right]=\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right\}^{L_{2}\left(\tau_{2}\right)}\right]\\
&=&F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)
\end{eqnarray*}
por tanto
\begin{equation}\label{Eq.PGF.Conjunta.Tau2}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{2}\right)}\right]=F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)
\end{equation}

Ahora, para el intervalo de tiempo
$\left[\overline{\tau}_{1},\tau_{2}\right]$ y $\left[\overline{\tau}_{2},\tau_{1}\right]$, los arribos de los usuarios modifican el n\'umero de usuarios que llegan a las colas, es decir, los procesos
$L_{1}\left(t\right)$ y $L_{2}\left(t\right)$. La PGF para el n\'umero de arribos a todas las estaciones durante el intervalo $\left[\overline{\tau}_{1},\tau_{2}\right]$  cuya distribuci\'on est\'a especificada por la distribuci\'on compuesta $R_{1}\left(\mathbf{z}\right),R_{2}\left(\mathbf{z}\right)$:

\begin{eqnarray*}
R_{1}\left(\mathbf{z}\right)=R_{1}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)=\esp\left[\left\{\prod_{i=1}^{2}P\left(z_{i}\right)\right\}^{\tau_{2}-\overline{\tau}_{1}}\right]\\
R_{2}\left(\mathbf{z}\right)=R_{2}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)=\esp\left[\left\{\prod_{i=1}^{2}P\left(z_{i}\right)\right\}^{\tau_{1}-\overline{\tau}_{2}}\right]\\
\end{eqnarray*}

Dado que los eventos en
$\left[\tau_{1},\overline{\tau}_{1}\right]$ y $\left[\overline{\tau}_{1},\tau_{2}\right]$ son independientes, la
PGF conjunta para el n\'umero de usuarios en el sistema al tiempo $t=\tau_{2}$ la PGF conjunta para el n\'umero de usuarios en el sistema est\'an dadas por

\begin{eqnarray*}
F_{1}\left(\mathbf{z}\right)&=&R_{2}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)\\
F_{2}\left(\mathbf{z}\right)&=&R_{1}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)\\
\end{eqnarray*}

Entonces debemos de determinar las siguientes expresiones:

\begin{eqnarray*}
\begin{array}{cc}
f_{1}\left(1\right)=\frac{\partial F_{1}\left(\mathbf{z}\right)}{\partial z_{1}}|_{\mathbf{z}=1}, & f_{1}\left(2\right)=\frac{\partial F_{1}\left(\mathbf{z}\right)}{\partial z_{2}}|_{\mathbf{z}=1},\\
f_{2}\left(1\right)=\frac{\partial F_{2}\left(\mathbf{z}\right)}{\partial z_{1}}|_{\mathbf{z}=1}, & f_{2}\left(2\right)=\frac{\partial F_{2}\left(\mathbf{z}\right)}{\partial z_{2}}|_{\mathbf{z}=1},\\
\end{array}
\end{eqnarray*}

calculando las derivadas parciales 
\begin{eqnarray*}
\frac{\partial R_{1}\left(\mathbf{z}\right)}{\partial
z_{1}}|_{\mathbf{z}=1}&=&R_{1}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial R_{1}\left(\mathbf{z}\right)}{\partial
z_{2}}|_{\mathbf{z}=1}&=&R_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\frac{\partial R_{2}\left(\mathbf{z}\right)}{\partial
z_{1}}|_{\mathbf{z}=1}&=&R_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial R_{2}\left(\mathbf{z}\right)}{\partial
z_{2}}|_{\mathbf{z}=1}&=&R_{2}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\end{eqnarray*}

igualando a cero

\begin{eqnarray*}
\frac{\partial}{\partial
z_{1}}F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)&=&0\\
\frac{\partial}{\partial
z_{2}}F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)&=&\frac{\partial
F_{1}}{\partial z_{2}}+\frac{\partial F_{1}}{\partial
z_{1}}\theta_{1}^{(1)}P_{2}^{(1)}\left(1\right)\\
\frac{\partial}{\partial
z_{1}}F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)&=&\frac{\partial
F_{2}}{\partial z_{1}}+\frac{\partial F_{2}}{\partial
z_{2}}\theta_{2}^{(1)}P_{1}^{(1)}\left(1\right)\\
\frac{\partial}{\partial
z_{2}}F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)&=&0.
\end{eqnarray*}


Por lo tanto de las dos secciones anteriores se tiene que:


\begin{eqnarray*}
\frac{\partial F_{1}}{\partial z_{1}}&=&\frac{\partial
R_{2}}{\partial z_{1}}|_{\mathbf{z}=1}+\frac{\partial F_{2}}{\partial z_{1}}|_{\mathbf{z}=1}=R_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)+f_{2}\left(1\right)+f_{2}\left(2\right)\theta_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial F_{1}}{\partial z_{2}}&=&\frac{\partial
R_{2}}{\partial z_{2}}|_{\mathbf{z}=1}+\frac{\partial F_{2}}{\partial z_{2}}|_{\mathbf{z}=1}=R_{2}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\frac{\partial F_{2}}{\partial z_{1}}&=&\frac{\partial
R_{1}}{\partial z_{1}}|_{\mathbf{z}=1}+\frac{\partial F_{1}}{\partial z_{1}}|_{\mathbf{z}=1}=R_{1}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial F_{2}}{\partial z_{2}}&=&\frac{\partial
R_{1}}{\partial z_{2}}|_{\mathbf{z}=1}+\frac{\partial F_{1}}{\partial z_{2}}|_{\mathbf{z}=1}
=R_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)+f_{1}\left(1\right)\theta_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\end{eqnarray*}


El cual se puede escribir en forma equivalente:
\begin{eqnarray*}
f_{1}\left(1\right)&=&r_{2}\mu_{1}+f_{2}\left(1\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}\\
f_{1}\left(2\right)&=&r_{2}\mu_{2}\\
f_{2}\left(1\right)&=&r_{1}\mu_{1}\\
f_{2}\left(2\right)&=&r_{1}\mu_{2}+f_{1}\left(2\right)+f_{1}\left(1\right)\frac{\mu_{2}}{1-\mu_{1}}\\
\end{eqnarray*}

De donde:
\begin{eqnarray*}
f_{1}\left(1\right)&=&\mu_{1}\left[r_{2}+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right]+f_{2}\left(1\right)\\
f_{2}\left(2\right)&=&\mu_{2}\left[r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]+f_{1}\left(2\right)\\
\end{eqnarray*}

Resolviendo para $f_{1}\left(1\right)$:
\begin{eqnarray*}
f_{1}\left(1\right)&=&r_{2}\mu_{1}+f_{2}\left(1\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=r_{2}\mu_{1}+r_{1}\mu_{1}+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}\\
&=&\mu_{1}\left(r_{2}+r_{1}\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=\mu_{1}\left(r+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right),\\
\end{eqnarray*}

entonces

\begin{eqnarray*}
f_{2}\left(2\right)&=&\mu_{2}\left(r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right)+f_{1}\left(2\right)=\mu_{2}\left(r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right)+r_{2}\mu_{2}\\
&=&\mu_{2}\left[r_{1}+r_{2}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]=\mu_{2}\left[r+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]\\
&=&\mu_{2}r+\mu_{1}\left(r+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right)\frac{\mu_{2}}{1-\mu_{1}}\\
&=&\mu_{2}r+\mu_{2}\frac{r\mu_{1}}{1-\mu_{1}}+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
&=&\mu_{2}\left(r+\frac{r\mu_{1}}{1-\mu_{1}}\right)+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
\end{eqnarray*}
entonces
\begin{eqnarray*}
f_{2}\left(2\right)-f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(1-\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(\frac{1-\mu_{1}-\mu_{2}+\mu_{1}\mu_{2}-\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(\frac{1-\mu}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
\end{eqnarray*}
por tanto
\begin{eqnarray*}
f_{2}\left(2\right)&=&\frac{r\frac{\mu_{2}}{1-\mu_{1}}}{\frac{1-\mu}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}}=\frac{r\mu_{2}\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}{\left(1-\mu_{1}\right)\left(1-\mu\right)}\\
&=&\frac{\mu_{2}\left(1-\mu_{2}\right)}{1-\mu}r=r\mu_{2}\frac{1-\mu_{2}}{1-\mu}.
\end{eqnarray*}
es decir

\begin{eqnarray}
f_{2}\left(2\right)&=&r\mu_{2}\frac{1-\mu_{2}}{1-\mu}.
\end{eqnarray}

Entonces

\begin{eqnarray*}
f_{1}\left(1\right)&=&\mu_{1}r+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=\mu_{1}r+\left(\frac{\mu_{2}\left(1-\mu_{2}\right)}{1-\mu}r\right)\frac{\mu_{1}}{1-\mu_{2}}\\
&=&\mu_{1}r+\mu_{1}r\left(\frac{\mu_{2}}{1-\mu}\right)=\mu_{1}r\left[1+\frac{\mu_{2}}{1-\mu}\right]\\
&=&r\mu_{1}\frac{1-\mu_{1}}{1-\mu}\\
\end{eqnarray*}

%_________________________________________________________________________
\section{El problema de la ruina del jugador}
%_________________________________________________________________________

Supongamos que se tiene un jugador que cuenta con un capital inicial de $\tilde{L}_{0}\geq0$ unidades, esta persona realiza una serie de dos juegos simult\'aneos e independientes de manera sucesiva, dichos eventos son independientes e id\'enticos entre s\'i para cada realizaci\'on. Para $n\geq0$ fijo, la ganancia en el $n$-\'esimo juego es $\tilde{X}_{n}=X_{n}+Y_{n}$ unidades de las cuales se resta una cuota de 1 unidad por cada juego simult\'aneo, es decir, se restan dos unidades por cada juego realizado. En t\'erminos de la teor\'ia de colas puede pensarse como el n\'umero de usuarios que llegan a una cola v\'ia dos procesos de arribo distintos e independientes entre s\'i. Su Funci\'on Generadora de Probabilidades (FGP) est\'a dada por $F\left(z\right)=\esp\left[z^{\tilde{L}_{0}}\right]$ para $z\in\mathbb{C}$, adem\'as
$$\tilde{P}\left(z\right)=\esp\left[z^{\tilde{X}_{n}}\right]=\esp\left[z^{X_{n}+Y_{n}}\right]=\esp\left[z^{X_{n}}z^{Y_{n}}\right]=\esp\left[z^{X_{n}}\right]\esp\left[z^{Y_{n}}\right]=P\left(z\right)\check{P}\left(z\right),$$ con $\tilde{\mu}=\esp\left[\tilde{X}_{n}\right]=\tilde{P}\left[z\right]<1$. 

Sea $\tilde{L}_{n}$ el capital remanente despu\'es del $n$-\'esimo
juego. Entonces
$$\tilde{L}_{n}=\tilde{L}_{0}+\tilde{X}_{1}+\tilde{X}_{2}+\cdots+\tilde{X}_{n}-2n.$$

La ruina del jugador ocurre despu\'es del $n$-\'esimo juego, es decir, la cola se vac\'ia despu\'es del $n$-\'esimo juego, entonces sea $T$ definida como $T=min\left\{\tilde{L}_{n}=0\right\}$. Si $\tilde{L}_{0}=0$, entonces claramente $T=0$. En este sentido $T$ puede interpretarse como la longitud del periodo de tiempo que el servidor ocupa para dar servicio en la cola, comenzando con $\tilde{L}_{0}$ grupos de usuarios presentes en la cola, quienes arribaron conforme a un proceso dado por $\tilde{P}\left(z\right)$.

Sea $g_{n,k}$ la probabilidad del evento de que el jugador no caiga en ruina antes del $n$-\'esimo juego, y que adem\'as tenga un capital de $k$ unidades antes del $n$-\'esimo juego, es decir, dada $n\in\left\{1,2,\ldots\right\}$ y $k\in\left\{0,1,2,\ldots\right\}$
\begin{eqnarray}
g_{n,k}:=P\left\{\tilde{L}_{j}>0, j=1,\ldots,n,
\tilde{L}_{n}=k\right\},
\end{eqnarray}
la cual adem\'as se puede escribir como:
\begin{eqnarray*}
g_{n,k}&=&P\left\{\tilde{L}_{j}>0, j=1,\ldots,n,
\tilde{L}_{n}=k\right\}=\sum_{j=1}^{k+1}g_{n-1,j}P\left\{\tilde{X}_{n}=k-j+1\right\}\\
&=&\sum_{j=1}^{k+1}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1\right\}=\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1,Y_{n}=l\right\}\\
&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1|Y_{n}=l\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\},
\end{eqnarray*}

es decir
\begin{eqnarray}\label{Eq.Gnk.2S}
g_{n,k}=\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}.
\end{eqnarray}
Adem\'as
\begin{equation}\label{Eq.L02S}
g_{0,k}=P\left\{\tilde{L}_{0}=k\right\}.
\end{equation}
Se definen las siguientes FGP:
\begin{equation}\label{Eq.3.16.a.2S}
G_{n}\left(z\right)=\sum_{k=0}^{\infty}g_{n,k}z^{k},\textrm{ para
}n=0,1,\ldots,
\end{equation}
y 
\begin{equation}\label{Eq.3.16.b.2S}
G\left(z,w\right)=\sum_{n=0}^{\infty}G_{n}\left(z\right)w^{n}, z,w\in\mathbb{C}.
\end{equation}
En particular para $k=0$,
\begin{eqnarray*}
g_{n,0}=G_{n}\left(0\right)=P\left\{\tilde{L}_{j}>0,\textrm{ para
}j<n,\textrm{ y }\tilde{L}_{n}=0\right\}=P\left\{T=n\right\},
\end{eqnarray*}
adem\'as
\begin{eqnarray*}%\label{Eq.G0w.2S}
G\left(0,w\right)=\sum_{n=0}^{\infty}G_{n}\left(0\right)w^{n}=\sum_{n=0}^{\infty}P\left\{T=n\right\}w^{n}
=\esp\left[w^{T}\right]
\end{eqnarray*}
la cu\'al resulta ser la FGP del tiempo de ruina $T$.

\begin{Prop}\label{Prop.1.1.2S}
Sean $z,w\in\mathbb{C}$ y sea $n\geq0$ fijo. Para $G_{n}\left(z\right)$ y $G\left(z,w\right)$ definidas como en (\ref{Eq.3.16.a.2S}) y (\ref{Eq.3.16.b.2S}) respectivamente, se tiene que
\begin{equation}\label{Eq.Pag.45}
G_{n}\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right).
\end{equation}

Adem\'as

\begin{equation}\label{Eq.Pag.46}
G\left(z,w\right)=\frac{zF\left(z\right)-wP\left(z\right)G\left(0,w\right)}{z-wR\left(z\right)},
\end{equation}

con un \'unico polo en el c\'irculo unitario, adem\'as, el polo es
de la forma $z=\theta\left(w\right)$ y satisface que

\begin{enumerate}
\item[i)]$\tilde{\theta}\left(1\right)=1$,

\item[ii)] $\tilde{\theta}^{(1)}\left(1\right)=\frac{1}{1-\tilde{\mu}}$,

\item[iii)]
$\tilde{\theta}^{(2)}\left(1\right)=\frac{\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}+\frac{\tilde{\sigma}}{\left(1-\tilde{\mu}\right)^{3}}$.
\end{enumerate}

Finalmente, adem\'as se cumple que
\begin{equation}
\esp\left[w^{T}\right]=G\left(0,w\right)=F\left[\tilde{\theta}\left(w\right)\right].
\end{equation}
\end{Prop}
\begin{proof}

Multiplicando las ecuaciones (\ref{Eq.Gnk.2S}) y (\ref{Eq.L02S})
por el t\'ermino $z^{k}$:

\begin{eqnarray*}
g_{n,k}z^{k}&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}z^{k},\\
g_{0,k}z^{k}&=&P\left\{\tilde{L}_{0}=k\right\}z^{k},
\end{eqnarray*}

ahora sumamos sobre $k$
\begin{eqnarray*}
\sum_{k=0}^{\infty}g_{n,k}z^{k}&=&\sum_{k=0}^{\infty}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}z^{k}\\
&=&\sum_{k=0}^{\infty}z^{k}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{k=0}^{\infty}z^{k+\left(j+l-1\right)-\left(j+l-1\right)}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{k=0}^{\infty}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}z^{j-1}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}\sum_{l=1}^{j}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{l=1}^{j}\sum_{k=j+l-1}^{\infty}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\sum_{l=1}^{j}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{l=1}^{\infty}P\left\{Y_{n}=l\right\}z^{l}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\\
&=&\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\check{P}\left(z\right)\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\\
&=&\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\check{P}\left(z\right)P\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right),
\end{eqnarray*}
es decir la ecuaci\'on (\ref{Eq.3.16.a.2S}) se puede reescribir como
\begin{equation}\label{Eq.3.16.a.2Sbis}
G_{n}\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right).
\end{equation}

Por otra parte recordemos la ecuaci\'on (\ref{Eq.3.16.a.2S})
\begin{eqnarray*}
G_{n}\left(z\right)&=&\sum_{k=0}^{\infty}g_{n,k}z^{k},\textrm{ entonces }\frac{G_{n}\left(z\right)}{z}=\sum_{k=1}^{\infty}g_{n,k}z^{k-1},
\end{eqnarray*}

por lo tanto utilizando la ecuaci\'on (\ref{Eq.3.16.a.2Sbis}):

\begin{eqnarray*}
G\left(z,w\right)&=&\sum_{n=0}^{\infty}G_{n}\left(z\right)w^{n}=G_{0}\left(z\right)+\sum_{n=1}^{\infty}G_{n}\left(z\right)w^{n}=F\left(z\right)+\sum_{n=0}^{\infty}\left[G_{n}\left(z\right)-G_{n}\left(0\right)\right]w^{n}\frac{\tilde{P}\left(z\right)}{z}\\
&=&F\left(z\right)+\frac{w}{z}\sum_{n=0}^{\infty}\left[G_{n}\left(z\right)-G_{n}\left(0\right)\right]w^{n-1}\tilde{P}\left(z\right)
\end{eqnarray*}
es decir
\begin{eqnarray*}
G\left(z,w\right)&=&F\left(z\right)+\frac{w}{z}\left[G\left(z,w\right)-G\left(0,w\right)\right]\tilde{P}\left(z\right),
\end{eqnarray*}
entonces
\begin{eqnarray*}
G\left(z,w\right)=F\left(z\right)+\frac{w}{z}\left[G\left(z,w\right)-G\left(0,w\right)\right]\tilde{P}\left(z\right)&=&F\left(z\right)+\frac{w}{z}\tilde{P}\left(z\right)G\left(z,w\right)-\frac{w}{z}\tilde{P}\left(z\right)G\left(0,w\right)\\
&\Leftrightarrow&\\
G\left(z,w\right)\left\{1-\frac{w}{z}\tilde{P}\left(z\right)\right\}&=&F\left(z\right)-\frac{w}{z}\tilde{P}\left(z\right)G\left(0,w\right),
\end{eqnarray*}
por lo tanto,
\begin{equation}
G\left(z,w\right)=\frac{zF\left(z\right)-w\tilde{P}\left(z\right)G\left(0,w\right)}{1-w\tilde{P}\left(z\right)}.
\end{equation}
Ahora $G\left(z,w\right)$ es anal\'itica en $|z|=1$. Sean $z,w$ tales que $|z|=1$ y $|w|\leq1$, como $\tilde{P}\left(z\right)$ es FGP
\begin{eqnarray*}
|z-\left(z-w\tilde{P}\left(z\right)\right)|<|z|\Leftrightarrow|w\tilde{P}\left(z\right)|<|z|
\end{eqnarray*}
es decir, se cumplen las condiciones del Teorema de Rouch\'e y por tanto, $z$ y $z-w\tilde{P}\left(z\right)$ tienen el mismo n\'umero de ceros en $|z|=1$. Sea $z=\tilde{\theta}\left(w\right)$ la soluci\'on \'unica de $z-w\tilde{P}\left(z\right)$, es decir
\begin{equation}\label{Eq.Theta.w}
\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)=0,
\end{equation}
con $|\tilde{\theta}\left(w\right)|<1$. Cabe hacer menci\'on que $\tilde{\theta}\left(w\right)$ es la FGP para el tiempo de ruina cuando $\tilde{L}_{0}=1$. Considerando la ecuaci\'on (\ref{Eq.Theta.w})
\begin{eqnarray*}
0&=&\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)|_{w=1}-\frac{\partial}{\partial w}\left\{w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}|_{w=1}=\tilde{\theta}^{(1)}\left(w\right)|_{w=1}-\frac{\partial}{\partial w}w\left\{\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}|_{w=1}\\
&-&w\frac{\partial}{\partial w}\tilde{P}\left(\tilde{\theta}\left(w\right)\right)|_{w=1}=\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}\left(\tilde{\theta}\left(1\right)\right)-w\left\{\frac{\partial \tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial \tilde{\theta}\left(w\right)}\cdot\frac{\partial\tilde{\theta}\left(w\right)}{\partial w}|_{w=1}\right\}\\
&=&\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}\left(\tilde{\theta}\left(1\right)
\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\cdot\tilde{\theta}^{(1)}\left(1\right),
\end{eqnarray*}
luego
$$\tilde{P}\left(\tilde{\theta}\left(1\right)\right)=\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\cdot\tilde{\theta}^{(1)}\left(1\right)=\tilde{\theta}^{(1)}\left(1\right)\left(1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\right),$$
por tanto $$\tilde{\theta}^{(1)}\left(1\right)=\frac{\tilde{P}\left(\tilde{\theta}\left(1\right)\right)}{\left(1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\right)}=\frac{1}{1-\tilde{\mu}}.$$
Ahora determinemos el segundo momento de $\tilde{\theta}\left(w\right)$,
nuevamente consideremos la ecuaci\'on (\ref{Eq.Theta.w}):
\begin{eqnarray*}
0&=&\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\Rightarrow 0=\frac{\partial}{\partial w}\left\{\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}\Rightarrow 0=\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\left\{\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}\right\}
\end{eqnarray*}
luego se tiene
\begin{eqnarray*}
&&\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)-\frac{\partial}{\partial w}\left[w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right]\right\}
=\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)-\frac{\partial}{\partial w}\left[w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\left[\tilde{P}\left(\tilde{\theta}\left(w\right)\right)+w\frac{\partial}{\partial w}P\left(\tilde{\theta}\left(w\right)\right)\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\left(\tilde{P}\left(\tilde{\theta}\left(w\right)\right)+w\frac{\partial \tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial w}\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\tilde{\theta}^{(1)}\left(w\right)-\tilde{P}\left(\tilde{\theta}\left(w\right)\right)-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)\right\}\\
&=&\frac{\partial}{\partial w}\tilde{\theta}^{(1)}\left(w\right)-\frac{\partial}{\partial w}\tilde{P}\left(\tilde{\theta}\left(w\right)\right)-\frac{\partial}{\partial w}\left[w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)\right]\\
&=&\frac{\partial}{\partial w}\tilde{\theta}^{(1)}\left(w\right)-\frac{\partial\tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial\tilde{\theta}\left(w\right)}\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\frac{\partial\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}{\partial w}\tilde{\theta}^{(1)}\left(w\right)\\
&-&w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\frac{\partial \tilde{\theta}^{(1)}\left(w\right)}{\partial w}\\
&=&\tilde{\theta}^{(2)}\left(w\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)\left(\tilde{\theta}^{(1)}\left(w\right)\right)^{2}\\
&-&w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(2)}\left(w\right)\\
&=&\tilde{\theta}^{(2)}\left(w\right)-2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)\left(\tilde{\theta}^{(1)}\left(w\right)\right)^{2}-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(2)}\left(w\right)\\
&=&\tilde{\theta}^{(2)}\left(w\right)\left[1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]-
\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]
\end{eqnarray*}
luego
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(w\right)&&\left[1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]-\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]=0\\
\tilde{\theta}^{(2)}\left(w\right)&=&\frac{\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2P^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}\\
&=&\frac{\tilde{\theta}^{(1)}\left(w\right)w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}+\frac{2\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}
\end{eqnarray*}
si evaluamos la expresi\'on anterior en $w=1$:
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(1\right)&=&\frac{\left(\tilde{\theta}^{(1)}\left(1\right)\right)^{2}\tilde{P}^{(2)}\left(\tilde{\theta}\left(1\right)\right)}{1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}+\frac{2\tilde{\theta}^{(1)}\left(1\right)\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}{1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}=\frac{\left(\tilde{\theta}^{(1)}\left(1\right)\right)^{2}\tilde{P}^{(2)}\left(1\right)}{1-\tilde{P}^{(1)}\left(1\right)}+\frac{2\tilde{\theta}^{(1)}\left(1\right)\tilde{P}^{(1)}\left(1\right)}{1-\tilde{P}^{(1)}\left(1\right)}\\
&=&\frac{\left(\frac{1}{1-\tilde{\mu}}\right)^{2}\tilde{P}^{(2)}\left(1\right)}{1-\tilde{\mu}}+\frac{2\left(\frac{1}{1-\tilde{\mu}}\right)\tilde{\mu}}{1-\tilde{\mu}}=\frac{\tilde{P}^{(2)}\left(1\right)}{\left(1-\tilde{\mu}\right)^{3}}+\frac{2\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}=\frac{\sigma^{2}-\tilde{\mu}+\tilde{\mu}^{2}}{\left(1-\tilde{\mu}\right)^{3}}+\frac{2\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}\\
&=&\frac{\sigma^{2}-\tilde{\mu}+\tilde{\mu}^{2}+2\tilde{\mu}\left(1-\tilde{\mu}\right)}{\left(1-\tilde{\mu}\right)^{3}}
\end{eqnarray*}
es decir
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(1\right)&=&\frac{\sigma^{2}}{\left(1-\tilde{\mu}\right)^{3}}+\frac{\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}.
\end{eqnarray*}
\end{proof}

\begin{Coro}
El tiempo de ruina del jugador tiene primer y segundo momento dados por
\begin{eqnarray}
\esp\left[T\right]&=&\frac{\esp\left[\tilde{L}_{0}\right]}{1-\tilde{\mu}}\\
Var\left[T\right]&=&\frac{Var\left[\tilde{L}_{0}\right]}{\left(1-\tilde{\mu}\right)^{2}}+\frac{\sigma^{2}\esp\left[\tilde{L}_{0}\right]}{\left(1-\tilde{\mu}\right)^{3}}.
\end{eqnarray}
\end{Coro}

Se considerar\'an intervalos de tiempo de la forma
$\left[t,t+1\right]$. Los usuarios arriban por paquetes de manera
independiente del resto de las colas. Se define el grupo de
usuarios que llegan a cada una de las colas del sistema 1,
caracterizadas por $Q_{1}$ y $Q_{2}$ respectivamente, en el
intervalo de tiempo $\left[t,t+1\right]$ por
$X_{1}\left(t\right),X_{2}\left(t\right)$.


%______________________________________________________________________
\section{Ecuaciones Centrales}
%______________________________________________________________________

\begin{Prop}
Supongamos

\begin{equation}\label{Eq.1}
f_{i}\left(i\right)-f_{j}\left(i\right)=\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]
\end{equation}

\begin{equation}\label{Eq.2}
f_{i+1}\left(i\right)=r_{i}\mu_{i},
\end{equation}

Demostrar que

\begin{eqnarray*}
f_{i}\left(i\right)&=&\mu_{i}\left[\sum_{k=1}^{N}r_{k}+\sum_{k=1,k\neq i}^{N}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right].
\end{eqnarray*}

En la Ecuaci\'on (\ref{Eq.2}) hagamos $j=i+1$, entonces se tiene $f_{j}=r_{i}\mu_{i}$, lo mismo para (\ref{Eq.1})

\begin{eqnarray*}
f_{i}\left(i\right)&=&r_{i}\mu_{i}+\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{i}\left[\sum_{k=j}^{i}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
\end{eqnarray*}

entonces, tomando sobre todo valor de $1,\ldots,N$, tanto para antes de $i$ como para despu\'es de $i$, entonces

\begin{eqnarray*}
f_{i}\left(i\right)&=&\mu_{i}\left[\sum_{k=1}^{N}r_{k}+\sum_{k=1,k\neq i}^{N}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right].
\end{eqnarray*}
\end{Prop}

Ahora, supongamos nuevamente la ecuaci\'on (\ref{Eq.1})

\begin{eqnarray*}
f_{i}\left(i\right)-f_{j}\left(i\right)&=&\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&\Leftrightarrow&\\
f_{j}\left(j\right)-f_{i}\left(j\right)&=&\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
f_{i}\left(j\right)&=&f_{j}\left(j\right)-\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left[\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\sum_{k=i}^{j-1}r_{k}-\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left[\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\sum_{k=i}^{j-1}r_{k}-\frac{r}{1-\mu}\sum_{k=i}^{j-1}\mu_{k}\right]\\
&=&\mu_{j}\left[\frac{r}{1-\mu}\left(1-\mu_{j}-\sum_{k=i}^{j-1}\mu_{k}\right)-\sum_{k=i}^{j-1}r_{k}\right]\\
&=&\mu_{j}\left[\frac{r}{1-\mu}\left(1-\sum_{k=i}^{j}\mu_{k}\right)-\sum_{k=i}^{j-1}r_{k}\right].\\
\end{eqnarray*}

Ahora,

\begin{eqnarray*}
1-\sum_{k=i}^{j}\mu_{k}&=&1-\sum_{k=1}^{N}\mu_{k}+\sum_{k=j+1}^{i-1}\mu_{k}\\
&\Leftrightarrow&\\
\sum_{k=i}^{j}\mu_{k}&=&\sum_{k=1}^{N}\mu_{k}-\sum_{k=j+1}^{i-1}\mu_{k}\\
&\Leftrightarrow&\\
\sum_{k=1}^{N}\mu_{k}&=&\sum_{k=i}^{j}\mu_{k}+\sum_{k=j+1}^{i-1}\mu_{k}\\
\end{eqnarray*}

Por tanto
\begin{eqnarray*}
f_{i}\left(j\right)&=&\mu_{j}\left[\frac{r}{1-\mu}\sum_{k=j+1}^{i-1}\mu_{k}+\sum_{k=j}^{i-1}r_{k}\right].
\end{eqnarray*}

\begin{Teo}[Teorema de Continuidad]
Sup\'ongase que $\left\{X_{n},n=1,2,3,\ldots\right\}$ son variables aleatorias finitas, no negativas con valores enteros tales que $P\left(X_{n}=k\right)=p_{k}^{(n)}$, para $n=1,2,3,\ldots$, $k=0,1,2,\ldots$, con $\sum_{k=0}^{\infty}p_{k}^{(n)}=1$, para $n=1,2,3,\ldots$. Sea $g_{n}$ la PGF para la variable aleatoria $X_{n}$. Entonces existe una sucesi\'on $\left\{p_{k}\right\}$ tal que \begin{eqnarray*}
lim_{n\rightarrow\infty}p_{k}^{(n)}=p_{k}\textrm{ para }0<s<1.
\end{eqnarray*}
En este caso, $g\left(s\right)=\sum_{k=0}^{\infty}s^{k}p_{k}$. Adem\'as
\begin{eqnarray*}
\sum_{k=0}^{\infty}p_{k}=1\textrm{ si y s\'olo si
}lim_{s\uparrow1}g\left(s\right)=1
\end{eqnarray*}
\end{Teo}

\begin{Teo}
Sea $N$ una variable aleatoria con valores enteros no negativos finita tal que $P\left(N=k\right)=p_{k}$, para $k=0,1,2,\ldots$, y $\sum_{k=0}^{\infty}p_{k}=P\left(N<\infty\right)=1$. Sea $\Phi$ la PGF de $N$ tal que $g\left(s\right)=\esp\left[s^{N}\right]=\sum_{k=0}^{\infty}s^{k}p_{k}$ con $g\left(1\right)=1$. Si $0\leq p_{1}\leq1$ y $\esp\left[N\right]=g^{'}\left(1\right)\leq1$, entonces no existe soluci\'on  de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$. Si $\esp\left[N\right]=g^{'}\left(1\right)>1$, lo cual implica que $0\leq p_{1}<1$, entonces existe una \'unica soluci\'on de la ecuaci\'on $g\left(s\right)=s$ en el intervalo
$\left[0,1\right)$.
\end{Teo}

\begin{Teo}
Si $X$ y $Y$ tienen PGF $G_{X}$ y $G_{Y}$ respectivamente, entonces,\[G_{X}\left(s\right)=G_{Y}\left(s\right)\] para toda $s$, si y s\'olo si \[P\left(X=k\right))=P\left(Y=k\right)\] para toda $k=0,1,\ldots,$., es decir, si y s\'olo si $X$ y $Y$ tienen la misma distribuci\'on de probabilidad.
\end{Teo}


\begin{Teo}
Para cada $n$ fijo, sea la sucesi\'oin de probabilidades $\left\{a_{0,n},a_{1,n},\ldots,\right\}$, tales que $a_{k,n}\geq0$ para toda $k=0,1,2,\ldots,$ y $\sum_{k\geq0}a_{k,n}=1$, y sea $G_{n}\left(s\right)$ la correspondiente funci\'on generadora, $G_{n}\left(s\right)=\sum_{k\geq0}a_{k,n}s^{k}$. De modo que para cada valor fijo de $k$
\begin{eqnarray*}
lim_{n\rightarrow\infty}a_{k,n}=a_{k},
\end{eqnarray*}
es decir converge en distribuci\'on, es necesario y suficiente que para cada valor fijo $s\in\left[0,\right)$,
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{n}\left(s\right)=G\left(s\right),
\end{eqnarray*}
donde $G\left(s\right)=\sum_{k\geq0}p_{k}s^{k}$, para cualquier la funci\'on generadora del l\'imite de la sucesi\'on.
\end{Teo}

\begin{Teo}[Teorema de Abel]
Sea $G\left(s\right)=\sum_{k\geq0}a_{k}s^{k}$ para cualquier $\left\{p_{0},p_{1},\ldots,\right\}$, tales que $p_{k}\geq0$ para toda $k=0,1,2,\ldots,$. Entonces $G\left(s\right)$ es continua por la derecha en $s=1$, es decir
\begin{eqnarray*}
lim_{s\uparrow1}G\left(s\right)=\sum_{k\geq0}p_{k}=G\left(\right),
\end{eqnarray*}
sin importar si la suma es finita o no.
\end{Teo}
\begin{Note}
El radio de Convergencia para cualquier PGF es $R\geq1$, entonces, el Teorema de Abel nos dice que a\'un en el peor escenario, cuando $R=1$, a\'un se puede confiar en que la PGF ser\'a continua en $s=1$, en contraste, no se puede asegurar que la PGF ser\'a continua en el l\'imite inferior $-R$, puesto que la PGF es sim\'etrica alrededor del cero: la PGF converge para todo $s\in\left(-R,R\right)$, y no lo hace para $s<-R$ o $s>R$. Adem\'as nos dice que podemos escribir $G_{X}\left(1\right)$ como una abreviaci\'on de $lim_{s\uparrow1}G_{X}\left(s\right)$.
\end{Note}

Entonces si suponemos que la diferenciaci\'on t\'ermino a t\'ermino est\'a permitida, entonces

\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x}
\end{eqnarray*}

el Teorema de Abel nos dice que
\begin{eqnarray*}
\esp\left(X\right]&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right):\\
\esp\left[X\right]&=&=\sum_{x=1}^{\infty}xp_{x}=G_{X}^{'}\left(1\right)\\
&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right),
\end{eqnarray*}
dado que el Teorema de Abel se aplica a
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x},
\end{eqnarray*}
estableciendo as\'i que $G_{X}^{'}\left(s\right)$ es continua en $s=1$. Sin el Teorema de Abel no se podr\'ia asegurar que el l\'imite de $G_{X}^{'}\left(s\right)$ conforme $s\uparrow1$ sea la respuesta correcta para $\esp\left[X\right]$.

\begin{Note}
La PGF converge para todo $|s|<R$, para alg\'un $R$. De hecho la PGF converge absolutamente si $|s|<R$. La PGF adem\'as converge uniformemente en conjuntos de la forma $\left\{s:|s|<R^{'}\right\}$, donde $R^{'}<R$, es decir, $\forall\epsilon>0, \exists n_{0}\in\ent$ tal que $\forall s$, con $|s|<R^{'}$, y $\forall n\geq n_{0}$,
\begin{eqnarray*}
|\sum_{x=0}^{n}s^{x}\prob\left(X=x\right)-G_{X}\left(s\right)|<\epsilon.
\end{eqnarray*}
De hecho, la convergencia uniforme es la que nos permite diferenciar t\'ermino a t\'ermino:
\begin{eqnarray*}
G_{X}\left(s\right)=\esp\left[s^{X}\right]=\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right),
\end{eqnarray*}
y sea $s<R$.
\begin{enumerate}
\item
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\frac{d}{ds}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)=\sum_{x=0}^{\infty}\frac{d}{ds}\left(s^{x}\prob\left(X=x\right)\right)\\
&=&\sum_{x=0}^{n}xs^{x-1}\prob\left(X=x\right).
\end{eqnarray*}

\item\begin{eqnarray*}
\int_{a}^{b}G_{X}\left(s\right)ds&=&\int_{a}^{b}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)ds=\sum_{x=0}^{\infty}\left(\int_{a}^{b}s^{x}\prob\left(X=x\right)ds\right)\\
&=&\sum_{x=0}^{\infty}\frac{s^{x+1}}{x+1}\prob\left(X=x\right),
\end{eqnarray*}
para $-R<a<b<R$.
\end{enumerate}
\end{Note}

\begin{Teo}[Teorema de Convergencia Mon\'otona para PGF]
Sean $X$ y $X_{n}$ variables aleatorias no negativas, con valores en los enteros, finitas, tales que
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{X_{n}}\left(s\right)&=&G_{X}\left(s\right)
\end{eqnarray*}
para $0\leq s\leq1$, entonces
\begin{eqnarray*}
lim_{n\rightarrow\infty}P\left(X_{n}=k\right)=P\left(X=k\right),
\end{eqnarray*}
para $k=0,1,2,\ldots.$
\end{Teo}

El teorema anterior requiere del siguiente lema

\begin{Lemma}
Sean $a_{n,k}\in\ent^{+}$, $n\in\nat$ constantes no negativas con $\sum_{k\geq0}a_{k,n}\leq1$. Sup\'ongase que para $0\leq s\leq1$,
se tiene
\begin{eqnarray*}
a_{n}\left(s\right)&=&\sum_{k=0}^{\infty}a_{k,n}s^{k}\rightarrow
a\left(s\right)=\sum_{k=0}^{\infty}a_{k}s^{k}.
\end{eqnarray*}
Entonces
\begin{eqnarray*}
a_{0,n}\rightarrow a_{0}.
\end{eqnarray*}
\end{Lemma}

%_________________________________________________________________________
\section{Redes de Jackson}
%_________________________________________________________________________
Cuando se considera la cantidad de
usuarios que llegan a cada uno de los nodos desde fuera del
sistema m\'as los que provienen del resto de los nodos, se dice
que la red es abierta y recibe el nombre de {\em Red de Jackson Abierta}.\\

Si denotamos por $Q_{1}\left(t\right),Q_{2}\left(t\right),\ldots,Q_{K}\left(t\right)$ el n\'umero de usuarios presentes en la cola $1,2,\ldots,K$ respectivamente al tiempo $t$, entonces se tiene la colecci\'on de colas $\left\{Q_{1},Q_{2},\ldots,Q_{K}\right\}$, donde despu\'es de que el usuario es atendido en la cola $i$, se traslada a la cola $j$ con probabilidad $p_{ij}$. En caso de que un usuario decida volver a ser atendido en $i$, este permanecer\'a en la misma cola con probabilidad $p_{ii}$. Para considerar a los usuarios que entran al sistema por primera vez por $i$, m\'as aquellos que provienen de otra cola, es necesario considerar un estado adicional $0$, con probabilidad de transici\'on $p_{00}=0$, $p_{0j}\geq0$ y $p_{j0}\geq0$, para $j=1,2,\ldots,K$, entonces en general la probabilidad de transici\'on de una cola a otra puede representarse por $P=\left(p_{ij}\right)_{i,j=0}^{K}$.\\

Para el caso espec\'ifico en el que en cada una de las colas los tiempos entre arribos y los tiempos de servicio sean exponenciales con par\'ametro de intensidad $\lambda$ y media $\mu$, respectivamente, con $m$ servidores y sin restricciones en la capacidad de almacenamiento en cada una de las colas, en Chee-Hook y Boon-Hee \cite{HookHee}, cap. 6, se muestra que el n\'umero de
usuarios en las $K$ colas, en el caso estacionario, puede determinarse por la ecuaci\'on (\ref{Eq.7.5.1})  que a
continuaci\'on se presenta, adem\'as de que la distribuci\'on l\'imite de la misma es (\ref{Eq.7.5.2}).\\

El n\'umero de usuarios en las $K$ colas en su estado estacionario, ver \cite{Bhat}, se define como
\begin{equation}\label{Eq.7.5.1}
p_{q_{1}q_{2}\cdots
q_{K}}=P\left[Q_{1}=q_{1},Q_{2}=q_{2},\ldots,Q_{K}=q_{K}\right].
\end{equation}

Jackson (1957), demostr\'o que la distribuci\'on l\'imite
$p_{q_{1}q_{2}\cdots q_{K}}$ de (\ref{Eq.7.5.1}) es

\begin{equation}\label{Eq.7.5.2}
p_{q_{1}q_{2}\cdots
q_{K}}=P_{1}\left(q_{1}\right)P_{2}\left(q_{2}\right)\cdots
P_{K}\left(q_{K}\right),
\end{equation}

donde
\begin{equation}\label{Eq.7.5.3}
p_{i}\left(r\right)=\left\{\begin{array}{cc}
 p_{i}\left(0\right)\frac{\left(\gamma_{i}/\mu_{i}\right)^{r}}{r!},  & r=0,1,2,\ldots,m, \\
 p_{i}\left(0\right)\frac{\left(\gamma_{i}/\mu_{i}\right)^{r}}{m!m^{r-m}}, & r=m,m+1,\ldots .\\
\end{array}\right.
\end{equation}

y

\begin{equation}\label{Eq.7.5.4}
\gamma_{i}=\lambda_{i}+\sum p_{ji}\gamma_{j},\textrm{
}i=1,2,\ldots,K.
\end{equation}

La relaci\'on (\ref{Eq.7.5.4}) es importante puesto que considera no solamente los arribos externos si no que adem\'as permite considerar intercambio de clientes entre las distintas colas que conforman el sistema.\\

Dados $\lambda_{i}$ y $p_{ij}$, la cantidad $\gamma_{i}$ puede determinarse a partir de la ecuaci\'on (\ref{Eq.7.5.4}) de manera recursiva. Adem\'as $p_{i}\left(0\right)$ puede determinarse utilizando la condici\'on de normalidad
\[\sum_{q_{1}}\sum_{q_{2}}\cdots\sum_{q_{K}}p_{q_{1}q_{2}\cdots q_{K}}=1.\]

Sin embargo las Redes de Jackson tienen el inconveniente de que no consideran el caso en que existan tiempos de traslado entre las colas. 



