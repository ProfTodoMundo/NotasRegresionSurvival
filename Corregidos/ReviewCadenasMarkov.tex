\documentclass{article}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
% PAQUETES A UTILIZAR
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\usepackage[utf8]{inputenc}
\usepackage[spanish,english]{babel}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{graphicx,graphics}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{color}
\usepackage{float} 
\usepackage{subfig}
\usepackage[figuresright]{rotating}
\usepackage{enumerate}
\usepackage{anysize} 
\usepackage{url}
\usepackage{imakeidx}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
% TITULO DEL DOCUMENTO
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\title{Notas sobre Sistemas de Espera\\
\small{Notes about Queueting Systems}}
\author{Carlos E. Martínez-Rodríguez}
\date{}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
% MODIFICACION DE LOS MARGENES
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\geometry{
  a4paper,
  left=15mm,
  right=15mm,
  left=14mm,
  right=14mm,
  top=30mm,
  bottom=30mm,
}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
% CONFIGURACION DE ENCABEZADOS Y PIES DE PAG
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\nouppercase{\leftmark}} % Sección en el encabezado izquierdo
\fancyfoot[C]{\thepage} % Número de página centrado en el pie
\fancyfoot[L]{\tiny Carlos E. Martínez-Rodríguez} % Autor en el pie izquierdo
\fancyfoot[R]{\tiny \nouppercase{\rightmark}} % Subsection actual en el pie derecho

%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
% Definiciones de nuevos entornos
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\newtheorem{Def}{Definición}[section]
\newtheorem{Ejem}{Ejemplo}[section]
\newtheorem{Teo}{Teorema}[section]
\newtheorem{Note}{Nota}[section]
\newtheorem{Prop}{Proposición}[section]
\newtheorem{Cor}{Corolario}[section]
\newtheorem{Coro}{Corolario}[section]
\newtheorem{Lema}{Lema}[section]
\newtheorem{Lemma}{Lema}[section]
\newtheorem{Lem}{Lema}[section]
\newtheorem{Sup}{Supuestos}[section]
\newtheorem{Obs}{Observación}[section]
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
%NUEVOS COMANDOS
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\newcommand{\nat}{\mathbb{N}}
\newcommand{\ent}{\mathbb{Z}}
\newcommand{\rea}{\mathbb{R}}
\newcommand{\Eb}{\mathbf{E}}
\newcommand{\esp}{\mathbb{E}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\indora}{\mbox{$1$\hspace{-0.8ex}$1$}}
\newcommand{\ER}{\left(E,\mathcal{E}\right)}
\newcommand{\KM}{\left(P_{s,t}\right)}
\newcommand{\PE}{\left(X_{t}\right)_{t\in I}}
\newcommand{\CM}{\mathbf{P}^{x}}
\renewcommand{\abstractname}{Resumen}
\numberwithin{equation}{section}
\newcommand{\acmclass}[1]{\noindent\textbf{ACM Class:} #1\\}
\newcommand{\mscclass}[1]{\noindent\textbf{MSC Class:} #1\\}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\makeindex

%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\begin{document}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\maketitle

%<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>
\begin{abstract}
%<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-

\end{abstract}

\begin{otherlanguage}{english}
\renewcommand{\abstractname}{Abstract} % Cambia "Resumen" a "Abstract"
\begin{abstract}

\end{abstract}
\end{otherlanguage}
%<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>

\tableofcontents
%\newpage

%<====>====<><====>====<><====>====<><====>====<><====>
%\part{Introducci\'on a Procesos Regenerativos}
%<====>====<><====>====<><====>====<><====>====<><====>
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-
\section*{Introducción}
%_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-



\begin{otherlanguage}{english}
\renewcommand{\abstractname}{Abstract} % Cambia "Resumen" a "Abstract"
\section*{Introduction}


\end{otherlanguage}




%_____________________________________________________________________________________
%
\section{Notaci\'on Kendall-Lee}
%_____________________________________________________________________________________
%

A partir de este momento se har\'an las siguientes consideraciones:
\begin{itemize}
\item[a) ]Si $t_{n}$ es el tiempo aleatorio en el que llega al sistema el $n$-\'esimo cliente, para $n=1,2,\ldots$, $t_{0}=0$ y $t_{0}<t_{1}<\cdots$ se definen los tiempos entre arribos $\tau_{n}=t_{n}-t_{n-1}$ para $n=1,2,\ldots$, variables aleatorias independientes e id\'enticamente distribuidas.

\item[b) ]Los tiempos entre arribos tienen un valor medio $E\left(\tau\right)$ finito y positivo $\frac{1}{\beta}$, es decir, $\beta$ se puede ver como la tasa o intensidad promedio de arribos al sistema por unidad de tiempo.
\item[c) ]  Adem\'as se supondr\'a que los servidores son identicos y si $s$ denota la variable aleatoria que describe el tiempo de servicio, entonces $E\left(s\right)=\frac{1}{\delta}$, $\delta$ es la tasa promedio de servicio por servidor.
\end{itemize}


La notaci\'on de Kendall-Lee es una forma abreviada de describir un sistema de espera con las siguientes componentes:
\begin{itemize}
\item[a)] {\em\bf Fuente}: Poblaci\'on de clientes potenciales del sistema, esta puede ser finita o infinita. 
\item[b)] {\em\bf Proceso de Arribos}: Proceso determinado por la funci\'on de distribuci\'on $A\left(t\right)=P\left\{\tau\leq t\right\}$ de los tiempos entre arribos.
\end{itemize}

Adem\'as tenemos las siguientes igualdades
\begin{equation}\label{Eq.0.1}
N\left(t\right)=N_{q}\left(t\right)+N_{s}\left(s\right)
\end{equation}
donde
\begin{itemize}
\item $N\left(t\right)$ es el n\'umero de clientes en el sistema al tiempo $t$. 
\item $N_{q}\left(t\right)$ es el n\'umero de cliente en la cola al tiempo $t$.
\item $N_{s}\left(t\right)$ es el n\'umero de clientes recibiendo servicio en el tiempo $t$.
\end{itemize}

Bajo la hip\'otesis de estacionareidad, es decir, las caracter\'isticas de funcionamiento del sistema se han estabilizado en valores independientes del tiempo, entonces
\begin{equation}
N=N_{q}+N_{s}.
\end{equation}

Los valores medios de las cantidades anteriores se escriben como $L=E\left(N\right)$, $L_{q}=E\left(N_{q}\right)$ y $L_{s}=E\left(N_{s}\right)$, entonces de la ecuaci\'on \ref{Eq.0.1} se obtiene

\begin{equation}
L=L_{q}+L_{s}
\end{equation}
Si $q$ es el tiempo que pasa un cliente en la cola antes de recibir servicio, y W es el tiempo total que un cliente pasa en el sistema, entonces \[w=q+s\] por lo tanto \[W=W_{q}+W_{s},\] donde $W=E\left(w\right)$, $W_{q}=E\left(q\right)$ y $W_{s}=E\left(s\right)=\frac{1}{\delta}$.

La intensidad de tr\'afico se define como
\begin{equation}
\rho=\frac{E\left(s\right)}{E\left(\tau\right)}=\frac{\beta}{\delta}.
\end{equation}

La utilizaci\'on por servidor es
\begin{equation}
u=\frac{\rho}{c}=\frac{\beta}{c\delta}.
\end{equation}
donde $c$ es el n\'umero de servidores.

Esta notaci\'on es una forma abreviada de describir un sistema de espera con componentes dados a continuaci\'on, la notaci\'on es

\begin{equation}\label{Notacion.K.L.}
A/S/c/K/F/d
\end{equation}

Cada una de las letras describe:

\begin{itemize}
\item $A$ es la distribuci\'on de los tiempos entre arribos.
\item $S$ es la distribuci\'on del tiempo de servicio.
\item $c$ es el n\'umero de servidores.
\item $K$ es la capacidad del sistema.
\item $F$ es el n\'umero de individuos en la fuente.
\item $d$ es la disciplina del servicio
\end{itemize}

Usualmente se acostumbra suponer que $K=\infty$, $F=\infty$ y $d=FIFO$, es decir, First In First Out. Las distribuciones usuales para $A$ y $B$ son:

\begin{itemize}
\item $GI$ para la distribuci\'on general de los tiempos entre arribos.
\item $G$ distribuci\'on general del tiempo de servicio.
\item $M$ Distribuci\'on exponencial para $A$ o $S$.
\item $E_{K}$ Distribuci\'on Erlang-$K$, para $A$ o $S$.
\item $D$ tiempos entre arribos o de servicio constantes, es decir, deterministicos.
\end{itemize}


%_____________________________________________________________________________________
%
\subsection{Cola $M/M/1$}
%_____________________________________________________________________________________
%
Este modelo corresponde a un proceso de nacimiento y muerte con $\beta_{n}=\beta$ y $\delta_{n}=\delta$ independiente del valor de $n$. La intensidad de tr\'afico $\rho=\frac{\beta}{\delta}$, implica que el criterio de recurrencia (ecuaci\'on \ref{Eq.2.1}) quede de la forma:
\begin{eqnarray*}
1+\sum_{n=1}^{\infty}\rho^{-n}=\infty.
\end{eqnarray*}
Equivalentemente el proceso es recurrente si y s\'olo si
\begin{eqnarray*}
\sum_{n\geq1}\left(\frac{\beta}{\delta}\right)^{n}<\infty\Leftrightarrow \frac{\beta}{\delta}<1.
\end{eqnarray*}
Entonces
$S=\frac{\delta}{\delta-\beta}$, luego por la ecuaci\'on \ref{Eq.2.4} se tiene que
\begin{eqnarray*}
\pi_{0}&=&\frac{\delta-\beta}{\delta}=1-\frac{\beta}{\delta},\\
\pi_{n}&=&\pi_{0}\left(\frac{\beta}{\delta}\right)^{n}=\left(1-\frac{\beta}{\delta}\right)\left(\frac{\beta}{\delta}\right)^{n}=\left(1-\rho\right)\rho^{n}.
\end{eqnarray*}


Lo cual nos lleva a la siguiente proposici\'on:

\begin{Prop}
La cola $M/M/1$ con intensidad de tr\'afico $\rho$, es recurrente si y s\'olo si $\rho\leq1$.
\end{Prop}

Entonces por el corolario \ref{Cor.2.3}

\begin{Prop}
La cola $M/M/1$ con intensidad de tr\'afico $\rho$ es erg\'odica si y s\'olo si $\rho<1$. En cuyo caso, la distribuci\'on de equilibrio $\pi$ de la longitud de la cola es geom\'etrica, $\pi_{n}=\left(1-\rho\right)\rho^{n}$, para $n=1,2,\ldots$.
\end{Prop}

De la proposici\'on anterior se desprenden varios hechos importantes.
\begin{itemize}
\item[a) ] $\prob\left[X_{t}=0\right]=\pi_{0}=1-\rho$, es decir, la probabilidad de que el sistema se encuentre ocupado.
\item[b) ] De las propiedades de la distribuci\'on Geom\'etrica se desprende que
\begin{itemize}
\item[i) ] $\esp\left[X_{t}\right]=\frac{\rho}{1-\rho}$,
\item[ii) ] $Var\left[X_{t}\right]=\frac{\rho}{\left(1-\rho\right)^{2}}$.
\end{itemize}
\end{itemize}

Si $L$ es el n\'umero esperado de clientes en el sistema, incluyendo los que est\'an siendo atendidos, entonces
\begin{eqnarray}
L=\frac{\rho}{1-\rho}.
\end{eqnarray}
Si adem\'as $W$ es el tiempo total del cliente en la cola: $W=W_{q}+W_{s}$, $\rho=\frac{\esp\left[s\right]}{\esp\left[\tau\right]}=\beta W_{s}$, puesto que $W_{s}=\esp\left[s\right]$ y $\esp\left[\tau\right]=\frac{1}{\delta}$. Por la f\'ormula de Little $L=\lambda W$
\begin{eqnarray*}
W&=&\frac{L}{\beta}=\frac{\frac{\rho}{1-\rho}}{\beta}=\frac{\rho}{\delta}\frac{1}{1-\rho}=\frac{W_{s}}{1-\rho}\\
&=&\frac{1}{\delta\left(1-\rho\right)}=\frac{1}{\delta-\beta},
\end{eqnarray*}

luego entonces

\begin{eqnarray*}
W_{q}&=&W-W_{s}=\frac{1}{\delta-\beta}-\frac{1}{\delta}=\frac{\beta}{\delta(\delta-\beta)}\\
&=&\frac{\rho}{1-\rho}\frac{1}{\delta}=\esp\left[s\right]\frac{\rho}{1-\rho}.
\end{eqnarray*}

Entonces

\begin{eqnarray*}
L_{q}=\beta W_{q}=\frac{\rho^{2}}{1-\rho}.
\end{eqnarray*}

Finalmente, tenemos las siguientes proposiciones:

\begin{Prop}
\begin{enumerate}
\item $W\left(t\right)=1-e^{-\frac{t}{W}}$.
\item $W_{q}\left(t\right)=1-\rho\exp^{-\frac{t}{W}}$.
\end{enumerate}
donde $W=\esp(w)$.
\end{Prop}

\begin{Prop}
La cola M/M/1 con intensidad de tr\'afico $\rho$ es recurrente si
y s\'olo si $\rho\leq1$
\end{Prop}

\begin{Prop}
La cola M/M/1 con intensidad de tr\'afica $\rho$ es ergodica si y
s\'olo si $\rho<1$. En este caso, la distribuci\'on de equilibrio
$\pi$ de la longitud de la cola es geom\'etrica,
$\pi_{n}=\left(1-\rho\right)\rho^{n}$, para $n=0,1,2,\ldots$.
\end{Prop}
%_____________________________________________________________________________________
%
\subsection{Cola $M/M/\infty$}
%_____________________________________________________________________________________
%

Este tipo de modelos se utilizan para estimar el n\'umero de l\'ineas en uso en una gran red comunicaci\'on o para estimar valores en los sistemas $M/M/c$ o $M/M/c/c$, en el se puede pensar que siempre hay un servidor disponible para cada cliente que llega.

Se puede considerar como un proceso de nacimiento y muerte con par\'ametros $\beta_{n}=\beta$ y $\mu_{n}=n\mu$ para $n=0,1,2,\ldots$. Este modelo corresponde al caso en que $\beta_{n}=\beta$ y $\delta_{n}=n\delta$, en este caso el par\'ametro de inter\'es $\eta=\frac{\beta}{\delta}$, luego, la ecuaci\'on \ref{Eq.2.1} queda de la forma:

\begin{eqnarray*}
\sum_{n=1}^{\infty}\frac{\delta_{1}\cdots\delta_{n}}{\beta_{1}\cdots\beta_{n}}=\sum_{n=1}^{\infty}n!\eta^{-n}=\infty\\
\end{eqnarray*}
con $S=1+\sum_{n=1}^{\infty}\frac{\eta^{n}}{n!}=e$, entonces por la ecuaci\'on \ref{Eq.2.4} se tiene que

\begin{eqnarray}\label{MMinf.pi}
\pi_{0}=e^{\rho},\\
\pi_{n}=e^{-\rho}\frac{\rho^{n}}{n!}.
\end{eqnarray}
Entonces, el n\'umero promedio de servidores ocupados es equivalente a considerar el n\'umero de clientes en el  sistema, es decir,
\begin{eqnarray}
L=\esp\left[N\right]=\rho.\\
Var\left[N\right]=\rho.
\end{eqnarray}
Adem\'as se tiene que $W_{q}=0$ y $L_{q}=0$. El tiempo promedio en el sistema es el tiempo promedio de servicio, es decir, $W=\esp\left[s\right]=\frac{1}{\delta}$.Resumiendo, tenemos la sisuguiente proposici\'on:

\begin{Prop}
La cola $M/M/\infty$ es erg\'odica para todos los valores de $\eta$. La distribuci\'on de equilibrio $\pi$ es Poisson con media $\eta$,
\begin{eqnarray}
\pi_{n}=\frac{e^{-n}\eta^{n}}{n!}.
\end{eqnarray}
\end{Prop}
%_____________________________________________________________________________________
%
\subsection{Cola $M/M/m$}
%_____________________________________________________________________________________
%

Este sistema considera $m$ servidores id\'enticos, con tiempos entre arribos y de servicio exponenciales con medias $\esp\left[\tau\right]=\frac{1}{\beta}$ y
$\esp\left[s\right]=\frac{1}{\delta}$. definimos ahora la utilizaci\'on por servidor como $u=\frac{\rho}{m}$ que tambi\'en se puede interpretar como la fracci\'on de tiempo promedio que cada servidor est\'a ocupado.

La cola $M/M/m$ se puede considerar como un proceso de nacimiento y muerte con par\'ametros: $\beta_{n}=\beta$ para $n=0,1,2,\ldots$ y
\begin{eqnarray}
\delta_{n}=\left\{\begin{array}{cc}
n\delta & n=0,1,\ldots,m-1\\
c\delta & n=m,\ldots\\
\end{array}\right.
\end{eqnarray}

entonces  la condici\'on de recurrencia se va a cumplir s\'i y s\'olo si $\sum_{n\geq1}\frac{\beta_{0}\cdots\beta_{n-1}}{\delta_{1}\cdots\delta_{n}}<\infty$,
equivalentemente se debe de cumplir que
\begin{eqnarray*}
S&=&1+\sum_{n\geq1}\frac{\beta_{0}\cdots\beta_{n-1}}{\delta_{1}\cdots\delta_{n}}=\sum_{n=0}^{m-1}\frac{\beta_{0}\cdots\beta_{n-1}}{\delta_{1}\cdots\delta_{n}}+\sum_{n=0}^{\infty}\frac{\beta_{0}\cdots\beta_{n-1}}{\delta_{1}\cdots\delta_{n}}\\
&=&\sum_{n=0}^{m-1}\frac{\beta^{n}}{n!\delta^{n}}+\sum_{n=0}^{\infty}\frac{\rho^{m}}{m!}u^{n}
\end{eqnarray*}
converja, lo cual ocurre si $u<1$, en este caso

\begin{eqnarray}
S=\sum_{n=0}^{m-1}\frac{\rho^{n}}{n!}+\frac{\rho^{m}}{m!}\left(1-u\right)
\end{eqnarray}
luego, para este caso se tiene que

\begin{eqnarray}
\pi_{0}&=&\frac{1}{S}\\
\pi_{n}&=&\left\{\begin{array}{cc}
\pi_{0}\frac{\rho^{n}}{n!} & n=0,1,\ldots,m-1\\
\pi_{0}\frac{\rho^{n}}{m!m^{n-m}}& n=m,\ldots\\
\end{array}\right.
\end{eqnarray}
Al igual que se hizo antes, determinaremos los valores de
$L_{q},W_{q},W$ y $L$:
\begin{eqnarray*}
L_{q}&=&\esp\left[N_{q}\right]=\sum_{n=0}^{\infty}\left(n-m\right)\pi_{n}=\sum_{n=0}^{\infty}n\pi_{n+m}\\
&=&\sum_{n=0}^{\infty}n\pi_{0}\frac{\rho^{n+m}}{m!m^{n+m}}=\pi_{0}\frac{\rho^{m}}{m!}\sum_{n=0}^{\infty}nu^{n}=\pi_{0}\frac{u\rho^{m}}{m!}\sum_{n=0}^{\infty}\frac{d}{du}u^{n}\\
&=&\pi_{0}\frac{u\rho^{m}}{m!}\frac{d}{du}\sum_{n=0}^{\infty}u^{n}=\pi_{0}\frac{u\rho^{m}}{m!}\frac{d}{du}\left(\frac{1}{1-u}\right)=\pi_{0}\frac{u\rho^{m}}{m!}\frac{1}{\left(1-u\right)^{2}},
\end{eqnarray*}

es decir
\begin{equation}
L_{q}=\frac{u\pi_{0}\rho^{m}}{m!\left(1-u\right)^{2}},
\end{equation}
luego
\begin{equation}
W_{q}=\frac{L_{q}}{\beta}.
\end{equation}
Adem\'as
\begin{equation}
W=W_{q}+\frac{1}{\delta}
\end{equation}

Si definimos
\begin{eqnarray}
C\left(m,\rho\right)=\frac{\pi_{0}\rho^{m}}{m!\left(1-u\right)}=\frac{\pi_{m}}{1-u},
\end{eqnarray}
que es la probabilidad de que un cliente que llegue al sistema
tenga que esperar en la cola. Entonces podemos reescribir las
ecuaciones reci\'en enunciadas:

\begin{eqnarray}
L_{q}&=&\frac{C\left(m,\rho\right)u}{1-u},\\
W_{q}&=&\frac{C\left(m,\rho\right)\esp\left[s\right]}{m\left(1-u\right)}\\
\end{eqnarray}
Por tanto tenemos las siguientes proposiciones:

\begin{Prop}
La cola $M/M/m$ con intensidad de tr\'afico $\rho$ es erg\'odica si y s\'olo si $\rho<1$. En este caso la distribuci\'on erg\'odica $\pi$ est\'a dada por
\begin{eqnarray}
\pi_{n}=\left\{\begin{array}{cc}
\frac{1}{S}\frac{\eta^{n}}{n!} & 0\leq n\leq m\\
\frac{1}{S}\frac{\eta^{m}}{m!}\rho^{n-m} & m\leq n<\infty\\
\end{array}\right.
\end{eqnarray}
\end{Prop}

\begin{Prop}
Para $t\geq0$
\begin{itemize}
\item[a)]
\begin{eqnarray}
W_{q}\left(t\right)=1-C\left(m,\rho\right)e^{-c\delta
t\left(1-u\right)}.
\end{eqnarray} 
\item[b)]\begin{eqnarray}
W\left(t\right)=\left\{\begin{array}{cc}
1+e^{-\delta t}\frac{\rho-m+W_{q}\left(0\right)}{m-1-\rho}+e^{-m\delta t\left(1-u\right)}\frac{C\left(m,\rho\right)}{m-1-\rho} & \rho\neq m-1\\
1-\left(1+C\left(m,\rho\right)\delta t\right)e^{-\delta t} & \rho=m-1\\
\end{array}\right.
\end{eqnarray}
\end{itemize}
\end{Prop}

Resumiendo, para este caso $\beta_{n}=\beta$ y
$\delta_{n}=m\left(n\right)\delta$, donde $m\left(n\right)$ es el n\'umero de servidores ocupados en el estado $n$, es decir,
$m\left(n\right)=m$, para $n\geq m$ y $m\left(n\right)=m$ para
$1\leq n\leq m$. La intensidad de tr\'afico es
$\rho=\frac{\beta}{m\delta}$ y $\frac{\beta_{n}}{\delta_{n}}=\rho$
para $n\geq m$. As\'i, al igual que en el caso $m=1$, la ecuaci\'on
\ref{Eq.2.1} y la recurrencia se cumplen si y s\'olo si
$\sum_{n=1}^{\infty}\rho^{-n}=\infty$, es decir, cuando
$\rho\leq1$. 


%_____________________________________________________________________________________
%
\subsection{Cola $M/M/m/m$}
%_____________________________________________________________________________________
%

Consideremos un sistema con $m$ servidores id\'enticos, pero ahora cada uno es de capacidad finita $m$. Si todos los servidores se encuentran ocupados, el siguiente usuario en llegar se pierde pues no se le deja esperar a que reciba servicio. Este tipo de sistemas pueden verse como un proceso de nacimiento y muerte con
\begin{eqnarray}
\beta_{n}=\left\{\begin{array}{cc}
\beta & n=0,1,2,\ldots,m-1\\
0 & n\geq m\\
\end{array}
\right.
\end{eqnarray}

\begin{eqnarray}
\delta_{n}=\left\{\begin{array}{cc}
n\delta & n=0,1,2,\ldots,m-1\\
0 & n\geq m\\
\end{array}
\right.
\end{eqnarray}
El proceso tiene epacio de estados finitos, $S=\left\{0,1,\ldots,m\right\}$, entonces de las ecuaciones que determinan la distribuci\'on estacionaria se tiene que
\begin{equation}\label{Eq.13.1}
\pi_{n}=\left\{\begin{array}{cc}
\pi_{0}\frac{\rho^{n}}{n!} & n=0,1,2,\ldots,m\\
0 & n\geq m\\
\end{array}
\right.
\end{equation}
y adem\'as
\begin{equation}
\pi_{0}=\left(\sum_{n=0}^{m}\frac{\rho^{n}}{n!}\right)^{-1}.
\end{equation}
A la ecuaci\'on \ref{Eq.13.1} se le llama {\em distribuci\'on truncada}. Si definimos
$\pi_{m}=B\left(m,\rho\right)=\pi_{0}\frac{\rho^{m}}{m!}$, $\pi_{m}$ representa la probabilidad de que todos los servidores se encuentren ocupados, y tambi\'en se le conoce como {\em f\'ormula de p\'erdida de Erlang}. Necesariamente en este caso el tiempo de espera en la cola $W_{q}$ y el n\'umero promedio de clientes en la cola $L_{q}$ deben de ser cero puesto que no se permite esperar para recibir servicio, m\'as a\'un, el tiempo de espera en el sistema y el tiempo de serivcio tienen la misma distribuci\'on, es decir,
\[W\left(t\right)=\prob\left\{w\leq t\right\}=1-e^{-\mu t},\] en particular
\[W=\esp\left[w\right]=\esp\left[s\right]=\frac{1}{\delta}.\]
Por otra parte, el n\'umero esperado de clientes en el sistema es
\begin{eqnarray*}
L&=&\esp\left[N\right]=\sum_{n=0}^{m}n\pi_{n}=\pi_{0}\rho\sum_{n=0}^{m}\frac{\rho^{n-1}}{\left(n-1\right)!}\\
&=&\pi_{0}\rho\sum_{n=0}^{m-1}\frac{\rho^{n}}{n!}
\end{eqnarray*}
entonces, se tiene que
\begin{equation}
L=\rho\left(1-B\left(m,\rho\right)\right)=\esp\left[s\right]\left(1-B\left(m,\rho\right)\right).
\end{equation}
Adem\'as
\begin{equation}
\delta_{q}=\delta\left(1-B\left(m,\rho\right)\right)
\end{equation}
representa la tasa promedio efectiva de arribos al sistema.
%_____________________________________________________________________________________
%
\subsection{Cola M/G/1}
%_____________________________________________________________________________________
%
Consideremos un sistema de espera con un servidor, en el que los tiempos entre arribos son exponenciales, y los tiempos de servicio tienen una distribuci\'on general $G$. Sea $N\left(t\right)_{t\geq0}$ el n\'umero de clientes en el sistema al tiempo $t$, y sean $t_{1}<t_{2}<\dots$ los tiempos sucesivos en los que los clientes completan su servicio y salen del sistema.

La sucesi\'on $\left\{X_{n}\right\}$ definida por
$X_{n}=N\left(t_{n}\right)$ es una cadena de Markov, en espec\'ifico es la Cadena encajada del proceso de llegadas de usuarios. Sea $U_{n}$ el n\'umero de clientes que llegan al sistema durante el tiempo de servicio del $n$-\'esimo cliente, entonces se tiene que

\begin{eqnarray*}
X_{n+1}=\left\{\begin{array}{cc}
X_{n}-1+U_{n+1} & \textrm{si }X_{n}\geq1,\\
U_{n+1} & \textrm{si }X_{n}=0\\
\end{array}\right.
\end{eqnarray*}

Dado que los procesos de arribos de los usuarios es Poisson con par\'ametro $\lambda$, la probabilidad condicional de que lleguen $j$ clientes al sistema dado que el tiempo de servicio es $s=t$, resulta:
\begin{eqnarray*}
\prob\left\{U=j|s=t\right\}=e^{-\lambda t}\frac{\left(\lambda
t\right)^{j}}{j!}\textrm{,   }j=0,1,\ldots
\end{eqnarray*}
por el teorema de la probabilidad total se tiene que
\begin{equation}
a_{j}=\prob\left\{U=j\right\}=\int_{0}^{\infty}\prob\left\{U=j|s=t\right\}dG\left(t\right)=\int_{0}^{\infty}e^{-\lambda
t}\frac{\left(\lambda t\right)^{j}}{j!}dG\left(t\right)
\end{equation}
donde $G$ es la distribuci\'on de los tiempos de servicio. Las probabilidades de transici\'on de la cadena est\'an dadas por
\begin{equation}
p_{0j}=\prob\left\{U_{n+1}=j\right\}=a_{j}\textrm{, para
}j=0,1,\ldots
\end{equation}
y para $i\geq1$
\begin{equation}
p_{ij}=\left\{\begin{array}{cc}
\prob\left\{U_{n+1}=j-i+1\right\}=a_{j-i+1}&\textrm{, para }j\geq i-1\\
0 & j<i-1\\
\end{array}
\right.
\end{equation}
Entonces la matriz de transici\'on es:
\begin{eqnarray*}
P=\left[\begin{array}{ccccc}
a_{0} & a_{1} & a_{2} & a_{3} & \cdots\\
a_{0} & a_{1} & a_{2} & a_{3} & \cdots\\
0 & a_{0} & a_{1} & a_{2} & \cdots\\
0 & 0 & a_{0} & a_{1} & \cdots\\
\vdots & \vdots & \cdots & \ddots &\vdots\\
\end{array}
\right].
\end{eqnarray*}
Sea $\rho=\sum_{n=0}na_{n}$, entonces se tiene el siguiente teorema:
\begin{Teo}
La cadena encajada $\left\{X_{n}\right\}$ es
\begin{itemize}
\item[a)] Recurrente positiva si $\rho<1$,
\item[b)] Transitoria
si $\rho>1$, 
\item[c)] Recurrente nula si $\rho=1$.
\end{itemize}
\end{Teo}

Recordemos que si la cadena de Markov $\left\{X_{n}\right\}$ tiene una distribuci\'on estacionaria entonces existe una distribuci\'on de probabilidad $\pi=\left(\pi_{0},\pi_{1},\ldots,\right)$, con $\pi_{i}\geq0$ y $\sum_{i\geq1}\pi_{i}=1$ tal que satisface la
ecuaci\'on $\pi=\pi P$, equivalentemente
\begin{equation}\label{Eq.18.9}
\pi_{j}=\sum_{i=0}^{\infty}\pi_{k}p_{ij},\textrm{ para
}j=0,1,2,\ldots
\end{equation}
que se puede ver como
\begin{equation}\label{Eq.19.6}
\pi_{j}=\pi_{0}a_{j}+\sum_{i=1}^{j+1}\pi_{i}a_{j-i+1}\textrm{,
para }j=0,1,\ldots
\end{equation}
si definimos
\begin{eqnarray}
\pi\left(z\right)=\sum_{j=0}^{\infty}\pi_{j}z^{j}
\end{eqnarray}
y 
\begin{equation}
A\left(z\right)=\sum_{j=0}^{\infty}a_{j}z^{j}
\end{equation}
con $|z_{j}|\leq1$. Si la ecuaci\'on \ref{Eq.19.6} la multiplicamos por $z^{j}$ y sumando sobre $j$, se tiene que
\begin{eqnarray*}
\sum_{j=0}^{\infty}\pi_{j}z^{j}&=&\sum_{j=0}^{\infty}\pi_{0}a_{j}z^{j}+\sum_{j=0}^{\infty}\sum_{i=1}^{j+1}\pi_{i}a_{j-i+1}z^{j}\\
&=&\pi_{0}\sum_{j=0}^{\infty}a_{j}z^{j}+\sum_{j=0}^{\infty}a_{j}z^{j}\sum_{i=1}^{\infty}\pi_{i}a_{i-1}\\
&=&\pi_{0}A\left(z\right)+A\left(z\right)\left(\frac{\pi\left(z\right)-\pi_{0}}{z}\right)\\
\end{eqnarray*}
es decir,

\begin{equation}
\pi\left(z\right)=\pi_{0}A\left(z\right)+A\left(z\right)\left(\frac{\pi\left(z\right)-\pi_{0}}{z}\right)\Leftrightarrow\pi\left(z\right)=\frac{\pi_{0}A\left(z\right)\left(z-1\right)}{z-A\left(z\right)}
\end{equation}

Si $z\rightarrow1$, entonces $A\left(z\right)\rightarrow A\left(1\right)=1$, y adem\'as $A^{'}\left(z\right)\rightarrow A^{'}\left(1\right)=\rho$. Si aplicamos la Regla de L'Hospital se tiene que
\begin{eqnarray*}
\sum_{j=0}^{\infty}\pi_{j}=lim_{z\rightarrow1^{-}}\pi\left(z\right)=\pi_{0}lim_{z\rightarrow1^{-}}\frac{z-1}{z-A\left(z\right)}=\frac{\pi_{0}}{1-\rho}
\end{eqnarray*}
Retomando,
\begin{eqnarray*}
a_{j}=\prob\left\{U=j\right\}=\int_{0}^{\infty}e^{-\lambda
t}\frac{\left(\lambda t\right)^{n}}{n!}dG\left(t\right)\textrm{,
para }n=0,1,2,\ldots
\end{eqnarray*}
entonces
\begin{eqnarray*}
\rho&=&\sum_{n=0}^{\infty}na_{n}=\sum_{n=0}^{\infty}n\int_{0}^{\infty}e^{-\lambda t}\frac{\left(\lambda t\right)^{n}}{n!}dG\left(t\right)\\
&=&\int_{0}^{\infty}\sum_{n=0}^{\infty}ne^{-\lambda
t}\frac{\left(\lambda
t\right)^{n}}{n!}dG\left(t\right)=\int_{0}^{\infty}\lambda
tdG\left(t\right)=\lambda\esp\left[s\right]
\end{eqnarray*}

Adem\'as, se tiene que $\rho=\beta\esp\left[s\right]=\frac{\beta}{\delta}$ y la distribuci\'on estacionaria est\'a dada por
\begin{eqnarray}
\pi_{j}&=&\pi_{0}a_{j}+\sum_{i=1}^{j+1}\pi_{i}a_{j-i+1}\textrm{, para }j=0,1,\ldots\\
\pi_{0}&=&1-\rho.
\end{eqnarray}
Por otra parte se tiene que\begin{equation}
L=\pi^{'}\left(1\right)=\rho+\frac{A^{''}\left(1\right)}{2\left(1-\rho\right)}
\end{equation}

pero $A^{''}\left(1\right)=\sum_{n=1}n\left(n-1\right)a_{n}= \esp\left[U^{2}\right]-\esp\left[U\right]$, $\esp\left[U\right]=\rho$ y
$\esp\left[U^{2}\right]=\lambda^{2}\esp\left[s^{2}\right]+\rho$.
Por lo tanto $L=\rho+\frac{\beta^{2}\esp\left[s^{2}\right]}{2\left(1-\rho\right)}$.

De las f\'ormulas de Little, se tiene que $W=E\left(w\right)=\frac{L}{\beta}$, tambi\'en el tiempo de espera en la cola
\begin{equation}
W_{q}=\esp\left(q\right)=\esp\left(w\right)-\esp\left(s\right)=\frac{L}{\beta}-\frac{1}{\delta},
\end{equation}
adem\'as el n\'umero promedio de clientes en la cola es
\begin{equation}
L_{q}=\esp\left(N_{q}\right)=\beta W_{q}=L-\rho
\end{equation}


%____________________________________________________________________________
\subsection{Cola con Infinidad de Servidores}

Este caso corresponde a $\beta_{n}=\beta$ y $\delta_{n}=n\delta$. El par\'ametro de inter\'es es $\eta=\frac{\beta}{\delta}$, de donde se obtiene:
\begin{eqnarray*}
\sum_{n\geq0}\frac{\delta_{1}\cdots\delta_{n}}{\beta_{1}\cdots\beta_{n}}=\sum_{n=1}^{\infty}n!\eta^{n}=\infty,\\
S=1+\sum_{n=1}^{\infty}\frac{\eta^{n}}{n!}=e^{n}.
\end{eqnarray*}

\begin{Prop}
La cola $M/M/\infty$ es ergodica para todos los valores de $\eta$. La distribuci\'on de equilibrio $\pi$ es Poisson con media $\eta$, $\pi_{n}=\frac{e^{-n}\eta}{n!}$
\end{Prop}



%_____________________________________________________________________________________
%
\section{Redes de Colas:Sistemas Abiertos}
%_____________________________________________________________________________________

Considerese un sistema con dos servidores, en los cuales los usuarios llegan de acuerdo a un proceso poisson con intensidad $\lambda_{1}$ al primer servidor, despu\'es de ser atendido se pasa a la siguiente cola en el segundo servidor. Cada servidor atiende a un usuario a la vez con tiempo exponencial con raz\'on $\mu_{i}$, para $i=1,2$. A este tipo de sistemas se les conoce como sistemas secuenciales.

Def\'inase el par $\left(n,m\right)$ como el n\'umero de usuarios en el servidor 1 y 2 respectivamente. Las ecuaciones de balance son
\begin{eqnarray}\label{Eq.Balance}
\lambda P_{0,0}&=&\mu_{2}P_{0,1}\\
\left(\lambda+\mu_{1}\right)P_{n,0}&=&\mu_{2}P_{n,1}+\lambda P_{n-1,0}\\
\left(\lambda+\mu_{2}\right)P_{0,m}&=&\mu_{2}P_{0,m+1}+\mu_{1}P_{1,m-1}\\
\left(\lambda+\mu_{1}+\mu_{2}\right)P_{n,m}&=&\mu_{2}P_{n,m+1}+\mu_{1}P_{n+1,m-1}+\lambda
P_{n-1,m}
\end{eqnarray}

Cada servidor puede ser visto como un modelo de tipo $M/M/1$, de igual manera el proceso de salida de una cola $M/M/1$ con raz\'on $\lambda$, nos permite asumir que el servidor 2 tambi\'en es una cola $M/M/1$. Adem\'as la probabilidad de que haya $n$ usuarios en el servidor 1 es
\begin{eqnarray*}
P\left\{n\textrm{ en el servidor }1\right\}&=&\left(\frac{\lambda}{\mu_{1}}\right)^{n}\left(1-\frac{\lambda}{\mu_{1}}\right)=\rho_{1}^{n}\left(1-\rho_{1}\right)\\
P\left\{m\textrm{ en el servidor }2\right\}&=&\left(\frac{\lambda}{\mu_{2}}\right)^{n}\left(1-\frac{\lambda}{\mu_{2}}\right)=\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\end{eqnarray*}
Si el n\'umero de usuarios en los servidores 1 y 2 son variables aleatorias independientes, se sigue que:
\begin{equation}\label{Eq.8.16}
P_{n,m}=\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)
\end{equation}
Verifiquemos que $P_{n,m}$ satisface las ecuaciones de balance (\ref{Eq.Balance}) Antes de eso, enunciemos unas igualdades que nos ser\'an de utilidad:
\begin{eqnarray*}
\mu_{i}\rho_{i}&=&\lambda\textrm{ para }i=1,2.\\
\lambda P_{0,0}&=&\lambda\left(1-\rho_{1}\right)\left(1-\rho_{2}\right)\\
\textrm{ y }\mu_{2} P_{0,1}&=&\mu_{2}\left(1-\rho_{1}\right)\rho_{2}\left(1-\rho_{2}\right)\Rightarrow\\
\lambda P_{0,0}&=&\mu_{2} P_{0,1}\\
\left(\lambda+\mu_{2}\right)P_{0,m}&=&\left(\lambda+\mu_{2}\right)\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\mu_{2}P_{0,m+1}&=&\lambda\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
&=&\mu_{2}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\mu_{1}P_{1,m-1}&=&\frac{\lambda}{\rho_{2}}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\Rightarrow\\
\left(\lambda+\mu_{2}\right)P_{0,m}&=&\mu_{2}P_{0,m+1}+\mu_{1}P_{1,m-1}\\
\left(\lambda+\mu_{1}+\mu_{2}\right)P_{n,m}&=&\left(\lambda+\mu_{1}+\mu_{2}\right)\rho^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\mu_{2}P_{n,m+1}&=&\mu_{2}\rho_{2}\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\mu_{1} P_{n-1,m-1}&=&\mu_{1}\frac{\rho_{1}}{\rho_{2}}\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\lambda P_{n-1,m}&=&\frac{\lambda}{\rho_{1}}\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
\Rightarrow\left(\lambda+\mu_{1}+\mu_{2}\right)P_{n,m}&=&\mu_{2}P_{n,m+1}+\mu_{1} P_{n-1,m-1}+\lambda P_{n-1,m}\\
\end{eqnarray*}
entonces efectivamente la ecuaci\'on (\ref{Eq.8.16}) satisface las ecuaciones de balance (\ref{Eq.Balance}). El n\'umero promedio  de usuarios en el sistema, est\'a dado por
\begin{eqnarray*}
L&=&\sum_{n,m}\left(n+m\right)P_{n,m}=\sum_{n,m}nP_{n,m}+\sum_{n,m}mP_{n,m}\\
&=&\sum_{n}\sum_{m}nP_{n,m}+\sum_{m}\sum_{n}mP_{n,m}=\sum_{n}n\sum_{m}P_{n,m}+\sum_{m}m\sum_{n}P_{n,m}\\
&=&\sum_{n}n\sum_{m}\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)+\sum_{m}m\sum_{n}\rho_{1}^{n}\left(1-\rho_{1}\right)\rho_{2}^{m}\left(1-\rho_{2}\right)\\
&=&\sum_{n}n\rho_{1}^{n}\left(1-\rho_{1}\right)\sum_{m}\rho_{2}^{m}\left(1-\rho_{2}\right)+\sum_{m}m\rho_{2}^{m}\left(1-\rho_{2}\right)\sum_{n}\rho_{1}^{n}\left(1-\rho_{1}\right)\\
&=&\sum_{n}n\rho_{1}^{n}\left(1-\rho_{1}\right)+\sum_{m}m\rho_{2}^{m}\left(1-\rho_{2}\right)\\
&=&\frac{\lambda}{\mu_{1}-\lambda}+\frac{\lambda}{\mu_{2}-\lambda}
\end{eqnarray*}


\section{Resultados para Procesos de Salida}

En \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}


%________________________________________________________
\section{Sistemas de Visitas}
%________________________________________________________

Los {\emph{Sistemas de Visitas}} fueron introducidos a principios de los a\~nos 50, ver \cite{Boxma,BoonMeiWinands,LevySidi,TesisRoubos,Takagi,Semenova}, con un problema relacionado con las personas encargadas de la revisi\'on y reparaci\'on de m\'aquinas; m\'as adelante fueron utilizados para estudiar problemas de control de se\~nales de tr\'afico. A partir de ese momento el campo de aplicaci\'on ha crecido considerablemente, por ejemplo en: comunicaci\'on en redes de computadoras, rob\'otica, tr\'afico y transporte, manufactura, producci\'on, distribuci\'on de correo, sistema de salud p\'ublica, etc.\index{Sistemas de Visita}\\

Un modelo de colas es un modelo matem\'atico que describe la situaci\'on en la que uno o varios usuarios solicitan de un servicio a una instancia, computadora o persona. Aquellos usuarios que no son atendidos inmediatamente toman un lugar en una cola en espera de servicio. Un sistema de visitas consiste en modelos de colas conformadas por varias colas y un solo servidor que las visita en alg\'un orden para atender a los usuarios que se encuentran esperando por servicio.\index{Sistemas de Espera}

Uno de los principales objetivos de este tipo de sistemas es tratar de mejorar el desempe\~no del sistema de visitas. Una de medida de desempe\~no importante es el tiempo de respuesta del sistema, as\'i como los tiempos promedios de espera en una fila y el tiempo promedio total que tarda en ser realizada una operaci\'on completa a lo largo de todo el sistema.\index{Medidas de Desempe\~no} Algunas medidas de desempe\~no para los usuarios son los valores promedio de espera para ser atendidos, de servicio, de permanencia total en el sistema; mientras que para el servidor son los valores promedio de permanencia en una cola atendiendo, de traslado entre las colas, de duraci\'on del ciclo entre dos visitas consecutivas a la misma cola, entre otras medidas de desempe\~no estudiadas en la literatura.\\

Los sistemas de visitas pueden dividirse en dos clases:
\begin{itemize}
\item[i)] hay varios servidores y los usuarios que llegan al sistema eligen un servidor de entre los que est\'an presentes.

\item[ii)] hay uno o varios servidores que son comunes a todas las colas, estos visitan a cada una de las colas y atienden a los usuarios que est\'an presentes al momento de la visita del
servidor.
\end{itemize}

Los usuarios llegan a las colas de manera tal que los tiempos entre arribos son independientes e id\'enticamente distribuidos. En la mayor\'ia de los modelos de visitas c\'iclicas, la capacidad de almacenamiento es infinita, es decir la cola puede acomodar a una cantidad infinita de usuarios a la vez. Los tiempos de servicio en una cola son usualmente considerados como muestra de una distribuci\'on de probabilidad que caracteriza a la cola, adem\'as se acostumbra considerarlos mutuamente independientes e independientes del estado actual del sistema. \\

La ruta de atenci\'on del servidor, es el orden en el cual el servidor visita las colas determinado por un mecanismo que puede depender del estado actual del sistema (din\'amico) o puede ser independiente del estado del sistema (est\'atico). El mecanismo m\'as utilizado es el c\'iclico. Para modelar sistemas en los cuales ciertas colas son visitadas con mayor frecuencia que otras, las colas c\'iclicas se han extendido a colas peri\'odicas, en las cuales el servidor visita la cola conforme a una orden de servicio de longitud finita. \index{Colas C\'iclicas}\\

El {\em orden de visita} se entiende como la regla utilizada por el servidor para elegir la pr\'oxima cola. Este servicio puede ser din\'amico o est\'atico:\index{Orden de visita}

\begin{itemize}
\item[i)] Para el caso {\em est\'atico} la regla permanece invariante a lo largo del curso de la operaci\'on del sistema.

\item[ii)] Para el caso {\em din\'amico} la cola que se elige para servicio en el momento depende de un conocimiento total o parcial del estado del sistema.
\end{itemize}

Dentro de los ordenes de tipo est\'atico hay varios, los m\'as comunes son:

\begin{itemize}
\item[i)] {\em c\'iclico}: Si denotamos por $\left\{Q_{i}\right\}_{i=1}^{N}$ al conjunto de colas a las cuales el servidor visita en el orden \[Q_{1},Q_{2},\ldots,Q_{N},Q_{1},Q_{2},\ldots,Q_{N}.\]

\item[ii)] {\em peri\'odico}: el servidor visita las colas en el orden:
\[Q_{T\left(1\right)},Q_{T\left(2\right)},\ldots,Q_{T\left(M\right)},Q_{T\left(1\right)},\ldots,Q_{T\left(M\right)}\]
caracterizada por una tabla de visitas
\[\left(T\left(1\right),T\left(2\right),\ldots,T\left(M\right)\right),\]
con $M\geq N$, $T\left(i\right)\in\left\{1,2,\ldots,N\right\}$ e $i=\overline{1,M}$. Hay un caso especial, {\em colas tipo elevador} donde las colas son atendidas en el orden \[Q_{1},Q_{2},\ldots,Q_{N},Q_{1},Q_{2},\ldots,Q_{N-1},Q_{N},Q_{N-1},\ldots,Q_{1},\].

\item[iii)] {\em aleatorio}: la cola $Q_{i}$ es elegida para ser atendida con probabilidad $p_{i}$, $i=\overline{1,N}$, $\sum_{i=1}^{N}p_{i}=1$. Una posible variaci\'on es que despu\'es de atender $Q_{i}$ el servidor se desplaza a $Q_{j}$ con probabilidad $p_{ij}$, con $i,j=\overline{1,N}$, $\sum_{j=1}^{N}p_{ij}=1$, para $i=\overline{1,N}$.
\end{itemize}

El servidor usualmente incurrir\'a en tiempos de traslado para ir de una cola a otra. Un sistema de visitas puede expresarse en un par de par\'ametros: el n\'umero de colas, que usualmente se denotar\'a por $N$, y el tr\'afico caracter\'istico de las colas, que consiste de los procesos de arribo y los procesos de servicio caracteriza a estos sistemas.\\

La disciplina de servicio especifica el n\'umero de usuarios que son atendidos durante la visita del servidor a la cola; estas pueden ser clasificadas en l\'imite de usuarios atendidos y en usuarios atendidos en un tiempo l\'imite, poniendo restricciones en la cantidad de tiempo utilizado por el servidor en una visita a la cola. Alternativamente pueden ser clasificadas en pol\'iticas exhaustivas y pol\'iticas cerradas, dependiendo en si los usuarios que llegaron a la cola mientras el servidor estaba dando servicio son candidatos para ser atendidos por el servidor que se encuentra en la cola dando servicio. En la pol\'itica exhaustiva estos usuarios son candidatos para ser atendidos mientras que en la cerrada no lo son. De estas dos pol\'iticas se han creado h\'ibridos los cuales pueden revisarse en \cite{BoonMeiWinands}.\index{Disciplina de Servicio}\\

La disciplina de la cola especifica el orden en el cual los usuarios presentes en la cola son atendidos. La m\'as com\'un es la {\em First-In-First-Served}. Las pol\'iticas m\'as comunes son las de tipo exhaustivo que consiste en que el servidor continuar\'a trabajando hasta que la cola quede vac\'ia; y la pol\'itica cerrada, bajo la cual ser\'an atendidos exactamente aquellos que estaban presentes al momento en que lleg\'o el servidor a la cola. \index{Pol\'itica de Servicio}\\

Las pol\'iticas de servicio deben de satisfacer las siguientes propiedades:
\begin{itemize}
\item[i)] No dependen de los procesos de servicio anteriores.
\item[ii)] La selecci\'on de los usuarios para ser atendidos es independiente del tiempo de servicio requerido  y de los posibles arribos futuros.
\item[iii)] las pol{\'\i}ticas de servicio que son aplicadas, es decir, el n\'umero de usuarios en la cola que ser{\'a}n atendidos durante la visita del servidor a la misma; \'estas pueden ser clasificadas por la cantidad de usuarios atendidos y por el n\'umero de usuarios atendidos en un intervalo de tiempo determinado. Las principales pol\'iticas de servicio para las cuales se han desarrollado aplicaciones son: la exhaustiva, la cerrada y la $k$-l\'imite, ver \cite{LevySidi, Takagi, Semenova}. De estas pol\'iticas se han creado h\'ibridos los cuales pueden revisarse en Boon and Van der Mei \cite{BoonMeiWinands}.

\item[iv)] Una pol{\'\i}tica de servicio es asignada a cada etapa independiente de la cola que se est{\'a} atendiendo, no necesariamente es la misma para todas las etapas.
\item[v)] El servidor da servicio de manera constante.

\item[vi)] La pol\'itica de servicio se asume mon\'otona (ver
\cite{Stability}).

\end{itemize}

Las principales pol\'iticas deterministas de servicio son:\index{Pol\'iticas Deterministas}
\begin{itemize}

\item[i)] {\em Cerrada} donde solamente los usuarios presentes al comienzo de la etapa son considerados para ser atendidos.

\item[ii)] {\em Exhaustiva} en la que tanto los usuarios presentes al comienzo de la etapa como los que arriban   mientras se est\'a dando servicio son considerados para ser atendidos.

\item[iii)] $k_{i}$-limited: el n\'umero de usuarios por atender en la cola $i$ est\' acotado por $k_{i}$.

\item[iv)] {\em tiempo limitado} la cola es atendida solo por un periodo de tiempo fijo.
\end{itemize}

\begin{Note}
\begin{itemize}
\item[a) ] Una etapa es el periodo de tiempo durante el cual el
servidor atiende de manera continua en una sola cola.

\item[b) ] Un ciclo  es el periodo necesario para terminar $l$ etapas.
\end{itemize}
\end{Note}

Boxma y Groenendijk \cite{Boxma2} enuncian la Ley de Pseudo-Conservaci\'on para la pol\'itica exhaustiva como\index{Ley de Pseudo-Conservaci\'on}

\begin{equation}\label{LPCPE}
\sum_{i=1}^{N}\rho_{i}\esp
W_{i}=\rho\frac{\sum_{i=1}^{N}\lambda_{i}\esp\left[\delta_{i}^{(2)}\left(1\right)\right]}{2\left(1-\rho\right)}+\rho\frac{\delta^{(2)}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\left[\rho^{2}-\sum_{i=1}^{N}\rho_{i}^{2}\right],
\end{equation}

donde $\delta=\sum_{i=1}^{N}\delta_{i}\left(1\right)$ y
$\delta_{i}^{(2)}$ denota el segundo momento de los tiempos de traslado entre colas del servidor, $\delta^{(2)}$ es el segundo momento de los tiempos de traslado entre las colas de todo el sistema, finalmente $\rho=\sum_{i=1}^{N}\rho_{i}$. Por otro lado, se tiene que

\begin{equation}\label{Eq.Tiempo.Espera}\index{Tiempos de Espera}
\esp W_{i}=\frac{\esp I_{i}^{2}}{2\esp
I_{i}}+\frac{\lambda_{i}\esp\left[\eta_{i}^{(2)}\left(1\right)\right]}{2\left(1-\rho_{i}\right)},
\end{equation}

con $I_{i}$ definido como el peri\'odo de intervisita, es decir el tiempo entre una salida y el pr\'oximo arribo del servidor a la cola $Q_{i}$, dado por $I_{i}=C_{i}-V_{i}$, donde $C_{i}$ es la longitud del ciclo, definido como el tiempo entre dos instantes de visita consecutivos a la cola $Q_{i}$ y $V_{i}$ es el periodo de visita, definido como el tiempo que el servidor utiliza en atender a los usuarios de la cola $Q_{i}$.\index{Periodo de Intervisita}
\begin{equation}\label{Eq.Periodo.Intervisita}
\esp
I_{i}=\frac{\left(1-\rho_{i}\right)}{1-\rho}\sum_{i=1}^{N}\esp\left[\delta_{i}\left(1\right)\right],
\end{equation}

con

\begin{equation}\label{SdoMomento.Periodo.Intervisita}
\esp
I_{i}^{2}=\esp\left[\delta_{i-1}^{(2)}\left(1\right)\right]-\left(\esp\left[\delta_{i-1}\left(1\right)\right]\right)^{2}+
\frac{1-\rho_{i}}{\rho_{i}}\sum_{j=1,j\neq i}^{N}r_{ij}+\left(\esp
I_{i}\right)^{2},
\end{equation}

donde el conjunto de valores $\left\{r_{ij}:i,j=1,2,\ldots,N\right\}$ representan la covarianza del tiempo para las colas $i$ y $j$; para sistemas con servicio exhaustivo, el tiempo de estaci\'on para la cola $i$ se define como el intervalo de tiempo entre instantes sucesivos cuando el servidor abandona la cola $i-1$ y la cola $i$. Hideaki Takagi \cite{Takagi} proporciona expresiones cerradas para calcular $r_{ij}$, \'estas implican resolver un sistema de $N^{2}$ ecuaciones lineales;

%{\footnotesize{
\begin{eqnarray}\label{Eq.Cov.TT}
\begin{array}{l}
r_{ij}=\frac{\rho_{i}}{1-\rho_{i}}\left(\sum_{m=i+1}^{N}r_{jm}+\sum_{m=1}^{j-1}r_{jm}+\sum_{m=j}^{i-1}r_{jm}\right),\textrm{
}j<i,\\
r_{ij}=\frac{\rho_{i}}{1-\rho_{i}}\left(\sum_{m=i+1}^{j-1}r_{jm}+\sum_{m=j}^{N}r_{jm}+\sum_{m=1}^{i-1}r_{jm}\right),\textrm{
}j>i,\\
r_{ij}=\frac{\esp\left[\delta_{i-1}^{(2)}\left(1\right)\right]-\left(\esp\left[\delta_{i-1}\left(1\right)\right]\right)^{2}}
{\left(1-\rho_{i}\right)^{2}}+\frac{\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]}{\left(1-\rho_{i}\right)^{3}}+\frac{\rho_{i}}{1-\rho_{i}}\sum_{j=i,j=1}^{N}r_{ij}.
\end{array}
\end{eqnarray}\index{Pol\'itica de Servicio Exhaustiva}

Para el caso de la Pol\'itica Cerrada la Ley de Pseudo-Conservaci\'on se expresa en los siguientes t\'erminos.
\begin{equation}\label{LPCPG}
\sum_{i=1}^{N}\rho_{i}\esp
W_{i}=\rho\frac{\sum_{i=1}^{N}\lambda_{i}\esp\left[\delta_{i}\left(1\right)^{(2)}\right]}{2\left(1-\rho\right)}+\rho\frac{\delta^{(2)}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\left[\rho^{2}+\sum_{i=1}^{N}\rho_{i}^{2}\right],
\end{equation}
el tiempo de espera promedio para los usuarios en la cola $Q_{1}$ se puede determinar por medio de
\begin{equation}\label{Eq.Tiempo.Espera.Gated}
\esp W_{i}=\frac{\left(1+\rho_{i}\right)\esp C_{i}^{2}}{2\esp
C_{i}},
\end{equation}\index{Tiempos de Espera}
donde $C_{i}$ denota la longitud del ciclo para la cola $Q_{i}$, definida como el tiempo entre dos instantes consecutivos de visita en $Q_{i}$, cuyo segundo momento est\'a dado por

\begin{equation}\label{Eq.Periodo.Intervisita.Gated}
\esp C_{i}^{2}=\frac{1}{\rho_{i}}\sum_{j=1,j\neq
i}^{N}r_{ij}+\sum_{j=1}^{N}r_{ij}+\left(\esp C\right)^{2},
\end{equation}\index{Periodo de Intervisita}
con
\begin{eqnarray*}
\esp C=\frac{\delta}{1-\rho},
\end{eqnarray*}
donde $r_{ij}$ representa la covarianza del tiempo de estaci\'on para las colas $i$ y $j$, pero el tiempo de estaci\'on para la cola $i$ para la pol\'itica cerrada se define como el intervalo de tiempo entre instantes sucesivos cuando el servidor visita la cola $i$ y la cola $i+1$. El conjunto $\left\{r_{ij}:i,j=1,2,\ldots,N\right\}$ se calcula resolviendo un
sistema de $N^{2}$ ecuaciones lineales

\begin{eqnarray}\label{Eq.Cov.TT.Gated}
\begin{array}{l}
r_{ij}=\rho_{i}\left(\sum_{m=i}^{N}r_{jm}+\sum_{m=1}^{j-1}r_{jm}+\sum_{m=j}^{i-1}r_{mj}\right),\textrm{
}j<i,\\
r_{ij}=\rho_{i}\left(\sum_{m=i}^{j-1}r_{jm}+\sum_{m=j}^{N}r_{jm}+\sum_{m=1}^{i-1}r_{mj}\right),\textrm{
}j>i,\\
r_{ij}=r_{i-1}^{(2)}-\left(r_{i-1}^{(1)}\right)^{2}+\lambda_{i}b_{i}^{(2)}\esp
C_{i}+\rho_{i}\sum_{j=1,j\neq
i}^{N}r_{ij}+\rho_{i}^{2}\sum_{i=j,j=1}^{N}r_{ij}.
\end{array}
\end{eqnarray}

Finalmente, Takagi \cite{Takagi} proponen una aproximaci\'on para los tiempos de espera de los usuarios en cada una de las colas:
\begin{eqnarray}
\begin{array}{l}
\sum_{i=1}^{N}\frac{\rho_{i}}{\rho}\left(1-\frac{\lambda_{i}\delta}{1-\rho}\right)\esp\left[W_{i}\right]=\sum_{i=1}^{N}\frac{\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]}{2\left(1-\rho\right)}\\
+\frac{\sum_{i=1}^{N}\esp\left[\delta_{i}^{2}\right]-\left(\esp\left[\delta_{i}\left(1\right)\right]\right)^{2}}{2\delta}+\frac{\delta\left(\rho-\sum_{i=1}^{N}\rho_{i}^{2}\right)}{2\rho\left(1-\rho\right)}+\frac{\delta\sum_{i=1}^{N}\rho_{i}^{2}}{\rho\left(1-\rho\right)},
\end{array}
\end{eqnarray}
entonces
\begin{eqnarray}\label{LPCPKL}
\begin{array}{l}
\esp
W_{i}\cong\frac{1-\rho+\rho_{i}}{1-\rho-\lambda_{i}\delta}\times\frac{1-\rho}{\rho\left(1-\rho\right)+\sum_{i=1}^{N}\rho_{i}^{2}}\\
\times\left[\frac{\rho}{2\left(1-\rho\right)}\sum_{i=1}^{N}\lambda_{i}\esp\left[\eta_{i}\left(1\right)^{(2)}\right]+\frac{\rho\Delta^{2}}{2\delta}+\frac{\delta}{2\left(1-\rho\right)}\sum_{i=1}^{N}\rho_{i}\left(1+\rho_{i}\right).\right]
\end{array}
\end{eqnarray}
donde $\Delta^{2}=\sum_{i=1}^{N}\delta_{i}^{2}$. El modelo est\'a compuesto por $c$ colas de capacidad infinita, etiquetadas de $1$ a $c$ las cuales son atendidas por $s$ servidores. Los servidores atienden de acuerdo a una cadena de Markov independiente $\left(X^{i}_{n}\right)_{n}$ con $1\leq i\leq s$ y $n\in\left\{1,2,\ldots,c\right\}$ con la misma matriz de transici\'on $r_{k,l}$ y \'unica medida invariante $\left(p_{k}\right)$. Cada servidor permanece atendiendo en la cola un periodo llamado de visita y determinada por la pol\'itica de servicio asignada a la cola.\\

Los usuarios llegan a la cola $k$ con una tasa $\lambda_{k}$ y son atendidos a una raz\'on $\mu_{k}$. Las sucesiones de tiempos de inter-arribo $\left(\tau_{k}\left(n\right)\right)_{n}$, la de tiempos de servicio $\left(\sigma_{k}^{i}\left(n\right)\right)_{n}$ y la de tiempos de cambio $\left(\sigma_{k,l}^{0,i}\left(n\right)\right)_{n}$ requeridas en la cola $k$ para el servidor $i$ son sucesiones independientes e id\'enticamente distribuidas con distribuci\'on general independiente de $i$, con media $\sigma_{k}=\frac{1}{\mu_{k}}$, respectivamente $\sigma_{k,l}^{0}=\frac{1}{\mu_{k,l}^{0}}$, e independiente de las cadenas de Markov $\left(X^{i}_{n}\right)_{n}$. Adem\'as se supone que los tiempos de interarribo se asume son acotados, para cada $\rho_{k}=\lambda_{k}\sigma_{k}<s$ para asegurar la estabilidad de la cola $k$ cuando opera como una cola $M/GM/1$.\index{Tiempos de inter-arribo}\\

Una pol\'itica de servicio determina el n\'umero de usuarios que ser\'an atendidos sin interrupci\'on en periodo de servicio por los servidores que atienden a la cola. Para un solo servidor esta se define a trav\'es de una funci\'on $f$ donde $f\left(x,a\right)$ es el n\'umero de usuarios que son atendidos sin interrupci\'on cuando el servidor llega a la cola y encuentra $x$ usuarios esperando dado el tiempo transcurrido de interarribo $a$. Sea $v\left(x,a\right)$ la du raci\'on del periodo de servicio para una sola condici\'on inicial $\left(x,a\right)$.\index{Pol\'itica de Servicio} Las pol\'iticas de servicio consideradas satisfacen las siguientes propiedades:

\begin{itemize}
\item[i)] Hay conservaci\'on del trabajo, es decir
\begin{eqnarray}
v\left(x,a\right)=\sum_{l=1}^{f\left(x,a\right)}\sigma\left(l\right)
\end{eqnarray}
con $f\left(0,a\right)=v\left(0,a\right)=0$, donde $\left(\sigma\left(l\right)\right)_{l}$ es una sucesi\'on independiente e id\'enticamente distribuida de los tiempos de servicio solicitados. 
\item[ii)] La selecci\'on de usuarios para se atendidos es independiente de sus correspondientes tiempos de servicio y del pasado hasta el inicio del periodo de servicio. As\'i las distribuci\'on $\left(f,v\right)$ no depende del orden en el cu\'al son atendidos los usuarios. \item[iii)] La pol\'itica de servicio es mon\'otona en el sentido de que para cada $a\geq0$ los n\'umeros $f\left(x,a\right)$ son mon\'otonos en distribuci\'on en $x$ y su l\'imite en distribuci\'on cuando $x\rightarrow\infty$ es una variable aleatoria $F^{*0}$ que no depende de $a$. \item[iv)] El n\'umero de usuarios atendidos por cada servidor es acotado por $f^{min}\left(x\right)$ de la longitud de la cola $x$ que adem\'as converge mon\'otonamente en distribuci\'on a $F^{*}$ cuando $x\rightarrow\infty$.
\end{itemize}


Un sistema de visitas o sistema de colas consiste en un cierto n\'umero de filas o colas atendidas por un solo servidor en un orden determinado, estos se puede aplicar en situaciones en las cuales varios tipos de usuarios intentan tener acceso a una fuente en com\'un que est\'a disponible para un solo tipo de usuario a la vez. 

%__________________________________________
 \section{Funci\'on Generadora de Probabilidades}
%__________________________________________

\begin{Teo}[Teorema de Continuidad]\index{Teorema de Continuidad}
Sup\'ongase que $\left\{X_{n},n=1,2,3,\ldots\right\}$ son variables aleatorias finitas, no negativas con valores enteros tales que $P\left(X_{n}=k\right)=p_{k}^{(n)}$, para $n=1,2,3,\ldots$, $k=0,1,2,\ldots$, con $\sum_{k=0}^{\infty}p_{k}^{(n)}=1$, para $n=1,2,3,\ldots$. Sea $g_{n}$ la Funci\'on Generadora de Probabilidades (FGP)  para la variable aleatoria $X_{n}$. Entonces existe una sucesi\'on $\left\{p_{k}\right\}$ tal que 
\begin{eqnarray}
lim_{n\rightarrow\infty}p_{k}^{(n)}=p_{k}\textrm{ para }0<s<1.
\end{eqnarray}

En este caso, $g\left(s\right)=\sum_{k=0}^{\infty}s^{k}p_{k}$. Adem\'as
\begin{eqnarray}
\sum_{k=0}^{\infty}p_{k}=1\textrm{ si y s\'olo si
}lim_{s\uparrow1}g\left(s\right)=1.
\end{eqnarray}
\end{Teo}

\begin{Teo}
Sea $N$ una variable aleatoria con valores enteros no negativos finita tal que $P\left(N=k\right)=p_{k}$, para $k=0,1,2,\ldots$, y 
\begin{eqnarray}
\sum_{k=0}^{\infty}p_{k}=P\left(N<\infty\right)=1.
\end{eqnarray} 

Sea $\Phi$ la FGP de $N$ tal que
\begin{eqnarray}
g\left(s\right)=\esp\left[s^{N}\right]=\sum_{k=0}^{\infty}s^{k}p_{k},
\end{eqnarray}
 con $g\left(1\right)=1$. Si $0\leq p_{1}\leq1$ y 
 \begin{eqnarray}
\esp\left[N\right]=g^{'}\left(1\right)\leq1,
\end{eqnarray}
 entonces no existe soluci\'on  de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$. Si $\esp\left[N\right]=g^{'}\left(1\right)>1$, lo cual implica que $0\leq p_{1}<1$, entonces existe una \'unica soluci\'on de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$.
\end{Teo}

\begin{Teo}
Si $X$ y $Y$ tienen PGF $G_{X}$ y $G_{Y}$ respectivamente, entonces,\[G_{X}\left(s\right)=G_{Y}\left(s\right)\] para toda $s$, s\'i y s\'olo s\'i
\begin{eqnarray}
P\left(X=k\right))=P\left(Y=k\right),
\end{eqnarray}
para toda $k=0,1,\ldots,$., es decir, si y s\'olo si $X$ y $Y$ tienen la misma distribuci\'on de probabilidad.
\end{Teo}

\begin{Teo}
Para cada $n$ fijo, sea la sucesi\'on de probabilidades $\left\{a_{0,n},a_{1,n},\ldots,\right\}$, tales que $a_{k,n}\geq0$ para toda $k=0,1,2,\ldots,$ y $\sum_{k\geq0}a_{k,n}=1$, y sea $G_{n}\left(s\right)$ la correspondiente funci\'on generadora, $G_{n}\left(s\right)=\sum_{k\geq0}a_{k,n}s^{k}$. De modo que para cada valor fijo de $k$
\begin{eqnarray}
lim_{n\rightarrow\infty}a_{k,n}=a_{k},
\end{eqnarray}
es decir converge en distribuci\'on, es necesario y suficiente que para cada valor fijo $s\in\left[0,\right)$,

\begin{eqnarray}
lim_{n\rightarrow\infty}G_{n}\left(s\right)=G\left(s\right),
\end{eqnarray}
donde $G\left(s\right)=\sum_{k\geq0}p_{k}s^{k}$, para cualquier la funci\'on generadora del l\'imite de la sucesi\'on.
\end{Teo}

\begin{Teo}[Teorema de Abel]\index{Teorema de Abel}
Sea $G\left(s\right)=\sum_{k\geq0}a_{k}s^{k}$ para cualquier $\left\{p_{0},p_{1},\ldots,\right\}$, tales que $p_{k}\geq0$ para toda $k=0,1,2,\ldots,$. Entonces $G\left(s\right)$ es continua por la derecha en $s=1$, es decir
\begin{eqnarray}
lim_{s\uparrow1}G\left(s\right)=\sum_{k\geq0}p_{k}=G\left(s\right),
\end{eqnarray}
sin importar si la suma es finita o no.
\end{Teo}

\begin{Note}
El radio de Convergencia para cualquier FGP es $R\geq1$, entonces, el Teorema de Abel nos dice que a\'un en el peor escenario, cuando $R=1$, a\'un se puede confiar en que la FGP ser\'a continua en $s=1$, en contraste, no se puede asegurar que la FGP ser\'a continua en el l\'imite inferior $-R$, puesto que la FGP es sim\'etrica alrededor del cero: la FGP converge para todo $s\in\left(-R,R\right)$, y no lo hace para $s<-R$ o $s>R$. Adem\'as nos dice que podemos escribir $G_{X}\left(1\right)$ como una abreviaci\'on de $lim_{s\uparrow1}G_{X}\left(s\right)$.
\end{Note}

Entonces si suponemos que la diferenciaci\'on t\'ermino a t\'ermino est\'a permitida, entonces

\begin{eqnarray}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x}
\end{eqnarray}

el Teorema de Abel nos dice que
\begin{eqnarray}
\begin{array}{l}
\esp\left(X\right]=\lim_{s\uparrow1}G_{X}^{'}\left(s\right):\\
\esp\left[X\right]=\sum_{x=1}^{\infty}xp_{x}=G_{X}^{'}\left(1\right)=\lim_{s\uparrow1}G_{X}^{'}\left(s\right),
\end{array}
\end{eqnarray}
dado que el Teorema de Abel se aplica a
\begin{eqnarray}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x},
\end{eqnarray}
estableciendo as\'i que $G_{X}^{'}\left(s\right)$ es continua en $s=1$. Sin el Teorema de Abel no se podr\'ia asegurar que el l\'imite de $G_{X}^{'}\left(s\right)$ conforme $s\uparrow1$ sea la respuesta correcta para $\esp\left[X\right]$.

\begin{Note}
La FGP converge para todo $|s|<R$, para alg\'un $R$. De hecho la FGP converge absolutamente si $|s|<R$. La FGP adem\'as converge uniformemente en conjuntos de la forma $\left\{s:|s|<R^{'}\right\}$, donde $R^{'}<R$, es decir, $\forall\epsilon>0, \exists n_{0}\in\ent$ tal que $\forall s$, con $|s|<R^{'}$, y $\forall n\geq n_{0}$,
\begin{eqnarray}
|\sum_{x=0}^{n}s^{x}\prob\left(X=x\right)-G_{X}\left(s\right)|<\epsilon.
\end{eqnarray}
De hecho, la convergencia uniforme es la que nos permite diferenciar t\'ermino a t\'ermino:
\begin{eqnarray}
G_{X}\left(s\right)=\esp\left[s^{X}\right]=\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right),
\end{eqnarray}
y sea $s<R$.
\begin{enumerate}
\item
\begin{eqnarray}
G_{X}^{'}\left(s\right)=\frac{d}{ds}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)=\sum_{x=0}^{\infty}\frac{d}{ds}\left(s^{x}\prob\left(X=x\right)\right)=\sum_{x=0}^{n}xs^{x-1}\prob\left(X=x\right).
\end{eqnarray}

\item\begin{eqnarray}
\int_{a}^{b}G_{X}\left(s\right)ds&=&\int_{a}^{b}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)ds=\sum_{x=0}^{\infty}\left(\int_{a}^{b}s^{x}\prob\left(X=x\right)ds\right)=\sum_{x=0}^{\infty}\frac{s^{x+1}}{x+1}\prob\left(X=x\right),
\end{eqnarray}
para $-R<a<b<R$.
\end{enumerate}
\end{Note}

\begin{Teo}[Teorema de Convergencia Mon\'otona para FGP]\index{Teorema de Convergencia Mon\'otona} Sean $X$ y $X_{n}$ variables aleatorias no negativas, con valores en los enteros, finitas, tales que
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{X_{n}}\left(s\right)&=&G_{X}\left(s\right)
\end{eqnarray*}
para $0\leq s\leq1$, entonces
\begin{eqnarray*}
lim_{n\rightarrow\infty}P\left(X_{n}=k\right)=P\left(X=k\right),
\end{eqnarray*}
para $k=0,1,2,\ldots.$
\end{Teo}

El teorema anterior requiere del siguiente lema:
\begin{Lemma}
Sean $a_{n,k}\in\ent^{+}$, $n\in\nat$ constantes no negativas con
$\sum_{k\geq0}a_{k,n}\leq1$. Sup\'ongase que para $0\leq s\leq1$,
se tiene
\begin{eqnarray}
a_{n}\left(s\right)&=&\sum_{k=0}^{\infty}a_{k,n}s^{k}\rightarrow
a\left(s\right)=\sum_{k=0}^{\infty}a_{k}s^{k}.
\end{eqnarray}
Entonces
\begin{eqnarray}
a_{0,n}\rightarrow a_{0}.
\end{eqnarray}
\end{Lemma}

Consideremos un sistema que consta de \'unicamente un servidor y una sola cola, a la cual los usuarios arriban conforme a un proceso poisson cuya tasa promedio de llegada es $1/\lambda$; la tasa promedio con la cual el servidor da servicio es $1/\mu$, adem\'as los tiempos entre arribos y los tiempos de servicio son independientes entre s\'i. Se define la carga de tr\'afico $\rho:=\frac{\lambda}{\mu}$, para este modelo existe un teorema que nos dice la relaci\'on que hay entre el valor de $\rho$ y la estabilidad de la cola:

\begin{Prop}\index{Cola $M/M/1$}
La cola $M/M/1$ con carga de tr\'afico $\rho$, es estable si y s\'olo si $\rho<1$.
\end{Prop}

Este teorema nos permite determinar las principales medidas de desempe\~no: Tiempo de espera en el sistema, $W$, el n\'umero esperado de clientes en el sistema, $L$, adem\'as de los tiempos promedio e espera tanto en la cola como de servicio, $s$ representa el tiempo de servicio para un cliente:

\begin{eqnarray}
\begin{array}{l}
 L=\frac{\rho}{1-\rho},\\
W=\frac{1}{\mu-\lambda},\\
W_{q}=\esp\left[s\right]\frac{\rho}{1-\rho}\textrm{,  y }\\
L_{q}=\frac{\rho^{2}}{1-\rho}.
\end{array}
\end{eqnarray}

Esta es la idea general, poder determinar la principales medidas de desempe\~no para un sistema de colas o sistema de visitas, para este fin es necesario realizar los siguientes supuestos. En teor\'ia de colas hay casos particulares, para los cuales es posible determinar espec\'ificamente medidas de desempe\~no del sistema bajo condiciones de estabilidad, tales como los tiempos promedio de espera y de servicio, tanto en el sistema como en cada
una de las colas.\\

En teor\'ia de colas hay casos particulares, para los cuales es posible determinar espec\'ificamente medidas de desempe\~no del sistema bajo condiciones de estabilidad, tales como los tiempos promedio de espera y de servicio, tanto en el sistema como en cada una de las colas. Se considerar\'an intervalos de tiempo de la forma $\left[t,t+1\right]$. Los usuarios arriban por paquetes de manera independiente del resto de las colas. Se define el grupo de usuarios que llegan a cada una de las colas del sistema 1, caracterizadas por $Q_{1}$ y $Q_{2}$ respectivamente, en el intervalo de tiempo $\left[t,t+1\right]$ por $X_{1}\left(t\right),X_{2}\left(t\right)$.\\

Para cada uno de los procesos anteriores se define su Funci\'on Generadora de Probabilidades (FGP):

\begin{eqnarray}
\begin{array}{cc}
P_{1}\left(z_{1}\right)=\esp\left[z_{1}^{X_{1}\left(t\right)}\right], & P_{2}\left(z_{2}\right)=\esp\left[z_{2}^{X_{2}\left(t\right)}\right].
\end{array}
\end{eqnarray}

Con primer momento definidos por

\begin{eqnarray}
\begin{array}{l}
\mu_{1}=\esp\left[X_{1}\left(t\right)\right]=P_{1}^{(1)}\left(1\right),\\
\mu_{2}=\esp\left[X_{2}\left(t\right)\right]=P_{2}^{(1)}\left(1\right).
\end{array}
\end{eqnarray}

En lo que respecta al servidor, en t\'erminos de los tiempos de visita a cada una de las colas, se denotar\'an por $\tau_{1},\tau_{2}$ para $Q_{1},Q_{2}$ respectivamente; y a los tiempos en que el servidor termina de atender en las colas $Q_{1},Q_{2}$, se les denotar\'a por $\overline{\tau}_{1},\overline{\tau}_{2}$ respectivamente. Entonces, los tiempos de servicio est\'an dados por las diferencias $\overline{\tau}_{1}-\tau_{1},\overline{\tau}_{2}-\tau_{2}$ para $Q_{1},Q_{2}$. \\

An\'alogamente los tiempos de traslado del servidor desde el momento en que termina de atender a una cola y llega a la siguiente para comenzar a dar servicio est\'an dados por $\tau_{2}-\overline{\tau}_{1},\tau_{1}-\overline{\tau}_{2}$. La FGP para estos tiempos de traslado est\'an dados por

\begin{eqnarray}
\begin{array}{cc}
R_{1}\left(z_{1}\right)=\esp\left[z_{1}^{\tau_{2}-\overline{\tau}_{1}}\right],
&
R_{2}\left(z_{2}\right)=\esp\left[z_{2}^{\tau_{1}-\overline{\tau}_{2}}\right],
\end{array}
\end{eqnarray}

y al igual que como se hizo con anterioridad

\begin{eqnarray}
\begin{array}{cc}
r_{1}=R_{1}^{(1)}\left(1\right)=\esp\left[\tau_{2}-\overline{\tau}_{1}\right],
&
r_{2}=R_{2}^{(1)}\left(1\right)=\esp\left[\tau_{1}-\overline{\tau}_{2}\right].
\end{array}
\end{eqnarray}
Sean $\alpha_{1},\alpha_{2}$ el n\'umero de usuarios que arriban
en grupo a la cola $Q_{1}$ y $Q_{2}$ respectivamente. Sus FGP's
est\'an definidas como

\begin{eqnarray}
\begin{array}{cc}
A_{1}\left(z\right)=\esp\left[z^{\alpha_{1}\left(t\right)}\right],&
A_{2}\left(z\right)=\esp\left[z^{\alpha_{2}\left(t\right)}\right].\\
\end{array}
\end{eqnarray}

Su primer momento est\'a dado por

\begin{eqnarray}
\begin{array}{cc}
\lambda_{1}=\esp\left[\alpha_{1}\left(t\right)\right]=A_{1}^{(1)}\left(1\right),&
\lambda_{2}=\esp\left[\alpha_{2}\left(t\right)\right]=A_{2}^{(1)}\left(1\right).\\
\end{array}
\end{eqnarray}

Sean $\beta_{1},\beta_{2}$ el n\'umero de usuarios que arriban en el grupo $\alpha_{1},\alpha_{2}$ a la cola $Q_{1}$ y $Q_{2}$, respectivamente, de igual manera se definen sus F'GPs

\begin{eqnarray}
\begin{array}{cc}
B_{1}\left(z\right)=\esp\left[z^{\beta_{1}\left(t\right)}\right],&
B_{2}\left(z\right)=\esp\left[z^{\beta_{2}\left(t\right)}\right],\\
\end{array}
\end{eqnarray}

con

\begin{eqnarray}
\begin{array}{cc}
b_{1}=\esp\left[\beta_{1}\left(t\right)\right]=B_{1}^{(1)}\left(1\right),&
b_{2}=\esp\left[\beta_{2}\left(t\right)\right]=B_{2}^{(1)}\left(1\right).\\
\end{array}
\end{eqnarray}

La distribuci\'on para el n\'umero de grupos que arriban al sistema en cada una de las colas se definen por:

\begin{eqnarray}
\begin{array}{cc}
P_{1}\left(z_{1}\right)=A_{1}\left[B_{1}\left(z_{1}\right)\right]=\esp\left[B_{1}\left(z_{1}\right)^{\alpha_{1}\left(t\right)}\right],& P_{2}\left(z_{1}\right)=A_{1}\left[B_{1}\left(z_{1}\right)\right]=\esp\left[B_{1}\left(z_{1}\right)^{\alpha_{1}\left(t\right)}\right],\\
\end{array}
\end{eqnarray}

entonces

\begin{eqnarray}
\begin{array}{l}
P_{1}^{(1)}\left(1\right)=\esp\left[\alpha_{1}\left(t\right)B_{1}^{(1)}\left(1\right)\right]=B_{1}^{(1)}\left(1\right)\esp\left[\alpha_{1}\left(t\right)\right]=\lambda_{1}b_{1}\\
P_{2}^{(1)}\left(1\right)=\esp\left[\alpha_{2}\left(t\right)B_{2}^{(1)}\left(1\right)\right]=B_{2}^{(1)}\left(1\right)\esp\left[\alpha_{2}\left(t\right)\right]=\lambda_{2}b_{2}.
\end{array}
\end{eqnarray}

De lo desarrollado hasta ahora se tiene lo siguiente

\begin{eqnarray*}
\begin{array}{l}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=\esp\left[z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=\esp\left[z_{2}^{L_{2}\left(\tau_{1}\right)+X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right]=\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{z_{2}^{X_{2}\left(\overline{\tau}_{1}-\tau_{1}\right)}\right\}\right]\\
=\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{P_{2}\left(z_{2}\right)\right\}^{\overline{\tau}_{1}-\tau_{1}}\right]=\esp\left[\left\{z_{2}^{L_{2}\left(\tau_{1}\right)}\right\}\left\{\theta_{1}\left(P_{2}\left(z_{2}\right)\right)\right\}^{L_{1}\left(\tau_{1}\right)}\right]=F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)
\end{array}
\end{eqnarray*}

es decir 
\begin{equation}\label{Eq.base.F1}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{1}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{1}\right)}\right]=F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right).
\end{equation}

Procediendo de manera an\'aloga para $\overline{\tau}_{2}$:

\begin{eqnarray*}
\begin{array}{l}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{2}\right)}\right]=\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}\right]=\esp\left[z_{1}^{L_{1}\left(\tau_{2}\right)+X_{1}\left(\overline{\tau}_{2}-\tau_{2}\right)}\right]=\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{z_{1}^{X_{1}\left(\overline{\tau}_{2}-\tau_{2}\right)}\right\}\right]\\
=\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{P_{1}\left(z_{1}\right)\right\}^{\overline{\tau}_{2}-\tau_{2}}\right]=\esp\left[\left\{z_{1}^{L_{1}\left(\tau_{2}\right)}\right\}\left\{\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right\}^{L_{2}\left(\tau_{2}\right)}\right]=F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)
\end{array}
\end{eqnarray*}
por tanto
\begin{equation}\label{Eq.PGF.Conjunta.Tau2}
\esp\left[z_{1}^{L_{1}\left(\overline{\tau}_{2}\right)}z_{2}^{L_{2}\left(\overline{\tau}_{2}\right)}\right]=F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)
\end{equation}

Ahora, para el intervalo de tiempo
$\left[\overline{\tau}_{1},\tau_{2}\right]$ y $\left[\overline{\tau}_{2},\tau_{1}\right]$, los arribos de los usuarios modifican el n\'umero de usuarios que llegan a las colas, es decir, los procesos
$L_{1}\left(t\right)$ y $L_{2}\left(t\right)$. La PGF para el n\'umero de arribos a todas las estaciones durante el intervalo $\left[\overline{\tau}_{1},\tau_{2}\right]$  cuya distribuci\'on est\'a especificada por la distribuci\'on compuesta $R_{1}\left(\mathbf{z}\right),R_{2}\left(\mathbf{z}\right)$:

\begin{eqnarray*}
R_{1}\left(\mathbf{z}\right)=R_{1}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)=\esp\left[\left\{\prod_{i=1}^{2}P\left(z_{i}\right)\right\}^{\tau_{2}-\overline{\tau}_{1}}\right]\\
R_{2}\left(\mathbf{z}\right)=R_{2}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)=\esp\left[\left\{\prod_{i=1}^{2}P\left(z_{i}\right)\right\}^{\tau_{1}-\overline{\tau}_{2}}\right]\\
\end{eqnarray*}

Dado que los eventos en
$\left[\tau_{1},\overline{\tau}_{1}\right]$ y $\left[\overline{\tau}_{1},\tau_{2}\right]$ son independientes, la
PGF conjunta para el n\'umero de usuarios en el sistema al tiempo $t=\tau_{2}$ la PGF conjunta para el n\'umero de usuarios en el sistema est\'an dadas por

\begin{eqnarray*}
F_{1}\left(\mathbf{z}\right)&=&R_{2}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)\\
F_{2}\left(\mathbf{z}\right)&=&R_{1}\left(\prod_{i=1}^{2}P\left(z_{i}\right)\right)F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)\\
\end{eqnarray*}

Entonces debemos de determinar las siguientes expresiones:

\begin{eqnarray*}
\begin{array}{cc}
f_{1}\left(1\right)=\frac{\partial F_{1}\left(\mathbf{z}\right)}{\partial z_{1}}|_{\mathbf{z}=1}, & f_{1}\left(2\right)=\frac{\partial F_{1}\left(\mathbf{z}\right)}{\partial z_{2}}|_{\mathbf{z}=1},\\
f_{2}\left(1\right)=\frac{\partial F_{2}\left(\mathbf{z}\right)}{\partial z_{1}}|_{\mathbf{z}=1}, & f_{2}\left(2\right)=\frac{\partial F_{2}\left(\mathbf{z}\right)}{\partial z_{2}}|_{\mathbf{z}=1},\\
\end{array}
\end{eqnarray*}

calculando las derivadas parciales 
\begin{eqnarray*}
\frac{\partial R_{1}\left(\mathbf{z}\right)}{\partial
z_{1}}|_{\mathbf{z}=1}&=&R_{1}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial R_{1}\left(\mathbf{z}\right)}{\partial
z_{2}}|_{\mathbf{z}=1}&=&R_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\frac{\partial R_{2}\left(\mathbf{z}\right)}{\partial
z_{1}}|_{\mathbf{z}=1}&=&R_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial R_{2}\left(\mathbf{z}\right)}{\partial
z_{2}}|_{\mathbf{z}=1}&=&R_{2}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\end{eqnarray*}

igualando a cero

\begin{eqnarray*}
\frac{\partial}{\partial
z_{1}}F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)&=&0\\
\frac{\partial}{\partial
z_{2}}F_{1}\left(\theta_{1}\left(P_{2}\left(z_{2}\right)\right),z_{2}\right)&=&\frac{\partial
F_{1}}{\partial z_{2}}+\frac{\partial F_{1}}{\partial
z_{1}}\theta_{1}^{(1)}P_{2}^{(1)}\left(1\right)\\
\frac{\partial}{\partial
z_{1}}F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)&=&\frac{\partial
F_{2}}{\partial z_{1}}+\frac{\partial F_{2}}{\partial
z_{2}}\theta_{2}^{(1)}P_{1}^{(1)}\left(1\right)\\
\frac{\partial}{\partial
z_{2}}F_{2}\left(z_{1},\theta_{2}\left(P_{1}\left(z_{1}\right)\right)\right)&=&0.
\end{eqnarray*}


Por lo tanto de las dos secciones anteriores se tiene que:


\begin{eqnarray*}
\frac{\partial F_{1}}{\partial z_{1}}&=&\frac{\partial
R_{2}}{\partial z_{1}}|_{\mathbf{z}=1}+\frac{\partial F_{2}}{\partial z_{1}}|_{\mathbf{z}=1}=R_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)+f_{2}\left(1\right)+f_{2}\left(2\right)\theta_{2}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial F_{1}}{\partial z_{2}}&=&\frac{\partial
R_{2}}{\partial z_{2}}|_{\mathbf{z}=1}+\frac{\partial F_{2}}{\partial z_{2}}|_{\mathbf{z}=1}=R_{2}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\frac{\partial F_{2}}{\partial z_{1}}&=&\frac{\partial
R_{1}}{\partial z_{1}}|_{\mathbf{z}=1}+\frac{\partial F_{1}}{\partial z_{1}}|_{\mathbf{z}=1}=R_{1}^{(1)}\left(1\right)P_{1}^{(1)}\left(1\right)\\
\frac{\partial F_{2}}{\partial z_{2}}&=&\frac{\partial
R_{1}}{\partial z_{2}}|_{\mathbf{z}=1}+\frac{\partial F_{1}}{\partial z_{2}}|_{\mathbf{z}=1}
=R_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)+f_{1}\left(1\right)\theta_{1}^{(1)}\left(1\right)P_{2}^{(1)}\left(1\right)\\
\end{eqnarray*}


El cual se puede escribir en forma equivalente:
\begin{eqnarray*}
f_{1}\left(1\right)&=&r_{2}\mu_{1}+f_{2}\left(1\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}\\
f_{1}\left(2\right)&=&r_{2}\mu_{2}\\
f_{2}\left(1\right)&=&r_{1}\mu_{1}\\
f_{2}\left(2\right)&=&r_{1}\mu_{2}+f_{1}\left(2\right)+f_{1}\left(1\right)\frac{\mu_{2}}{1-\mu_{1}}\\
\end{eqnarray*}

De donde:
\begin{eqnarray*}
f_{1}\left(1\right)&=&\mu_{1}\left[r_{2}+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right]+f_{2}\left(1\right)\\
f_{2}\left(2\right)&=&\mu_{2}\left[r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]+f_{1}\left(2\right)\\
\end{eqnarray*}

Resolviendo para $f_{1}\left(1\right)$:
\begin{eqnarray*}
f_{1}\left(1\right)&=&r_{2}\mu_{1}+f_{2}\left(1\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=r_{2}\mu_{1}+r_{1}\mu_{1}+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}\\
&=&\mu_{1}\left(r_{2}+r_{1}\right)+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=\mu_{1}\left(r+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right),\\
\end{eqnarray*}

entonces

\begin{eqnarray*}
f_{2}\left(2\right)&=&\mu_{2}\left(r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right)+f_{1}\left(2\right)=\mu_{2}\left(r_{1}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right)+r_{2}\mu_{2}\\
&=&\mu_{2}\left[r_{1}+r_{2}+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]=\mu_{2}\left[r+\frac{f_{1}\left(1\right)}{1-\mu_{1}}\right]\\
&=&\mu_{2}r+\mu_{1}\left(r+\frac{f_{2}\left(2\right)}{1-\mu_{2}}\right)\frac{\mu_{2}}{1-\mu_{1}}\\
&=&\mu_{2}r+\mu_{2}\frac{r\mu_{1}}{1-\mu_{1}}+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
&=&\mu_{2}\left(r+\frac{r\mu_{1}}{1-\mu_{1}}\right)+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)+f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\\
\end{eqnarray*}
entonces
\begin{eqnarray*}
f_{2}\left(2\right)-f_{2}\left(2\right)\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(1-\frac{\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(\frac{1-\mu_{1}-\mu_{2}+\mu_{1}\mu_{2}-\mu_{1}\mu_{2}}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
f_{2}\left(2\right)\left(\frac{1-\mu}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}\right)&=&\mu_{2}\left(\frac{r}{1-\mu_{1}}\right)\\
\end{eqnarray*}
por tanto
\begin{eqnarray*}
f_{2}\left(2\right)&=&\frac{r\frac{\mu_{2}}{1-\mu_{1}}}{\frac{1-\mu}{\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}}=\frac{r\mu_{2}\left(1-\mu_{1}\right)\left(1-\mu_{2}\right)}{\left(1-\mu_{1}\right)\left(1-\mu\right)}\\
&=&\frac{\mu_{2}\left(1-\mu_{2}\right)}{1-\mu}r=r\mu_{2}\frac{1-\mu_{2}}{1-\mu}.
\end{eqnarray*}
es decir

\begin{eqnarray}
f_{2}\left(2\right)&=&r\mu_{2}\frac{1-\mu_{2}}{1-\mu}.
\end{eqnarray}

Entonces

\begin{eqnarray*}
f_{1}\left(1\right)&=&\mu_{1}r+f_{2}\left(2\right)\frac{\mu_{1}}{1-\mu_{2}}=\mu_{1}r+\left(\frac{\mu_{2}\left(1-\mu_{2}\right)}{1-\mu}r\right)\frac{\mu_{1}}{1-\mu_{2}}\\
&=&\mu_{1}r+\mu_{1}r\left(\frac{\mu_{2}}{1-\mu}\right)=\mu_{1}r\left[1+\frac{\mu_{2}}{1-\mu}\right]\\
&=&r\mu_{1}\frac{1-\mu_{1}}{1-\mu}\\
\end{eqnarray*}

%_________________________________________________________________________
\section{El problema de la ruina del jugador}
%_________________________________________________________________________

Supongamos que se tiene un jugador que cuenta con un capital inicial de $\tilde{L}_{0}\geq0$ unidades, esta persona realiza una serie de dos juegos simult\'aneos e independientes de manera sucesiva, dichos eventos son independientes e id\'enticos entre s\'i para cada realizaci\'on. Para $n\geq0$ fijo, la ganancia en el $n$-\'esimo juego es $\tilde{X}_{n}=X_{n}+Y_{n}$ unidades de las cuales se resta una cuota de 1 unidad por cada juego simult\'aneo, es decir, se restan dos unidades por cada juego realizado. En t\'erminos de la teor\'ia de colas puede pensarse como el n\'umero de usuarios que llegan a una cola v\'ia dos procesos de arribo distintos e independientes entre s\'i. Su Funci\'on Generadora de Probabilidades (FGP) est\'a dada por $F\left(z\right)=\esp\left[z^{\tilde{L}_{0}}\right]$ para $z\in\mathbb{C}$, adem\'as
$$\tilde{P}\left(z\right)=\esp\left[z^{\tilde{X}_{n}}\right]=\esp\left[z^{X_{n}+Y_{n}}\right]=\esp\left[z^{X_{n}}z^{Y_{n}}\right]=\esp\left[z^{X_{n}}\right]\esp\left[z^{Y_{n}}\right]=P\left(z\right)\check{P}\left(z\right),$$ con $\tilde{\mu}=\esp\left[\tilde{X}_{n}\right]=\tilde{P}\left[z\right]<1$. 

Sea $\tilde{L}_{n}$ el capital remanente despu\'es del $n$-\'esimo
juego. Entonces
$$\tilde{L}_{n}=\tilde{L}_{0}+\tilde{X}_{1}+\tilde{X}_{2}+\cdots+\tilde{X}_{n}-2n.$$

La ruina del jugador ocurre despu\'es del $n$-\'esimo juego, es decir, la cola se vac\'ia despu\'es del $n$-\'esimo juego, entonces sea $T$ definida como $T=min\left\{\tilde{L}_{n}=0\right\}$. Si $\tilde{L}_{0}=0$, entonces claramente $T=0$. En este sentido $T$ puede interpretarse como la longitud del periodo de tiempo que el servidor ocupa para dar servicio en la cola, comenzando con $\tilde{L}_{0}$ grupos de usuarios presentes en la cola, quienes arribaron conforme a un proceso dado por $\tilde{P}\left(z\right)$.

Sea $g_{n,k}$ la probabilidad del evento de que el jugador no caiga en ruina antes del $n$-\'esimo juego, y que adem\'as tenga un capital de $k$ unidades antes del $n$-\'esimo juego, es decir, dada $n\in\left\{1,2,\ldots\right\}$ y $k\in\left\{0,1,2,\ldots\right\}$
\begin{eqnarray}
g_{n,k}:=P\left\{\tilde{L}_{j}>0, j=1,\ldots,n,
\tilde{L}_{n}=k\right\},
\end{eqnarray}
la cual adem\'as se puede escribir como:
\begin{eqnarray*}
g_{n,k}&=&P\left\{\tilde{L}_{j}>0, j=1,\ldots,n,
\tilde{L}_{n}=k\right\}=\sum_{j=1}^{k+1}g_{n-1,j}P\left\{\tilde{X}_{n}=k-j+1\right\}\\
&=&\sum_{j=1}^{k+1}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1\right\}=\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1,Y_{n}=l\right\}\\
&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}+Y_{n}=k-j+1|Y_{n}=l\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\},
\end{eqnarray*}

es decir
\begin{eqnarray}\label{Eq.Gnk.2S}
g_{n,k}=\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}.
\end{eqnarray}
Adem\'as
\begin{equation}\label{Eq.L02S}
g_{0,k}=P\left\{\tilde{L}_{0}=k\right\}.
\end{equation}
Se definen las siguientes FGP:
\begin{equation}\label{Eq.3.16.a.2S}
G_{n}\left(z\right)=\sum_{k=0}^{\infty}g_{n,k}z^{k},\textrm{ para
}n=0,1,\ldots,
\end{equation}
y 
\begin{equation}\label{Eq.3.16.b.2S}
G\left(z,w\right)=\sum_{n=0}^{\infty}G_{n}\left(z\right)w^{n}, z,w\in\mathbb{C}.
\end{equation}
En particular para $k=0$,
\begin{eqnarray*}
g_{n,0}=G_{n}\left(0\right)=P\left\{\tilde{L}_{j}>0,\textrm{ para
}j<n,\textrm{ y }\tilde{L}_{n}=0\right\}=P\left\{T=n\right\},
\end{eqnarray*}
adem\'as
\begin{eqnarray*}%\label{Eq.G0w.2S}
G\left(0,w\right)=\sum_{n=0}^{\infty}G_{n}\left(0\right)w^{n}=\sum_{n=0}^{\infty}P\left\{T=n\right\}w^{n}
=\esp\left[w^{T}\right]
\end{eqnarray*}
la cu\'al resulta ser la FGP del tiempo de ruina $T$.

\begin{Prop}\label{Prop.1.1.2S}
Sean $z,w\in\mathbb{C}$ y sea $n\geq0$ fijo. Para $G_{n}\left(z\right)$ y $G\left(z,w\right)$ definidas como en (\ref{Eq.3.16.a.2S}) y (\ref{Eq.3.16.b.2S}) respectivamente, se tiene que
\begin{equation}\label{Eq.Pag.45}
G_{n}\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right).
\end{equation}

Adem\'as

\begin{equation}\label{Eq.Pag.46}
G\left(z,w\right)=\frac{zF\left(z\right)-wP\left(z\right)G\left(0,w\right)}{z-wR\left(z\right)},
\end{equation}

con un \'unico polo en el c\'irculo unitario, adem\'as, el polo es
de la forma $z=\theta\left(w\right)$ y satisface que

\begin{enumerate}
\item[i)]$\tilde{\theta}\left(1\right)=1$,

\item[ii)] $\tilde{\theta}^{(1)}\left(1\right)=\frac{1}{1-\tilde{\mu}}$,

\item[iii)]
$\tilde{\theta}^{(2)}\left(1\right)=\frac{\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}+\frac{\tilde{\sigma}}{\left(1-\tilde{\mu}\right)^{3}}$.
\end{enumerate}

Finalmente, adem\'as se cumple que
\begin{equation}
\esp\left[w^{T}\right]=G\left(0,w\right)=F\left[\tilde{\theta}\left(w\right)\right].
\end{equation}
\end{Prop}
\begin{proof}

Multiplicando las ecuaciones (\ref{Eq.Gnk.2S}) y (\ref{Eq.L02S})
por el t\'ermino $z^{k}$:

\begin{eqnarray*}
g_{n,k}z^{k}&=&\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}z^{k},\\
g_{0,k}z^{k}&=&P\left\{\tilde{L}_{0}=k\right\}z^{k},
\end{eqnarray*}

ahora sumamos sobre $k$
\begin{eqnarray*}
\sum_{k=0}^{\infty}g_{n,k}z^{k}&=&\sum_{k=0}^{\infty}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-j-l+1\right\}P\left\{Y_{n}=l\right\}z^{k}\\
&=&\sum_{k=0}^{\infty}z^{k}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{k=0}^{\infty}z^{k+\left(j+l-1\right)-\left(j+l-1\right)}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}P\left\{Y_{n}=l\right\}\\
&=&\sum_{k=0}^{\infty}\sum_{j=1}^{k+1}\sum_{l=1}^{j}g_{n-1,j}z^{j-1}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}\sum_{l=1}^{j}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{l=1}^{j}\sum_{k=j+l-1}^{\infty}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\sum_{l=1}^{j}P\left\{Y_{n}=l\right\}z^{l}\\
&=&\sum_{j=1}^{\infty}g_{n-1,j}z^{j-1}\sum_{l=1}^{\infty}P\left\{Y_{n}=l\right\}z^{l}\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\\
&=&\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\check{P}\left(z\right)\sum_{k=j+l-1}^{\infty}\sum_{l=1}^{j}P\left\{X_{n}=k-\left(j+l-1\right)\right\}z^{k-\left(j+l-1\right)}\\
&=&\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\check{P}\left(z\right)P\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right),
\end{eqnarray*}
es decir la ecuaci\'on (\ref{Eq.3.16.a.2S}) se puede reescribir como
\begin{equation}\label{Eq.3.16.a.2Sbis}
G_{n}\left(z\right)=\frac{1}{z}\left[G_{n-1}\left(z\right)-G_{n-1}\left(0\right)\right]\tilde{P}\left(z\right).
\end{equation}

Por otra parte recordemos la ecuaci\'on (\ref{Eq.3.16.a.2S})
\begin{eqnarray*}
G_{n}\left(z\right)&=&\sum_{k=0}^{\infty}g_{n,k}z^{k},\textrm{ entonces }\frac{G_{n}\left(z\right)}{z}=\sum_{k=1}^{\infty}g_{n,k}z^{k-1},
\end{eqnarray*}

por lo tanto utilizando la ecuaci\'on (\ref{Eq.3.16.a.2Sbis}):

\begin{eqnarray*}
G\left(z,w\right)&=&\sum_{n=0}^{\infty}G_{n}\left(z\right)w^{n}=G_{0}\left(z\right)+\sum_{n=1}^{\infty}G_{n}\left(z\right)w^{n}=F\left(z\right)+\sum_{n=0}^{\infty}\left[G_{n}\left(z\right)-G_{n}\left(0\right)\right]w^{n}\frac{\tilde{P}\left(z\right)}{z}\\
&=&F\left(z\right)+\frac{w}{z}\sum_{n=0}^{\infty}\left[G_{n}\left(z\right)-G_{n}\left(0\right)\right]w^{n-1}\tilde{P}\left(z\right)
\end{eqnarray*}
es decir
\begin{eqnarray*}
G\left(z,w\right)&=&F\left(z\right)+\frac{w}{z}\left[G\left(z,w\right)-G\left(0,w\right)\right]\tilde{P}\left(z\right),
\end{eqnarray*}
entonces
\begin{eqnarray*}
G\left(z,w\right)=F\left(z\right)+\frac{w}{z}\left[G\left(z,w\right)-G\left(0,w\right)\right]\tilde{P}\left(z\right)&=&F\left(z\right)+\frac{w}{z}\tilde{P}\left(z\right)G\left(z,w\right)-\frac{w}{z}\tilde{P}\left(z\right)G\left(0,w\right)\\
&\Leftrightarrow&\\
G\left(z,w\right)\left\{1-\frac{w}{z}\tilde{P}\left(z\right)\right\}&=&F\left(z\right)-\frac{w}{z}\tilde{P}\left(z\right)G\left(0,w\right),
\end{eqnarray*}
por lo tanto,
\begin{equation}
G\left(z,w\right)=\frac{zF\left(z\right)-w\tilde{P}\left(z\right)G\left(0,w\right)}{1-w\tilde{P}\left(z\right)}.
\end{equation}
Ahora $G\left(z,w\right)$ es anal\'itica en $|z|=1$. Sean $z,w$ tales que $|z|=1$ y $|w|\leq1$, como $\tilde{P}\left(z\right)$ es FGP
\begin{eqnarray*}
|z-\left(z-w\tilde{P}\left(z\right)\right)|<|z|\Leftrightarrow|w\tilde{P}\left(z\right)|<|z|
\end{eqnarray*}
es decir, se cumplen las condiciones del Teorema de Rouch\'e y por tanto, $z$ y $z-w\tilde{P}\left(z\right)$ tienen el mismo n\'umero de ceros en $|z|=1$. Sea $z=\tilde{\theta}\left(w\right)$ la soluci\'on \'unica de $z-w\tilde{P}\left(z\right)$, es decir
\begin{equation}\label{Eq.Theta.w}
\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)=0,
\end{equation}
con $|\tilde{\theta}\left(w\right)|<1$. Cabe hacer menci\'on que $\tilde{\theta}\left(w\right)$ es la FGP para el tiempo de ruina cuando $\tilde{L}_{0}=1$. Considerando la ecuaci\'on (\ref{Eq.Theta.w})
\begin{eqnarray*}
0&=&\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)|_{w=1}-\frac{\partial}{\partial w}\left\{w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}|_{w=1}=\tilde{\theta}^{(1)}\left(w\right)|_{w=1}-\frac{\partial}{\partial w}w\left\{\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}|_{w=1}\\
&-&w\frac{\partial}{\partial w}\tilde{P}\left(\tilde{\theta}\left(w\right)\right)|_{w=1}=\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}\left(\tilde{\theta}\left(1\right)\right)-w\left\{\frac{\partial \tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial \tilde{\theta}\left(w\right)}\cdot\frac{\partial\tilde{\theta}\left(w\right)}{\partial w}|_{w=1}\right\}\\
&=&\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}\left(\tilde{\theta}\left(1\right)
\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\cdot\tilde{\theta}^{(1)}\left(1\right),
\end{eqnarray*}
luego
$$\tilde{P}\left(\tilde{\theta}\left(1\right)\right)=\tilde{\theta}^{(1)}\left(1\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\cdot\tilde{\theta}^{(1)}\left(1\right)=\tilde{\theta}^{(1)}\left(1\right)\left(1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\right),$$
por tanto $$\tilde{\theta}^{(1)}\left(1\right)=\frac{\tilde{P}\left(\tilde{\theta}\left(1\right)\right)}{\left(1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)\right)}=\frac{1}{1-\tilde{\mu}}.$$
Ahora determinemos el segundo momento de $\tilde{\theta}\left(w\right)$,
nuevamente consideremos la ecuaci\'on (\ref{Eq.Theta.w}):
\begin{eqnarray*}
0&=&\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\Rightarrow 0=\frac{\partial}{\partial w}\left\{\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}\Rightarrow 0=\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\left\{\tilde{\theta}\left(w\right)-w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right\}\right\}
\end{eqnarray*}
luego se tiene
\begin{eqnarray*}
&&\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)-\frac{\partial}{\partial w}\left[w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right]\right\}
=\frac{\partial}{\partial w}\left\{\frac{\partial}{\partial w}\tilde{\theta}\left(w\right)-\frac{\partial}{\partial w}\left[w\tilde{P}\left(\tilde{\theta}\left(w\right)\right)\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\left[\tilde{P}\left(\tilde{\theta}\left(w\right)\right)+w\frac{\partial}{\partial w}P\left(\tilde{\theta}\left(w\right)\right)\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\left(\tilde{P}\left(\tilde{\theta}\left(w\right)\right)+w\frac{\partial \tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial w}\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}\right]\right\}\\
&=&\frac{\partial}{\partial w}\left\{\tilde{\theta}^{(1)}\left(w\right)-\tilde{P}\left(\tilde{\theta}\left(w\right)\right)-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)\right\}\\
&=&\frac{\partial}{\partial w}\tilde{\theta}^{(1)}\left(w\right)-\frac{\partial}{\partial w}\tilde{P}\left(\tilde{\theta}\left(w\right)\right)-\frac{\partial}{\partial w}\left[w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)\right]\\
&=&\frac{\partial}{\partial w}\tilde{\theta}^{(1)}\left(w\right)-\frac{\partial\tilde{P}\left(\tilde{\theta}\left(w\right)\right)}{\partial\tilde{\theta}\left(w\right)}\frac{\partial \tilde{\theta}\left(w\right)}{\partial w}-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\frac{\partial\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}{\partial w}\tilde{\theta}^{(1)}\left(w\right)\\
&-&w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\frac{\partial \tilde{\theta}^{(1)}\left(w\right)}{\partial w}\\
&=&\tilde{\theta}^{(2)}\left(w\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)\left(\tilde{\theta}^{(1)}\left(w\right)\right)^{2}\\
&-&w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(2)}\left(w\right)\\
&=&\tilde{\theta}^{(2)}\left(w\right)-2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(1)}\left(w\right)-w\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)\left(\tilde{\theta}^{(1)}\left(w\right)\right)^{2}-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\tilde{\theta}^{(2)}\left(w\right)\\
&=&\tilde{\theta}^{(2)}\left(w\right)\left[1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]-
\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]
\end{eqnarray*}
luego
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(w\right)&&\left[1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]-\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]=0\\
\tilde{\theta}^{(2)}\left(w\right)&=&\frac{\tilde{\theta}^{(1)}\left(w\right)\left[w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)+2P^{(1)}\left(\tilde{\theta}\left(w\right)\right)\right]}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}\\
&=&\frac{\tilde{\theta}^{(1)}\left(w\right)w\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(2)}\left(\tilde{\theta}\left(w\right)\right)}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}+\frac{2\tilde{\theta}^{(1)}\left(w\right)\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}{1-w\tilde{P}^{(1)}\left(\tilde{\theta}\left(w\right)\right)}
\end{eqnarray*}
si evaluamos la expresi\'on anterior en $w=1$:
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(1\right)&=&\frac{\left(\tilde{\theta}^{(1)}\left(1\right)\right)^{2}\tilde{P}^{(2)}\left(\tilde{\theta}\left(1\right)\right)}{1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}+\frac{2\tilde{\theta}^{(1)}\left(1\right)\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}{1-\tilde{P}^{(1)}\left(\tilde{\theta}\left(1\right)\right)}=\frac{\left(\tilde{\theta}^{(1)}\left(1\right)\right)^{2}\tilde{P}^{(2)}\left(1\right)}{1-\tilde{P}^{(1)}\left(1\right)}+\frac{2\tilde{\theta}^{(1)}\left(1\right)\tilde{P}^{(1)}\left(1\right)}{1-\tilde{P}^{(1)}\left(1\right)}\\
&=&\frac{\left(\frac{1}{1-\tilde{\mu}}\right)^{2}\tilde{P}^{(2)}\left(1\right)}{1-\tilde{\mu}}+\frac{2\left(\frac{1}{1-\tilde{\mu}}\right)\tilde{\mu}}{1-\tilde{\mu}}=\frac{\tilde{P}^{(2)}\left(1\right)}{\left(1-\tilde{\mu}\right)^{3}}+\frac{2\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}=\frac{\sigma^{2}-\tilde{\mu}+\tilde{\mu}^{2}}{\left(1-\tilde{\mu}\right)^{3}}+\frac{2\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}\\
&=&\frac{\sigma^{2}-\tilde{\mu}+\tilde{\mu}^{2}+2\tilde{\mu}\left(1-\tilde{\mu}\right)}{\left(1-\tilde{\mu}\right)^{3}}
\end{eqnarray*}
es decir
\begin{eqnarray*}
\tilde{\theta}^{(2)}\left(1\right)&=&\frac{\sigma^{2}}{\left(1-\tilde{\mu}\right)^{3}}+\frac{\tilde{\mu}}{\left(1-\tilde{\mu}\right)^{2}}.
\end{eqnarray*}
\end{proof}

\begin{Coro}
El tiempo de ruina del jugador tiene primer y segundo momento dados por
\begin{eqnarray}
\esp\left[T\right]&=&\frac{\esp\left[\tilde{L}_{0}\right]}{1-\tilde{\mu}}\\
Var\left[T\right]&=&\frac{Var\left[\tilde{L}_{0}\right]}{\left(1-\tilde{\mu}\right)^{2}}+\frac{\sigma^{2}\esp\left[\tilde{L}_{0}\right]}{\left(1-\tilde{\mu}\right)^{3}}.
\end{eqnarray}
\end{Coro}

Se considerar\'an intervalos de tiempo de la forma
$\left[t,t+1\right]$. Los usuarios arriban por paquetes de manera
independiente del resto de las colas. Se define el grupo de
usuarios que llegan a cada una de las colas del sistema 1,
caracterizadas por $Q_{1}$ y $Q_{2}$ respectivamente, en el
intervalo de tiempo $\left[t,t+1\right]$ por
$X_{1}\left(t\right),X_{2}\left(t\right)$.


%______________________________________________________________________
\section{Ecuaciones Centrales}
%______________________________________________________________________

\begin{Prop}
Supongamos

\begin{equation}\label{Eq.1}
f_{i}\left(i\right)-f_{j}\left(i\right)=\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]
\end{equation}

\begin{equation}\label{Eq.2}
f_{i+1}\left(i\right)=r_{i}\mu_{i},
\end{equation}

Demostrar que

\begin{eqnarray*}
f_{i}\left(i\right)&=&\mu_{i}\left[\sum_{k=1}^{N}r_{k}+\sum_{k=1,k\neq i}^{N}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right].
\end{eqnarray*}

En la Ecuaci\'on (\ref{Eq.2}) hagamos $j=i+1$, entonces se tiene $f_{j}=r_{i}\mu_{i}$, lo mismo para (\ref{Eq.1})

\begin{eqnarray*}
f_{i}\left(i\right)&=&r_{i}\mu_{i}+\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{i}\left[\sum_{k=j}^{i}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
\end{eqnarray*}

entonces, tomando sobre todo valor de $1,\ldots,N$, tanto para antes de $i$ como para despu\'es de $i$, entonces

\begin{eqnarray*}
f_{i}\left(i\right)&=&\mu_{i}\left[\sum_{k=1}^{N}r_{k}+\sum_{k=1,k\neq i}^{N}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right].
\end{eqnarray*}
\end{Prop}

Ahora, supongamos nuevamente la ecuaci\'on (\ref{Eq.1})

\begin{eqnarray*}
f_{i}\left(i\right)-f_{j}\left(i\right)&=&\mu_{i}\left[\sum_{k=j}^{i-1}r_{k}+\sum_{k=j}^{i-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&\Leftrightarrow&\\
f_{j}\left(j\right)-f_{i}\left(j\right)&=&\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
f_{i}\left(j\right)&=&f_{j}\left(j\right)-\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\mu_{j}\left[\sum_{k=i}^{j-1}r_{k}+\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left[\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\sum_{k=i}^{j-1}r_{k}-\sum_{k=i}^{j-1}\frac{f_{k}\left(k\right)}{1-\mu_{k}}\right]\\
&=&\mu_{j}\left[\left(1-\mu_{j}\right)\frac{r}{1-\mu}-\sum_{k=i}^{j-1}r_{k}-\frac{r}{1-\mu}\sum_{k=i}^{j-1}\mu_{k}\right]\\
&=&\mu_{j}\left[\frac{r}{1-\mu}\left(1-\mu_{j}-\sum_{k=i}^{j-1}\mu_{k}\right)-\sum_{k=i}^{j-1}r_{k}\right]\\
&=&\mu_{j}\left[\frac{r}{1-\mu}\left(1-\sum_{k=i}^{j}\mu_{k}\right)-\sum_{k=i}^{j-1}r_{k}\right].\\
\end{eqnarray*}

Ahora,

\begin{eqnarray*}
1-\sum_{k=i}^{j}\mu_{k}&=&1-\sum_{k=1}^{N}\mu_{k}+\sum_{k=j+1}^{i-1}\mu_{k}\\
&\Leftrightarrow&\\
\sum_{k=i}^{j}\mu_{k}&=&\sum_{k=1}^{N}\mu_{k}-\sum_{k=j+1}^{i-1}\mu_{k}\\
&\Leftrightarrow&\\
\sum_{k=1}^{N}\mu_{k}&=&\sum_{k=i}^{j}\mu_{k}+\sum_{k=j+1}^{i-1}\mu_{k}\\
\end{eqnarray*}

Por tanto
\begin{eqnarray*}
f_{i}\left(j\right)&=&\mu_{j}\left[\frac{r}{1-\mu}\sum_{k=j+1}^{i-1}\mu_{k}+\sum_{k=j}^{i-1}r_{k}\right].
\end{eqnarray*}

\begin{Teo}[Teorema de Continuidad]
Sup\'ongase que $\left\{X_{n},n=1,2,3,\ldots\right\}$ son variables aleatorias finitas, no negativas con valores enteros tales que $P\left(X_{n}=k\right)=p_{k}^{(n)}$, para $n=1,2,3,\ldots$, $k=0,1,2,\ldots$, con $\sum_{k=0}^{\infty}p_{k}^{(n)}=1$, para $n=1,2,3,\ldots$. Sea $g_{n}$ la PGF para la variable aleatoria $X_{n}$. Entonces existe una sucesi\'on $\left\{p_{k}\right\}$ tal que \begin{eqnarray*}
lim_{n\rightarrow\infty}p_{k}^{(n)}=p_{k}\textrm{ para }0<s<1.
\end{eqnarray*}
En este caso, $g\left(s\right)=\sum_{k=0}^{\infty}s^{k}p_{k}$. Adem\'as
\begin{eqnarray*}
\sum_{k=0}^{\infty}p_{k}=1\textrm{ si y s\'olo si
}lim_{s\uparrow1}g\left(s\right)=1
\end{eqnarray*}
\end{Teo}

\begin{Teo}
Sea $N$ una variable aleatoria con valores enteros no negativos finita tal que $P\left(N=k\right)=p_{k}$, para $k=0,1,2,\ldots$, y $\sum_{k=0}^{\infty}p_{k}=P\left(N<\infty\right)=1$. Sea $\Phi$ la PGF de $N$ tal que $g\left(s\right)=\esp\left[s^{N}\right]=\sum_{k=0}^{\infty}s^{k}p_{k}$ con $g\left(1\right)=1$. Si $0\leq p_{1}\leq1$ y $\esp\left[N\right]=g^{'}\left(1\right)\leq1$, entonces no existe soluci\'on  de la ecuaci\'on $g\left(s\right)=s$ en el intervalo $\left[0,1\right)$. Si $\esp\left[N\right]=g^{'}\left(1\right)>1$, lo cual implica que $0\leq p_{1}<1$, entonces existe una \'unica soluci\'on de la ecuaci\'on $g\left(s\right)=s$ en el intervalo
$\left[0,1\right)$.
\end{Teo}

\begin{Teo}
Si $X$ y $Y$ tienen PGF $G_{X}$ y $G_{Y}$ respectivamente, entonces,\[G_{X}\left(s\right)=G_{Y}\left(s\right)\] para toda $s$, si y s\'olo si \[P\left(X=k\right))=P\left(Y=k\right)\] para toda $k=0,1,\ldots,$., es decir, si y s\'olo si $X$ y $Y$ tienen la misma distribuci\'on de probabilidad.
\end{Teo}


\begin{Teo}
Para cada $n$ fijo, sea la sucesi\'oin de probabilidades $\left\{a_{0,n},a_{1,n},\ldots,\right\}$, tales que $a_{k,n}\geq0$ para toda $k=0,1,2,\ldots,$ y $\sum_{k\geq0}a_{k,n}=1$, y sea $G_{n}\left(s\right)$ la correspondiente funci\'on generadora, $G_{n}\left(s\right)=\sum_{k\geq0}a_{k,n}s^{k}$. De modo que para cada valor fijo de $k$
\begin{eqnarray*}
lim_{n\rightarrow\infty}a_{k,n}=a_{k},
\end{eqnarray*}
es decir converge en distribuci\'on, es necesario y suficiente que para cada valor fijo $s\in\left[0,\right)$,
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{n}\left(s\right)=G\left(s\right),
\end{eqnarray*}
donde $G\left(s\right)=\sum_{k\geq0}p_{k}s^{k}$, para cualquier la funci\'on generadora del l\'imite de la sucesi\'on.
\end{Teo}

\begin{Teo}[Teorema de Abel]
Sea $G\left(s\right)=\sum_{k\geq0}a_{k}s^{k}$ para cualquier $\left\{p_{0},p_{1},\ldots,\right\}$, tales que $p_{k}\geq0$ para toda $k=0,1,2,\ldots,$. Entonces $G\left(s\right)$ es continua por la derecha en $s=1$, es decir
\begin{eqnarray*}
lim_{s\uparrow1}G\left(s\right)=\sum_{k\geq0}p_{k}=G\left(\right),
\end{eqnarray*}
sin importar si la suma es finita o no.
\end{Teo}
\begin{Note}
El radio de Convergencia para cualquier PGF es $R\geq1$, entonces, el Teorema de Abel nos dice que a\'un en el peor escenario, cuando $R=1$, a\'un se puede confiar en que la PGF ser\'a continua en $s=1$, en contraste, no se puede asegurar que la PGF ser\'a continua en el l\'imite inferior $-R$, puesto que la PGF es sim\'etrica alrededor del cero: la PGF converge para todo $s\in\left(-R,R\right)$, y no lo hace para $s<-R$ o $s>R$. Adem\'as nos dice que podemos escribir $G_{X}\left(1\right)$ como una abreviaci\'on de $lim_{s\uparrow1}G_{X}\left(s\right)$.
\end{Note}

Entonces si suponemos que la diferenciaci\'on t\'ermino a t\'ermino est\'a permitida, entonces

\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x}
\end{eqnarray*}

el Teorema de Abel nos dice que
\begin{eqnarray*}
\esp\left(X\right]&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right):\\
\esp\left[X\right]&=&=\sum_{x=1}^{\infty}xp_{x}=G_{X}^{'}\left(1\right)\\
&=&\lim_{s\uparrow1}G_{X}^{'}\left(s\right),
\end{eqnarray*}
dado que el Teorema de Abel se aplica a
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\sum_{x=1}^{\infty}xs^{x-1}p_{x},
\end{eqnarray*}
estableciendo as\'i que $G_{X}^{'}\left(s\right)$ es continua en $s=1$. Sin el Teorema de Abel no se podr\'ia asegurar que el l\'imite de $G_{X}^{'}\left(s\right)$ conforme $s\uparrow1$ sea la respuesta correcta para $\esp\left[X\right]$.

\begin{Note}
La PGF converge para todo $|s|<R$, para alg\'un $R$. De hecho la PGF converge absolutamente si $|s|<R$. La PGF adem\'as converge uniformemente en conjuntos de la forma $\left\{s:|s|<R^{'}\right\}$, donde $R^{'}<R$, es decir, $\forall\epsilon>0, \exists n_{0}\in\ent$ tal que $\forall s$, con $|s|<R^{'}$, y $\forall n\geq n_{0}$,
\begin{eqnarray*}
|\sum_{x=0}^{n}s^{x}\prob\left(X=x\right)-G_{X}\left(s\right)|<\epsilon.
\end{eqnarray*}
De hecho, la convergencia uniforme es la que nos permite diferenciar t\'ermino a t\'ermino:
\begin{eqnarray*}
G_{X}\left(s\right)=\esp\left[s^{X}\right]=\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right),
\end{eqnarray*}
y sea $s<R$.
\begin{enumerate}
\item
\begin{eqnarray*}
G_{X}^{'}\left(s\right)&=&\frac{d}{ds}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)=\sum_{x=0}^{\infty}\frac{d}{ds}\left(s^{x}\prob\left(X=x\right)\right)\\
&=&\sum_{x=0}^{n}xs^{x-1}\prob\left(X=x\right).
\end{eqnarray*}

\item\begin{eqnarray*}
\int_{a}^{b}G_{X}\left(s\right)ds&=&\int_{a}^{b}\left(\sum_{x=0}^{\infty}s^{x}\prob\left(X=x\right)\right)ds=\sum_{x=0}^{\infty}\left(\int_{a}^{b}s^{x}\prob\left(X=x\right)ds\right)\\
&=&\sum_{x=0}^{\infty}\frac{s^{x+1}}{x+1}\prob\left(X=x\right),
\end{eqnarray*}
para $-R<a<b<R$.
\end{enumerate}
\end{Note}

\begin{Teo}[Teorema de Convergencia Mon\'otona para PGF]
Sean $X$ y $X_{n}$ variables aleatorias no negativas, con valores en los enteros, finitas, tales que
\begin{eqnarray*}
lim_{n\rightarrow\infty}G_{X_{n}}\left(s\right)&=&G_{X}\left(s\right)
\end{eqnarray*}
para $0\leq s\leq1$, entonces
\begin{eqnarray*}
lim_{n\rightarrow\infty}P\left(X_{n}=k\right)=P\left(X=k\right),
\end{eqnarray*}
para $k=0,1,2,\ldots.$
\end{Teo}

El teorema anterior requiere del siguiente lema

\begin{Lemma}
Sean $a_{n,k}\in\ent^{+}$, $n\in\nat$ constantes no negativas con $\sum_{k\geq0}a_{k,n}\leq1$. Sup\'ongase que para $0\leq s\leq1$,
se tiene
\begin{eqnarray*}
a_{n}\left(s\right)&=&\sum_{k=0}^{\infty}a_{k,n}s^{k}\rightarrow
a\left(s\right)=\sum_{k=0}^{\infty}a_{k}s^{k}.
\end{eqnarray*}
Entonces
\begin{eqnarray*}
a_{0,n}\rightarrow a_{0}.
\end{eqnarray*}
\end{Lemma}


%_________________________________________________________________________
\section{Redes de Jackson}
%_________________________________________________________________________
Cuando se considera la cantidad de
usuarios que llegan a cada uno de los nodos desde fuera del
sistema m\'as los que provienen del resto de los nodos, se dice
que la red es abierta y recibe el nombre de {\em Red de Jackson Abierta}.\\

Si denotamos por $Q_{1}\left(t\right),Q_{2}\left(t\right),\ldots,Q_{K}\left(t\right)$ el n\'umero de usuarios presentes en la cola $1,2,\ldots,K$ respectivamente al tiempo $t$, entonces se tiene la colecci\'on de colas $\left\{Q_{1},Q_{2},\ldots,Q_{K}\right\}$, donde despu\'es de que el usuario es atendido en la cola $i$, se traslada a la cola $j$ con probabilidad $p_{ij}$. En caso de que un usuario decida volver a ser atendido en $i$, este permanecer\'a en la misma cola con probabilidad $p_{ii}$. Para considerar a los usuarios que entran al sistema por primera vez por $i$, m\'as aquellos que provienen de otra cola, es necesario considerar un estado adicional $0$, con probabilidad de transici\'on $p_{00}=0$, $p_{0j}\geq0$ y $p_{j0}\geq0$, para $j=1,2,\ldots,K$, entonces en general la probabilidad de transici\'on de una cola a otra puede representarse por $P=\left(p_{ij}\right)_{i,j=0}^{K}$.\\

Para el caso espec\'ifico en el que en cada una de las colas los tiempos entre arribos y los tiempos de servicio sean exponenciales con par\'ametro de intensidad $\lambda$ y media $\mu$, respectivamente, con $m$ servidores y sin restricciones en la capacidad de almacenamiento en cada una de las colas, en Chee-Hook y Boon-Hee \cite{HookHee}, cap. 6, se muestra que el n\'umero de
usuarios en las $K$ colas, en el caso estacionario, puede determinarse por la ecuaci\'on (\ref{Eq.7.5.1})  que a
continuaci\'on se presenta, adem\'as de que la distribuci\'on l\'imite de la misma es (\ref{Eq.7.5.2}).\\

El n\'umero de usuarios en las $K$ colas en su estado estacionario, ver \cite{Bhat}, se define como
\begin{equation}\label{Eq.7.5.1}
p_{q_{1}q_{2}\cdots
q_{K}}=P\left[Q_{1}=q_{1},Q_{2}=q_{2},\ldots,Q_{K}=q_{K}\right].
\end{equation}

Jackson (1957), demostr\'o que la distribuci\'on l\'imite
$p_{q_{1}q_{2}\cdots q_{K}}$ de (\ref{Eq.7.5.1}) es

\begin{equation}\label{Eq.7.5.2}
p_{q_{1}q_{2}\cdots
q_{K}}=P_{1}\left(q_{1}\right)P_{2}\left(q_{2}\right)\cdots
P_{K}\left(q_{K}\right),
\end{equation}

donde
\begin{equation}\label{Eq.7.5.3}
p_{i}\left(r\right)=\left\{\begin{array}{cc}
 p_{i}\left(0\right)\frac{\left(\gamma_{i}/\mu_{i}\right)^{r}}{r!},  & r=0,1,2,\ldots,m, \\
 p_{i}\left(0\right)\frac{\left(\gamma_{i}/\mu_{i}\right)^{r}}{m!m^{r-m}}, & r=m,m+1,\ldots .\\
\end{array}\right.
\end{equation}

y

\begin{equation}\label{Eq.7.5.4}
\gamma_{i}=\lambda_{i}+\sum p_{ji}\gamma_{j},\textrm{
}i=1,2,\ldots,K.
\end{equation}

La relaci\'on (\ref{Eq.7.5.4}) es importante puesto que considera no solamente los arribos externos si no que adem\'as permite considerar intercambio de clientes entre las distintas colas que conforman el sistema.\\

Dados $\lambda_{i}$ y $p_{ij}$, la cantidad $\gamma_{i}$ puede determinarse a partir de la ecuaci\'on (\ref{Eq.7.5.4}) de manera recursiva. Adem\'as $p_{i}\left(0\right)$ puede determinarse utilizando la condici\'on de normalidad
\[\sum_{q_{1}}\sum_{q_{2}}\cdots\sum_{q_{K}}p_{q_{1}q_{2}\cdots q_{K}}=1.\]

Sin embargo las Redes de Jackson tienen el inconveniente de que no consideran el caso en que existan tiempos de traslado entre las colas. 



\section{Resultados Adicionales}


%_______________________________________________________________________________________
\subsection{Procesos de Renovaci\'on y Regenerativos}
%_______________________________________________________________________________________




En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R1}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}



%________________________________________________________________________
%\subsection{Procesos Regenerativos Sigman, Thorisson y Wolff \cite{Sigman1}}
%________________________________________________________________________


\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.


\begin{Note}
La existencia de un primer tiempo de regeneraci\'on, $R_{1}$, implica la existencia de una sucesi\'on completa de estos tiempos $R_{1},R_{2}\ldots,$ que satisfacen la propiedad deseada \cite{Sigman2}.
\end{Note}


\begin{Note} Para la cola $GI/GI/1$ los usuarios arriban con tiempos $t_{n}$ y son atendidos con tiempos de servicio $S_{n}$, los tiempos de arribo forman un proceso de renovaci\'on  con tiempos entre arribos independientes e identicamente distribuidos (\texttt{i.i.d.})$T_{n}=t_{n}-t_{n-1}$, adem\'as los tiempos de servicio son \texttt{i.i.d.} e independientes de los procesos de arribo. Por \textit{estable} se entiende que $\esp S_{n}<\esp T_{n}<\infty$.
\end{Note}
 


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.
 
\begin{Note}
Funciones de procesos regenerativos son regenerativas, es decir, si $X\left(t\right)$ es regenerativo y se define el proceso $Y\left(t\right)$ por $Y\left(t\right)=f\left(X\left(t\right)\right)$ para alguna funci\'on Borel medible $f\left(\cdot\right)$. Adem\'as $Y$ es regenerativo con los mismos tiempos de renovaci\'on que $X$. 

En general, los tiempos de renovaci\'on, $Z_{k}$ de un proceso regenerativo no requieren ser tiempos de paro con respecto a la evoluci\'on de $X\left(t\right)$.
\end{Note} 

\begin{Note}
Una funci\'on de un proceso de Markov, usualmente no ser\'a un proceso de Markov, sin embargo ser\'a regenerativo si el proceso de Markov lo es.
\end{Note}

 
\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

\begin{Coro}
Sea $\left\{V\left(t\right),t\geq0\right\}$ un proceso regenerativo no negativo, con modificaci\'on medible. Si $\esp <\infty$, $F$ es no-aritm\'etica, y para todo $x\geq0$, $P\left\{V\left(t\right)\leq x,C>x\right\}$ es de variaci\'on acotada como funci\'on de $t$ en cada intervalo finito $\left[0,\tau\right]$, entonces $V\left(t\right)$ converge en distribuci\'on  cuando $t\rightarrow\infty$ y $$\esp V=\frac{\esp \int_{0}^{X}V\left(s\right)ds}{\esp X}$$
Donde $V$ tiene la distribuci\'on l\'imite de $V\left(t\right)$ cuando $t\rightarrow\infty$.

\end{Coro}

Para el caso discreto se tienen resultados similares.



%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Teorema Principal de Renovaci\'on}
%___________________________________________________________________________________________
%

\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}



%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}

%___________________________________________________________________________________________
%
%\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}
%___________________________________________________________________________________________
%
\subsection{Propiedades de los Procesos de Renovaci\'on}
%___________________________________________________________________________________________
%

Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}

%___________________________________________________________________________________________
%
%\subsection{Funci\'on de Renovaci\'on}
%___________________________________________________________________________________________
%


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}

%______________________________________________________________________
%\subsection{Procesos de Renovaci\'on}
%______________________________________________________________________

\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes NÃºmeros.
\end{Note}

%___________________________________________________________________________________________
%
%\subsection{Renewal and Regenerative Processes: Serfozo\cite{Serfozo}}
%___________________________________________________________________________________________
%
\begin{Def}%\label{Def.Tn}
Sean $0\leq T_{1}\leq T_{2}\leq \ldots$ son tiempos aleatorios infinitos en los cuales ocurren ciertos eventos. El n\'umero de tiempos $T_{n}$ en el intervalo $\left[0,t\right)$ es

\begin{eqnarray}
N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right),
\end{eqnarray}
para $t\geq0$.
\end{Def}

Si se consideran los puntos $T_{n}$ como elementos de $\rea_{+}$, y $N\left(t\right)$ es el n\'umero de puntos en $\rea$. El proceso denotado por $\left\{N\left(t\right):t\geq0\right\}$, denotado por $N\left(t\right)$, es un proceso puntual en $\rea_{+}$. Los $T_{n}$ son los tiempos de ocurrencia, el proceso puntual $N\left(t\right)$ es simple si su n\'umero de ocurrencias son distintas: $0<T_{1}<T_{2}<\ldots$ casi seguramente.

\begin{Def}
Un proceso puntual $N\left(t\right)$ es un proceso de renovaci\'on si los tiempos de interocurrencia $\xi_{n}=T_{n}-T_{n-1}$, para $n\geq1$, son independientes e identicamente distribuidos con distribuci\'on $F$, donde $F\left(0\right)=0$ y $T_{0}=0$. Los $T_{n}$ son llamados tiempos de renovaci\'on, referente a la independencia o renovaci\'on de la informaci\'on estoc\'astica en estos tiempos. Los $\xi_{n}$ son los tiempos de inter-renovaci\'on, y $N\left(t\right)$ es el n\'umero de renovaciones en el intervalo $\left[0,t\right)$
\end{Def}


\begin{Note}
Para definir un proceso de renovaci\'on para cualquier contexto, solamente hay que especificar una distribuci\'on $F$, con $F\left(0\right)=0$, para los tiempos de inter-renovaci\'on. La funci\'on $F$ en turno degune las otra variables aleatorias. De manera formal, existe un espacio de probabilidad y una sucesi\'on de variables aleatorias $\xi_{1},\xi_{2},\ldots$ definidas en este con distribuci\'on $F$. Entonces las otras cantidades son $T_{n}=\sum_{k=1}^{n}\xi_{k}$ y $N\left(t\right)=\sum_{n=1}^{\infty}\indora\left(T_{n}\leq t\right)$, donde $T_{n}\rightarrow\infty$ casi seguramente por la Ley Fuerte de los Grandes N\'umeros.
\end{Note}







Los tiempos $T_{n}$ est\'an relacionados con los conteos de $N\left(t\right)$ por

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
T_{N\left(t\right)}\leq &t&<T_{N\left(t\right)+1},
\end{eqnarray*}

adem\'as $N\left(T_{n}\right)=n$, y 

\begin{eqnarray*}
N\left(t\right)=\max\left\{n:T_{n}\leq t\right\}=\min\left\{n:T_{n+1}>t\right\}
\end{eqnarray*}

Por propiedades de la convoluci\'on se sabe que

\begin{eqnarray*}
P\left\{T_{n}\leq t\right\}=F^{n\star}\left(t\right)
\end{eqnarray*}
que es la $n$-\'esima convoluci\'on de $F$. Entonces 

\begin{eqnarray*}
\left\{N\left(t\right)\geq n\right\}&=&\left\{T_{n}\leq t\right\}\\
P\left\{N\left(t\right)\leq n\right\}&=&1-F^{\left(n+1\right)\star}\left(t\right)
\end{eqnarray*}

Adem\'as usando el hecho de que $\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}P\left\{N\left(t\right)\geq n\right\}$
se tiene que

\begin{eqnarray*}
\esp\left[N\left(t\right)\right]=\sum_{n=1}^{\infty}F^{n\star}\left(t\right)
\end{eqnarray*}

\begin{Prop}
Para cada $t\geq0$, la funci\'on generadora de momentos $\esp\left[e^{\alpha N\left(t\right)}\right]$ existe para alguna $\alpha$ en una vecindad del 0, y de aqu\'i que $\esp\left[N\left(t\right)^{m}\right]<\infty$, para $m\geq1$.
\end{Prop}

\begin{Ejem}[\textbf{Proceso Poisson}]

Suponga que se tienen tiempos de inter-renovaci\'on \textit{i.i.d.} del proceso de renovaci\'on $N\left(t\right)$ tienen distribuci\'on exponencial $F\left(t\right)=q-e^{-\lambda t}$ con tasa $\lambda$. Entonces $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$.

\end{Ejem}


\begin{Note}
Si el primer tiempo de renovaci\'on $\xi_{1}$ no tiene la misma distribuci\'on que el resto de las $\xi_{n}$, para $n\geq2$, a $N\left(t\right)$ se le llama Proceso de Renovaci\'on retardado, donde si $\xi$ tiene distribuci\'on $G$, entonces el tiempo $T_{n}$ de la $n$-\'esima renovaci\'on tiene distribuci\'on $G\star F^{\left(n-1\right)\star}\left(t\right)$
\end{Note}


\begin{Teo}
Para una constante $\mu\leq\infty$ ( o variable aleatoria), las siguientes expresiones son equivalentes:

\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}T_{n}&=&\mu,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}N\left(t\right)&=&1/\mu,\textrm{ c.s.}
\end{eqnarray}
\end{Teo}


Es decir, $T_{n}$ satisface la Ley Fuerte de los Grandes N\'umeros s\'i y s\'olo s\'i $N\left/t\right)$ la cumple.


\begin{Coro}[Ley Fuerte de los Grandes N\'umeros para Procesos de Renovaci\'on]
Si $N\left(t\right)$ es un proceso de renovaci\'on cuyos tiempos de inter-renovaci\'on tienen media $\mu\leq\infty$, entonces
\begin{eqnarray}
t^{-1}N\left(t\right)\rightarrow 1/\mu,\textrm{ c.s. cuando }t\rightarrow\infty.
\end{eqnarray}

\end{Coro}


Considerar el proceso estoc\'astico de valores reales $\left\{Z\left(t\right):t\geq0\right\}$ en el mismo espacio de probabilidad que $N\left(t\right)$

\begin{Def}
Para el proceso $\left\{Z\left(t\right):t\geq0\right\}$ se define la fluctuaci\'on m\'axima de $Z\left(t\right)$ en el intervalo $\left(T_{n-1},T_{n}\right]$:
\begin{eqnarray*}
M_{n}=\sup_{T_{n-1}<t\leq T_{n}}|Z\left(t\right)-Z\left(T_{n-1}\right)|
\end{eqnarray*}
\end{Def}

\begin{Teo}
Sup\'ongase que $n^{-1}T_{n}\rightarrow\mu$ c.s. cuando $n\rightarrow\infty$, donde $\mu\leq\infty$ es una constante o variable aleatoria. Sea $a$ una constante o variable aleatoria que puede ser infinita cuando $\mu$ es finita, y considere las expresiones l\'imite:
\begin{eqnarray}
lim_{n\rightarrow\infty}n^{-1}Z\left(T_{n}\right)&=&a,\textrm{ c.s.}\\
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)&=&a/\mu,\textrm{ c.s.}
\end{eqnarray}
La segunda expresi\'on implica la primera. Conversamente, la primera implica la segunda si el proceso $Z\left(t\right)$ es creciente, o si $lim_{n\rightarrow\infty}n^{-1}M_{n}=0$ c.s.
\end{Teo}

\begin{Coro}
Si $N\left(t\right)$ es un proceso de renovaci\'on, y $\left(Z\left(T_{n}\right)-Z\left(T_{n-1}\right),M_{n}\right)$, para $n\geq1$, son variables aleatorias independientes e id\'enticamente distribuidas con media finita, entonces,
\begin{eqnarray}
lim_{t\rightarrow\infty}t^{-1}Z\left(t\right)\rightarrow\frac{\esp\left[Z\left(T_{1}\right)-Z\left(T_{0}\right)\right]}{\esp\left[T_{1}\right]},\textrm{ c.s. cuando  }t\rightarrow\infty.
\end{eqnarray}
\end{Coro}


Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}



Sup\'ongase que $N\left(t\right)$ es un proceso de renovaci\'on con distribuci\'on $F$ con media finita $\mu$.

\begin{Def}
La funci\'on de renovaci\'on asociada con la distribuci\'on $F$, del proceso $N\left(t\right)$, es
\begin{eqnarray*}
U\left(t\right)=\sum_{n=1}^{\infty}F^{n\star}\left(t\right),\textrm{   }t\geq0,
\end{eqnarray*}
donde $F^{0\star}\left(t\right)=\indora\left(t\geq0\right)$.
\end{Def}


\begin{Prop}
Sup\'ongase que la distribuci\'on de inter-renovaci\'on $F$ tiene densidad $f$. Entonces $U\left(t\right)$ tambi\'en tiene densidad, para $t>0$, y es $U^{'}\left(t\right)=\sum_{n=0}^{\infty}f^{n\star}\left(t\right)$. Adem\'as
\begin{eqnarray*}
\prob\left\{N\left(t\right)>N\left(t-\right)\right\}=0\textrm{,   }t\geq0.
\end{eqnarray*}
\end{Prop}

\begin{Def}
La Transformada de Laplace-Stieljes de $F$ est\'a dada por

\begin{eqnarray*}
\hat{F}\left(\alpha\right)=\int_{\rea_{+}}e^{-\alpha t}dF\left(t\right)\textrm{,  }\alpha\geq0.
\end{eqnarray*}
\end{Def}

Entonces

\begin{eqnarray*}
\hat{U}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F^{n\star}}\left(\alpha\right)=\sum_{n=0}^{\infty}\hat{F}\left(\alpha\right)^{n}=\frac{1}{1-\hat{F}\left(\alpha\right)}.
\end{eqnarray*}


\begin{Prop}
La Transformada de Laplace $\hat{U}\left(\alpha\right)$ y $\hat{F}\left(\alpha\right)$ determina una a la otra de manera \'unica por la relaci\'on $\hat{U}\left(\alpha\right)=\frac{1}{1-\hat{F}\left(\alpha\right)}$.
\end{Prop}


\begin{Note}
Un proceso de renovaci\'on $N\left(t\right)$ cuyos tiempos de inter-renovaci\'on tienen media finita, es un proceso Poisson con tasa $\lambda$ si y s\'olo s\'i $\esp\left[U\left(t\right)\right]=\lambda t$, para $t\geq0$.
\end{Note}


\begin{Teo}
Sea $N\left(t\right)$ un proceso puntual simple con puntos de localizaci\'on $T_{n}$ tal que $\eta\left(t\right)=\esp\left[N\left(\right)\right]$ es finita para cada $t$. Entonces para cualquier funci\'on $f:\rea_{+}\rightarrow\rea$,
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(\right)}f\left(T_{n}\right)\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*}
suponiendo que la integral exista. Adem\'as si $X_{1},X_{2},\ldots$ son variables aleatorias definidas en el mismo espacio de probabilidad que el proceso $N\left(t\right)$ tal que $\esp\left[X_{n}|T_{n}=s\right]=f\left(s\right)$, independiente de $n$. Entonces
\begin{eqnarray*}
\esp\left[\sum_{n=1}^{N\left(t\right)}X_{n}\right]=\int_{\left(0,t\right]}f\left(s\right)d\eta\left(s\right)\textrm{,  }t\geq0,
\end{eqnarray*} 
suponiendo que la integral exista. 
\end{Teo}

\begin{Coro}[Identidad de Wald para Renovaciones]
Para el proceso de renovaci\'on $N\left(t\right)$,
\begin{eqnarray*}
\esp\left[T_{N\left(t\right)+1}\right]=\mu\esp\left[N\left(t\right)+1\right]\textrm{,  }t\geq0,
\end{eqnarray*}  
\end{Coro}


\begin{Def}
Sea $h\left(t\right)$ funci\'on de valores reales en $\rea$ acotada en intervalos finitos e igual a cero para $t<0$ La ecuaci\'on de renovaci\'on para $h\left(t\right)$ y la distribuci\'on $F$ es

\begin{eqnarray}%\label{Ec.Renovacion}
H\left(t\right)=h\left(t\right)+\int_{\left[0,t\right]}H\left(t-s\right)dF\left(s\right)\textrm{,    }t\geq0,
\end{eqnarray}
donde $H\left(t\right)$ es una funci\'on de valores reales. Esto es $H=h+F\star H$. Decimos que $H\left(t\right)$ es soluci\'on de esta ecuaci\'on si satisface la ecuaci\'on, y es acotada en intervalos finitos e iguales a cero para $t<0$.
\end{Def}

\begin{Prop}
La funci\'on $U\star h\left(t\right)$ es la \'unica soluci\'on de la ecuaci\'on de renovaci\'on (\ref{Ec.Renovacion}).
\end{Prop}

\begin{Teo}[Teorema Renovaci\'on Elemental]
\begin{eqnarray*}
t^{-1}U\left(t\right)\rightarrow 1/\mu\textrm{,    cuando }t\rightarrow\infty.
\end{eqnarray*}
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}


\begin{Note} Una funci\'on $h:\rea_{+}\rightarrow\rea$ es Directamente Riemann Integrable en los siguientes casos:
\begin{itemize}
\item[a)] $h\left(t\right)\geq0$ es decreciente y Riemann Integrable.
\item[b)] $h$ es continua excepto posiblemente en un conjunto de Lebesgue de medida 0, y $|h\left(t\right)|\leq b\left(t\right)$, donde $b$ es DRI.
\end{itemize}
\end{Note}

\begin{Teo}[Teorema Principal de Renovaci\'on]
Si $F$ es no aritm\'etica y $h\left(t\right)$ es Directamente Riemann Integrable (DRI), entonces

\begin{eqnarray*}
lim_{t\rightarrow\infty}U\star h=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds.
\end{eqnarray*}
\end{Teo}

\begin{Prop}
Cualquier funci\'on $H\left(t\right)$ acotada en intervalos finitos y que es 0 para $t<0$ puede expresarse como
\begin{eqnarray*}
H\left(t\right)=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=H\left(t\right)-F\star H\left(t\right)
\end{eqnarray*}
\end{Prop}

\begin{Def}
Un proceso estoc\'astico $X\left(t\right)$ es crudamente regenerativo en un tiempo aleatorio positivo $T$ si
\begin{eqnarray*}
\esp\left[X\left(T+t\right)|T\right]=\esp\left[X\left(t\right)\right]\textrm{, para }t\geq0,\end{eqnarray*}
y con las esperanzas anteriores finitas.
\end{Def}

\begin{Prop}
Sup\'ongase que $X\left(t\right)$ es un proceso crudamente regenerativo en $T$, que tiene distribuci\'on $F$. Si $\esp\left[X\left(t\right)\right]$ es acotado en intervalos finitos, entonces
\begin{eqnarray*}
\esp\left[X\left(t\right)\right]=U\star h\left(t\right)\textrm{,  donde }h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right].
\end{eqnarray*}
\end{Prop}

\begin{Teo}[Regeneraci\'on Cruda]
Sup\'ongase que $X\left(t\right)$ es un proceso con valores positivo crudamente regenerativo en $T$, y def\'inase $M=\sup\left\{|X\left(t\right)|:t\leq T\right\}$. Si $T$ es no aritm\'etico y $M$ y $MT$ tienen media finita, entonces
\begin{eqnarray*}
lim_{t\rightarrow\infty}\esp\left[X\left(t\right)\right]=\frac{1}{\mu}\int_{\rea_{+}}h\left(s\right)ds,
\end{eqnarray*}
donde $h\left(t\right)=\esp\left[X\left(t\right)\indora\left(T>t\right)\right]$.
\end{Teo}

\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}


\begin{Note}
Un proceso estoc\'astico a tiempo continuo o discreto es regenerativo si existe un proceso de renovaci\'on  tal que los segmentos del proceso entre tiempos de renovaci\'on sucesivos son i.i.d., es decir, para $\left\{X\left(t\right):t\geq0\right\}$ proceso estoc\'astico a tiempo continuo con espacio de estados $S$, espacio m\'etrico.
\end{Note}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}

\begin{Teo}[Procesos Regenerativos]
Suponga que el proceso
\end{Teo}


\begin{Def}[Renewal Process Trinity]
Para un proceso de renovaci\'on $N\left(t\right)$, los siguientes procesos proveen de informaci\'on sobre los tiempos de renovaci\'on.
\begin{itemize}
\item $A\left(t\right)=t-T_{N\left(t\right)}$, el tiempo de recurrencia hacia atr\'as al tiempo $t$, que es el tiempo desde la \'ultima renovaci\'on para $t$.

\item $B\left(t\right)=T_{N\left(t\right)+1}-t$, el tiempo de recurrencia hacia adelante al tiempo $t$, residual del tiempo de renovaci\'on, que es el tiempo para la pr\'oxima renovaci\'on despu\'es de $t$.

\item $L\left(t\right)=\xi_{N\left(t\right)+1}=A\left(t\right)+B\left(t\right)$, la longitud del intervalo de renovaci\'on que contiene a $t$.
\end{itemize}
\end{Def}

\begin{Note}
El proceso tridimensional $\left(A\left(t\right),B\left(t\right),L\left(t\right)\right)$ es regenerativo sobre $T_{n}$, y por ende cada proceso lo es. Cada proceso $A\left(t\right)$ y $B\left(t\right)$ son procesos de MArkov a tiempo continuo con trayectorias continuas por partes en el espacio de estados $\rea_{+}$. Una expresi\'on conveniente para su distribuci\'on conjunta es, para $0\leq x<t,y\geq0$
\begin{equation}\label{NoRenovacion}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=
P\left\{N\left(t+y\right)-N\left((t-x)\right)=0\right\}
\end{equation}
\end{Note}

\begin{Ejem}[Tiempos de recurrencia Poisson]
Si $N\left(t\right)$ es un proceso Poisson con tasa $\lambda$, entonces de la expresi\'on (\ref{NoRenovacion}) se tiene que

\begin{eqnarray*}
\begin{array}{lc}
P\left\{A\left(t\right)>x,B\left(t\right)>y\right\}=e^{-\lambda\left(x+y\right)},&0\leq x<t,y\geq0,
\end{array}
\end{eqnarray*}
que es la probabilidad Poisson de no renovaciones en un intervalo de longitud $x+y$.

\end{Ejem}

\begin{Note}
Una cadena de Markov erg\'odica tiene la propiedad de ser estacionaria si la distribuci\'on de su estado al tiempo $0$ es su distribuci\'on estacionaria.
\end{Note}


\begin{Def}
Un proceso estoc\'astico a tiempo continuo $\left\{X\left(t\right):t\geq0\right\}$ en un espacio general es estacionario si sus distribuciones finito dimensionales son invariantes bajo cualquier  traslado: para cada $0\leq s_{1}<s_{2}<\cdots<s_{k}$ y $t\geq0$,
\begin{eqnarray*}
\left(X\left(s_{1}+t\right),\ldots,X\left(s_{k}+t\right)\right)=_{d}\left(X\left(s_{1}\right),\ldots,X\left(s_{k}\right)\right).
\end{eqnarray*}
\end{Def}

\begin{Note}
Un proceso de Markov es estacionario si $X\left(t\right)=_{d}X\left(0\right)$, $t\geq0$.
\end{Note}

Considerese el proceso $N\left(t\right)=\sum_{n}\indora\left(\tau_{n}\leq t\right)$ en $\rea_{+}$, con puntos $0<\tau_{1}<\tau_{2}<\cdots$.

\begin{Prop}
Si $N$ es un proceso puntual estacionario y $\esp\left[N\left(1\right)\right]<\infty$, entonces $\esp\left[N\left(t\right)\right]=t\esp\left[N\left(1\right)\right]$, $t\geq0$

\end{Prop}

\begin{Teo}
Los siguientes enunciados son equivalentes
\begin{itemize}
\item[i)] El proceso retardado de renovaci\'on $N$ es estacionario.

\item[ii)] EL proceso de tiempos de recurrencia hacia adelante $B\left(t\right)$ es estacionario.


\item[iii)] $\esp\left[N\left(t\right)\right]=t/\mu$,


\item[iv)] $G\left(t\right)=F_{e}\left(t\right)=\frac{1}{\mu}\int_{0}^{t}\left[1-F\left(s\right)\right]ds$
\end{itemize}
Cuando estos enunciados son ciertos, $P\left\{B\left(t\right)\leq x\right\}=F_{e}\left(x\right)$, para $t,x\geq0$.

\end{Teo}

\begin{Note}
Una consecuencia del teorema anterior es que el Proceso Poisson es el \'unico proceso sin retardo que es estacionario.
\end{Note}

\begin{Coro}
El proceso de renovaci\'on $N\left(t\right)$ sin retardo, y cuyos tiempos de inter renonaci\'on tienen media finita, es estacionario si y s\'olo si es un proceso Poisson.

\end{Coro}


%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________



\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}
%\subsection*{Procesos Regenerativos: Sigman\cite{Sigman1}}
\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.




\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%________________________________________________________________________
%\subsection{Procesos Regenerativos}
%________________________________________________________________________

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



\begin{Def}
Para el proceso $\left\{\left(N\left(t\right),X\left(t\right)\right):t\geq0\right\}$, sus trayectoria muestrales en el intervalo de tiempo $\left[T_{n-1},T_{n}\right)$ est\'an descritas por
\begin{eqnarray*}
\zeta_{n}=\left(\xi_{n},\left\{X\left(T_{n-1}+t\right):0\leq t<\xi_{n}\right\}\right)
\end{eqnarray*}
Este $\zeta_{n}$ es el $n$-\'esimo segmento del proceso. El proceso es regenerativo sobre los tiempos $T_{n}$ si sus segmentos $\zeta_{n}$ son independientes e id\'enticamennte distribuidos.
\end{Def}


\begin{Note}
Si $\tilde{X}\left(t\right)$ con espacio de estados $\tilde{S}$ es regenerativo sobre $T_{n}$, entonces $X\left(t\right)=f\left(\tilde{X}\left(t\right)\right)$ tambi\'en es regenerativo sobre $T_{n}$, para cualquier funci\'on $f:\tilde{S}\rightarrow S$.
\end{Note}

\begin{Note}
Los procesos regenerativos son crudamente regenerativos, pero no al rev\'es.
\end{Note}

\begin{Def}[Definici\'on Cl\'asica]
Un proceso estoc\'astico $X=\left\{X\left(t\right):t\geq0\right\}$ es llamado regenerativo is existe una variable aleatoria $R_{1}>0$ tal que
\begin{itemize}
\item[i)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es independiente de $\left\{\left\{X\left(t\right):t<R_{1}\right\},\right\}$
\item[ii)] $\left\{X\left(t+R_{1}\right):t\geq0\right\}$ es estoc\'asticamente equivalente a $\left\{X\left(t\right):t>0\right\}$
\end{itemize}

Llamamos a $R_{1}$ tiempo de regeneraci\'on, y decimos que $X$ se regenera en este punto.
\end{Def}

$\left\{X\left(t+R_{1}\right)\right\}$ es regenerativo con tiempo de regeneraci\'on $R_{2}$, independiente de $R_{1}$ pero con la misma distribuci\'on que $R_{1}$. Procediendo de esta manera se obtiene una secuencia de variables aleatorias independientes e id\'enticamente distribuidas $\left\{R_{n}\right\}$ llamados longitudes de ciclo. Si definimos a $Z_{k}\equiv R_{1}+R_{2}+\cdots+R_{k}$, se tiene un proceso de renovaci\'on llamado proceso de renovaci\'on encajado para $X$.

\begin{Note}
Un proceso regenerativo con media de la longitud de ciclo finita es llamado positivo recurrente.
\end{Note}


\begin{Def}
Para $x$ fijo y para cada $t\geq0$, sea $I_{x}\left(t\right)=1$ si $X\left(t\right)\leq x$,  $I_{x}\left(t\right)=0$ en caso contrario, y def\'inanse los tiempos promedio
\begin{eqnarray*}
\overline{X}&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}X\left(u\right)du\\
\prob\left(X_{\infty}\leq x\right)&=&lim_{t\rightarrow\infty}\frac{1}{t}\int_{0}^{\infty}I_{x}\left(u\right)du,
\end{eqnarray*}
cuando estos l\'imites existan.
\end{Def}

Como consecuencia del teorema de Renovaci\'on-Recompensa, se tiene que el primer l\'imite  existe y es igual a la constante
\begin{eqnarray*}
\overline{X}&=&\frac{\esp\left[\int_{0}^{R_{1}}X\left(t\right)dt\right]}{\esp\left[R_{1}\right]},
\end{eqnarray*}
suponiendo que ambas esperanzas son finitas.

\begin{Note}
\begin{itemize}
\item[a)] Si el proceso regenerativo $X$ es positivo recurrente y tiene trayectorias muestrales no negativas, entonces la ecuaci\'on anterior es v\'alida.
\item[b)] Si $X$ es positivo recurrente regenerativo, podemos construir una \'unica versi\'on estacionaria de este proceso, $X_{e}=\left\{X_{e}\left(t\right)\right\}$, donde $X_{e}$ es un proceso estoc\'astico regenerativo y estrictamente estacionario, con distribuci\'on marginal distribuida como $X_{\infty}$
\end{itemize}
\end{Note}

%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}


%__________________________________________________________________________________________
%\subsection{Procesos Regenerativos Estacionarios - Stidham \cite{Stidham}}
%__________________________________________________________________________________________


Un proceso estoc\'astico a tiempo continuo $\left\{V\left(t\right),t\geq0\right\}$ es un proceso regenerativo si existe una sucesi\'on de variables aleatorias independientes e id\'enticamente distribuidas $\left\{X_{1},X_{2},\ldots\right\}$, sucesi\'on de renovaci\'on, tal que para cualquier conjunto de Borel $A$, 

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A|X_{1}+X_{2}+\cdots+X_{R\left(t\right)}=s,\left\{V\left(\tau\right),\tau<s\right\}\right\}=\prob\left\{V\left(t-s\right)\in A|X_{1}>t-s\right\},
\end{eqnarray*}
para todo $0\leq s\leq t$, donde $R\left(t\right)=\max\left\{X_{1}+X_{2}+\cdots+X_{j}\leq t\right\}=$n\'umero de renovaciones ({\emph{puntos de regeneraci\'on}}) que ocurren en $\left[0,t\right]$. El intervalo $\left[0,X_{1}\right)$ es llamado {\emph{primer ciclo de regeneraci\'on}} de $\left\{V\left(t \right),t\geq0\right\}$, $\left[X_{1},X_{1}+X_{2}\right)$ el {\emph{segundo ciclo de regeneraci\'on}}, y as\'i sucesivamente.

Sea $X=X_{1}$ y sea $F$ la funci\'on de distrbuci\'on de $X$


\begin{Def}
Se define el proceso estacionario, $\left\{V^{*}\left(t\right),t\geq0\right\}$, para $\left\{V\left(t\right),t\geq0\right\}$ por

\begin{eqnarray*}
\prob\left\{V\left(t\right)\in A\right\}=\frac{1}{\esp\left[X\right]}\int_{0}^{\infty}\prob\left\{V\left(t+x\right)\in A|X>x\right\}\left(1-F\left(x\right)\right)dx,
\end{eqnarray*} 
para todo $t\geq0$ y todo conjunto de Borel $A$.
\end{Def}

\begin{Def}
Una distribuci\'on se dice que es {\emph{aritm\'etica}} si todos sus puntos de incremento son m\'ultiplos de la forma $0,\lambda, 2\lambda,\ldots$ para alguna $\lambda>0$ entera.
\end{Def}


\begin{Def}
Una modificaci\'on medible de un proceso $\left\{V\left(t\right),t\geq0\right\}$, es una versi\'on de este, $\left\{V\left(t,w\right)\right\}$ conjuntamente medible para $t\geq0$ y para $w\in S$, $S$ espacio de estados para $\left\{V\left(t\right),t\geq0\right\}$.
\end{Def}

\begin{Teo}
Sea $\left\{V\left(t\right),t\geq\right\}$ un proceso regenerativo no negativo con modificaci\'on medible. Sea $\esp\left[X\right]<\infty$. Entonces el proceso estacionario dado por la ecuaci\'on anterior est\'a bien definido y tiene funci\'on de distribuci\'on independiente de $t$, adem\'as
\begin{itemize}
\item[i)] \begin{eqnarray*}
\esp\left[V^{*}\left(0\right)\right]&=&\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}\end{eqnarray*}
\item[ii)] Si $\esp\left[V^{*}\left(0\right)\right]<\infty$, equivalentemente, si $\esp\left[\int_{0}^{X}V\left(s\right)ds\right]<\infty$,entonces
\begin{eqnarray*}
\frac{\int_{0}^{t}V\left(s\right)ds}{t}\rightarrow\frac{\esp\left[\int_{0}^{X}V\left(s\right)ds\right]}{\esp\left[X\right]}
\end{eqnarray*}
con probabilidad 1 y en media, cuando $t\rightarrow\infty$.
\end{itemize}
\end{Teo}

Para $\left\{X\left(t\right):t\geq0\right\}$ Proceso Estoc\'astico a tiempo continuo con estado de espacios $S$, que es un espacio m\'etrico, con trayectorias continuas por la derecha y con l\'imites por la izquierda c.s. Sea $N\left(t\right)$ un proceso de renovaci\'on en $\rea_{+}$ definido en el mismo espacio de probabilidad que $X\left(t\right)$, con tiempos de renovaci\'on $T$ y tiempos de inter-renovaci\'on $\xi_{n}=T_{n}-T_{n-1}$, con misma distribuci\'on $F$ de media finita $\mu$.



Sean $T_{1},T_{2},\ldots$ los puntos donde las longitudes de las colas de la red de sistemas de visitas c\'iclicas son cero simult\'aneamente, cuando la cola $Q_{j}$ es visitada por el servidor para dar servicio, es decir, $L_{1}\left(T_{i}\right)=0,L_{2}\left(T_{i}\right)=0,\hat{L}_{1}\left(T_{i}\right)=0$ y $\hat{L}_{2}\left(T_{i}\right)=0$, a estos puntos se les denominar\'a puntos regenerativos. Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$\footnote{En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito, es decir: $\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty$, como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que $\esp\left[C_{i}\right]<\infty$,
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por $\sum_{k=1}^{N}\mu_{k}<1.$}, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Haciendo las siguientes sustituciones en la ecuaci\'on (\ref{Corolario2}): $n\rightarrow t-\tau_{i}\left(m\right)$, $T \rightarrow \overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)$, $L_{n}\rightarrow L_{i}\left(t\right)$ y $F\left(z\right)=\esp\left[z^{L_{0}}\right]\rightarrow F_{i}\left(z\right)=\esp\left[z^{L_{i}\tau_{i}\left(m\right)}\right]$, se puede ver que

\begin{eqnarray}\label{Eq.Arribos.Primera}
\esp\left[\sum_{n=0}^{T-1}z^{L_{n}}\right]=
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}z^{L_{i}\left(t\right)}\right]
=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray}

Por otra parte durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&
\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Por lo tanto

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}
\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\overline{\tau}_{i}\left(m\right)-1}
z^{L_{i}\left(t\right)}\right]
+\esp\left[\sum_{t=\overline{\tau}_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}
z^{L_{i}\left(t\right)}\right]\right\}\\
&=&\frac{1}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\left\{
z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}+\frac{1-F_{i}\left(z\right)}
{1-P_{i}\left(z\right)}
\right\}
\end{eqnarray*}

es decir

\begin{equation}
Q_{i}\left(z\right)=\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{equation}

\begin{Teo}
Dada una Red de Sistemas de Visitas C\'iclicas (RSVC), conformada por dos Sistemas de Visitas C\'iclicas (SVC), donde cada uno de ellos consta de dos colas tipo $M/M/1$. Los dos sistemas est\'an comunicados entre s\'i por medio de la transferencia de usuarios entre las colas $Q_{1}\leftrightarrow Q_{3}$ y $Q_{2}\leftrightarrow Q_{4}$. Se definen los eventos para los procesos de arribos al tiempo $t$, $A_{j}\left(t\right)=\left\{0 \textrm{ arribos en }Q_{j}\textrm{ al tiempo }t\right\}$ para alg\'un tiempo $t\geq0$ y $Q_{j}$ la cola $j$-\'esima en la RSVC, para $j=1,2,3,4$.  Existe un intervalo $I\neq\emptyset$ tal que para $T^{*}\in I$, tal que $\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(Tt^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I\right\}>0$.
\end{Teo}

\begin{proof}
Sin p\'erdida de generalidad podemos considerar como base del an\'alisis a la cola $Q_{1}$ del primer sistema que conforma la RSVC.

Sea $n>0$, ciclo en el primer sistema en el que se sabe que $L_{j}\left(\overline{\tau}_{1}\left(n\right)\right)=0$, pues la pol\'itica de servicio con que atienden los servidores es la exhaustiva. Como es sabido, para trasladarse a la siguiente cola, el servidor incurre en un tiempo de traslado $r_{1}\left(n\right)>0$, entonces tenemos que $\tau_{2}\left(n\right)=\overline{\tau}_{1}\left(n\right)+r_{1}\left(n\right)$.


Definamos el intervalo $I_{1}\equiv\left[\overline{\tau}_{1}\left(n\right),\tau_{2}\left(n\right)\right]$ de longitud $\xi_{1}=r_{1}\left(n\right)$. Dado que los tiempos entre arribo son exponenciales con tasa $\tilde{\mu}_{1}=\mu_{1}+\hat{\mu}_{1}$ ($\mu_{1}$ son los arribos a $Q_{1}$ por primera vez al sistema, mientras que $\hat{\mu}_{1}$ son los arribos de traslado procedentes de $Q_{3}$) se tiene que la probabilidad del evento $A_{1}\left(t\right)$ est\'a dada por 

\begin{equation}
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}=e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}.
\end{equation} 

Por otra parte, para la cola $Q_{2}$, el tiempo $\overline{\tau}_{2}\left(n-1\right)$ es tal que $L_{2}\left(\overline{\tau}_{2}\left(n-1\right)\right)=0$, es decir, es el tiempo en que la cola queda totalmente vac\'ia en el ciclo anterior a $n$. Entonces tenemos un sgundo intervalo $I_{2}\equiv\left[\overline{\tau}_{2}\left(n-1\right),\tau_{2}\left(n\right)\right]$. Por lo tanto la probabilidad del evento $A_{2}\left(t\right)$ tiene probabilidad dada por

\begin{equation}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}=e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)},
\end{equation} 

donde $\xi_{2}\left(n\right)=\tau_{2}\left(n\right)-\overline{\tau}_{2}\left(n-1\right)$.



Entonces, se tiene que

\begin{eqnarray*}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}&=&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}\\
&\geq&
\prob\left\{A_{1}\left(t\right)|t\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(t\right)|t\in I_{2}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{1}\xi_{1}\left(n\right)}e^{-\tilde{\mu}_{2}\xi_{2}\left(n\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}\left(n\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{1}\left(t\right),A_{2}\left(t\right)|t\in I_{1}\left(n\right)\right\}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)+\tilde{\mu}_{2}\xi_{2}
\left(n\right)\right]}>0.
\end{equation}

En lo que respecta a la relaci\'on entre los dos SVC que conforman la RSVC, se afirma que existe $m>0$ tal que $\overline{\tau}_{3}\left(m\right)<\tau_{2}\left(n\right)<\tau_{4}\left(m\right)$.

Para $Q_{3}$ sea $I_{3}=\left[\overline{\tau}_{3}\left(m\right),\tau_{4}\left(m\right)\right]$ con longitud  $\xi_{3}\left(m\right)=r_{3}\left(m\right)$, entonces 

\begin{equation}
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}=e^{-\tilde{\mu}_{3}\xi_{3}\left(n\right)}.
\end{equation} 

An\'alogamente que como se hizo para $Q_{2}$, tenemos que para $Q_{4}$ se tiene el intervalo $I_{4}=\left[\overline{\tau}_{4}\left(m-1\right),\tau_{4}\left(m\right)\right]$ con longitud $\xi_{4}\left(m\right)=\tau_{4}\left(m\right)-\overline{\tau}_{4}\left(m-1\right)$, entonces


\begin{equation}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}=e^{-\tilde{\mu}_{4}\xi_{4}\left(n\right)}.
\end{equation} 

Al igual que para el primer sistema, dado que $I_{3}\left(m\right)\subset I_{4}\left(m\right)$, se tiene que

\begin{eqnarray*}
\xi_{3}\left(m\right)\leq\xi_{4}\left(m\right)&\Leftrightarrow& -\xi_{3}\left(m\right)\geq-\xi_{4}\left(m\right)
\\
-\tilde{\mu}_{4}\xi_{3}\left(m\right)\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right)&\Leftrightarrow&
e^{-\tilde{\mu}_{4}\xi_{3}\left(m\right)}\geq e^{-\tilde{\mu}_{4}\xi_{4}\left(m\right)}\\
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&\geq&
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(m\right)\right\}
\end{eqnarray*}

Entonces, dado que los eventos $A_{3}$ y $A_{4}$ son independientes, se tiene que

\begin{eqnarray*}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}&=&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}\\
&\geq&
\prob\left\{A_{3}\left(t\right)|t\in I_{3}\left(n\right)\right\}
\prob\left\{A_{4}\left(t\right)|t\in I_{4}\left(n\right)\right\}\\
&=&e^{-\tilde{\mu}_{3}\xi_{3}\left(m\right)}e^{-\tilde{\mu}_{4}\xi_{4}
\left(m\right)}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}.
\end{eqnarray*}


es decir, 

\begin{equation}
\prob\left\{A_{3}\left(t\right),A_{4}\left(t\right)|t\in I_{3}\left(m\right)\right\}
=e^{-\left[\tilde{\mu}_{3}\xi_{3}\left(m\right)+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{equation}

Por construcci\'on se tiene que $I\left(n,m\right)\equiv I_{1}\left(n\right)\cap I_{3}\left(m\right)\neq\emptyset$,entonces en particular se tienen las contenciones $I\left(n,m\right)\subseteq I_{1}\left(n\right)$ y $I\left(n,m\right)\subseteq I_{3}\left(m\right)$, por lo tanto si definimos $\xi_{n,m}\equiv\ell\left(I\left(n,m\right)\right)$ tenemos que

\begin{eqnarray*}
\xi_{n,m}\leq\xi_{1}\left(n\right)\textrm{ y }\xi_{n,m}\leq\xi_{3}\left(m\right)\textrm{ entonces }
-\xi_{n,m}\geq-\xi_{1}\left(n\right)\textrm{ y }-\xi_{n,m}\leq-\xi_{3}\left(m\right)\\
\end{eqnarray*}
por lo tanto tenemos las desigualdades 



\begin{eqnarray*}
\begin{array}{ll}
-\tilde{\mu}_{1}\xi_{n,m}\geq-\tilde{\mu}_{1}\xi_{1}\left(n\right),&
-\tilde{\mu}_{2}\xi_{n,m}\geq-\tilde{\mu}_{2}\xi_{1}\left(n\right)
\geq-\tilde{\mu}_{2}\xi_{2}\left(n\right),\\
-\tilde{\mu}_{3}\xi_{n,m}\geq-\tilde{\mu}_{3}\xi_{3}\left(m\right),&
-\tilde{\mu}_{4}\xi_{n,m}\geq-\tilde{\mu}_{4}\xi_{3}\left(m\right)
\geq-\tilde{\mu}_{4}\xi_{4}\left(m\right).
\end{array}
\end{eqnarray*}

Sea $T^{*}\in I_{n,m}$, entonces dado que en particular $T^{*}\in I_{1}\left(n\right)$ se cumple con probabilidad positiva que no hay arribos a las colas $Q_{1}$ y $Q_{2}$, en consecuencia, tampoco hay usuarios de transferencia para $Q_{3}$ y $Q_{4}$, es decir, $\tilde{\mu}_{1}=\mu_{1}$, $\tilde{\mu}_{2}=\mu_{2}$, $\tilde{\mu}_{3}=\mu_{3}$, $\tilde{\mu}_{4}=\mu_{4}$, es decir, los eventos $Q_{1}$ y $Q_{3}$ son condicionalmente independientes en el intervalo $I_{n,m}$; lo mismo ocurre para las colas $Q_{2}$ y $Q_{4}$, por lo tanto tenemos que


\begin{eqnarray}
\begin{array}{l}
\prob\left\{A_{1}\left(T^{*}\right),A_{2}\left(T^{*}\right),
A_{3}\left(T^{*}\right),A_{4}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}
=\prod_{j=1}^{4}\prob\left\{A_{j}\left(T^{*}\right)|T^{*}\in I_{n,m}\right\}\\
\geq\prob\left\{A_{1}\left(T^{*}\right)|T^{*}\in I_{1}\left(n\right)\right\}
\prob\left\{A_{2}\left(T^{*}\right)|T^{*}\in I_{2}\left(n\right)\right\}
\prob\left\{A_{3}\left(T^{*}\right)|T^{*}\in I_{3}\left(m\right)\right\}
\prob\left\{A_{4}\left(T^{*}\right)|T^{*}\in I_{4}\left(m\right)\right\}\\
=e^{-\mu_{1}\xi_{1}\left(n\right)}
e^{-\mu_{2}\xi_{2}\left(n\right)}
e^{-\mu_{3}\xi_{3}\left(m\right)}
e^{-\mu_{4}\xi_{4}\left(m\right)}
=e^{-\left[\tilde{\mu}_{1}\xi_{1}\left(n\right)
+\tilde{\mu}_{2}\xi_{2}\left(n\right)
+\tilde{\mu}_{3}\xi_{3}\left(m\right)
+\tilde{\mu}_{4}\xi_{4}
\left(m\right)\right]}>0.
\end{array}
\end{eqnarray}
\end{proof}


Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}


\subsection{Resultados para Procesos de Salida}

En Sigman, Thorison y Wolff \cite{Sigman2} prueban que para la existencia de un una sucesi\'on infinita no decreciente de tiempos de regeneraci\'on $\tau_{1}\leq\tau_{2}\leq\cdots$ en los cuales el proceso se regenera, basta un tiempo de regeneraci\'on $R_{1}$, donde $R_{j}=\tau_{j}-\tau_{j-1}$. Para tal efecto se requiere la existencia de un espacio de probabilidad $\left(\Omega,\mathcal{F},\prob\right)$, y proceso estoc\'astico $\textit{X}=\left\{X\left(t\right):t\geq0\right\}$ con espacio de estados $\left(S,\mathcal{R}\right)$, con $\mathcal{R}$ $\sigma$-\'algebra.

\begin{Prop}
Si existe una variable aleatoria no negativa $R_{1}$ tal que $\theta_{R\footnotesize{1}}X=_{D}X$, entonces $\left(\Omega,\mathcal{F},\prob\right)$ puede extenderse para soportar una sucesi\'on estacionaria de variables aleatorias $R=\left\{R_{k}:k\geq1\right\}$, tal que para $k\geq1$,
\begin{eqnarray*}
\theta_{k}\left(X,R\right)=_{D}\left(X,R\right).
\end{eqnarray*}

Adem\'as, para $k\geq1$, $\theta_{k}R$ es condicionalmente independiente de $\left(X,R_{1},\ldots,R_{k}\right)$, dado $\theta_{\tau k}X$.

\end{Prop}


\begin{itemize}
\item Doob en 1953 demostr\'o que el estado estacionario de un proceso de partida en un sistema de espera $M/G/\infty$, es Poisson con la misma tasa que el proceso de arribos.

\item Burke en 1968, fue el primero en demostrar que el estado estacionario de un proceso de salida de una cola $M/M/s$ es un proceso Poisson.

\item Disney en 1973 obtuvo el siguiente resultado:

\begin{Teo}
Para el sistema de espera $M/G/1/L$ con disciplina FIFO, el proceso $\textbf{I}$ es un proceso de renovaci\'on si y s\'olo si el proceso denominado longitud de la cola es estacionario y se cumple cualquiera de los siguientes casos:

\begin{itemize}
\item[a)] Los tiempos de servicio son identicamente cero;
\item[b)] $L=0$, para cualquier proceso de servicio $S$;
\item[c)] $L=1$ y $G=D$;
\item[d)] $L=\infty$ y $G=M$.
\end{itemize}
En estos casos, respectivamente, las distribuciones de interpartida $P\left\{T_{n+1}-T_{n}\leq t\right\}$ son


\begin{itemize}
\item[a)] $1-e^{-\lambda t}$, $t\geq0$;
\item[b)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$;
\item[c)] $1-e^{-\lambda t}*\indora_{d}\left(t\right)$, $t\geq0$;
\item[d)] $1-e^{-\lambda t}*F\left(t\right)$, $t\geq0$.
\end{itemize}
\end{Teo}


\item Finch (1959) mostr\'o que para los sistemas $M/G/1/L$, con $1\leq L\leq \infty$ con distribuciones de servicio dos veces diferenciable, solamente el sistema $M/M/1/\infty$ tiene proceso de salida de renovaci\'on estacionario.

\item King (1971) demostro que un sistema de colas estacionario $M/G/1/1$ tiene sus tiempos de interpartida sucesivas $D_{n}$ y $D_{n+1}$ son independientes, si y s\'olo si, $G=D$, en cuyo caso le proceso de salida es de renovaci\'on.

\item Disney (1973) demostr\'o que el \'unico sistema estacionario $M/G/1/L$, que tiene proceso de salida de renovaci\'on  son los sistemas $M/M/1$ y $M/D/1/1$.



\item El siguiente resultado es de Disney y Koning (1985)
\begin{Teo}
En un sistema de espera $M/G/s$, el estado estacionario del proceso de salida es un proceso Poisson para cualquier distribuci\'on de los tiempos de servicio si el sistema tiene cualquiera de las siguientes cuatro propiedades.

\begin{itemize}
\item[a)] $s=\infty$
\item[b)] La disciplina de servicio es de procesador compartido.
\item[c)] La disciplina de servicio es LCFS y preemptive resume, esto se cumple para $L<\infty$
\item[d)] $G=M$.
\end{itemize}

\end{Teo}

\item El siguiente resultado es de Alamatsaz (1983)

\begin{Teo}
En cualquier sistema de colas $GI/G/1/L$ con $1\leq L<\infty$ y distribuci\'on de interarribos $A$ y distribuci\'on de los tiempos de servicio $B$, tal que $A\left(0\right)=0$, $A\left(t\right)\left(1-B\left(t\right)\right)>0$ para alguna $t>0$ y $B\left(t\right)$ para toda $t>0$, es imposible que el proceso de salida estacionario sea de renovaci\'on.
\end{Teo}

\end{itemize}

Estos resultados aparecen en Daley (1968) \cite{Daley68} para $\left\{T_{n}\right\}$ intervalos de inter-arribo, $\left\{D_{n}\right\}$ intervalos de inter-salida y $\left\{S_{n}\right\}$ tiempos de servicio.

\begin{itemize}
\item Si el proceso $\left\{T_{n}\right\}$ es Poisson, el proceso $\left\{D_{n}\right\}$ es no correlacionado si y s\'olo si es un proceso Poisso, lo cual ocurre si y s\'olo si $\left\{S_{n}\right\}$ son exponenciales negativas.

\item Si $\left\{S_{n}\right\}$ son exponenciales negativas, $\left\{D_{n}\right\}$ es un proceso de renovaci\'on  si y s\'olo si es un proceso Poisson, lo cual ocurre si y s\'olo si $\left\{T_{n}\right\}$ es un proceso Poisson.

\item $\esp\left(D_{n}\right)=\esp\left(T_{n}\right)$.

\item Para un sistema de visitas $GI/M/1$ se tiene el siguiente teorema:

\begin{Teo}
En un sistema estacionario $GI/M/1$ los intervalos de interpartida tienen
\begin{eqnarray*}
\esp\left(e^{-\theta D_{n}}\right)&=&\mu\left(\mu+\theta\right)^{-1}\left[\delta\theta
-\mu\left(1-\delta\right)\alpha\left(\theta\right)\right]
\left[\theta-\mu\left(1-\delta\right)^{-1}\right]\\
\alpha\left(\theta\right)&=&\esp\left[e^{-\theta T_{0}}\right]\\
var\left(D_{n}\right)&=&var\left(T_{0}\right)-\left(\tau^{-1}-\delta^{-1}\right)
2\delta\left(\esp\left(S_{0}\right)\right)^{2}\left(1-\delta\right)^{-1}.
\end{eqnarray*}
\end{Teo}



\begin{Teo}
El proceso de salida de un sistema de colas estacionario $GI/M/1$ es un proceso de renovaci\'on si y s\'olo si el proceso de entrada es un proceso Poisson, en cuyo caso el proceso de salida es un proceso Poisson.
\end{Teo}


\begin{Teo}
Los intervalos de interpartida $\left\{D_{n}\right\}$ de un sistema $M/G/1$ estacionario son no correlacionados si y s\'olo si la distribuci\'on de los tiempos de servicio es exponencial negativa, es decir, el sistema es de tipo  $M/M/1$.

\end{Teo}



\end{itemize}
%\newpage

\section{Aplicaci\'on a Teor\'ia de Colas}



Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}




Sea la funci\'on generadora de momentos para $L_{i}$, el n\'umero de usuarios en la cola $Q_{i}\left(z\right)$ en cualquier momento, est\'a dada por el tiempo promedio de $z^{L_{i}\left(t\right)}$ sobre el ciclo regenerativo definido anteriormente:

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(t\right)}\right]=\frac{\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

$M_{i}$ es un tiempo de paro en el proceso regenerativo con $\esp\left[M_{i}\right]<\infty$, se sigue del lema de Wald que:


\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[M_{i}\right]\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]\\
\esp\left[\sum_{m=1}^{M_{i}}\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]&=&\esp\left[M_{i}\right]\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]
\end{eqnarray*}

por tanto se tiene que


\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]}{\esp\left[\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)\right]}
\end{eqnarray*}

observar que el denominador es simplemente la duraci\'on promedio del tiempo del ciclo.


Se puede demostrar (ver Hideaki Takagi 1986) que

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]=z\frac{F_{i}\left(z\right)-1}{z-P_{i}\left(z\right)}
\end{eqnarray*}

Durante el tiempo de intervisita para la cola $i$, $L_{i}\left(t\right)$ solamente se incrementa de manera que el incremento por intervalo de tiempo est\'a dado por la funci\'on generadora de probabilidades de $P_{i}\left(z\right)$, por tanto la suma sobre el tiempo de intervisita puede evaluarse como:

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}\left\{P_{i}\left(z\right)\right\}^{t-\overline{\tau}_{i}\left(m\right)}\right]=\frac{1-\esp\left[\left\{P_{i}\left(z\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]}{1-P_{i}\left(z\right)}\\
&=&\frac{1-I_{i}\left[P_{i}\left(z\right)\right]}{1-P_{i}\left(z\right)}
\end{eqnarray*}
por tanto

\begin{eqnarray*}
\esp\left[\sum_{t=\tau_{i}\left(m\right)}^{\tau_{i}\left(m+1\right)-1}z^{L_{i}\left(t\right)}\right]&=&\frac{1-F_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

Haciendo uso de lo hasta ahora desarrollado se tiene que

\begin{eqnarray*}
Q_{i}\left(z\right)&=&\frac{1}{\esp\left[C_{i}\right]}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}\\
&=&\frac{\mu_{i}\left(1-\mu_{i}\right)}{f_{i}\left(i\right)}\cdot\frac{1-F_{i}\left(z\right)}{P_{i}\left(z\right)-z}\cdot\frac{\left(1-z\right)P_{i}\left(z\right)}{1-P_{i}\left(z\right)}
\end{eqnarray*}

\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}


\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

derivando con respecto a $z$



\begin{eqnarray*}
\frac{d Q_{i}\left(z\right)}{d z}&=&\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray*}

Calculando el l\'imite cuando $z\rightarrow1^{+}$:
\begin{eqnarray}
Q_{i}^{(1)}\left(z\right)=\lim_{z\rightarrow1^{+}}\frac{d Q_{i}\left(z\right)}{dz}&=&\lim_{z\rightarrow1}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&-&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\esp\left[C_{i}\right]\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}
\end{eqnarray}

Entonces:
%______________________________________________________

\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right)F_{i}^{'}\left(z\right)+\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________


\begin{eqnarray*}
\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}&=&\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)P_{i}\left(z\right)F_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-P_{i}\left(z\right) F_{i}^{'}\left(z\right)+(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) P_{i}\left(z\right)F_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}
\end{eqnarray*}


%______________________________________________________

\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)\left(P_{i}^{'}\left(z\right)-1\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)^{2}\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)-(1-z) P_{i}\left(z\right)F_{i}^{'}\left(z\right)\left(-1+P_{i}^{'}\left(z\right)\right)}{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right) P_{i}^{'}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}\\
&+&\lim_{z\rightarrow1^{+}}\frac{+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right)P_{i}^{''}\left(z\right)}{{2\left(1-P_{i}\left(z\right)\right)\left(-z+P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right)^2 P_{i}^{'}\left(z\right)}}
\end{eqnarray*}











%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)-(1-z) F_{i}^{'}\left(z\right) P_{i}^{'}\left(z\right)+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right) \left(-1+P_{i}^{'}\left(z\right)\right)-\left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\frac{}{}
\end{eqnarray*}

%______________________________________________________
\begin{eqnarray*}
&&\lim_{z\rightarrow1^{+}}\frac{\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)}=\lim_{z\rightarrow1^{+}}\frac{\frac{d}{dz}\left[\left(1-z\right)\left(1-F_{i}\left(z\right)\right)P_{i}\left(z\right)P_{i}^{'}\left(z\right)\right]}{\frac{d}{dz}\left[\left(1-P_{i}\left(z\right)\right)^{2}\left(P_{i}\left(z\right)-z\right)\right]}\\
&=&\lim_{z\rightarrow1^{+}}\frac{-\left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{'}\left(z\right)-(1-z) P_{i}\left(z\right) F_{i}^{'}\left(z\right)P_i'[z]}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
&+&\lim_{z\rightarrow1^{+}}\frac{(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)^2+(1-z) \left(1-F_{i}\left(z\right)\right) P_{i}\left(z\right) P_{i}^{''}\left(z\right)}{\left(1-P_{i}\left(z\right)\right)^2 \left(-1+P_{i}^{'}\left(z\right)\right)-2 \left(1-P_{i}\left(z\right)\right) \left(-z+P_{i}\left(z\right)\right) P_{i}^{'}\left(z\right)}\\
\end{eqnarray*}



En nuestra notaci\'on $V\left(t\right)\equiv C_{i}$ y $X_{i}=C_{i}^{(m)}$ para nuestra segunda definici\'on, mientras que para la primera la notaci\'on es: $X\left(t\right)\equiv C_{i}$ y $R_{i}\equiv C_{i}^{(m)}$.


%___________________________________________________________________________________________
%\section{Tiempos de Ciclo e Intervisita}
%___________________________________________________________________________________________


\begin{Def}
Sea $L_{i}^{*}$el n\'umero de usuarios en la cola $Q_{i}$ cuando es visitada por el servidor para dar servicio, entonces

\begin{eqnarray}
\esp\left[L_{i}^{*}\right]&=&f_{i}\left(i\right)\\
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+\esp\left[L_{i}^{*}\right]-\esp\left[L_{i}^{*}\right]^{2}.
\end{eqnarray}

\end{Def}

\begin{Def}
El tiempo de Ciclo $C_{i}$ es e periodo de tiempo que comienza cuando la cola $i$ es visitada por primera vez en un ciclo, y termina cuando es visitado nuevamente en el pr\'oximo ciclo. La duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\tau_{i}\left(m\right)$, o equivalentemente $\overline{\tau}_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$ bajo condiciones de estabilidad.
\end{Def}

\begin{Def}
El tiempo de intervisita $I_{i}$ es el periodo de tiempo que comienza cuando se ha completado el servicio en un ciclo y termina cuando es visitada nuevamente en el pr\'oximo ciclo. Su  duraci\'on del mismo est\'a dada por $\tau_{i}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)$.
\end{Def}


Recordemos las siguientes expresiones:

\begin{eqnarray*}
S_{i}\left(z\right)&=&\esp\left[z^{\overline{\tau}_{i}\left(m\right)-\tau_{i}\left(m\right)}\right]=F_{i}\left(\theta\left(z\right)\right),\\
F\left(z\right)&=&\esp\left[z^{L_{0}}\right],\\
P\left(z\right)&=&\esp\left[z^{X_{n}}\right],\\
F_{i}\left(z\right)&=&\esp\left[z^{L_{i}\left(\tau_{i}\left(m\right)\right)}\right],
\theta_{i}\left(z\right)-zP_{i}
\end{eqnarray*}

entonces 

\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\frac{\esp\left[L_{i}^{*}\right]}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{1-\mu_{i}},\\
Var\left[S_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{2}}+\frac{\sigma^{2}\esp\left[L_{i}^{*}\right]}{\left(1-\mu_{i}\right)^{3}}
\end{eqnarray*}

donde recordemos que

\begin{eqnarray*}
Var\left[L_{i}^{*}\right]&=&f_{i}\left(i,i\right)+f_{i}\left(i\right)-f_{i}\left(i\right)^{2}.
\end{eqnarray*}

La duraci\'on del tiempo de intervisita es $\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)$. Dado que el n\'umero de usuarios presentes en $Q_{i}$ al tiempo $t=\tau_{i}\left(m+1\right)$ es igual al n\'umero de arribos durante el intervalo de tiempo $\left[\overline{\tau}\left(m\right),\tau_{i}\left(m+1\right)\right]$ se tiene que


\begin{eqnarray*}
\esp\left[z_{i}^{L_{i}\left(\tau_{i}\left(m+1\right)\right)}\right]=\esp\left[\left\{P_{i}\left(z_{i}\right)\right\}^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]
\end{eqnarray*}

entonces, si \begin{eqnarray*}I_{i}\left(z\right)&=&\esp\left[z^{\tau_{i}\left(m+1\right)-\overline{\tau}\left(m\right)}\right]\end{eqnarray*} se tienen que

\begin{eqnarray*}
F_{i}\left(z\right)=I_{i}\left[P_{i}\left(z\right)\right]
\end{eqnarray*}
para $i=1,2$, por tanto



\begin{eqnarray*}
\esp\left[L_{i}^{*}\right]&=&\mu_{i}\esp\left[I_{i}\right]\\
Var\left[L_{i}^{*}\right]&=&\mu_{i}^{2}Var\left[I_{i}\right]+\sigma^{2}\esp\left[I_{i}\right]
\end{eqnarray*}
para $i=1,2$, por tanto


\begin{eqnarray*}
\esp\left[I_{i}\right]&=&\frac{f_{i}\left(i\right)}{\mu_{i}},
\end{eqnarray*}
adem\'as

\begin{eqnarray*}
Var\left[I_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}}-\frac{\sigma_{i}^{2}}{\mu_{i}^{2}}f_{i}\left(i\right).
\end{eqnarray*}


Si  $C_{i}\left(z\right)=\esp\left[z^{\overline{\tau}\left(m+1\right)-\overline{\tau}_{i}\left(m\right)}\right]$el tiempo de duraci\'on del ciclo, entonces, por lo hasta ahora establecido, se tiene que

\begin{eqnarray*}
C_{i}\left(z\right)=I_{i}\left[\theta_{i}\left(z\right)\right],
\end{eqnarray*}
entonces

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\esp\left[I_{i}\right]\esp\left[\theta_{i}\left(z\right)\right]=\frac{\esp\left[L_{i}^{*}\right]}{\mu_{i}}\frac{1}{1-\mu_{i}}=\frac{f_{i}\left(i\right)}{\mu_{i}\left(1-\mu_{i}\right)}\\
Var\left[C_{i}\right]&=&\frac{Var\left[L_{i}^{*}\right]}{\mu_{i}^{2}\left(1-\mu_{i}\right)^{2}}.
\end{eqnarray*}

Por tanto se tienen las siguientes igualdades


\begin{eqnarray*}
\esp\left[S_{i}\right]&=&\mu_{i}\esp\left[C_{i}\right],\\
\esp\left[I_{i}\right]&=&\left(1-\mu_{i}\right)\esp\left[C_{i}\right]\\
\end{eqnarray*}

Def\'inanse los puntos de regenaraci\'on  en el proceso $\left[L_{1}\left(t\right),L_{2}\left(t\right),\ldots,L_{N}\left(t\right)\right]$. Los puntos cuando la cola $i$ es visitada y todos los $L_{j}\left(\tau_{i}\left(m\right)\right)=0$ para $i=1,2$  son puntos de regeneraci\'on. Se llama ciclo regenerativo al intervalo entre dos puntos regenerativos sucesivos.

Sea $M_{i}$  el n\'umero de ciclos de visita en un ciclo regenerativo, y sea $C_{i}^{(m)}$, para $m=1,2,\ldots,M_{i}$ la duraci\'on del $m$-\'esimo ciclo de visita en un ciclo regenerativo. Se define el ciclo del tiempo de visita promedio $\esp\left[C_{i}\right]$ como

\begin{eqnarray*}
\esp\left[C_{i}\right]&=&\frac{\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]}{\esp\left[M_{i}\right]}
\end{eqnarray*}


En Stid72 y Heym82 se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}



\begin{Note}\label{Cita1.Stidham}
En Stidham\cite{Stidham} y Heyman  se muestra que una condici\'on suficiente para que el proceso regenerativo 
estacionario sea un procesoo estacionario es que el valor esperado del tiempo del ciclo regenerativo sea finito:

\begin{eqnarray*}
\esp\left[\sum_{m=1}^{M_{i}}C_{i}^{(m)}\right]<\infty.
\end{eqnarray*}

como cada $C_{i}^{(m)}$ contiene intervalos de r\'eplica positivos, se tiene que $\esp\left[M_{i}\right]<\infty$, adem\'as, como $M_{i}>0$, se tiene que la condici\'on anterior es equivalente a tener que 

\begin{eqnarray*}
\esp\left[C_{i}\right]<\infty,
\end{eqnarray*}
por lo tanto una condici\'on suficiente para la existencia del proceso regenerativo est\'a dada por

\begin{eqnarray*}
\sum_{k=1}^{N}\mu_{k}<1.
\end{eqnarray*}
\end{Note}





\input{bibliografia}

\printindex
\end{document}
